[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brendan’s Website",
    "section": "",
    "text": "Hello.\nWelcome to my domain."
  },
  {
    "objectID": "library/about.html",
    "href": "library/about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "library/posts/welcome/index.html",
    "href": "library/posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome! fix\n\n\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "library/posts/post-with-code/index.html",
    "href": "library/posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "library/index.html",
    "href": "library/index.html",
    "title": "Library",
    "section": "",
    "text": "Welcome to my library.\nYou may find books, articles, and curated research documents spanning many topics."
  },
  {
    "objectID": "writes/about.html",
    "href": "writes/about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "writes/posts/welcome/index.html",
    "href": "writes/posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "writes/posts/post-with-code/index.html",
    "href": "writes/posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "writes/index.html",
    "href": "writes/index.html",
    "title": "Writes",
    "section": "",
    "text": "On the Risks of AI\n\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2022\n\n\nBrendan\n\n\n\n\n\n\n  \n\n\n\n\nBlockchain != Privacy\n\n\n\n\n\n\n\n\n\n\n\n\nJul 24, 2022\n\n\nBrendan\n\n\n\n\n\n\n  \n\n\n\n\nMoney in Ancient Rome\n\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2021\n\n\nBrendan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/index.html",
    "href": "reads/index.html",
    "title": "Library",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\nFinance\n\n\nAll things finance\n\n\n\n\nSoftware\n\n\nAll things Sofwtare\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/posts/post-with-code/index.html",
    "href": "reads/posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "reads/posts/welcome/index.html",
    "href": "reads/posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome! fix\n\n\n\n\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "reads/posts/finance/quant-trading/quant-trading.html",
    "href": "reads/posts/finance/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "reads/posts/software/ai/history-of-ai/history-of-ai.html",
    "href": "reads/posts/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "This is a History of AI."
  },
  {
    "objectID": "reads/posts/software/crypto/ethena/ethena.html",
    "href": "reads/posts/software/crypto/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "reads/posts/finance/finance-101/finance-101.html",
    "href": "reads/posts/finance/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "reads/categories/finance/posts/finance-101/finance-101.html",
    "href": "reads/categories/finance/posts/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "reads/categories/software/ai/history-of-ai/history-of-ai.html",
    "href": "reads/categories/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "This is a History of AI."
  },
  {
    "objectID": "reads/categories/software/crypto/ethena/ethena.html",
    "href": "reads/categories/software/crypto/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "reads/categories/finance/posts/quant-trading/quant-trading.html",
    "href": "reads/categories/finance/posts/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "reads/categories/finance/index.html",
    "href": "reads/categories/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "This is a collection of finance-related resources.\n\n\n\n\n\n\n\n\n  \n\n\n\n\nQuant Trading\n\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\n  \n\n\n\n\nFinance 101\n\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/categories/software/software.html",
    "href": "reads/categories/software/software.html",
    "title": "Software",
    "section": "",
    "text": "This is a collection of software-related resources.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/categories/software/index.html",
    "href": "reads/categories/software/index.html",
    "title": "Software",
    "section": "",
    "text": "This is a collection of software-related resources.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/finance/index.html",
    "href": "reads/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "Quant Trading\n\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\n  \n\n\n\n\nFinance 101\n\n\nIntro to Finance\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/finance/posts/quant-trading/quant-trading.html",
    "href": "reads/finance/posts/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "reads/software/index.html",
    "href": "reads/software/index.html",
    "title": "Software",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "reads/software/crypto/ethena/ethena.html",
    "href": "reads/software/crypto/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "reads/software/ai/history-of-ai/history-of-ai.html",
    "href": "reads/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "This is a History of AI."
  },
  {
    "objectID": "reads/finance/posts/finance-101/finance-101.html",
    "href": "reads/finance/posts/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "reads/index.html#recent-library-additions",
    "href": "reads/index.html#recent-library-additions",
    "title": "Library",
    "section": "",
    "text": "software\n\n\ncrypto\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\nIntro to Finance\n\n\n\n\nfinance\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/index.html#browse-by-category",
    "href": "reads/index.html#browse-by-category",
    "title": "Library",
    "section": "Browse by Category",
    "text": "Browse by Category"
  },
  {
    "objectID": "reads/index.html#recent-additions",
    "href": "reads/index.html#recent-additions",
    "title": "Library",
    "section": "",
    "text": "software\n\n\ncrypto\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\nIntro to Finance\n\n\n\n\nfinance\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reads/EXAMPLE/EXAMPLE.html",
    "href": "reads/EXAMPLE/EXAMPLE.html",
    "title": "Example Read",
    "section": "",
    "text": "This is simply an example."
  },
  {
    "objectID": "library/finance/index.html",
    "href": "library/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "library/finance/posts/quant-trading/quant-trading.html",
    "href": "library/finance/posts/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "library/software/ai/history-of-ai/history-of-ai.html",
    "href": "library/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "This is a History of AI."
  },
  {
    "objectID": "library/software/crypto/index.html",
    "href": "library/software/crypto/index.html",
    "title": "Crypto",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "library/EXAMPLE/EXAMPLE.html",
    "href": "library/EXAMPLE/EXAMPLE.html",
    "title": "Example Read",
    "section": "",
    "text": "This is simply an example."
  },
  {
    "objectID": "library/software/crypto/ethena/ethena.html",
    "href": "library/software/crypto/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "library/software/index.html",
    "href": "library/software/index.html",
    "title": "Software",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\nCrypto\n\n\nAll things relevant to the world of crypto\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "library/finance/posts/finance-101/finance-101.html",
    "href": "library/finance/posts/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/topics/finance/index.html",
    "href": "library/topics/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "Quant Trading\n\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\n  \n\n\n\n\nFinance 101\n\n\nIntro to Finance\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nBrendan McCaffrey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "library/topics/finance/posts/quant-trading/quant-trading.html",
    "href": "library/topics/finance/posts/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "library/topics/software/index.html",
    "href": "library/topics/software/index.html",
    "title": "Software",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\nCrypto\n\n\nAll things relevant to the world of crypto\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "library/topics/software/crypto/ethena/ethena.html",
    "href": "library/topics/software/crypto/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "library/topics/software/crypto/index.html",
    "href": "library/topics/software/crypto/index.html",
    "title": "Crypto",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "library/topics/software/ai/history-of-ai/history-of-ai.html",
    "href": "library/topics/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "This is a History of AI."
  },
  {
    "objectID": "library/topics/finance/posts/finance-101/finance-101.html",
    "href": "library/topics/finance/posts/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/finance/finance-101/finance-101.html",
    "href": "library/finance/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/finance/quant-trading/quant-trading.html",
    "href": "library/finance/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "library/crypto/mev/overview.html",
    "href": "library/crypto/mev/overview.html",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay"
  },
  {
    "objectID": "library/crypto/mev/overview.html#videos-talks",
    "href": "library/crypto/mev/overview.html#videos-talks",
    "title": "Overview",
    "section": "Videos & Talks",
    "text": "Videos & Talks\n\nMEV Day\n\nVideo Recap\n\nEncode x Wintermute: MEV with Robert Miller\nStanford MEV Workshop Recording"
  },
  {
    "objectID": "library/crypto/mev/overview.html#protocols-and-implementation-resources",
    "href": "library/crypto/mev/overview.html#protocols-and-implementation-resources",
    "title": "Overview",
    "section": "Protocols, and Implementation Resources",
    "text": "Protocols, and Implementation Resources\nUniswap V3 Book - docs\nAutomated Market Making and Arbitrage Profits in the Presence of Fees - paper\nMEV Capturing AMM - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\nA Framework for Building Searchers - article\nSomeone’s Mega-resource on MEV - notion\nRunning MEV-Relay at Scale - notion\nLatency Arms Race - post\nFBAs (frequent batch auctions) are a nerd snipe - tweet\nJaredFromSubway.eth’s Access Lists - etherscan\nManifold Freelay"
  },
  {
    "objectID": "library/crypto/blockchain-protocols/ethena/ethena.html",
    "href": "library/crypto/blockchain-protocols/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "library/crypto/mev/overview.html#early-research",
    "href": "library/crypto/mev/overview.html#early-research",
    "title": "Overview",
    "section": "Early Research",
    "text": "Early Research\n\nEnter the Hydra\nThe Cost of Decentralization in 0x and EtherDelta\nFlash Boys 2.0\nOrder-Fairness for Byzantine Consensus\nThemis: Fast, Strong Order-Fairness in Byzantine Consensus\nMEV… Wat Do?\nEthereum is a Dark Forest\nFlashbots: Frontrunning the MEV Crisis"
  },
  {
    "objectID": "library/crypto/mev/overview.html#dashboards",
    "href": "library/crypto/mev/overview.html#dashboards",
    "title": "Overview",
    "section": "Dashboards",
    "text": "Dashboards\n\nZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard"
  },
  {
    "objectID": "library/crypto/mev/overview.html#research",
    "href": "library/crypto/mev/overview.html#research",
    "title": "Overview",
    "section": "Research",
    "text": "Research\n\nEarly Research\n\nEnter the Hydra\nThe Cost of Decentralization in 0x and EtherDelta\nFlash Boys 2.0\nOrder-Fairness for Byzantine Consensus\nThemis: Fast, Strong Order-Fairness in Byzantine Consensus\nMEV… Wat Do?\nEthereum is a Dark Forest\nFlashbots: Frontrunning the MEV Crisis\n\n\n\nGeneral\n\nStudying Flash Loan Attacks | paper\nMEV by Galaxy Digital | Blog Pt 2\nModular MEV Write-up\nPerformant routing and latency benchmarking for Ethereum RPC and Relay Service Providers\nHigh Granularity Cex Data | tardis.dev\nMEV in Fixed Price Auctions | paper | tweet\nMEV Boost Capella Upgrades | article\nFrontier Research | website\nSo you want to run a builder?\nHow to Fix Ethereum’s MEV Problem\nMEV in ETH2 - An Early Exploration\nImproving PoS Economic Security via MEV Redistribution\nTowards a Theory of MEV I\nFlashbots Research Repository\n\n\n\nMEV-Boost / Proposer-Builder Separation\n\nProposer Boost Considerations\nMEV-Boost Plan\n\n\n\nVideos & Talks\n\nMEV Day\n\nVideo Recap\n\nEncode x Wintermute: MEV with Robert Miller\nStanford MEV Workshop Recording\nMEVconomics Playlist | youtube\nStanford Blockchain Conference (SBC’23)\nRecordings: Day 1 | Day 2 | Day 3\nMEV Workshop at SBC’23 | Recording\n\n\n\nProtocols, and Implementation Resources\nUniswap V3 Book - docs\nAutomated Market Making and Arbitrage Profits in the Presence of Fees - paper\nMEV Capturing AMM - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\nA Framework for Building Searchers - article\nSomeone’s Mega-resource on MEV - notion\nRunning MEV-Relay at Scale - notion\nLatency Arms Race - post\nFBAs (frequent batch auctions) are a nerd snipe - tweet\nJaredFromSubway.eth’s Access Lists - etherscan"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum.html",
    "href": "library/crypto/blockchains/evm/ethereum.html",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum.html#general",
    "href": "library/crypto/blockchains/evm/ethereum.html#general",
    "title": "Ethereum",
    "section": "General",
    "text": "General\nEthereum Inactivity Leak - documentation\nIntent Based Architectures and Their Risks - article\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses - article\nAccount Abstraction Using Alt Mempool - article\nEIP-1153: Transient Storage - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\n2FA ZK Rollups using SGX - article\nClient Bootnode Concerns - article\nCollecting Signatures for Faster Finality - article\nProof of Solvency - article\nState of Testnets - tweet\nEth Withdrawals FAQ - website\n100 Days After the Merge - see section “Looking ahead to Shanghai” - article\nWithdrawals after Shanghai - blog\nExecution Layer Meeting - video\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs - article\nEthereum Data Structures - paper\nEth2Book: A lot of Good Info on Ethereum - documentation\nVitalik: An Incomplete Guide to Rollups - article\nA Rollup-Centric Ethereum Roadmap - article\nOfficial Merge Announcement - article\nValidator Withdrawal design - article\nVitalik: the roads not taken - article"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum.html#consensus",
    "href": "library/crypto/blockchains/evm/ethereum.html#consensus",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum.html#consensus-attacks",
    "href": "library/crypto/blockchains/evm/ethereum.html#consensus-attacks",
    "title": "Ethereum",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum.html#proposer-builder-separation",
    "href": "library/crypto/blockchains/evm/ethereum.html#proposer-builder-separation",
    "title": "Ethereum",
    "section": "Proposer Builder Separation",
    "text": "Proposer Builder Separation\n\nMEV-Boost Plan\nProposer Boost Considerations\nMEV-Boost in a Nutshell\nPBS Censorship Resistance\nState of research: increasing censorship resistance of transactions under PBS\nPBS Censorship-Resistance Alternatives\nCurrent crList Proposal"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum.html#sharding",
    "href": "library/crypto/blockchains/evm/ethereum.html#sharding",
    "title": "Ethereum",
    "section": "Sharding",
    "text": "Sharding\n\nDanksharding\n\nPolynya on Danksharding\n\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding"
  },
  {
    "objectID": "library/crypto/blockchains/index.html",
    "href": "library/crypto/blockchains/index.html",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/crypto/blockchains/index.html#early-contributions-papers",
    "href": "library/crypto/blockchains/index.html#early-contributions-papers",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/crypto/blockchains/index.html#whitepapers",
    "href": "library/crypto/blockchains/index.html#whitepapers",
    "title": "Blockchains",
    "section": "Whitepapers",
    "text": "Whitepapers\n\nBitcoin\nEthereum: A Next-Generation Smart Contract and Decentralized Application Platform\nEthereum: A Secure Decentralized Generalized Transaction Ledger\nZerocash: Decentralized Anonymous Payments from Bitcoin\nCosmos: Internet of Blockchains\nSolana: A new Architecture for a High Performance Blockchain\nCardano\nAlgorand: Scaling Byzantine Agreements for Cryptocurrencies\nAvalanche Platform\nThe Spacemesh Protocol"
  },
  {
    "objectID": "library/crypto/blockchains/evm/layer-2/index.html",
    "href": "library/crypto/blockchains/evm/layer-2/index.html",
    "title": "Layer 2 Rollups",
    "section": "",
    "text": "Vitalik: An Incomplete Guide to Rollups\nA Rollup-Centric Ethereum Roadmap\nArbitrum: Scalable, Private Smart Contracts\nVitalik: An Incomplete Guide to Rollups"
  },
  {
    "objectID": "library/crypto/blockchains/evm/index.html",
    "href": "library/crypto/blockchains/evm/index.html",
    "title": "EVM",
    "section": "",
    "text": "Ethereum Data Structures"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum/index.html",
    "href": "library/crypto/blockchains/evm/ethereum/index.html",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum/index.html#consensus",
    "href": "library/crypto/blockchains/evm/ethereum/index.html#consensus",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum/index.html#consensus-attacks",
    "href": "library/crypto/blockchains/evm/ethereum/index.html#consensus-attacks",
    "title": "Ethereum",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum/index.html#proposer-builder-separation",
    "href": "library/crypto/blockchains/evm/ethereum/index.html#proposer-builder-separation",
    "title": "Ethereum",
    "section": "Proposer Builder Separation",
    "text": "Proposer Builder Separation\n\nMEV-Boost Plan\nProposer Boost Considerations\nMEV-Boost in a Nutshell\nPBS Censorship Resistance\nState of research: increasing censorship resistance of transactions under PBS\nPBS Censorship-Resistance Alternatives\nCurrent crList Proposal"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum/index.html#sharding",
    "href": "library/crypto/blockchains/evm/ethereum/index.html#sharding",
    "title": "Ethereum",
    "section": "Sharding",
    "text": "Sharding\n\nDanksharding\nPolynya on Danksharding\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding"
  },
  {
    "objectID": "library/crypto/blockchains/evm/ethereum/index.html#general",
    "href": "library/crypto/blockchains/evm/ethereum/index.html#general",
    "title": "Ethereum",
    "section": "General",
    "text": "General\nEthereum Inactivity Leak - documentation\nIntent Based Architectures and Their Risks - article\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses - article\nAccount Abstraction Using Alt Mempool - article\nEIP-1153: Transient Storage - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\n2FA ZK Rollups using SGX - article\nClient Bootnode Concerns - article\nCollecting Signatures for Faster Finality - article\nProof of Solvency - article\nState of Testnets - tweet\nEth Withdrawals FAQ - website\n100 Days After the Merge - see section “Looking ahead to Shanghai” - article\nWithdrawals after Shanghai - blog\nExecution Layer Meeting - video\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs - article\nEthereum Data Structures - paper\nEth2Book: A lot of Good Info on Ethereum - documentation\nVitalik: An Incomplete Guide to Rollups - article\nA Rollup-Centric Ethereum Roadmap - article\nOfficial Merge Announcement - article\nValidator Withdrawal design - article\nVitalik: the roads not taken - article"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/index.html",
    "href": "library/crypto/blockchains/bitcoin/index.html",
    "title": "Bitcoin",
    "section": "",
    "text": "Bitcoin: A Peer to Peer Electronic Cash System\nBitcoin Lightning Network\nSegregated Witness Benefits\nVulnerability | tweet\n\nExplorer | btcscan"
  },
  {
    "objectID": "library/crypto/blockchains/solana/index.html",
    "href": "library/crypto/blockchains/solana/index.html",
    "title": "Solana",
    "section": "",
    "text": "How will Solana Improve its Stability?\n\n\nFee Markets\n\nPriority Fees Github Issue\nDune Query: % of Sol Txs with Fee above base\n\n\n\nThe Solana Validator\n\nFiredancer: A New Client by Jump\nValidator Economics on Solana"
  },
  {
    "objectID": "library/crypto/blockchains/consensus.html",
    "href": "library/crypto/blockchains/consensus.html",
    "title": "Consensus",
    "section": "",
    "text": "Tendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical"
  },
  {
    "objectID": "library/crypto/blockchains/consensus.html#whitepapers",
    "href": "library/crypto/blockchains/consensus.html#whitepapers",
    "title": "Consensus",
    "section": "",
    "text": "Tendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical"
  },
  {
    "objectID": "library/crypto/blockchains/consensus.html#research",
    "href": "library/crypto/blockchains/consensus.html#research",
    "title": "Consensus",
    "section": "Research",
    "text": "Research\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands\n\nHow to run a Bitcoin full node. I have decided to run a node 5 minutes ago, so I am making this tutorial as I go. Let’s see how long it takes."
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html#resources",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html#resources",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands\n\nHow to run a Bitcoin full node. I have decided to run a node 5 minutes ago, so I am making this tutorial as I go. Let’s see how long it takes."
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html#short-version",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html#short-version",
    "title": "Running Bitcoin Core",
    "section": "Short Version",
    "text": "Short Version\n# download software\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n# extract contents\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\n# install extracted contents to local bin\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*\n# check version\nbitcoind --version\n# start the software\nbitcoind -daemon -txindex\n# check status\nbitcoin-cli -getinfo\n# check block count\nbitcoin-cli getblockcount\n# stop the software\nbitcoin-cli stop"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 1: Download Bitcoin Core",
    "text": "Step 1: Download Bitcoin Core\nAs of today (Feb 11, 2023), the latest version of Bitcoin Core is 24.0.1. You can find the download links here\n\nCopy the link address of the version you need - I am running Linux Ubuntu so I will use the x86_64-linux-gnu.tar.gz\n\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n\nExtract the contents\n\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\nThis downloads the contents into /usr/local/ directory"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "title": "Running Bitcoin Core",
    "section": "Step 2: Install Bitcoin from Downloaded Contents",
    "text": "Step 2: Install Bitcoin from Downloaded Contents\nRun this command (idk the details who cares)\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 3: Run Bitcoin Core",
    "text": "Step 3: Run Bitcoin Core\nbitcoind -daemon\nYou can check the progress of syncing with bitcoin-cli -getinfo\nThis should produce something that looks like this\nubuntu@REDACTED:~$ bitcoin-cli -getinfo\nChain: main\nBlocks: 235213\nHeaders: 775994\nVerification progress: ▒░░░░░░░░░░░░░░░░░░░░ 2.1719%\nDifficulty: 10076292.88341872\n\nNetwork: in 0, out 10, total 10\nVersion: 240001\nTime offset (s): -1\nProxies: n/a\nMin tx relay fee rate (BTC/kvB): 0.00001000\nCompare “blocks” with the latest block on the chain."
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/btc-core.html#done",
    "href": "library/crypto/blockchains/bitcoin/btc-core.html#done",
    "title": "Running Bitcoin Core",
    "section": "Done!",
    "text": "Done!\nAll in all, it took me 34 minutes to figure this out. Easier than running Go Ethereum, and far easier than running Solana core. Incredibly impressive!"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/versions.html",
    "href": "library/crypto/blockchains/bitcoin/versions.html",
    "title": "The Tech",
    "section": "",
    "text": "Bitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/versions.html#transaction-versions",
    "href": "library/crypto/blockchains/bitcoin/versions.html#transaction-versions",
    "title": "The Tech",
    "section": "",
    "text": "Bitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/crypto/blockchains/consensus.html#events",
    "href": "library/crypto/blockchains/consensus.html#events",
    "title": "Consensus",
    "section": "Events",
    "text": "Events\nMay 12, 2023: Ethereum Consensus Issues\n\ntweet one\ntweet two"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html",
    "title": "Ordinals",
    "section": "",
    "text": "How to Split Ordinals Mixed in a Single UTXO - article\nSplitting Bitcoin from Inscriptions on Ordinals Wallet - article"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html#tech-stuff",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html#tech-stuff",
    "title": "Ordinals",
    "section": "Tech Stuff",
    "text": "Tech Stuff\n# create ordinal wallet\nord wallet create\n\n# receive sats\nord wallet receive\n\n# create inscription\nord wallet inscribe --fee-rate 22 &lt;FILE&gt;\n\nIssues\nTransport error upon inscription attempt here\nInscriptions taking too long here\nIndexing not working here\nHow much does an inscription cost? - calculator"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html#guides",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html#guides",
    "title": "Ordinals",
    "section": "Guides",
    "text": "Guides\n\nHow to create\nHow to buy\nMinting Ordinals"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html#btc-naming-service",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html#btc-naming-service",
    "title": "Ordinals",
    "section": "BTC Naming Service",
    "text": "BTC Naming Service\nCasey Rodarmor’s Thoughts: 26:00 min mark - here\n\nLook up top level domain (com)\nFind the output its in, and get address of the output\nGet authenticated encrypted channel with the person that owns that\nAsk “who has ‘myname.com’?” and they send you signed message of the pubkey, and then you get IP address. But no good names exist yet.\n\n\nThings I’ve Learned on the Ordinals Journey\nBitcoin has several address formats.\n\nLegacy Addresses\nScript Addresses\nSegwit Addresses\nTaproot Addresses\n\nOrdinals uses Taproot Addresses, which result from a recent upgrade aimed to introduce more reobust security, privacy, and scalability."
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html#other-stuff",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html#other-stuff",
    "title": "Ordinals",
    "section": "Other Stuff",
    "text": "Other Stuff\nWhat is it?\n\nanswered here\n\nResources\n\nHandbook\nGithub\nBIP\nMainnet Explorer\nTestnet (Signet) Explorer\nGuide\nNo Code Mint Platform\n\nCool Info\nOn August 21st, 2012, Charlie Lee posted a proposal to add proof-of-stake to Bitcoin to the Bitcoin Talk forum. This wasn’t an asset scheme, but did use the ordinal algorithm, and was implemented but never deployed.\nOn October 8th, 2012, jl2012 posted a scheme to the the same forum which uses decimal notation and has all the important properties of ordinals. The scheme was discussed but never implemented.\nGud Video\n\nyoutube\ninterview\n\nMultimint - video"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html#mint-an-nft",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html#mint-an-nft",
    "title": "Ordinals",
    "section": "Mint an NFT",
    "text": "Mint an NFT\n# inscribe\nord wallet inscribe --fee-rate 20 ABSOLUTE_FILE_PATH"
  },
  {
    "objectID": "library/crypto/blockchains/bitcoin/ordinals.html#test",
    "href": "library/crypto/blockchains/bitcoin/ordinals.html#test",
    "title": "Ordinals",
    "section": "TEST",
    "text": "TEST\nI inscribed an image of Logan Tobias onto the Bitcoin blockchain.\n$ ord wallet inscribe --fee-rate 20 /home/ubuntu/server-share/logan_resized.jpeg \n{\n  \"commit\": \"93f5630a6f6eb49235fb25878df06563f509ff5d5d89da6a4092af5d68eb4afd\",\n  \"inscription\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8i0\",\n  \"reveal\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8\",\n  \"fees\": 282600\n}\nSat: 465805240538644\n\nOrdinal Project\nThis is a short guide on how to mint multiple ordinals quickly.\n\nCreate a Sparrow wallet to generate multiple UTXOs.\nCalculate cost per ordinal.\n\n\ncalculator\nmempool Add 600 (dust limit) + 10,000 (ordinal fee) to sats amount\n\nWe have: 132,000 sats per ordinal + 600 + 10,000 = 142,600 sats per ordinal"
  },
  {
    "objectID": "library/crypto/cex/index.html",
    "href": "library/crypto/cex/index.html",
    "title": "CEXs",
    "section": "",
    "text": "SEC Files 13 Charges Against Binance Entities and Founder Changpeng Zhao - release\nBinance Commingled Customer Funds and Company Revenue - article\nBinance doesn’t have Enough BCH to Process Withdrawals - tweet"
  },
  {
    "objectID": "library/crypto/cex/index.html#binance",
    "href": "library/crypto/cex/index.html#binance",
    "title": "CEXs",
    "section": "",
    "text": "SEC Files 13 Charges Against Binance Entities and Founder Changpeng Zhao - release\nBinance Commingled Customer Funds and Company Revenue - article\nBinance doesn’t have Enough BCH to Process Withdrawals - tweet"
  },
  {
    "objectID": "library/crypto/apps/ethena/ethena.html",
    "href": "library/crypto/apps/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "library/crypto/blockchains/index.html#recent-general",
    "href": "library/crypto/blockchains/index.html#recent-general",
    "title": "Blockchains",
    "section": "Recent, General",
    "text": "Recent, General\n\nThe Tie: Solving the Blockchain Trilemma\nEndgame: Proof of Governance"
  },
  {
    "objectID": "library/crypto/blockchains/consensus.html#consensus-attacks",
    "href": "library/crypto/blockchains/consensus.html#consensus-attacks",
    "title": "Consensus",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/crypto/blockchains/solana/events/mango.html",
    "href": "library/crypto/blockchains/solana/events/mango.html",
    "title": "Mango Rekt",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/crypto/blockchains/solana/events/mango.html#overview",
    "href": "library/crypto/blockchains/solana/events/mango.html#overview",
    "title": "Mango Rekt",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/crypto/blockchains/solana/events/mango.html#how-it-worked",
    "href": "library/crypto/blockchains/solana/events/mango.html#how-it-worked",
    "title": "Mango Rekt",
    "section": "How it worked",
    "text": "How it worked\nAttacker had two accounts, let’s call them account A and account B.\n\nAttacker funds account A with $5 million of USDC, to be used as collateral for on-chain positions.\nAttacker then offered out (sold short) ~483 million MNGO tokens, trading at $0.038 at the time.\nAttacker then funds account B with $5 million USDC, and purchases those ~438 million MNGO at $0.0382\nAttacker then purchases MNGO on the Spot market, artificially increasing its price. The price of mango reached $0.91 (a 24x increase).\nAt this new inflated price, account B was in the money for ~ $423 million. He used this account value to take out a loan of $116 million consisting of several tokens.\nAfter the attack, the MNGO/USD spot market then traded down to $0.02, which put account A in the money. However, Mango protocol was effectively drained of all liquidity, so account A could not be paid out."
  },
  {
    "objectID": "library/crypto/blockchains/solana/events/mango.html#summary",
    "href": "library/crypto/blockchains/solana/events/mango.html#summary",
    "title": "Mango Rekt",
    "section": "Summary",
    "text": "Summary\nMango Markets were designed to give loans at a certain collateralization ratio (e.g. 400%), but they used the spot market as an oracle for “fair price” of the token. Thus, tokens with low liquidity could be easily manipulated such that the protocol believes “fair price” is multiples above what anyone would purchase the token at in free markets."
  },
  {
    "objectID": "library/crypto/blockchains/solana/events/mango.html#future-mitigation",
    "href": "library/crypto/blockchains/solana/events/mango.html#future-mitigation",
    "title": "Mango Rekt",
    "section": "Future Mitigation",
    "text": "Future Mitigation\nMitigating this type of attack is as simple as fixing the Oracle mechanism. For example, one could use a 24hr rolling average price to determine “fair value” for lending, which would make the market manipulator’s attack much more difficult (must pump price for 24 hour rather than a few seconds)."
  },
  {
    "objectID": "library/crypto/blockchains/solana/events/mango.html#credits-commentary",
    "href": "library/crypto/blockchains/solana/events/mango.html#credits-commentary",
    "title": "Mango Rekt",
    "section": "Credits & Commentary",
    "text": "Credits & Commentary\n\nNotice of Exploit by Otter Security\nEarly Analysis of What Happened\nSam Bankman Freid on How to Protect from this Attack\nAttacker Admitting his Involvement"
  },
  {
    "objectID": "library/crypto/apps/hyperliquid/index.html",
    "href": "library/crypto/apps/hyperliquid/index.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/crypto/apps/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "href": "library/crypto/apps/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/crypto/apps/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "href": "library/crypto/apps/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/physics/superconductor/lk99.html",
    "href": "library/physics/superconductor/lk99.html",
    "title": "LK-99",
    "section": "",
    "text": "Original paper(s) is(are) released twice, the first time (suspected to rush to beat the second) with only 3 authors, making the team eligible for a noble prize.\n\nThe First Room-Temperature Ambient-Pressure Superconductor\n\nPeople rush to replicate the study/results.\n\nFirst-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n\nA theoretical explanation for LK-99 is released on July 31, 2023, by Sinead Griffin out of Berkeley.\n\nOrigin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\nDouglas Natelson published a blog post expressing a pessemistic view on the whole debacle.\nA (failed?) replication attempt out of Beijing; shows semiconductor behavior, not super\n\nSemiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)"
  },
  {
    "objectID": "library/physics/superconductor/lk99.html#tldr-as-of-august-1-2023",
    "href": "library/physics/superconductor/lk99.html#tldr-as-of-august-1-2023",
    "title": "LK-99",
    "section": "",
    "text": "Since 1999, a tiny group of Korean scientists, working in obscurity and in their off-time, pursue the dying wishes of their materials professor who has his own theory about room temperature and pressure superconductors, a century-defining material, the holy grail of materials science and an instant Nobel prize.\nA week ago, one of them went rogue and published a paper describing how to produce their substance, LK-99, which may or not be this holy grail material. It requires no exotic materials or equipment to reproduce, but the paper omits a lot of detail about the specifics of the synthesis.\nThey accompany it with pictures and a video. There are mistakes in the paper, but they authors say they are trivial, will be fixed, and all of them stand by their claims, even as they feud with each other.\nThis kicks off a world-wide race to deboonk or reproduce. US, Chinese, Japanese, and Indian labs all drop what they’re doing and give LK-99 a shot. One guy at a startup in California tries on his own as well, and 10,000 people tune in to watch a Twitch stream of a webcam pointed at a kiln. The process takes a few days.\nA Russian anime catgirl joins the fracas, ruthlessly making fun of both the original Korean scientists for their bizarre methodology, and of Western/Chinese labs for simply following the steps without understanding what they do. She applies the Soviet technique of ignoring the steps outlined and instead trying to figure out what they actually do, and comes up with her own procedure using shit just laying around her apartment.\nShe produces a small grain of the floaty rock, takes a picture but refuses to take a video, and mercilessly ridicules everybody who keeps asking her for more proofs because it was so easy to do, they should just be doing it themselves if they weren’t mediocre westoids. She’s catty and great."
  },
  {
    "objectID": "library/physics/superconductor/lk99.html#original-paper",
    "href": "library/physics/superconductor/lk99.html#original-paper",
    "title": "LK-99",
    "section": "Original Paper",
    "text": "Original Paper\nThe First Room-Tempurature Ambient-Pressure Superconductor\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\nA theoretical explanation for LK-99 is released on August 31, 2023, by Sinead Griffin out of Berkeley."
  },
  {
    "objectID": "library/physics/superconductor/lk99.html#discussion",
    "href": "library/physics/superconductor/lk99.html#discussion",
    "title": "LK-99",
    "section": "Discussion",
    "text": "Discussion\nDouglas Natelson published a blog post expressing a pessemistic view on the whole debacle."
  },
  {
    "objectID": "library/physics/superconductor/lk99.html#sequence-of-events",
    "href": "library/physics/superconductor/lk99.html#sequence-of-events",
    "title": "LK-99",
    "section": "Sequence of Events",
    "text": "Sequence of Events"
  },
  {
    "objectID": "library/physics/superconductor/lk99.html#overview",
    "href": "library/physics/superconductor/lk99.html#overview",
    "title": "LK-99",
    "section": "",
    "text": "Original paper(s) is(are) released twice, the first time (suspected to rush to beat the second) with only 3 authors, making the team eligible for a noble prize.\n\nThe First Room-Temperature Ambient-Pressure Superconductor\n\nPeople rush to replicate the study/results.\n\nFirst-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n\nA theoretical explanation for LK-99 is released on July 31, 2023, by Sinead Griffin out of Berkeley.\n\nOrigin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\nDouglas Natelson published a blog post expressing a pessemistic view on the whole debacle.\nA (failed?) replication attempt out of Beijing; shows semiconductor behavior, not super\n\nSemiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)"
  },
  {
    "objectID": "library/physics/superconductor/lk99.html#tldr-on-the-drama-as-of-august-1-2023",
    "href": "library/physics/superconductor/lk99.html#tldr-on-the-drama-as-of-august-1-2023",
    "title": "LK-99",
    "section": "TLDR on the drama as of August 1, 2023",
    "text": "TLDR on the drama as of August 1, 2023\nSince 1999, a tiny group of Korean scientists, working in obscurity and in their off-time, pursue the dying wishes of their materials professor who has his own theory about room temperature and pressure superconductors, a century-defining material, the holy grail of materials science and an instant Nobel prize.\nA week ago, one of them went rogue and published a paper describing how to produce their substance, LK-99, which may or not be this holy grail material. It requires no exotic materials or equipment to reproduce, but the paper omits a lot of detail about the specifics of the synthesis.\nThey accompany it with pictures and a video. There are mistakes in the paper, but they authors say they are trivial, will be fixed, and all of them stand by their claims, even as they feud with each other.\nThis kicks off a world-wide race to deboonk or reproduce. US, Chinese, Japanese, and Indian labs all drop what they’re doing and give LK-99 a shot. One guy at a startup in California tries on his own as well, and 10,000 people tune in to watch a Twitch stream of a webcam pointed at a kiln. The process takes a few days.\nA Russian anime catgirl joins the fracas, ruthlessly making fun of both the original Korean scientists for their bizarre methodology, and of Western/Chinese labs for simply following the steps without understanding what they do. She applies the Soviet technique of ignoring the steps outlined and instead trying to figure out what they actually do, and comes up with her own procedure using shit just laying around her apartment.\nShe produces a small grain of the floaty rock, takes a picture but refuses to take a video, and mercilessly ridicules everybody who keeps asking her for more proofs because it was so easy to do, they should just be doing it themselves if they weren’t mediocre westoids. She’s catty and great."
  },
  {
    "objectID": "library/physics/superconductor/index.html",
    "href": "library/physics/superconductor/index.html",
    "title": "Superconductors",
    "section": "",
    "text": "Superconductivity is a macro-quantum state wherein a material displays (effectively) zero resistivity. (SUMMARIZE PT 1 1:09)\nA phenomenal overview of the phenomenon, from first principles, can be found on youtube.\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale\n\nPart 1 of 2\nPart 2 of 2\n\nBelow is practically nothing more than a summary of these lectures, plus some wikipedia content."
  },
  {
    "objectID": "library/physics/quantum/compute/index.html",
    "href": "library/physics/quantum/compute/index.html",
    "title": "Computation",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization"
  },
  {
    "objectID": "library/physics/quantum/compute/index.html#resources",
    "href": "library/physics/quantum/compute/index.html#resources",
    "title": "Computation",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization"
  },
  {
    "objectID": "library/physics/quantum/field-theory/effective-or-fundamental.html",
    "href": "library/physics/quantum/field-theory/effective-or-fundamental.html",
    "title": "Fundamental?",
    "section": "",
    "text": "The Quantum Theory of Fields: Effective or Fundamental?\n\nvideo\ncorresponding article\nQuantum Field Theory was born just pertaining to the electromagnetic field.\nWhen expanding this theory, it seemed it couldn’t be trusted at high energies. (Decline)\nLate 1940s, there was a new optimizing with the invention of a relatavistic perturbation theory, where the infinities could be absorbed into a redefinition of parameters like mass and charge of the electron. People thought this was sweeping problems under the rug, but it also may have been a way of selecting good theories (renormalizable theories).\nFor example, theere’s nothing in the symmetries of quantum electrodynamics which rules out putting a term in the field equations (or Lagrangian), which could make the magnetic moment of the electron anything you want. This would make the mass of the electron -1, which means the theory is not renormalizable, and thus shows invalid.\nLate 1960s and early 70s, the standard model came to fruition - this was the renaissance of Quantum Field theory. But there were still doubts whether this was a fundamental theory or an effective one.\nQuantum Field Theory & Einsteinian Physics may be low energy approximations of a more fundamental theory."
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/lk99.html",
    "href": "library/physics/electromagnetism/superconductor/lk99.html",
    "title": "LK-99",
    "section": "",
    "text": "Superconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise."
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/lk99.html#overview",
    "href": "library/physics/electromagnetism/superconductor/lk99.html#overview",
    "title": "LK-99",
    "section": "",
    "text": "July 22:\n\nThe First Room-Temperature Ambient-Pressure Superconductor\nOriginal paper(s) is(are) released twice, the first time (suspected to rush to beat the second) with only 3 authors, making the team eligible for a noble prize.\n\nJuly 26:\n\nI predict the superconductor hype (“we are so fucking back”) is all noise.\n\nJuly 27:\n\nDouglas Natelson publishes a blog post expressing a pessemistic view on the whole debacle.\nCondensed Matter Theory Center deconstructs “the non-experimental parts of the Korean room temp SC claims.”\n\nHype ensues, and magnifies, as people rush to replicate the study/results.\nJuly 29:\n\nFirst-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\n\nJuly 31:\n\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n\nA (failed?) replication attempt out of Beijing; shows semiconductor behavior, not super\n\nSemiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)\n\nAugust 4:\nA theoretical explanation for LK-99 is released on July 31, 2023, by Sinead Griffin out of Berkeley.\n\nOrigin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\nAugust 6:\nGroup claims/proves LK-99 is a ferromagnet (NOT a superconductor)\n\nFerromagnetic half levitation of LK-99-like synthetic samples"
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/lk99.html#tldr-on-the-drama-as-of-august-1-2023",
    "href": "library/physics/electromagnetism/superconductor/lk99.html#tldr-on-the-drama-as-of-august-1-2023",
    "title": "LK-99",
    "section": "TLDR on the drama as of August 1, 2023",
    "text": "TLDR on the drama as of August 1, 2023\nSince 1999, a tiny group of Korean scientists, working in obscurity and in their off-time, pursue the dying wishes of their materials professor who has his own theory about room temperature and pressure superconductors, a century-defining material, the holy grail of materials science and an instant Nobel prize.\nA week ago, one of them went rogue and published a paper describing how to produce their substance, LK-99, which may or not be this holy grail material. It requires no exotic materials or equipment to reproduce, but the paper omits a lot of detail about the specifics of the synthesis.\nThey accompany it with pictures and a video. There are mistakes in the paper, but they authors say they are trivial, will be fixed, and all of them stand by their claims, even as they feud with each other.\nThis kicks off a world-wide race to deboonk or reproduce. US, Chinese, Japanese, and Indian labs all drop what they’re doing and give LK-99 a shot. One guy at a startup in California tries on his own as well, and 10,000 people tune in to watch a Twitch stream of a webcam pointed at a kiln. The process takes a few days.\nA Russian anime catgirl joins the fracas, ruthlessly making fun of both the original Korean scientists for their bizarre methodology, and of Western/Chinese labs for simply following the steps without understanding what they do. She applies the Soviet technique of ignoring the steps outlined and instead trying to figure out what they actually do, and comes up with her own procedure using shit just laying around her apartment.\nShe produces a small grain of the floaty rock, takes a picture but refuses to take a video, and mercilessly ridicules everybody who keeps asking her for more proofs because it was so easy to do, they should just be doing it themselves if they weren’t mediocre westoids. She’s catty and great."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html",
    "href": "library/physics/government/darpa-fellows.html",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#allegra-a.-beal-cohen",
    "href": "library/physics/government/darpa-fellows.html#allegra-a.-beal-cohen",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#rebecca-chmiel",
    "href": "library/physics/government/darpa-fellows.html#rebecca-chmiel",
    "title": "DARPA Fellows",
    "section": "Rebecca Chmiel",
    "text": "Rebecca Chmiel\nDr. Rebecca Chmiel joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. She received her Bachelor of Arts in chemistry and environmental studies from Colby College and her doctorate from the Massachusetts Institute of Technology and the Woods Hole Oceanographic Institution in marine biogeochemistry, and her research focused on the interactions between trace metal nutrients and marine phytoplankton. She has participated in four ocean research expeditions totaling over seven months at sea, and received the Antarctica Service Medal as part of her oceanographic fieldwork."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#alex-place",
    "href": "library/physics/government/darpa-fellows.html#alex-place",
    "title": "DARPA Fellows",
    "section": "Alex Place",
    "text": "Alex Place\nDr. Alex Place joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. He received his Bachelor of Science in physics from the California Institute of Technology and his doctorate in electrical and computer engineering and materials science from Princeton University. His dissertation focused on improving the lifetimes of superconducting qubits, the building block of many industrial quantum computing efforts. He has also spent time developing nanoelectromechanical systems, novel solar cell designs, and medical devices."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#lt-krishnan-rajagopalan-usn",
    "href": "library/physics/government/darpa-fellows.html#lt-krishnan-rajagopalan-usn",
    "title": "DARPA Fellows",
    "section": "LT Krishnan Rajagopalan, USN",
    "text": "LT Krishnan Rajagopalan, USN\nLt. Krishnan (Krish) Rajagopalan joined DARPA in March 2023 as part of the first cohort of DARPA Innovation Fellows. As a Navy Explosive Ordnance Disposal (EOD) Officer, he has led units of unmanned underwater vehicle operators and EOD divers tasked with countering explosive hazards underwater. He also served as a requirements officer on the staff of the Chief of Naval Operations and, most recently, as the operations officer at Expeditionary Exploitation Unit ONE (EXU-1). Rajagopalan is a qualified EOD Technician and Navy Diving Officer. He received a Bachelor of Science in operations research from the U.S. Naval Academy and a Master of Science in operations research from the Massachusetts Institute of Technology (MIT), where he was an MIT Lincoln Laboratory Military Fellow."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#graham-h.-reid",
    "href": "library/physics/government/darpa-fellows.html#graham-h.-reid",
    "title": "DARPA Fellows",
    "section": "Graham H. Reid",
    "text": "Graham H. Reid\nDr. Graham Reid joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Reid received a Bachelor of Arts in physics from Kenyon College and a doctorate from University of Maryland, College Park. His dissertation research, conducted at NIST as a guest researcher through the Joint Quantum Institute, used ultracold atoms to study topological physics in dynamically evolving quantum systems."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#rené-m.-xavier",
    "href": "library/physics/government/darpa-fellows.html#rené-m.-xavier",
    "title": "DARPA Fellows",
    "section": "René M. Xavier",
    "text": "René M. Xavier\nDr. René Xavier joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Xavier recently graduated from Florida Atlantic University, where she conducted research at the Harbor Branch Oceanographic Institute using shotgun metagenomics to analyze the biosynthesis of marine natural products. She received her Bachelor of Science in molecular, cellular, and developmental biology from the University of Washington in Seattle and was awarded a Fulbright Fellowship to study the regulation of reactive oxygen species at the Czech Institute of Experimental Botany in Prague. Prior to her academic career, she served as a nuclear electrician in the U.S. Navy where she was decorated with multiple honors including the Humanitarian Ribbon for her relief efforts during Hurricane Katrina."
  },
  {
    "objectID": "library/physics/government/darpa-fellows.html#alessandra-m.-zito",
    "href": "library/physics/government/darpa-fellows.html#alessandra-m.-zito",
    "title": "DARPA Fellows",
    "section": "Alessandra M. Zito",
    "text": "Alessandra M. Zito\nDr. Alessandra (Allie) Zito joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Zito received her Bachelor of Arts in chemistry and French language and literature from Johns Hopkins University and her doctorate in chemistry from the University of California, Irvine. Her graduate work focused on synthesizing and characterizing redox-active organic and inorganic molecules to be used for electrochemical carbon dioxide capture and concentration. She also has research experience in investigating catalyst loading on carbon aerogels, homogeneous and heterogeneous CO2 reduction catalysis, and electrode design for supercapacitors."
  },
  {
    "objectID": "library/physics/government/pentagon/pleads-fifth-exotic-materials.html",
    "href": "library/physics/government/pentagon/pleads-fifth-exotic-materials.html",
    "title": "Pentagon Pleads the Fifth",
    "section": "",
    "text": "Pentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs\narticle"
  },
  {
    "objectID": "library/physics/government/pentagon/pleads-fifth-exotic-materials.html#summary",
    "href": "library/physics/government/pentagon/pleads-fifth-exotic-materials.html#summary",
    "title": "Pentagon Pleads the Fifth",
    "section": "Summary",
    "text": "Summary\nThe blog post discusses the Pentagon’s inability to confirm or deny whether its UFO office, known as the All-domain Anomaly Resolution Office (AARO), has discovered any verifiable information to substantiate claims that any current or former U.S. programs have had possession or reverse-engineered materials from non-human intelligences or unknown origin. The Department of Defense (DoD) spokesperson, Susan Gough, stated that the AARO has not discovered any verifiable information to substantiate such claims. However, she declined to comment further on whether the term “extraterrestrial” could extend to materials of unknown origin or non-human intelligences."
  },
  {
    "objectID": "library/physics/government/pentagon/pleads-fifth-exotic-materials.html#notes",
    "href": "library/physics/government/pentagon/pleads-fifth-exotic-materials.html#notes",
    "title": "Pentagon Pleads the Fifth",
    "section": "Notes",
    "text": "Notes\n\nAll-domain Anomaly Resolution Office (AARO): The AARO is the Pentagon’s UFO office. It is currently unable to confirm or deny whether it has discovered any verifiable information to substantiate claims that any current or former U.S. programs have had possession or reverse-engineered materials from non-human intelligences or unknown origin.\nDepartment of Defense (DoD) Stance: The DoD spokesperson, Susan Gough, stated that the AARO has not discovered any verifiable information to substantiate such claims. However, she declined to comment further on whether the term “extraterrestrial” could extend to materials of unknown origin or non-human intelligences.\nAccess to Information: Gough confirmed that the AARO has not been denied access to any U.S. government program, past or present, during the course of its work. She also stated that the AARO may receive all UAP-related information, including any classified national security information involving military, intelligence, and intelligence-related activities, at all levels of classification regardless of any restrictive access controls, special access programs, or compartmented access programs.\nTitle 50 Authorities: Gough addressed the issue of Title 50 authorities, stating that such authorities are unrelated to the AARO’s ability to receive all UAP-related information through authorized disclosures.\nPublic Affairs Policies: Gough explained that it is DoD policy that all interactions with the news media at the Department level, including press queries, are coordinated with the Office of the Assistant to the Secretary of Defense for Public Affairs. She also noted that her portfolio includes UAP, AARO, and the Office of the Under Secretary of Defense for Intelligence & Security, as well as other issues and offices.\nWhistleblower Trust: The blog post mentions that the AARO, which currently reports to the Office of the Under Secretary of Defense for Intelligence & Security, is not trusted by numerous whistleblowers. The issue may stem from the AARO’s proximity to the OUSDI&S, which has previously been criticized for allegedly persecuting whistleblowers.\nConclusion: The blog post concludes by noting that the National Defense Authorization Act of 2023 means that the AARO should report directly to Deputy Secretary of Defense, Kathleen Hicks, and the Principal Deputy Director of National Intelligence on all operational and security matters relating to the AARO. However, there is no indication that this has been implemented yet."
  },
  {
    "objectID": "library/physics/unification/string-theory/index.html",
    "href": "library/physics/unification/string-theory/index.html",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/physics/unification/string-theory/index.html#resources",
    "href": "library/physics/unification/string-theory/index.html#resources",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/physics/unification/index.html",
    "href": "library/physics/unification/index.html",
    "title": "Unification",
    "section": "",
    "text": "Unitarity"
  },
  {
    "objectID": "library/physics/unification/index.html#resources",
    "href": "library/physics/unification/index.html#resources",
    "title": "Unification",
    "section": "",
    "text": "Unitarity"
  },
  {
    "objectID": "library/physics/government/index.html",
    "href": "library/physics/government/index.html",
    "title": "Government",
    "section": "",
    "text": "Making Muons for Scientific Discovery, National Security\nX-65 | Control of Revolutionary Aircraft with Novel Effectors (CRANE)\nAn Evening With Director of National Intelligence Avril Haines\nThe new Schumer-Rounds Amendment (“UAP Disclosure Act”) was added to the FY 2024 National Defense Authorization Act (S. 2226) without objection.\n\nPentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/physics/government/index.html#resources",
    "href": "library/physics/government/index.html#resources",
    "title": "Government",
    "section": "",
    "text": "Making Muons for Scientific Discovery, National Security\nX-65 | Control of Revolutionary Aircraft with Novel Effectors (CRANE)\nAn Evening With Director of National Intelligence Avril Haines\nThe new Schumer-Rounds Amendment (“UAP Disclosure Act”) was added to the FY 2024 National Defense Authorization Act (S. 2226) without objection.\n\nPentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/index.html",
    "href": "library/physics/electromagnetism/superconductor/index.html",
    "title": "Superconductors",
    "section": "",
    "text": "Piezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 1 of 2\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 2 of 2"
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/index.html#resources",
    "href": "library/physics/electromagnetism/superconductor/index.html#resources",
    "title": "Superconductors",
    "section": "",
    "text": "Piezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 1 of 2\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 2 of 2"
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/index.html#summary",
    "href": "library/physics/electromagnetism/superconductor/index.html#summary",
    "title": "Superconductors",
    "section": "Summary",
    "text": "Summary\nSuperconductivity is a macro-quantum state wherein a material displays (effectively) zero resistivity. (SUMMARIZE PT 1 1:09)\nA phenomenal overview of the phenomenon, from first principles, can be found on youtube.\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale\n\nPart 1 of 2\nPart 2 of 2\n\nBelow is practically nothing more than a summary of these lectures, plus some wikipedia content."
  },
  {
    "objectID": "library/physics/quantum/index.html",
    "href": "library/physics/quantum/index.html",
    "title": "Quantum",
    "section": "",
    "text": "MIT Quantum Physics I\nMIT Relatavistic Quantum Field Theory I\nMIT Relatavistic Quantum Field Theory II\nLangrangian and Hamiltonian Mechanics\nIntroductory Minicourse to AdS/CFT | youtube\nDavid Gross: Fifty Years of Quantum Chromodynamics (The Theory of The Strong Nuclear Force)\n\nQuantum Field Theory: Effective or Fundamental?"
  },
  {
    "objectID": "library/physics/quantum/index.html#resources",
    "href": "library/physics/quantum/index.html#resources",
    "title": "Quantum",
    "section": "",
    "text": "MIT Quantum Physics I\nMIT Relatavistic Quantum Field Theory I\nMIT Relatavistic Quantum Field Theory II\nLangrangian and Hamiltonian Mechanics\nIntroductory Minicourse to AdS/CFT | youtube\nDavid Gross: Fifty Years of Quantum Chromodynamics (The Theory of The Strong Nuclear Force)\n\nQuantum Field Theory: Effective or Fundamental?"
  },
  {
    "objectID": "library/health/cognition/index.html",
    "href": "library/health/cognition/index.html",
    "title": "Cognition",
    "section": "",
    "text": "Olfactory enrichment (aroma therapy) at night produces improvements in both cognitive and neural functioning.\nOvernight olfactory enrichment using an odorant diffuser improves memory and modifies the uncinate fasciculus in older adults\nResults: A statistically significant 226% improvement was observed in the enriched group compared to the control group on the Rey Auditory Verbal Learning Test and improved functioning was observed in the left uncinate fasciculus, as assessed by mean diffusivity.\nConclusion: Minimal olfactory enrichment administered at night produces improvements in both cognitive and neural functioning. Thus, olfactory enrichment may provide an effective and low-effort pathway to improved brain health."
  },
  {
    "objectID": "library/crypto/blockchains/evm/tooling.html",
    "href": "library/crypto/blockchains/evm/tooling.html",
    "title": "Tools & Resources",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis"
  },
  {
    "objectID": "library/crypto/blockchains/evm/index.html#resources",
    "href": "library/crypto/blockchains/evm/index.html#resources",
    "title": "EVM",
    "section": "",
    "text": "Ethereum Data Structures"
  },
  {
    "objectID": "library/finance/trading/trades/comstock/index.html",
    "href": "library/finance/trading/trades/comstock/index.html",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/finance/trading/trades/comstock/index.html#resources",
    "href": "library/finance/trading/trades/comstock/index.html#resources",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/finance/trading/trades/JGByields/index.html",
    "href": "library/finance/trading/trades/JGByields/index.html",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/finance/trading/trades/JGByields/index.html#resources",
    "href": "library/finance/trading/trades/JGByields/index.html#resources",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/politics/corruption/biden.html",
    "href": "library/politics/corruption/biden.html",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview"
  },
  {
    "objectID": "library/politics/corruption/biden.html#burisma",
    "href": "library/politics/corruption/biden.html#burisma",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview"
  },
  {
    "objectID": "library/politics/deep-state.html",
    "href": "library/politics/deep-state.html",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/politics/deep-state.html#resources",
    "href": "library/politics/deep-state.html#resources",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/health/covid/psyop.html",
    "href": "library/health/covid/psyop.html",
    "title": "psyop",
    "section": "",
    "text": "German MEP, Christine Anderson: Governments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”\nFull interview"
  },
  {
    "objectID": "library/health/covid/psyop.html#germany",
    "href": "library/health/covid/psyop.html#germany",
    "title": "psyop",
    "section": "",
    "text": "German MEP, Christine Anderson: Governments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”\nFull interview"
  },
  {
    "objectID": "library/health/covid/vaccine.html",
    "href": "library/health/covid/vaccine.html",
    "title": "mRNA Vaccine",
    "section": "",
    "text": "Australia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis"
  },
  {
    "objectID": "library/health/covid/vaccine.html#resources",
    "href": "library/health/covid/vaccine.html#resources",
    "title": "mRNA Vaccine",
    "section": "",
    "text": "Australia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis"
  },
  {
    "objectID": "library/health/covid/vaccine.html#horse-dewormer-a-necessary-narrative-for-fda-emergency-authorization",
    "href": "library/health/covid/vaccine.html#horse-dewormer-a-necessary-narrative-for-fda-emergency-authorization",
    "title": "mRNA Vaccine",
    "section": "“Horse Dewormer”, A necessary Narrative for FDA emergency Authorization",
    "text": "“Horse Dewormer”, A necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\nTODO"
  },
  {
    "objectID": "library/health/covid/vaccine.html#mrna-vaccine-x-myocarditispericarditis",
    "href": "library/health/covid/vaccine.html#mrna-vaccine-x-myocarditispericarditis",
    "title": "mRNA Vaccine",
    "section": "mRNA Vaccine x Myocarditis/Pericarditis",
    "text": "mRNA Vaccine x Myocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSERUM VAX SPIKE\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/crypto/blockchains/evm/tooling.html#resources",
    "href": "library/crypto/blockchains/evm/tooling.html#resources",
    "title": "Tools & Resources",
    "section": "Resources",
    "text": "Resources\n\nSolidity Data Representation"
  },
  {
    "objectID": "library/health/covid/index.html",
    "href": "library/health/covid/index.html",
    "title": "covid",
    "section": "",
    "text": "Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/health/covid/index.html#resources",
    "href": "library/health/covid/index.html#resources",
    "title": "covid",
    "section": "",
    "text": "Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/politics/reads/index.html",
    "href": "library/politics/reads/index.html",
    "title": "Reads",
    "section": "",
    "text": "Peter Thiel: Straussian Moment\nLegacy of Ashes"
  },
  {
    "objectID": "library/environment/climate/index.html",
    "href": "library/environment/climate/index.html",
    "title": "Climate Change",
    "section": "",
    "text": "Climate is an NP-complete problem. This can be proven by a reduction to turbulent mechanics. I do not abide by the “general” modern climate-change (Greta) view. However, it’s ridiculous to ignore the recent and rapid alterations in atmospheric content as a product of human industrialization."
  },
  {
    "objectID": "library/environment/climate/index.html#a-collection-of-views-and-information",
    "href": "library/environment/climate/index.html#a-collection-of-views-and-information",
    "title": "Climate Change",
    "section": "A Collection of Views and Information",
    "text": "A Collection of Views and Information\n\nThe North Atlantic Sea Surface Tempurature Anomoly\nTweet: We’ve been accidentally geoengineering for decades… then we stopped"
  },
  {
    "objectID": "library/crypto/events/2023/08/ygg.html",
    "href": "library/crypto/events/2023/08/ygg.html",
    "title": "YGG Manipulation",
    "section": "",
    "text": "August 7\n9:04 am YGG in top 3 volume, followed by shitcoins with negative funding (heavy shorts)\nHsaka’s Take | tweet\nAug 6, 7:04am YGG “looking spicy” says Nik’s quant\nReported at 9:52am Binance increased the funding rate settlement frequency from 8 hours to 2 hours\nReminder that 2018 scam pumps were even crazier\n\nso much commentary and ‘hate’ on the YGG situation when people don’t remember the summer of 2022 where we had 10x pumps in 1 minute on shitcoins. oh sweet children you haven’t experienced the true depths of market manipulation yet"
  },
  {
    "objectID": "library/health/covid/vaccine.html#mrna-platform",
    "href": "library/health/covid/vaccine.html#mrna-platform",
    "title": "mRNA Vaccine",
    "section": "mRNA Platform",
    "text": "mRNA Platform\nExcerpt from Brett Weinstein\n\nThe mRNA platform is brilliant. But it has a giant gaping flaw in it, which is; Any cell of yours that produces a foreign protein, will be targetted by your immune system and destroyed. You will create an autoimmune disorder. When it works. How do you keep it out of your heart. Not by coding it in a lipid nanoparticle. So, they had no way to deliver it safely to market. So then they had a pandemic, the emergency allowed them to do it. This technology, in my opinion, was at least 3 decades out from being usefully and safely deployed at all, if at all. They did not want to wait, this crisis gave them the opportunity not to wait. And now, they will blame the spike protein, we picked the wrong protein. When in actual fact there are 2 problems, the spike protein and the platform itself."
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/lk99.html#asides",
    "href": "library/physics/electromagnetism/superconductor/lk99.html#asides",
    "title": "LK-99",
    "section": "Asides",
    "text": "Asides\nAuthor of the original paper, Hyun-Tak Kim, from 2018\nWhy does BCS theory fail to explain superconductivity at high temperatures?"
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/lk99.html#tldr",
    "href": "library/physics/electromagnetism/superconductor/lk99.html#tldr",
    "title": "LK-99",
    "section": "",
    "text": "Superconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise."
  },
  {
    "objectID": "library/physics/electromagnetism/superconductor/lk99.html#timeline",
    "href": "library/physics/electromagnetism/superconductor/lk99.html#timeline",
    "title": "LK-99",
    "section": "Timeline",
    "text": "Timeline\nJuly 22:\n\nThe First Room-Temperature Ambient-Pressure Superconductor\nOriginal paper(s) is(are) released twice, the first time (suspected to rush to beat the second) with only 3 authors, making the team eligible for a noble prize.\n\nJuly 26:\n\nI predict the superconductor hype (“we are so fucking back”) is all noise.\n\nJuly 27:\n\nDouglas Natelson publishes a blog post expressing a pessemistic view on the whole debacle.\nCondensed Matter Theory Center deconstructs “the non-experimental parts of the Korean room temp SC claims.”\n\nHype ensues, and magnifies, as people rush to replicate the study/results.\nJuly 29:\n\nFirst-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\n\nJuly 31:\n\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n\nA (failed?) replication attempt out of Beijing; shows semiconductor behavior, not super\n\nSemiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)\n\nAugust 4:\nA theoretical explanation for LK-99 is released on July 31, 2023, by Sinead Griffin out of Berkeley.\n\nOrigin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\nAugust 6:\nGroup claims/proves LK-99 is a ferromagnet (NOT a superconductor)\n\nFerromagnetic half levitation of LK-99-like synthetic samples"
  },
  {
    "objectID": "library/physics/electromagnetism/index.html",
    "href": "library/physics/electromagnetism/index.html",
    "title": "Electromagnetism",
    "section": "",
    "text": "Dr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/physics/electromagnetism/index.html#resources",
    "href": "library/physics/electromagnetism/index.html#resources",
    "title": "Electromagnetism",
    "section": "",
    "text": "Dr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/physics/electromagnetism/mhd/index.html",
    "href": "library/physics/electromagnetism/mhd/index.html",
    "title": "MHD",
    "section": "",
    "text": "Magnetohydrodynamic (MHD) Propulsion\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/physics/electromagnetism/mhd/index.html#resources",
    "href": "library/physics/electromagnetism/mhd/index.html#resources",
    "title": "MHD",
    "section": "",
    "text": "Magnetohydrodynamic (MHD) Propulsion\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/physics/electromagnetism/mhd/index.html#summary",
    "href": "library/physics/electromagnetism/mhd/index.html#summary",
    "title": "MHD",
    "section": "Summary",
    "text": "Summary\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism.\nThe governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations. In the ideal MHD approximation, effects such as resistivity and viscosity are neglected, leading to a relatively simple set of governing equations:\n\nContinuity Equation: This equation ensures the conservation of mass.\n∂ρ/∂t + ∇·(ρv) = 0\nMomentum Equation: Combines Newton’s second law and the Lorentz force, accounting for the forces due to pressure gradients, gravity, and electromagnetic fields. In the absence of viscosity, this simplifies to:\nρ(∂v/∂t + v·∇v) = -∇p + ρg + (J×B)\nInduction Equation: Describes how the magnetic field evolves over time, given the fluid’s velocity and existing magnetic field.\n∂B/∂t = ∇×(v×B)\nEnergy Equation: This equation describes the conservation of energy, which is usually taken in the form of the first law of thermodynamics.\nAmpère’s Law with Maxwell’s Addition:\n∇×B = μ0J\nJ is the current density vector, B is the magnetic field, and μ0 is the magnetic permeability.\n\nIn these equations, ρ represents fluid density, v fluid velocity, p pressure, g gravitational acceleration, J current density, and B magnetic field.\nMHD has a wide range of applications, from studying astrophysical phenomena such as solar flares and accretion disks, to engineering applications like nuclear fusion research, liquid metal cooling in reactors, and even potential propulsion systems.\nHowever, real-world situations often involve non-ideal MHD where effects such as resistivity cannot be ignored. Understanding these effects often requires incorporating the full set of Maxwell’s equations and solving them alongside the fluid dynamics equations, which makes for a much more complex computational problem. In some non-ideal MHD scenarios, magnetic reconnection, turbulence, and other instabilities can occur, which are active research areas in this field."
  },
  {
    "objectID": "library/physics/uap/early/index.html",
    "href": "library/physics/uap/early/index.html",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/physics/uap/early/index.html#sources",
    "href": "library/physics/uap/early/index.html#sources",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/physics/uap/early/index.html#unordered-stuff",
    "href": "library/physics/uap/early/index.html#unordered-stuff",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/physics/uap/early/index.html#ulat-1",
    "href": "library/physics/uap/early/index.html#ulat-1",
    "title": "Early",
    "section": "ULAT-1",
    "text": "ULAT-1\nWordpress article\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\na.    UF6 in metallic form;\nb.    hydrogen-fluoride gas;\nc.    water and uranium tetra fluoride;\nd.    powdered magnesium and potassium chlorate,\ne.    metal similar to lead with a chocolate brown color;\nf.   U-235 in metallic form;\ng.   plastic-like material similar to NE 102,\nh.    Beryllium,\ni.    Pure aluminium;\nj.   Thorium isotope material;\nj.   Plutonium powder.\n\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns."
  },
  {
    "objectID": "library/physics/uap/early/index.html#project-white-hot",
    "href": "library/physics/uap/early/index.html#project-white-hot",
    "title": "Early",
    "section": "Project White Hot",
    "text": "Project White Hot\nPROJECT ‘WHITE HOT’ Mission Assessment of Recovered Lenticular Aerodyne Objects\nGeneral Nathan Twining Briefing document for President Eisenhower\nPART 1. PROJECT WHITE HOT INTELLIGENCE ESTIMATE (PRELIMINARY)\nLANDING ZONE NO, 1 Socorro, New Mexico–the unidentified lenticular-shaped Aerodyne which has been designated ULAT-1, has been evaluated as a non air breathing aircraft of unknown origin. Totally lacking conventional wing, fuselage, nacelle, control, and fuel systems strongly indicates it is not Russian.\nConsultation with Paperclip specialists concur. Aerodynamic features exhibited in ULAT-1 represents a very high degree of engineering and sophistication not seen in this country.\nDimensional homogeneity study cannot explain how this craft sustains load and lift factors necessary for flight.\nThe power plant does not even remotely resemble any conventional type now in use. Lacking any discernible intake or exhaust features, it is the opinion of AMC and ONR that this craft was designed to operate outside of the earth’s atmosphere.\nThe unconventional conclusions reached by members of this fact finding mission remain tentative at this time. Some members have expressed the view that ULAT-1 may be the product of an advanced culture from another planet that is much older than ours and has utilized their science and intellect for interplanetary space travel. It is not precisely known if the occupants purposely had the objective of exploration and of curiosity or with the intent of surveying for other reasons. So far, no hostile action or intent has been observed since they made their presence known.\nGiven the fact that our atomic bomb tests, atmospheric exploration with rockets, and XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXed in New Mexico, could have precipitated the events that led to the incident and subsequent actions taken by the military.\nOperating under the assumption that the fallen object was a long-range Russian reconnaissance platform collecting aerial photographic intelligence data military intelligence personnel were a instructed to secure the craft, debris and any occupants as rapidly as possible.\nConcerns over possible exposure to civilian of unknown biological and chemical agents dictated the quarantine measures taken.\nRadiation hazards were assumed and protective measures were taken as well.\nIn the interest or National Security priorities it was necessary to detain civilian witnesses for interrogation to satisfy intelligence requirements and quash rumors that could alert potential espionage agents known to be in the vicinity.\nSeveral bodies were discovered.\nBecause on-site medical personnel were unsure of the physiological make up of the occupants, special preparations and preservation methods were employed. Autopsy information obtained so far suggests that the occupants mimic the features associated with Orientals.\nOutwardly, they appear human-like with but one exception, autopsy notes mention a rarely observed XXXXXXXXXXXXXXXXXXXXXXXXXXXXXs present which supports the premise that these beings originate from another planet.\nPART TWO TECHNICAL EVALUATION (PRELIMINARY) ULAT-1\nUpon close examination of the exterior surfaces of the craft’s fuselage, metallurgists found the the skin to be of a ferrous metal white in color. The metal exhibits all the characteristics of high grade steel. It was determined that the steel was cold-formed and heat created.\n\nTensile strength was estimated in excess of 50,000 pounds per square inch. Shear tests give the metal a durability rating above 175,000 pounds per square inch, making this fuselage extremely strong and heat resistant.\nStatic and pressure flow simulations were impressive. The low profile ration of 6-1 gives the aerodyne a great advantage in overcoming the restrictions of the boundary layer effect in high performance operations.\nSpan flanges are constructed in unusual kinematic design which is believed to allow strain relief at supersonic speeds. There were no visible signs of plate-stiffeners, there were no fasteners, weld, rivets, or fittings, holding the fuselage together.\nLack of wings, flaps, stabilizers, and surface central features, suggests that the craft is a lifting body.\nThere are no air intakes for exhaust.\nThere are no cables\nThere are no identifiable electronics (wiring, ignition, lights, instrument, compartment, engine, motors, vacuum tubes, solenoids, generators, heaters, etc.)\nThe power-plant, (severely damaged) XXXXXXXXXXXXXXXXXx neutronic engine. XXXXXXXXXXXXXXXXXXXXXx detected heavy water and deuterium (light hydrogen) elements appeared to be the primary ignitor. A series of coils and heavy magnets connected to the neutronic engine via an oddly arranged group of electrodes (actually not yet identified) appears to be the active force. One small motor was examined. It is encased in a pure aluminium capsule directly underneath the main compartment. There is a small exhaust aperture attached that was what can only be described as an helicoid mechanism XXXXXXXXXXXXXXXXXXXXX. The auxiliary motor may be articulated.\n\nAdvertisement\n\nNavigation and engine controls may be activated by tactile manipulation. Viewing may have been achieved by form of television imagery. Symbolic notation appears to be the form of flight and control indicators. Flat panels of unknown metal has been suggested as a device associated with the operation of the aerodyne was discovered and analyzed. It’s mode of operation and purpose is unknown.\nThe absence of provisions, berthing compartments and storage areas, suggest the notion that this craft may be a short range reconnaissance platform. The only recognizable features XXXXXXXXXXX XXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nMode of operation of operation is believed to be instrumentation and suggests that the aerodyne from reconstruction from available wreckage XXXXXXXXXXXXXXXXXX biosensory and optical stimuli for these reasons:\n\nabsence of indicator signals Absence of any circular dials Absence of linear dials or moving pointers Absence of counters Absence of scopes No mechanical signal indicators 12. There were identifiable control types found among the assortment of artefacts that would indicate the operation of the propulsion unit was manually activated – no knobs, push buttons, toggle switches, levers, balls, handwheels, hand-cranks, or foot pedals were observed in the interior space of the flight cabin.\n\nThe apparent lack of additional clothing and equipment reinforces the belief that the occupants were engaged in a purely exploratory flight.\nIt is not presently known if electromagnetic radiation effects from the power plant had contributed to pilot error or death before impact. If inadequate shielding was the primary cause of pilot error XXXXXXXXXXXXXXs detected.\nIt is believed by some of the crash inspection personnel that sudden decompression and change in atmospheric pressure may have contributed to pilot error. Clothing removed from occupants do not resemble any pressure suit currently being tested by the Army or the Navy for high altitude experiments. Since temperature and humidity factors for the occupants is unknown, it is impossible to determine if decompression and temperature changed affected circulatory and dexterity functions. Although it is believed the occupants may have been overcome by some yet undiscovered pollutant or noxious fumes originating inside the craft.\nRotation or rapid oscillation could have been a contributing factor in pilot error. It is not known if organic effects played a part either since medical data is non-existent in which to make any judgment as to exact cause of death or machine failure.\nThe most probable cause of the crash is believed to be excessive acceleration combined with steep descent. The seating arrangement was transversely designed about the vertical axis of the occupants in a positive direction of flight. The panels removed from the craft resemble the ones taken from the occupants, suggesting a symbionic relationship between operator and the function of the aerodyne’s operation. A very tentative working theory was expressed by the scientific members of the inspection team that pilot-aerodyne interaction may occur via electronic-nonword symbols perceived through the tactile manipulation of the fingers feeding impulses to the brain and visa versa. All of which may suggest a non-inert quality or the materials existent as being a product or artificial intelligence.\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\n\nUF6 in metallic form;\nhydrogen-fluoride gas;\nwater and uranium tetra fluoride;\npowdered magnesium and potassium chlorate,\nmetal similar to lead with a chocolate brown color;\nU-235 in metallic form;\nplastic-like material similar to NE 102,\nBeryllium,\nPure aluminium;\nThorium isotope material;\nPlutonium powder.\n\n\nScientists from Los Alamos and Sandia Base were alarmed that the power plant could possibly function as a bomb if the elements described above were processed in similar fashion as was done for the lens and shot-gun detonators. This originally was the first conclusion. After further evaluation, it was determined that since no recognizable firing circuits were identified, the threat or detonation did not exist.\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns.\n\nPART III SCIENTIFIC PROBABILITIES\n\nBased on all available evidence collected from recovered exhibits currently under study by AHC, AFSWP, NEPA, AEC, ONA, NACA, JBDB, RAND, USAAF SAG. and MIT, are deemed extraterrestrial in nature. This conclusion was reached as a result of comparisons of artifacts XXXXXXXXXXXXXXXXXX discovery in 1941. The technology is outside the scope of US science, even that of German rocket and aircraft development.\nInterplanetary space travel is possible provided adequate funding, necessary resources are made available, and national interest is piqued.\nOur solar system is not unique. Chances are favorable for intelligent life on other planets notwithstanding similar development not unlike our own.\nBeing that our culture is relatively young (in relation to the cosmic scale), it is possible that other cultures may have developed faster, or are much older and have avoided the pitfalls common in our historical and scientific development.\nHuman origins may not be constrained to one planet. Our genus may be found among solar systems similar to our own.\nThe laws of physics and genetics may have a genesis in a higher, structured order than once previously thought.\n\nPART IV POLITICAL CONSIDERATIONS\nGiven the existing political climate in the US and the unstable conditions in Europe, it is the considered opinion of the members, that if the Administration went public with the information as found in this report now, the results would be damaging, even fatal to the world Political structure as it now exists. The following considerations were reviewed and debated, which led the mission to the following opinions:\n\nPublic trust of the political institutions may be eroded and possibly be held in disrepute.\nA complete revisioning make take place as institutions of higher learning thus calling into question the certainty of scientific knowledge.\nThe ability of the Armed Forces to secure National Security would be put in jeopardy and possibly lead to undue public fear and disorder.\nHistory and religion in the political context would probably suffer the most damage causing unprecedented upheaval in social and psychological well-being.\nPolitical repercussions may occur in our diplomatic efforts of containing the Communist threat to our democratic interests.\nIf such an announcement were made by the current Administration, it could be perceived by opposing party as a trick, laying open to accusations of unethetical (sic) posturing and manipulation of the public’s mind.\n\nPART V NATIONAL SECURITY STRUCTURE\nWith the passage of the National Security Act of 1947 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXas presented an unprecedented situation regarding maintaining secrecy related to the information contained in this report.\nIn the early months of 1942, up until the present, intrusions of unidentified aircraft have occasionally been documented, but there has been no serious investigations by the intelligence arm of the Government. Even the recovery case of 1941 did not create a unified intelligence effort to exploit possible technological gains with the exception of the Manhattan Project. We now have an opportunity to extend our technology beyond the threshold that we have achieved, XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXX. Aside from technological gains, we face an even greater challenge, that of learning the intent of such a presence. There are questions that remain unanswered, such as: What forces face us? What kind of defense do we have? Where do they come from and what kind of weapons do they possess? Where can we stage our forces in advance, XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX How wide a front? How many craft can we expect? And XXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXX\nThe members of the mission are prepared to submit a separate report on just this problem alone. And it would take a dozen volumes to explain how these problems should be met.\nOur only point, however, is that a combined intelligence and research operation would be a vast, intricate, covertly planned marshaling of resources, human and material, to solve a specific, clearly defined problem.\nWe have to find effective methods of persuasion with other government agencies without creating a sense of impending doom. The first task is to carefully appraise the problem. The second is to evaluate the known resources and probable strategy of the visitors. The third is to inventory our own ways and means, ascertain how much resources we can bring to bear, and how fast. The third is to devise our strategic plan. And last is to work out with infinite pains the tactical details and the myriad secondary problems of funding and security.\nIt is the unanimous opinion of the members that Operation MAJESTIC TWELVE be a fully funded ant operational TOP SECRET Research and Development intelligence gathering agency. It is also recommended that a panel of experts be appointed to chair and oversee the functions and operations of said agency. It’s members should have appropriate security clearances and full cooperation XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX XXXX XXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXX the National Security Council, the Pentagon, XXXXXXXht, XXXXXXXXXXXXXXXXXXXXX Joint Intelligence Committee, Joint Intelligence Objectives Agency, Central Intelligence Agency, Atomic Energy Commission, Joint Research and Development Board, Army Security Agency, and the National Advisory Board on Aeronautics.\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXgy are highlighted:\n\nPropeller driven bomber aircraft and jet engines, armed with conventional and atomic bombs.\nJet fighter aircraft, including some of super­sonic speed, armed with rockets and guns.\nPropeller-driven aircraft, valued for their endurance. .\nGuided anti-aircraft missiles, and radar-guided anti-aircraft guns.\nShort and medium-range guided missiles. Drone aircraft.\nAtomic charges, in bombs, missiles and torpedoes.\n\nIn the arena of nuclear weapons we feel there is a certain advantage to be gained XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX. It is speculated by some that if reduced size and miniature circuitry were introduced into the proposed hydrogen bomb program, it would give US Strategic Air Forces a great deterrence capability over the Russians. Current studies at MIT of micro-electronics taken from ULAT-1 may give us the strategic advantage so desired. It is strongly recommended that funding be allocated in this area.\nThere is a good chance that the Russians may try to make use of the flying saucer scare by public news media and diplomatic means of a technological breakthrough in aircraft and missile development. We feel that such a disclosure would certainly cause great embarrassment to our elected officials and to the military, not to mention the panic felt by the citizenry. To counter such a threat, it is recommended that a counterintelligence program be drawn up and held in abeyance if at such time the situation should present itself. It might be suggested that we should make a preempted use of these objects for the purpose of psychological warfare once the true nature of these objects are known and understood.\nTo further assist and aid all MAJCOM in the US and overseas, it is recommended that a standard intelligence reporting system be implemented through standard reporting channels with technical data forwarding instructions. At present, there are no specific intelligence guidelines available to military commanders in dealing with sightings and material evidence collection. It would be advisable for the respective Secretaries of the Armed Forces to devise a security policy of plausible denial, if and when the public becomes aware of the reality of these objects and the interest of the military of such incidents.\nIn conclusion, for reasons of national security and the public well being, the US must be perceived as being the top of the heap and every effort must be made to insure that there is, and never has been, a threat to the country."
  },
  {
    "objectID": "library/physics/uap/index.html",
    "href": "library/physics/uap/index.html",
    "title": "UAP",
    "section": "",
    "text": "My take, in a few sentences:\nThe UAP phenomenon is extraordinary. There are two primary candidate explanations.\nI believe both are at play. Confidence level: 10%"
  },
  {
    "objectID": "library/physics/uap/index.html#resources",
    "href": "library/physics/uap/index.html#resources",
    "title": "UAP",
    "section": "Resources",
    "text": "Resources\n\nGood github repo: UAP Resources\nThe Case for UFO Secrecy\nAvalon Project\nAureon: At the Intersection of Energy and Matter | history\n\nChapel Hill Conference\n\nChapel Hill Conference\nBehind the Scenes Chapel Hill\nThe Role of Gravitation in Physics\n\nTo The Stars Academy\n\nTo The Stars Academy purchases exotic “assets” for $35,000\nMagnesium-Zinc-Bismuth (MgZn/Bi) material, allegedly recovered from a Rowsell crash, has several interesting physics properties."
  },
  {
    "objectID": "library/physics/uap/index.html#government-archive",
    "href": "library/physics/uap/index.html#government-archive",
    "title": "UAP",
    "section": "Government Archive",
    "text": "Government Archive\nProject BLUE BOOK - UFOs\nFBI says this document is fake"
  },
  {
    "objectID": "library/physics/uap/index.html#speculative-tech",
    "href": "library/physics/uap/index.html#speculative-tech",
    "title": "UAP",
    "section": "Speculative Tech",
    "text": "Speculative Tech\n\nAdvanced Space Propulsion Based on Vacuum Engineering\nNovel Ni-Doped Bismuth–Magnesium Tantalate Pyrochlores: Structural and Electrical Properties, Thermal Expansion, X-ray Photoelectron Spectroscopy, and Near-Edge X-ray Absorption Fine Structure Spectra\nFew-layer bismuth selenide cathode for low-temperature quasi-solid-state aqueous zinc metal batteries\nFaster than Light Travel\nWarp Drives Part 1: Problem Statement and Insights\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nPolarizable Vacuum “Metric Engineering” Approach to GR-Type Effects\nSuperconductors as quantum transducers and antennas for gravitational and electromagnetic radiation"
  },
  {
    "objectID": "library/politics/corruption/index.html#ukraine",
    "href": "library/politics/corruption/index.html#ukraine",
    "title": "Corruption",
    "section": "Ukraine",
    "text": "Ukraine\n\nUN, Zakharov\nThe son of Alexander Zakharov, mastermind of Russia’s killer drones that attack civilians in Ukraine, is now interning at the U.N.’s disarmament institute. UNIDIR says he was selected through a “competitive and transparent recruitment process…on the basis of his qualifications, skills and experience for the position.”\nTribune de Geneve: “The presence of Zakharov’s son in Geneva implies that Switzerland issued him with a visa, which is compulsory for Russian nationals wishing to enter and stay in the country. When questioned, the Swiss State Secretariat for Migration would not comment on the case. Alexander Zakharov’s son did not respond to our messages.”\n\ntweet\narticle"
  },
  {
    "objectID": "library/software/ai/bio/index.html",
    "href": "library/software/ai/bio/index.html",
    "title": "AI x Bio",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology"
  },
  {
    "objectID": "library/software/ai/bio/index.html#resources",
    "href": "library/software/ai/bio/index.html#resources",
    "title": "AI x Bio",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology"
  },
  {
    "objectID": "library/environment/animals/index.html",
    "href": "library/environment/animals/index.html",
    "title": "Animals",
    "section": "",
    "text": "The Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet.\n\ntweet\ndiscovery article"
  },
  {
    "objectID": "library/environment/animals/index.html#barbery-lions",
    "href": "library/environment/animals/index.html#barbery-lions",
    "title": "Animals",
    "section": "",
    "text": "The Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet.\n\ntweet\ndiscovery article"
  },
  {
    "objectID": "library/physics/government/index.html#directed-energy",
    "href": "library/physics/government/index.html#directed-energy",
    "title": "Government",
    "section": "Directed Energy",
    "text": "Directed Energy\n\nD-Wave and Davidson Technologies Introduce New Innovations to Advance National Defense Efforts"
  },
  {
    "objectID": "library/physics/astro/index.html",
    "href": "library/physics/astro/index.html",
    "title": "Astrophysics & Cosmology",
    "section": "",
    "text": "James Webb Images\n\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nHolography of the Photon Ring\n\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics - article - Discovery of Gamma Rays from the Quiescent Sun with HAWC"
  },
  {
    "objectID": "library/physics/astro/index.html#awesome",
    "href": "library/physics/astro/index.html#awesome",
    "title": "Astrophysics & Cosmology",
    "section": "",
    "text": "James Webb Images\n\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nHolography of the Photon Ring\n\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics - article - Discovery of Gamma Rays from the Quiescent Sun with HAWC"
  },
  {
    "objectID": "library/physics/astro/webb.html",
    "href": "library/physics/astro/webb.html",
    "title": "James Webb",
    "section": "",
    "text": "10 galaxies that existed just 830 million years after the Big Bang\nThe seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster."
  },
  {
    "objectID": "library/physics/astro/webb.html#resources",
    "href": "library/physics/astro/webb.html#resources",
    "title": "James Webb",
    "section": "",
    "text": "10 galaxies that existed just 830 million years after the Big Bang\nThe seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster."
  },
  {
    "objectID": "library/physics/black-holes/index.html",
    "href": "library/physics/black-holes/index.html",
    "title": "Black Holes",
    "section": "",
    "text": "Math Proof Draws New Boundaries Around Black Hole Formation\n\nQuanta article\nPaper"
  },
  {
    "objectID": "library/politics/index.html",
    "href": "library/politics/index.html",
    "title": "Geopolitics",
    "section": "",
    "text": "Arab support to Egypt, as of Dec-2022\nLong-term deposits = $15b, from: - UAE = $5.7b - Saudi = $5.3b - Kuwait = $4b\nShort-term deposits = $14.9b, from: - UAE = $5b - Saudi = $5b - Qatar = $4b (from $3b in Mar) - Libya = $0.9b (from 0 in Mar)"
  },
  {
    "objectID": "library/health/physiology/index.html",
    "href": "library/health/physiology/index.html",
    "title": "Physiology",
    "section": "",
    "text": "Why does one stick their tongue out when performing a meticulous task with hand tools? Why do tennis players (and martial artist) shout alongside their movements? On the innate linking of the hands and mouth: - The Hidden Brain Connections Between Our Hands and Tongues - Effect of Syllable Articulation on Precision and Power Grip Performance - The initiation of a hand grip is delayed by silently reading an incompatible syllable - Motor and visual-motor functions of the premotor cortex - Complex Movements Evoked by Microstimulation of Precentral Cortex\nMotor proficiency predicts linguistic ability\n\nLanguage as a Tool: Motor Proficiency Using a Tool Predicts Individual Linguistic Abilities"
  },
  {
    "objectID": "library/health/physiology/index.html#reads",
    "href": "library/health/physiology/index.html#reads",
    "title": "Physiology",
    "section": "",
    "text": "Why does one stick their tongue out when performing a meticulous task with hand tools? Why do tennis players (and martial artist) shout alongside their movements? On the innate linking of the hands and mouth: - The Hidden Brain Connections Between Our Hands and Tongues - Effect of Syllable Articulation on Precision and Power Grip Performance - The initiation of a hand grip is delayed by silently reading an incompatible syllable - Motor and visual-motor functions of the premotor cortex - Complex Movements Evoked by Microstimulation of Precentral Cortex\nMotor proficiency predicts linguistic ability\n\nLanguage as a Tool: Motor Proficiency Using a Tool Predicts Individual Linguistic Abilities"
  },
  {
    "objectID": "library/crypto/mev/overview.html#dashboards-tools",
    "href": "library/crypto/mev/overview.html#dashboards-tools",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay"
  },
  {
    "objectID": "library/crypto/rekt/index.html",
    "href": "library/crypto/rekt/index.html",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2"
  },
  {
    "objectID": "library/crypto/rekt/index.html#resources",
    "href": "library/crypto/rekt/index.html#resources",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2"
  },
  {
    "objectID": "library/crypto/blockchains/evm/tooling.html#tools",
    "href": "library/crypto/blockchains/evm/tooling.html#tools",
    "title": "Tools & Resources",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis"
  },
  {
    "objectID": "library/crypto/mev/amm/index.html",
    "href": "library/crypto/mev/amm/index.html",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/crypto/mev/amm/index.html#papers-research",
    "href": "library/crypto/mev/amm/index.html#papers-research",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/crypto/mev/amm/index.html#strategies",
    "href": "library/crypto/mev/amm/index.html#strategies",
    "title": "MEV on AMMs",
    "section": "Strategies",
    "text": "Strategies\n\nIncoming Swap\n\nSandwiching\n\nIncoming buy, deliver bundle {mybuy, buy, mysell}\nIncoming sell (requires inventory), deliver bundle {mysell, sell, mybuy} (JaredFromSubway’s claim to fame and riches)\n\n\n\nJIT Liquidity\nIncoming transaction, frontrun it with a large liquidity position at the optimal tick bounds\n\n\nJIT + Sandwich Combo\nThis is the optimal strategy assuming negligible gas fees\n\nIncoming buy: frontrun buy, add LP, victim buy, remove LP, backrun sell\nIncoming sell: opposite\n\nResources on it: tweet 1\nExample bot executing this etherscan\nList of examples in prod tweet\n\n\n\nIncoming Liquidity Provision Position\n\nLP Addition\nIncoming LP Addition, deliver bundle {mybuy, lpAdd, mysell} - since liquidity is greater during sell, face less slippage - net sell price &gt; net buy price\n\n\nLP Removal\nIncoming LP Removal, deliver bundle {mysell, lpRemove, mybuy} - since liquidity is greater during buy, face less slippage. End up with more tokens than you started with. - net sell price &lt; net buy price"
  },
  {
    "objectID": "library/software/coding/rust/index.html",
    "href": "library/software/coding/rust/index.html",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/software/coding/rust/index.html#learning-resources",
    "href": "library/software/coding/rust/index.html#learning-resources",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/physics/relativity/index.html",
    "href": "library/physics/relativity/index.html",
    "title": "Relativity",
    "section": "",
    "text": "Only Harmonic Springs and Gravity produce periodic motions\n\ntweet"
  },
  {
    "objectID": "library/nat-sci/physics/quantum/compute/index.html",
    "href": "library/nat-sci/physics/quantum/compute/index.html",
    "title": "Computation",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization"
  },
  {
    "objectID": "library/nat-sci/physics/quantum/compute/index.html#resources",
    "href": "library/nat-sci/physics/quantum/compute/index.html#resources",
    "title": "Computation",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization"
  },
  {
    "objectID": "library/nat-sci/physics/quantum/field-theory/effective-or-fundamental.html",
    "href": "library/nat-sci/physics/quantum/field-theory/effective-or-fundamental.html",
    "title": "Fundamental?",
    "section": "",
    "text": "The Quantum Theory of Fields: Effective or Fundamental?\n\nvideo\ncorresponding article\nQuantum Field Theory was born just pertaining to the electromagnetic field.\nWhen expanding this theory, it seemed it couldn’t be trusted at high energies. (Decline)\nLate 1940s, there was a new optimizing with the invention of a relatavistic perturbation theory, where the infinities could be absorbed into a redefinition of parameters like mass and charge of the electron. People thought this was sweeping problems under the rug, but it also may have been a way of selecting good theories (renormalizable theories).\nFor example, theere’s nothing in the symmetries of quantum electrodynamics which rules out putting a term in the field equations (or Lagrangian), which could make the magnetic moment of the electron anything you want. This would make the mass of the electron -1, which means the theory is not renormalizable, and thus shows invalid.\nLate 1960s and early 70s, the standard model came to fruition - this was the renaissance of Quantum Field theory. But there were still doubts whether this was a fundamental theory or an effective one.\nQuantum Field Theory & Einsteinian Physics may be low energy approximations of a more fundamental theory."
  },
  {
    "objectID": "library/nat-sci/physics/astro/index.html",
    "href": "library/nat-sci/physics/astro/index.html",
    "title": "Astrophysics & Cosmology",
    "section": "",
    "text": "James Webb Images\n\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nHolography of the Photon Ring\n\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics - article - Discovery of Gamma Rays from the Quiescent Sun with HAWC"
  },
  {
    "objectID": "library/nat-sci/physics/astro/index.html#awesome",
    "href": "library/nat-sci/physics/astro/index.html#awesome",
    "title": "Astrophysics & Cosmology",
    "section": "",
    "text": "James Webb Images\n\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nHolography of the Photon Ring\n\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics - article - Discovery of Gamma Rays from the Quiescent Sun with HAWC"
  },
  {
    "objectID": "library/nat-sci/physics/uap/index.html",
    "href": "library/nat-sci/physics/uap/index.html",
    "title": "UAP",
    "section": "",
    "text": "My take, in a few sentences:\nThe UAP phenomenon is extraordinary. There are two primary candidate explanations.\nI believe both are at play. Confidence level: 10%"
  },
  {
    "objectID": "library/nat-sci/physics/uap/index.html#resources",
    "href": "library/nat-sci/physics/uap/index.html#resources",
    "title": "UAP",
    "section": "Resources",
    "text": "Resources\n\nGood github repo: UAP Resources\nThe Case for UFO Secrecy\nAvalon Project\nAureon: At the Intersection of Energy and Matter | history\n\nChapel Hill Conference\n\nChapel Hill Conference\nBehind the Scenes Chapel Hill\nThe Role of Gravitation in Physics\n\nTo The Stars Academy\n\nTo The Stars Academy purchases exotic “assets” for $35,000\nMagnesium-Zinc-Bismuth (MgZn/Bi) material, allegedly recovered from a Rowsell crash, has several interesting physics properties."
  },
  {
    "objectID": "library/nat-sci/physics/uap/index.html#speculative-tech",
    "href": "library/nat-sci/physics/uap/index.html#speculative-tech",
    "title": "UAP",
    "section": "Speculative Tech",
    "text": "Speculative Tech\n\nAdvanced Space Propulsion Based on Vacuum Engineering\nNovel Ni-Doped Bismuth–Magnesium Tantalate Pyrochlores: Structural and Electrical Properties, Thermal Expansion, X-ray Photoelectron Spectroscopy, and Near-Edge X-ray Absorption Fine Structure Spectra\nFew-layer bismuth selenide cathode for low-temperature quasi-solid-state aqueous zinc metal batteries\nFaster than Light Travel\nWarp Drives Part 1: Problem Statement and Insights\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nPolarizable Vacuum “Metric Engineering” Approach to GR-Type Effects\nSuperconductors as quantum transducers and antennas for gravitational and electromagnetic radiation"
  },
  {
    "objectID": "library/nat-sci/physics/uap/index.html#government-archive",
    "href": "library/nat-sci/physics/uap/index.html#government-archive",
    "title": "UAP",
    "section": "Government Archive",
    "text": "Government Archive\nProject BLUE BOOK - UFOs\nFBI says this document is fake"
  },
  {
    "objectID": "library/nat-sci/physics/nuclear-energy/fusion.html",
    "href": "library/nat-sci/physics/nuclear-energy/fusion.html",
    "title": "Fusion",
    "section": "",
    "text": "A thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/nat-sci/physics/nuclear-energy/fusion.html#fusion-weapon-overview",
    "href": "library/nat-sci/physics/nuclear-energy/fusion.html#fusion-weapon-overview",
    "title": "Fusion",
    "section": "",
    "text": "A thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/nat-sci/physics/nuclear-energy/fusion.html#energy-sources",
    "href": "library/nat-sci/physics/nuclear-energy/fusion.html#energy-sources",
    "title": "Fusion",
    "section": "Energy Sources",
    "text": "Energy Sources\n\nBreakthroughs\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/mhd/index.html",
    "href": "library/nat-sci/physics/electromagnetism/mhd/index.html",
    "title": "MHD",
    "section": "",
    "text": "Magnetohydrodynamic (MHD) Propulsion\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/mhd/index.html#resources",
    "href": "library/nat-sci/physics/electromagnetism/mhd/index.html#resources",
    "title": "MHD",
    "section": "",
    "text": "Magnetohydrodynamic (MHD) Propulsion\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/mhd/index.html#summary",
    "href": "library/nat-sci/physics/electromagnetism/mhd/index.html#summary",
    "title": "MHD",
    "section": "Summary",
    "text": "Summary\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism.\nThe governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations. In the ideal MHD approximation, effects such as resistivity and viscosity are neglected, leading to a relatively simple set of governing equations:\n\nContinuity Equation: This equation ensures the conservation of mass.\n∂ρ/∂t + ∇·(ρv) = 0\nMomentum Equation: Combines Newton’s second law and the Lorentz force, accounting for the forces due to pressure gradients, gravity, and electromagnetic fields. In the absence of viscosity, this simplifies to:\nρ(∂v/∂t + v·∇v) = -∇p + ρg + (J×B)\nInduction Equation: Describes how the magnetic field evolves over time, given the fluid’s velocity and existing magnetic field.\n∂B/∂t = ∇×(v×B)\nEnergy Equation: This equation describes the conservation of energy, which is usually taken in the form of the first law of thermodynamics.\nAmpère’s Law with Maxwell’s Addition:\n∇×B = μ0J\nJ is the current density vector, B is the magnetic field, and μ0 is the magnetic permeability.\n\nIn these equations, ρ represents fluid density, v fluid velocity, p pressure, g gravitational acceleration, J current density, and B magnetic field.\nMHD has a wide range of applications, from studying astrophysical phenomena such as solar flares and accretion disks, to engineering applications like nuclear fusion research, liquid metal cooling in reactors, and even potential propulsion systems.\nHowever, real-world situations often involve non-ideal MHD where effects such as resistivity cannot be ignored. Understanding these effects often requires incorporating the full set of Maxwell’s equations and solving them alongside the fluid dynamics equations, which makes for a much more complex computational problem. In some non-ideal MHD scenarios, magnetic reconnection, turbulence, and other instabilities can occur, which are active research areas in this field."
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/index.html",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/index.html",
    "title": "Superconductors",
    "section": "",
    "text": "Piezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 1 of 2\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 2 of 2"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/index.html#resources",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/index.html#resources",
    "title": "Superconductors",
    "section": "",
    "text": "Piezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 1 of 2\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 2 of 2"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/index.html#summary",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/index.html#summary",
    "title": "Superconductors",
    "section": "Summary",
    "text": "Summary\nSuperconductivity is a macro-quantum state wherein a material displays (effectively) zero resistivity. (SUMMARIZE PT 1 1:09)\nA phenomenal overview of the phenomenon, from first principles, can be found on youtube.\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale\n\nPart 1 of 2\nPart 2 of 2\n\nBelow is practically nothing more than a summary of these lectures, plus some wikipedia content."
  },
  {
    "objectID": "library/nat-sci/physics/relativity/index.html",
    "href": "library/nat-sci/physics/relativity/index.html",
    "title": "Relativity",
    "section": "",
    "text": "Only Harmonic Springs and Gravity produce periodic motions\n\ntweet"
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html",
    "href": "library/nat-sci/physics/government/darpa-fellows.html",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#allegra-a.-beal-cohen",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#allegra-a.-beal-cohen",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#rebecca-chmiel",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#rebecca-chmiel",
    "title": "DARPA Fellows",
    "section": "Rebecca Chmiel",
    "text": "Rebecca Chmiel\nDr. Rebecca Chmiel joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. She received her Bachelor of Arts in chemistry and environmental studies from Colby College and her doctorate from the Massachusetts Institute of Technology and the Woods Hole Oceanographic Institution in marine biogeochemistry, and her research focused on the interactions between trace metal nutrients and marine phytoplankton. She has participated in four ocean research expeditions totaling over seven months at sea, and received the Antarctica Service Medal as part of her oceanographic fieldwork."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#alex-place",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#alex-place",
    "title": "DARPA Fellows",
    "section": "Alex Place",
    "text": "Alex Place\nDr. Alex Place joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. He received his Bachelor of Science in physics from the California Institute of Technology and his doctorate in electrical and computer engineering and materials science from Princeton University. His dissertation focused on improving the lifetimes of superconducting qubits, the building block of many industrial quantum computing efforts. He has also spent time developing nanoelectromechanical systems, novel solar cell designs, and medical devices."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#lt-krishnan-rajagopalan-usn",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#lt-krishnan-rajagopalan-usn",
    "title": "DARPA Fellows",
    "section": "LT Krishnan Rajagopalan, USN",
    "text": "LT Krishnan Rajagopalan, USN\nLt. Krishnan (Krish) Rajagopalan joined DARPA in March 2023 as part of the first cohort of DARPA Innovation Fellows. As a Navy Explosive Ordnance Disposal (EOD) Officer, he has led units of unmanned underwater vehicle operators and EOD divers tasked with countering explosive hazards underwater. He also served as a requirements officer on the staff of the Chief of Naval Operations and, most recently, as the operations officer at Expeditionary Exploitation Unit ONE (EXU-1). Rajagopalan is a qualified EOD Technician and Navy Diving Officer. He received a Bachelor of Science in operations research from the U.S. Naval Academy and a Master of Science in operations research from the Massachusetts Institute of Technology (MIT), where he was an MIT Lincoln Laboratory Military Fellow."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#graham-h.-reid",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#graham-h.-reid",
    "title": "DARPA Fellows",
    "section": "Graham H. Reid",
    "text": "Graham H. Reid\nDr. Graham Reid joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Reid received a Bachelor of Arts in physics from Kenyon College and a doctorate from University of Maryland, College Park. His dissertation research, conducted at NIST as a guest researcher through the Joint Quantum Institute, used ultracold atoms to study topological physics in dynamically evolving quantum systems."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#rené-m.-xavier",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#rené-m.-xavier",
    "title": "DARPA Fellows",
    "section": "René M. Xavier",
    "text": "René M. Xavier\nDr. René Xavier joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Xavier recently graduated from Florida Atlantic University, where she conducted research at the Harbor Branch Oceanographic Institute using shotgun metagenomics to analyze the biosynthesis of marine natural products. She received her Bachelor of Science in molecular, cellular, and developmental biology from the University of Washington in Seattle and was awarded a Fulbright Fellowship to study the regulation of reactive oxygen species at the Czech Institute of Experimental Botany in Prague. Prior to her academic career, she served as a nuclear electrician in the U.S. Navy where she was decorated with multiple honors including the Humanitarian Ribbon for her relief efforts during Hurricane Katrina."
  },
  {
    "objectID": "library/nat-sci/physics/government/darpa-fellows.html#alessandra-m.-zito",
    "href": "library/nat-sci/physics/government/darpa-fellows.html#alessandra-m.-zito",
    "title": "DARPA Fellows",
    "section": "Alessandra M. Zito",
    "text": "Alessandra M. Zito\nDr. Alessandra (Allie) Zito joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Zito received her Bachelor of Arts in chemistry and French language and literature from Johns Hopkins University and her doctorate in chemistry from the University of California, Irvine. Her graduate work focused on synthesizing and characterizing redox-active organic and inorganic molecules to be used for electrochemical carbon dioxide capture and concentration. She also has research experience in investigating catalyst loading on carbon aerogels, homogeneous and heterogeneous CO2 reduction catalysis, and electrode design for supercapacitors."
  },
  {
    "objectID": "library/nat-sci/physics/government/pentagon/pleads-fifth-exotic-materials.html",
    "href": "library/nat-sci/physics/government/pentagon/pleads-fifth-exotic-materials.html",
    "title": "Pentagon Pleads the Fifth",
    "section": "",
    "text": "Pentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs\narticle"
  },
  {
    "objectID": "library/nat-sci/physics/government/pentagon/pleads-fifth-exotic-materials.html#summary",
    "href": "library/nat-sci/physics/government/pentagon/pleads-fifth-exotic-materials.html#summary",
    "title": "Pentagon Pleads the Fifth",
    "section": "Summary",
    "text": "Summary\nThe blog post discusses the Pentagon’s inability to confirm or deny whether its UFO office, known as the All-domain Anomaly Resolution Office (AARO), has discovered any verifiable information to substantiate claims that any current or former U.S. programs have had possession or reverse-engineered materials from non-human intelligences or unknown origin. The Department of Defense (DoD) spokesperson, Susan Gough, stated that the AARO has not discovered any verifiable information to substantiate such claims. However, she declined to comment further on whether the term “extraterrestrial” could extend to materials of unknown origin or non-human intelligences."
  },
  {
    "objectID": "library/nat-sci/physics/government/pentagon/pleads-fifth-exotic-materials.html#notes",
    "href": "library/nat-sci/physics/government/pentagon/pleads-fifth-exotic-materials.html#notes",
    "title": "Pentagon Pleads the Fifth",
    "section": "Notes",
    "text": "Notes\n\nAll-domain Anomaly Resolution Office (AARO): The AARO is the Pentagon’s UFO office. It is currently unable to confirm or deny whether it has discovered any verifiable information to substantiate claims that any current or former U.S. programs have had possession or reverse-engineered materials from non-human intelligences or unknown origin.\nDepartment of Defense (DoD) Stance: The DoD spokesperson, Susan Gough, stated that the AARO has not discovered any verifiable information to substantiate such claims. However, she declined to comment further on whether the term “extraterrestrial” could extend to materials of unknown origin or non-human intelligences.\nAccess to Information: Gough confirmed that the AARO has not been denied access to any U.S. government program, past or present, during the course of its work. She also stated that the AARO may receive all UAP-related information, including any classified national security information involving military, intelligence, and intelligence-related activities, at all levels of classification regardless of any restrictive access controls, special access programs, or compartmented access programs.\nTitle 50 Authorities: Gough addressed the issue of Title 50 authorities, stating that such authorities are unrelated to the AARO’s ability to receive all UAP-related information through authorized disclosures.\nPublic Affairs Policies: Gough explained that it is DoD policy that all interactions with the news media at the Department level, including press queries, are coordinated with the Office of the Assistant to the Secretary of Defense for Public Affairs. She also noted that her portfolio includes UAP, AARO, and the Office of the Under Secretary of Defense for Intelligence & Security, as well as other issues and offices.\nWhistleblower Trust: The blog post mentions that the AARO, which currently reports to the Office of the Under Secretary of Defense for Intelligence & Security, is not trusted by numerous whistleblowers. The issue may stem from the AARO’s proximity to the OUSDI&S, which has previously been criticized for allegedly persecuting whistleblowers.\nConclusion: The blog post concludes by noting that the National Defense Authorization Act of 2023 means that the AARO should report directly to Deputy Secretary of Defense, Kathleen Hicks, and the Principal Deputy Director of National Intelligence on all operational and security matters relating to the AARO. However, there is no indication that this has been implemented yet."
  },
  {
    "objectID": "library/nat-sci/physics/unification/index.html",
    "href": "library/nat-sci/physics/unification/index.html",
    "title": "Unification",
    "section": "",
    "text": "Unitarity"
  },
  {
    "objectID": "library/nat-sci/physics/unification/index.html#resources",
    "href": "library/nat-sci/physics/unification/index.html#resources",
    "title": "Unification",
    "section": "",
    "text": "Unitarity"
  },
  {
    "objectID": "library/nat-sci/software/coding/rust/index.html",
    "href": "library/nat-sci/software/coding/rust/index.html",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/nat-sci/software/coding/rust/index.html#learning-resources",
    "href": "library/nat-sci/software/coding/rust/index.html#learning-resources",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/nat-sci/software/ai/bio/index.html",
    "href": "library/nat-sci/software/ai/bio/index.html",
    "title": "AI x Bio",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology"
  },
  {
    "objectID": "library/nat-sci/software/ai/bio/index.html#resources",
    "href": "library/nat-sci/software/ai/bio/index.html#resources",
    "title": "AI x Bio",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology"
  },
  {
    "objectID": "library/nat-sci/crypto/mev/overview.html",
    "href": "library/nat-sci/crypto/mev/overview.html",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay"
  },
  {
    "objectID": "library/nat-sci/crypto/mev/overview.html#dashboards-tools",
    "href": "library/nat-sci/crypto/mev/overview.html#dashboards-tools",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay"
  },
  {
    "objectID": "library/nat-sci/crypto/mev/overview.html#research",
    "href": "library/nat-sci/crypto/mev/overview.html#research",
    "title": "Overview",
    "section": "Research",
    "text": "Research\n\nEarly Research\n\nEnter the Hydra\nThe Cost of Decentralization in 0x and EtherDelta\nFlash Boys 2.0\nOrder-Fairness for Byzantine Consensus\nThemis: Fast, Strong Order-Fairness in Byzantine Consensus\nMEV… Wat Do?\nEthereum is a Dark Forest\nFlashbots: Frontrunning the MEV Crisis\n\n\n\nGeneral\n\nStudying Flash Loan Attacks | paper\nMEV by Galaxy Digital | Blog Pt 2\nModular MEV Write-up\nPerformant routing and latency benchmarking for Ethereum RPC and Relay Service Providers\nHigh Granularity Cex Data | tardis.dev\nMEV in Fixed Price Auctions | paper | tweet\nMEV Boost Capella Upgrades | article\nFrontier Research | website\nSo you want to run a builder?\nHow to Fix Ethereum’s MEV Problem\nMEV in ETH2 - An Early Exploration\nImproving PoS Economic Security via MEV Redistribution\nTowards a Theory of MEV I\nFlashbots Research Repository\n\n\n\nMEV-Boost / Proposer-Builder Separation\n\nProposer Boost Considerations\nMEV-Boost Plan\n\n\n\nVideos & Talks\n\nMEV Day\n\nVideo Recap\n\nEncode x Wintermute: MEV with Robert Miller\nStanford MEV Workshop Recording\nMEVconomics Playlist | youtube\nStanford Blockchain Conference (SBC’23)\nRecordings: Day 1 | Day 2 | Day 3\nMEV Workshop at SBC’23 | Recording\n\n\n\nProtocols, and Implementation Resources\nUniswap V3 Book - docs\nAutomated Market Making and Arbitrage Profits in the Presence of Fees - paper\nMEV Capturing AMM - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\nA Framework for Building Searchers - article\nSomeone’s Mega-resource on MEV - notion\nRunning MEV-Relay at Scale - notion\nLatency Arms Race - post\nFBAs (frequent batch auctions) are a nerd snipe - tweet\nJaredFromSubway.eth’s Access Lists - etherscan"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/layer-2/index.html",
    "href": "library/nat-sci/crypto/blockchains/evm/layer-2/index.html",
    "title": "Layer 2 Rollups",
    "section": "",
    "text": "Vitalik: An Incomplete Guide to Rollups\nA Rollup-Centric Ethereum Roadmap\nArbitrum: Scalable, Private Smart Contracts\nVitalik: An Incomplete Guide to Rollups"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/tooling.html",
    "href": "library/nat-sci/crypto/blockchains/evm/tooling.html",
    "title": "Tools & Resources",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/tooling.html#tools",
    "href": "library/nat-sci/crypto/blockchains/evm/tooling.html#tools",
    "title": "Tools & Resources",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/tooling.html#resources",
    "href": "library/nat-sci/crypto/blockchains/evm/tooling.html#resources",
    "title": "Tools & Resources",
    "section": "Resources",
    "text": "Resources\n\nSolidity Data Representation"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/index.html",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/index.html",
    "title": "Bitcoin",
    "section": "",
    "text": "Bitcoin: A Peer to Peer Electronic Cash System\nBitcoin Lightning Network\nSegregated Witness Benefits\nVulnerability | tweet\n\nExplorer | btcscan"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/versions.html",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/versions.html",
    "title": "The Tech",
    "section": "",
    "text": "Bitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/versions.html#transaction-versions",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/versions.html#transaction-versions",
    "title": "The Tech",
    "section": "",
    "text": "Bitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/index.html",
    "href": "library/nat-sci/crypto/blockchains/index.html",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/index.html#early-contributions-papers",
    "href": "library/nat-sci/crypto/blockchains/index.html#early-contributions-papers",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/index.html#whitepapers",
    "href": "library/nat-sci/crypto/blockchains/index.html#whitepapers",
    "title": "Blockchains",
    "section": "Whitepapers",
    "text": "Whitepapers\n\nBitcoin\nEthereum: A Next-Generation Smart Contract and Decentralized Application Platform\nEthereum: A Secure Decentralized Generalized Transaction Ledger\nZerocash: Decentralized Anonymous Payments from Bitcoin\nCosmos: Internet of Blockchains\nSolana: A new Architecture for a High Performance Blockchain\nCardano\nAlgorand: Scaling Byzantine Agreements for Cryptocurrencies\nAvalanche Platform\nThe Spacemesh Protocol"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/index.html#recent-general",
    "href": "library/nat-sci/crypto/blockchains/index.html#recent-general",
    "title": "Blockchains",
    "section": "Recent, General",
    "text": "Recent, General\n\nThe Tie: Solving the Blockchain Trilemma\nEndgame: Proof of Governance"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/index.html",
    "href": "library/nat-sci/crypto/blockchains/solana/index.html",
    "title": "Solana",
    "section": "",
    "text": "How will Solana Improve its Stability?\n\n\nFee Markets\n\nPriority Fees Github Issue\nDune Query: % of Sol Txs with Fee above base\n\n\n\nThe Solana Validator\n\nFiredancer: A New Client by Jump\nValidator Economics on Solana"
  },
  {
    "objectID": "library/nat-sci/crypto/apps/ethena/ethena.html",
    "href": "library/nat-sci/crypto/apps/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "About Ethena protocol…"
  },
  {
    "objectID": "library/nat-sci/crypto/events/2023/08/ygg.html",
    "href": "library/nat-sci/crypto/events/2023/08/ygg.html",
    "title": "YGG Manipulation",
    "section": "",
    "text": "August 7\n9:04 am YGG in top 3 volume, followed by shitcoins with negative funding (heavy shorts)\nHsaka’s Take | tweet\nAug 6, 7:04am YGG “looking spicy” says Nik’s quant\nReported at 9:52am Binance increased the funding rate settlement frequency from 8 hours to 2 hours\nReminder that 2018 scam pumps were even crazier\n\nso much commentary and ‘hate’ on the YGG situation when people don’t remember the summer of 2022 where we had 10x pumps in 1 minute on shitcoins. oh sweet children you haven’t experienced the true depths of market manipulation yet"
  },
  {
    "objectID": "library/social/finance/finance-101/finance-101.html",
    "href": "library/social/finance/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/social/finance/trading/trades/JGByields/index.html",
    "href": "library/social/finance/trading/trades/JGByields/index.html",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/social/finance/trading/trades/JGByields/index.html#resources",
    "href": "library/social/finance/trading/trades/JGByields/index.html#resources",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/social/finance/quant-trading/quant-trading.html",
    "href": "library/social/finance/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "library/social/politics/corruption/index.html#ukraine",
    "href": "library/social/politics/corruption/index.html#ukraine",
    "title": "Corruption",
    "section": "Ukraine",
    "text": "Ukraine\n\nUN, Zakharov\nThe son of Alexander Zakharov, mastermind of Russia’s killer drones that attack civilians in Ukraine, is now interning at the U.N.’s disarmament institute. UNIDIR says he was selected through a “competitive and transparent recruitment process…on the basis of his qualifications, skills and experience for the position.”\nTribune de Geneve: “The presence of Zakharov’s son in Geneva implies that Switzerland issued him with a visa, which is compulsory for Russian nationals wishing to enter and stay in the country. When questioned, the Swiss State Secretariat for Migration would not comment on the case. Alexander Zakharov’s son did not respond to our messages.”\n\ntweet\narticle"
  },
  {
    "objectID": "library/social/politics/deep-state.html",
    "href": "library/social/politics/deep-state.html",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/social/politics/deep-state.html#resources",
    "href": "library/social/politics/deep-state.html#resources",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/life/environment/climate/index.html",
    "href": "library/life/environment/climate/index.html",
    "title": "Climate Change",
    "section": "",
    "text": "Climate is an NP-complete problem. This can be proven by a reduction to turbulent mechanics. I do not abide by the “general” modern climate-change (Greta) view. However, it’s ridiculous to ignore the recent and rapid alterations in atmospheric content as a product of human industrialization."
  },
  {
    "objectID": "library/life/environment/climate/index.html#a-collection-of-views-and-information",
    "href": "library/life/environment/climate/index.html#a-collection-of-views-and-information",
    "title": "Climate Change",
    "section": "A Collection of Views and Information",
    "text": "A Collection of Views and Information\n\nThe North Atlantic Sea Surface Tempurature Anomoly\nTweet: We’ve been accidentally geoengineering for decades… then we stopped"
  },
  {
    "objectID": "library/life/health/covid/psyop.html",
    "href": "library/life/health/covid/psyop.html",
    "title": "psyop",
    "section": "",
    "text": "German MEP, Christine Anderson: Governments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”\nFull interview"
  },
  {
    "objectID": "library/life/health/covid/psyop.html#germany",
    "href": "library/life/health/covid/psyop.html#germany",
    "title": "psyop",
    "section": "",
    "text": "German MEP, Christine Anderson: Governments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”\nFull interview"
  },
  {
    "objectID": "library/life/health/covid/vaccine.html",
    "href": "library/life/health/covid/vaccine.html",
    "title": "mRNA Vaccine",
    "section": "",
    "text": "Australia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis"
  },
  {
    "objectID": "library/life/health/covid/vaccine.html#resources",
    "href": "library/life/health/covid/vaccine.html#resources",
    "title": "mRNA Vaccine",
    "section": "",
    "text": "Australia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis"
  },
  {
    "objectID": "library/life/health/covid/vaccine.html#horse-dewormer-a-necessary-narrative-for-fda-emergency-authorization",
    "href": "library/life/health/covid/vaccine.html#horse-dewormer-a-necessary-narrative-for-fda-emergency-authorization",
    "title": "mRNA Vaccine",
    "section": "“Horse Dewormer”, A necessary Narrative for FDA emergency Authorization",
    "text": "“Horse Dewormer”, A necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\nTODO"
  },
  {
    "objectID": "library/life/health/covid/vaccine.html#mrna-vaccine-x-myocarditispericarditis",
    "href": "library/life/health/covid/vaccine.html#mrna-vaccine-x-myocarditispericarditis",
    "title": "mRNA Vaccine",
    "section": "mRNA Vaccine x Myocarditis/Pericarditis",
    "text": "mRNA Vaccine x Myocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSERUM VAX SPIKE\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/life/health/covid/vaccine.html#mrna-platform",
    "href": "library/life/health/covid/vaccine.html#mrna-platform",
    "title": "mRNA Vaccine",
    "section": "mRNA Platform",
    "text": "mRNA Platform\nExcerpt from Brett Weinstein\n\nThe mRNA platform is brilliant. But it has a giant gaping flaw in it, which is; Any cell of yours that produces a foreign protein, will be targetted by your immune system and destroyed. You will create an autoimmune disorder. When it works. How do you keep it out of your heart. Not by coding it in a lipid nanoparticle. So, they had no way to deliver it safely to market. So then they had a pandemic, the emergency allowed them to do it. This technology, in my opinion, was at least 3 decades out from being usefully and safely deployed at all, if at all. They did not want to wait, this crisis gave them the opportunity not to wait. And now, they will blame the spike protein, we picked the wrong protein. When in actual fact there are 2 problems, the spike protein and the platform itself."
  },
  {
    "objectID": "library/life/health/cognition/index.html",
    "href": "library/life/health/cognition/index.html",
    "title": "Cognition",
    "section": "",
    "text": "Olfactory enrichment (aroma therapy) at night produces improvements in both cognitive and neural functioning.\nOvernight olfactory enrichment using an odorant diffuser improves memory and modifies the uncinate fasciculus in older adults\nResults: A statistically significant 226% improvement was observed in the enriched group compared to the control group on the Rey Auditory Verbal Learning Test and improved functioning was observed in the left uncinate fasciculus, as assessed by mean diffusivity.\nConclusion: Minimal olfactory enrichment administered at night produces improvements in both cognitive and neural functioning. Thus, olfactory enrichment may provide an effective and low-effort pathway to improved brain health."
  },
  {
    "objectID": "library/life/health/physiology/index.html",
    "href": "library/life/health/physiology/index.html",
    "title": "Physiology",
    "section": "",
    "text": "Why does one stick their tongue out when performing a meticulous task with hand tools? Why do tennis players (and martial artist) shout alongside their movements? On the innate linking of the hands and mouth: - The Hidden Brain Connections Between Our Hands and Tongues - Effect of Syllable Articulation on Precision and Power Grip Performance - The initiation of a hand grip is delayed by silently reading an incompatible syllable - Motor and visual-motor functions of the premotor cortex - Complex Movements Evoked by Microstimulation of Precentral Cortex\nMotor proficiency predicts linguistic ability\n\nLanguage as a Tool: Motor Proficiency Using a Tool Predicts Individual Linguistic Abilities"
  },
  {
    "objectID": "library/life/health/physiology/index.html#reads",
    "href": "library/life/health/physiology/index.html#reads",
    "title": "Physiology",
    "section": "",
    "text": "Why does one stick their tongue out when performing a meticulous task with hand tools? Why do tennis players (and martial artist) shout alongside their movements? On the innate linking of the hands and mouth: - The Hidden Brain Connections Between Our Hands and Tongues - Effect of Syllable Articulation on Precision and Power Grip Performance - The initiation of a hand grip is delayed by silently reading an incompatible syllable - Motor and visual-motor functions of the premotor cortex - Complex Movements Evoked by Microstimulation of Precentral Cortex\nMotor proficiency predicts linguistic ability\n\nLanguage as a Tool: Motor Proficiency Using a Tool Predicts Individual Linguistic Abilities"
  },
  {
    "objectID": "library/life/health/covid/index.html",
    "href": "library/life/health/covid/index.html",
    "title": "covid",
    "section": "",
    "text": "Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/life/health/covid/index.html#resources",
    "href": "library/life/health/covid/index.html#resources",
    "title": "covid",
    "section": "",
    "text": "Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/life/environment/animals/index.html",
    "href": "library/life/environment/animals/index.html",
    "title": "Animals",
    "section": "",
    "text": "The Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet.\n\ntweet\ndiscovery article"
  },
  {
    "objectID": "library/life/environment/animals/index.html#barbery-lions",
    "href": "library/life/environment/animals/index.html#barbery-lions",
    "title": "Animals",
    "section": "",
    "text": "The Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet.\n\ntweet\ndiscovery article"
  },
  {
    "objectID": "library/social/politics/index.html",
    "href": "library/social/politics/index.html",
    "title": "Geopolitics",
    "section": "",
    "text": "Arab support to Egypt, as of Dec-2022\nLong-term deposits = $15b, from: - UAE = $5.7b - Saudi = $5.3b - Kuwait = $4b\nShort-term deposits = $14.9b, from: - UAE = $5b - Saudi = $5b - Qatar = $4b (from $3b in Mar) - Libya = $0.9b (from 0 in Mar)"
  },
  {
    "objectID": "library/social/politics/reads/index.html",
    "href": "library/social/politics/reads/index.html",
    "title": "Reads",
    "section": "",
    "text": "Peter Thiel: Straussian Moment\nLegacy of Ashes"
  },
  {
    "objectID": "library/social/politics/corruption/biden.html",
    "href": "library/social/politics/corruption/biden.html",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview"
  },
  {
    "objectID": "library/social/politics/corruption/biden.html#burisma",
    "href": "library/social/politics/corruption/biden.html#burisma",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview"
  },
  {
    "objectID": "library/social/finance/index.html",
    "href": "library/social/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "library/social/finance/trading/trades/comstock/index.html",
    "href": "library/social/finance/trading/trades/comstock/index.html",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/social/finance/trading/trades/comstock/index.html#resources",
    "href": "library/social/finance/trading/trades/comstock/index.html#resources",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/nat-sci/crypto/rekt/index.html",
    "href": "library/nat-sci/crypto/rekt/index.html",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2"
  },
  {
    "objectID": "library/nat-sci/crypto/rekt/index.html#resources",
    "href": "library/nat-sci/crypto/rekt/index.html#resources",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2"
  },
  {
    "objectID": "library/nat-sci/crypto/apps/hyperliquid/index.html",
    "href": "library/nat-sci/crypto/apps/hyperliquid/index.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/nat-sci/crypto/apps/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "href": "library/nat-sci/crypto/apps/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/nat-sci/crypto/apps/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "href": "library/nat-sci/crypto/apps/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/nat-sci/crypto/cex/index.html",
    "href": "library/nat-sci/crypto/cex/index.html",
    "title": "CEXs",
    "section": "",
    "text": "SEC Files 13 Charges Against Binance Entities and Founder Changpeng Zhao - release\nBinance Commingled Customer Funds and Company Revenue - article\nBinance doesn’t have Enough BCH to Process Withdrawals - tweet"
  },
  {
    "objectID": "library/nat-sci/crypto/cex/index.html#binance",
    "href": "library/nat-sci/crypto/cex/index.html#binance",
    "title": "CEXs",
    "section": "",
    "text": "SEC Files 13 Charges Against Binance Entities and Founder Changpeng Zhao - release\nBinance Commingled Customer Funds and Company Revenue - article\nBinance doesn’t have Enough BCH to Process Withdrawals - tweet"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/events/mango.html",
    "href": "library/nat-sci/crypto/blockchains/solana/events/mango.html",
    "title": "Mango Rekt",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/events/mango.html#overview",
    "href": "library/nat-sci/crypto/blockchains/solana/events/mango.html#overview",
    "title": "Mango Rekt",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/events/mango.html#how-it-worked",
    "href": "library/nat-sci/crypto/blockchains/solana/events/mango.html#how-it-worked",
    "title": "Mango Rekt",
    "section": "How it worked",
    "text": "How it worked\nAttacker had two accounts, let’s call them account A and account B.\n\nAttacker funds account A with $5 million of USDC, to be used as collateral for on-chain positions.\nAttacker then offered out (sold short) ~483 million MNGO tokens, trading at $0.038 at the time.\nAttacker then funds account B with $5 million USDC, and purchases those ~438 million MNGO at $0.0382\nAttacker then purchases MNGO on the Spot market, artificially increasing its price. The price of mango reached $0.91 (a 24x increase).\nAt this new inflated price, account B was in the money for ~ $423 million. He used this account value to take out a loan of $116 million consisting of several tokens.\nAfter the attack, the MNGO/USD spot market then traded down to $0.02, which put account A in the money. However, Mango protocol was effectively drained of all liquidity, so account A could not be paid out."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/events/mango.html#summary",
    "href": "library/nat-sci/crypto/blockchains/solana/events/mango.html#summary",
    "title": "Mango Rekt",
    "section": "Summary",
    "text": "Summary\nMango Markets were designed to give loans at a certain collateralization ratio (e.g. 400%), but they used the spot market as an oracle for “fair price” of the token. Thus, tokens with low liquidity could be easily manipulated such that the protocol believes “fair price” is multiples above what anyone would purchase the token at in free markets."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/events/mango.html#future-mitigation",
    "href": "library/nat-sci/crypto/blockchains/solana/events/mango.html#future-mitigation",
    "title": "Mango Rekt",
    "section": "Future Mitigation",
    "text": "Future Mitigation\nMitigating this type of attack is as simple as fixing the Oracle mechanism. For example, one could use a 24hr rolling average price to determine “fair value” for lending, which would make the market manipulator’s attack much more difficult (must pump price for 24 hour rather than a few seconds)."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/solana/events/mango.html#credits-commentary",
    "href": "library/nat-sci/crypto/blockchains/solana/events/mango.html#credits-commentary",
    "title": "Mango Rekt",
    "section": "Credits & Commentary",
    "text": "Credits & Commentary\n\nNotice of Exploit by Otter Security\nEarly Analysis of What Happened\nSam Bankman Freid on How to Protect from this Attack\nAttacker Admitting his Involvement"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands\n\nHow to run a Bitcoin full node. I have decided to run a node 5 minutes ago, so I am making this tutorial as I go. Let’s see how long it takes."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#resources",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#resources",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands\n\nHow to run a Bitcoin full node. I have decided to run a node 5 minutes ago, so I am making this tutorial as I go. Let’s see how long it takes."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#short-version",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#short-version",
    "title": "Running Bitcoin Core",
    "section": "Short Version",
    "text": "Short Version\n# download software\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n# extract contents\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\n# install extracted contents to local bin\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*\n# check version\nbitcoind --version\n# start the software\nbitcoind -daemon -txindex\n# check status\nbitcoin-cli -getinfo\n# check block count\nbitcoin-cli getblockcount\n# stop the software\nbitcoin-cli stop"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 1: Download Bitcoin Core",
    "text": "Step 1: Download Bitcoin Core\nAs of today (Feb 11, 2023), the latest version of Bitcoin Core is 24.0.1. You can find the download links here\n\nCopy the link address of the version you need - I am running Linux Ubuntu so I will use the x86_64-linux-gnu.tar.gz\n\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n\nExtract the contents\n\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\nThis downloads the contents into /usr/local/ directory"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "title": "Running Bitcoin Core",
    "section": "Step 2: Install Bitcoin from Downloaded Contents",
    "text": "Step 2: Install Bitcoin from Downloaded Contents\nRun this command (idk the details who cares)\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 3: Run Bitcoin Core",
    "text": "Step 3: Run Bitcoin Core\nbitcoind -daemon\nYou can check the progress of syncing with bitcoin-cli -getinfo\nThis should produce something that looks like this\nubuntu@REDACTED:~$ bitcoin-cli -getinfo\nChain: main\nBlocks: 235213\nHeaders: 775994\nVerification progress: ▒░░░░░░░░░░░░░░░░░░░░ 2.1719%\nDifficulty: 10076292.88341872\n\nNetwork: in 0, out 10, total 10\nVersion: 240001\nTime offset (s): -1\nProxies: n/a\nMin tx relay fee rate (BTC/kvB): 0.00001000\nCompare “blocks” with the latest block on the chain."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#done",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/btc-core.html#done",
    "title": "Running Bitcoin Core",
    "section": "Done!",
    "text": "Done!\nAll in all, it took me 34 minutes to figure this out. Easier than running Go Ethereum, and far easier than running Solana core. Incredibly impressive!"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html",
    "title": "Ordinals",
    "section": "",
    "text": "How to Split Ordinals Mixed in a Single UTXO - article\nSplitting Bitcoin from Inscriptions on Ordinals Wallet - article"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#tech-stuff",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#tech-stuff",
    "title": "Ordinals",
    "section": "Tech Stuff",
    "text": "Tech Stuff\n# create ordinal wallet\nord wallet create\n\n# receive sats\nord wallet receive\n\n# create inscription\nord wallet inscribe --fee-rate 22 &lt;FILE&gt;\n\nIssues\nTransport error upon inscription attempt here\nInscriptions taking too long here\nIndexing not working here\nHow much does an inscription cost? - calculator"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#guides",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#guides",
    "title": "Ordinals",
    "section": "Guides",
    "text": "Guides\n\nHow to create\nHow to buy\nMinting Ordinals"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#btc-naming-service",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#btc-naming-service",
    "title": "Ordinals",
    "section": "BTC Naming Service",
    "text": "BTC Naming Service\nCasey Rodarmor’s Thoughts: 26:00 min mark - here\n\nLook up top level domain (com)\nFind the output its in, and get address of the output\nGet authenticated encrypted channel with the person that owns that\nAsk “who has ‘myname.com’?” and they send you signed message of the pubkey, and then you get IP address. But no good names exist yet.\n\n\nThings I’ve Learned on the Ordinals Journey\nBitcoin has several address formats.\n\nLegacy Addresses\nScript Addresses\nSegwit Addresses\nTaproot Addresses\n\nOrdinals uses Taproot Addresses, which result from a recent upgrade aimed to introduce more reobust security, privacy, and scalability."
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#other-stuff",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#other-stuff",
    "title": "Ordinals",
    "section": "Other Stuff",
    "text": "Other Stuff\nWhat is it?\n\nanswered here\n\nResources\n\nHandbook\nGithub\nBIP\nMainnet Explorer\nTestnet (Signet) Explorer\nGuide\nNo Code Mint Platform\n\nCool Info\nOn August 21st, 2012, Charlie Lee posted a proposal to add proof-of-stake to Bitcoin to the Bitcoin Talk forum. This wasn’t an asset scheme, but did use the ordinal algorithm, and was implemented but never deployed.\nOn October 8th, 2012, jl2012 posted a scheme to the the same forum which uses decimal notation and has all the important properties of ordinals. The scheme was discussed but never implemented.\nGud Video\n\nyoutube\ninterview\n\nMultimint - video"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#mint-an-nft",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#mint-an-nft",
    "title": "Ordinals",
    "section": "Mint an NFT",
    "text": "Mint an NFT\n# inscribe\nord wallet inscribe --fee-rate 20 ABSOLUTE_FILE_PATH"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#test",
    "href": "library/nat-sci/crypto/blockchains/bitcoin/ordinals.html#test",
    "title": "Ordinals",
    "section": "TEST",
    "text": "TEST\nI inscribed an image of Logan Tobias onto the Bitcoin blockchain.\n$ ord wallet inscribe --fee-rate 20 /home/ubuntu/server-share/logan_resized.jpeg \n{\n  \"commit\": \"93f5630a6f6eb49235fb25878df06563f509ff5d5d89da6a4092af5d68eb4afd\",\n  \"inscription\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8i0\",\n  \"reveal\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8\",\n  \"fees\": 282600\n}\nSat: 465805240538644\n\nOrdinal Project\nThis is a short guide on how to mint multiple ordinals quickly.\n\nCreate a Sparrow wallet to generate multiple UTXOs.\nCalculate cost per ordinal.\n\n\ncalculator\nmempool Add 600 (dust limit) + 10,000 (ordinal fee) to sats amount\n\nWe have: 132,000 sats per ordinal + 600 + 10,000 = 142,600 sats per ordinal"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/consensus.html",
    "href": "library/nat-sci/crypto/blockchains/consensus.html",
    "title": "Consensus",
    "section": "",
    "text": "Tendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/consensus.html#whitepapers",
    "href": "library/nat-sci/crypto/blockchains/consensus.html#whitepapers",
    "title": "Consensus",
    "section": "",
    "text": "Tendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/consensus.html#research",
    "href": "library/nat-sci/crypto/blockchains/consensus.html#research",
    "title": "Consensus",
    "section": "Research",
    "text": "Research\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/consensus.html#consensus-attacks",
    "href": "library/nat-sci/crypto/blockchains/consensus.html#consensus-attacks",
    "title": "Consensus",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/consensus.html#events",
    "href": "library/nat-sci/crypto/blockchains/consensus.html#events",
    "title": "Consensus",
    "section": "Events",
    "text": "Events\nMay 12, 2023: Ethereum Consensus Issues\n\ntweet one\ntweet two"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/index.html",
    "href": "library/nat-sci/crypto/blockchains/evm/index.html",
    "title": "EVM",
    "section": "",
    "text": "Ethereum Data Structures"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/index.html#resources",
    "href": "library/nat-sci/crypto/blockchains/evm/index.html#resources",
    "title": "EVM",
    "section": "",
    "text": "Ethereum Data Structures"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html",
    "href": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#consensus",
    "href": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#consensus",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#consensus-attacks",
    "href": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#consensus-attacks",
    "title": "Ethereum",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#proposer-builder-separation",
    "href": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#proposer-builder-separation",
    "title": "Ethereum",
    "section": "Proposer Builder Separation",
    "text": "Proposer Builder Separation\n\nMEV-Boost Plan\nProposer Boost Considerations\nMEV-Boost in a Nutshell\nPBS Censorship Resistance\nState of research: increasing censorship resistance of transactions under PBS\nPBS Censorship-Resistance Alternatives\nCurrent crList Proposal"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#sharding",
    "href": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#sharding",
    "title": "Ethereum",
    "section": "Sharding",
    "text": "Sharding\n\nDanksharding\nPolynya on Danksharding\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding"
  },
  {
    "objectID": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#general",
    "href": "library/nat-sci/crypto/blockchains/evm/ethereum/index.html#general",
    "title": "Ethereum",
    "section": "General",
    "text": "General\nEthereum Inactivity Leak - documentation\nIntent Based Architectures and Their Risks - article\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses - article\nAccount Abstraction Using Alt Mempool - article\nEIP-1153: Transient Storage - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\n2FA ZK Rollups using SGX - article\nClient Bootnode Concerns - article\nCollecting Signatures for Faster Finality - article\nProof of Solvency - article\nState of Testnets - tweet\nEth Withdrawals FAQ - website\n100 Days After the Merge - see section “Looking ahead to Shanghai” - article\nWithdrawals after Shanghai - blog\nExecution Layer Meeting - video\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs - article\nEthereum Data Structures - paper\nEth2Book: A lot of Good Info on Ethereum - documentation\nVitalik: An Incomplete Guide to Rollups - article\nA Rollup-Centric Ethereum Roadmap - article\nOfficial Merge Announcement - article\nValidator Withdrawal design - article\nVitalik: the roads not taken - article"
  },
  {
    "objectID": "library/nat-sci/crypto/mev/amm/index.html",
    "href": "library/nat-sci/crypto/mev/amm/index.html",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/nat-sci/crypto/mev/amm/index.html#papers-research",
    "href": "library/nat-sci/crypto/mev/amm/index.html#papers-research",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/nat-sci/crypto/mev/amm/index.html#strategies",
    "href": "library/nat-sci/crypto/mev/amm/index.html#strategies",
    "title": "MEV on AMMs",
    "section": "Strategies",
    "text": "Strategies\n\nIncoming Swap\n\nSandwiching\n\nIncoming buy, deliver bundle {mybuy, buy, mysell}\nIncoming sell (requires inventory), deliver bundle {mysell, sell, mybuy} (JaredFromSubway’s claim to fame and riches)\n\n\n\nJIT Liquidity\nIncoming transaction, frontrun it with a large liquidity position at the optimal tick bounds\n\n\nJIT + Sandwich Combo\nThis is the optimal strategy assuming negligible gas fees\n\nIncoming buy: frontrun buy, add LP, victim buy, remove LP, backrun sell\nIncoming sell: opposite\n\nResources on it: tweet 1\nExample bot executing this etherscan\nList of examples in prod tweet\n\n\n\nIncoming Liquidity Provision Position\n\nLP Addition\nIncoming LP Addition, deliver bundle {mybuy, lpAdd, mysell} - since liquidity is greater during sell, face less slippage - net sell price &gt; net buy price\n\n\nLP Removal\nIncoming LP Removal, deliver bundle {mysell, lpRemove, mybuy} - since liquidity is greater during buy, face less slippage. End up with more tokens than you started with. - net sell price &lt; net buy price"
  },
  {
    "objectID": "library/nat-sci/software/ai/history-of-ai/history-of-ai.html",
    "href": "library/nat-sci/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "This is a History of AI."
  },
  {
    "objectID": "library/nat-sci/physics/unification/string-theory/index.html",
    "href": "library/nat-sci/physics/unification/string-theory/index.html",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/nat-sci/physics/unification/string-theory/index.html#resources",
    "href": "library/nat-sci/physics/unification/string-theory/index.html#resources",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/nat-sci/physics/black-holes/index.html",
    "href": "library/nat-sci/physics/black-holes/index.html",
    "title": "Black Holes",
    "section": "",
    "text": "Math Proof Draws New Boundaries Around Black Hole Formation\n\nQuanta article\nPaper"
  },
  {
    "objectID": "library/nat-sci/physics/government/index.html",
    "href": "library/nat-sci/physics/government/index.html",
    "title": "Government",
    "section": "",
    "text": "Making Muons for Scientific Discovery, National Security\nX-65 | Control of Revolutionary Aircraft with Novel Effectors (CRANE)\nAn Evening With Director of National Intelligence Avril Haines\nThe new Schumer-Rounds Amendment (“UAP Disclosure Act”) was added to the FY 2024 National Defense Authorization Act (S. 2226) without objection.\n\nPentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/nat-sci/physics/government/index.html#resources",
    "href": "library/nat-sci/physics/government/index.html#resources",
    "title": "Government",
    "section": "",
    "text": "Making Muons for Scientific Discovery, National Security\nX-65 | Control of Revolutionary Aircraft with Novel Effectors (CRANE)\nAn Evening With Director of National Intelligence Avril Haines\nThe new Schumer-Rounds Amendment (“UAP Disclosure Act”) was added to the FY 2024 National Defense Authorization Act (S. 2226) without objection.\n\nPentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/nat-sci/physics/government/index.html#directed-energy",
    "href": "library/nat-sci/physics/government/index.html#directed-energy",
    "title": "Government",
    "section": "Directed Energy",
    "text": "Directed Energy\n\nD-Wave and Davidson Technologies Introduce New Innovations to Advance National Defense Efforts"
  },
  {
    "objectID": "library/nat-sci/physics/government/nuclear.html",
    "href": "library/nat-sci/physics/government/nuclear.html",
    "title": "Nuclear Stance",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/nat-sci/physics/government/nuclear.html#resources",
    "href": "library/nat-sci/physics/government/nuclear.html#resources",
    "title": "Nuclear Stance",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html",
    "title": "LK-99",
    "section": "",
    "text": "Superconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise."
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html#tldr",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html#tldr",
    "title": "LK-99",
    "section": "",
    "text": "Superconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise."
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html#timeline",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html#timeline",
    "title": "LK-99",
    "section": "Timeline",
    "text": "Timeline\nJuly 22:\n\nThe First Room-Temperature Ambient-Pressure Superconductor\nOriginal paper(s) is(are) released twice, the first time (suspected to rush to beat the second) with only 3 authors, making the team eligible for a noble prize.\n\nJuly 26:\n\nI predict the superconductor hype (“we are so fucking back”) is all noise.\n\nJuly 27:\n\nDouglas Natelson publishes a blog post expressing a pessemistic view on the whole debacle.\nCondensed Matter Theory Center deconstructs “the non-experimental parts of the Korean room temp SC claims.”\n\nHype ensues, and magnifies, as people rush to replicate the study/results.\nJuly 29:\n\nFirst-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\n\nJuly 31:\n\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n\nA (failed?) replication attempt out of Beijing; shows semiconductor behavior, not super\n\nSemiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)\n\nAugust 4:\nA theoretical explanation for LK-99 is released on July 31, 2023, by Sinead Griffin out of Berkeley.\n\nOrigin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\nAugust 6:\nGroup claims/proves LK-99 is a ferromagnet (NOT a superconductor)\n\nFerromagnetic half levitation of LK-99-like synthetic samples"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html#asides",
    "href": "library/nat-sci/physics/electromagnetism/superconductor/lk99.html#asides",
    "title": "LK-99",
    "section": "Asides",
    "text": "Asides\nAuthor of the original paper, Hyun-Tak Kim, from 2018\nWhy does BCS theory fail to explain superconductivity at high temperatures?"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/index.html",
    "href": "library/nat-sci/physics/electromagnetism/index.html",
    "title": "Electromagnetism",
    "section": "",
    "text": "Dr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/nat-sci/physics/electromagnetism/index.html#resources",
    "href": "library/nat-sci/physics/electromagnetism/index.html#resources",
    "title": "Electromagnetism",
    "section": "",
    "text": "Dr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/nat-sci/physics/uap/early/index.html",
    "href": "library/nat-sci/physics/uap/early/index.html",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/nat-sci/physics/uap/early/index.html#unordered-stuff",
    "href": "library/nat-sci/physics/uap/early/index.html#unordered-stuff",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/nat-sci/physics/uap/early/index.html#ulat-1",
    "href": "library/nat-sci/physics/uap/early/index.html#ulat-1",
    "title": "Early",
    "section": "ULAT-1",
    "text": "ULAT-1\nWordpress article\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\na.    UF6 in metallic form;\nb.    hydrogen-fluoride gas;\nc.    water and uranium tetra fluoride;\nd.    powdered magnesium and potassium chlorate,\ne.    metal similar to lead with a chocolate brown color;\nf.   U-235 in metallic form;\ng.   plastic-like material similar to NE 102,\nh.    Beryllium,\ni.    Pure aluminium;\nj.   Thorium isotope material;\nj.   Plutonium powder.\n\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns."
  },
  {
    "objectID": "library/nat-sci/physics/uap/early/index.html#project-white-hot",
    "href": "library/nat-sci/physics/uap/early/index.html#project-white-hot",
    "title": "Early",
    "section": "Project White Hot",
    "text": "Project White Hot\nPROJECT ‘WHITE HOT’ Mission Assessment of Recovered Lenticular Aerodyne Objects\nGeneral Nathan Twining Briefing document for President Eisenhower\nPART 1. PROJECT WHITE HOT INTELLIGENCE ESTIMATE (PRELIMINARY)\nLANDING ZONE NO, 1 Socorro, New Mexico–the unidentified lenticular-shaped Aerodyne which has been designated ULAT-1, has been evaluated as a non air breathing aircraft of unknown origin. Totally lacking conventional wing, fuselage, nacelle, control, and fuel systems strongly indicates it is not Russian.\nConsultation with Paperclip specialists concur. Aerodynamic features exhibited in ULAT-1 represents a very high degree of engineering and sophistication not seen in this country.\nDimensional homogeneity study cannot explain how this craft sustains load and lift factors necessary for flight.\nThe power plant does not even remotely resemble any conventional type now in use. Lacking any discernible intake or exhaust features, it is the opinion of AMC and ONR that this craft was designed to operate outside of the earth’s atmosphere.\nThe unconventional conclusions reached by members of this fact finding mission remain tentative at this time. Some members have expressed the view that ULAT-1 may be the product of an advanced culture from another planet that is much older than ours and has utilized their science and intellect for interplanetary space travel. It is not precisely known if the occupants purposely had the objective of exploration and of curiosity or with the intent of surveying for other reasons. So far, no hostile action or intent has been observed since they made their presence known.\nGiven the fact that our atomic bomb tests, atmospheric exploration with rockets, and XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXed in New Mexico, could have precipitated the events that led to the incident and subsequent actions taken by the military.\nOperating under the assumption that the fallen object was a long-range Russian reconnaissance platform collecting aerial photographic intelligence data military intelligence personnel were a instructed to secure the craft, debris and any occupants as rapidly as possible.\nConcerns over possible exposure to civilian of unknown biological and chemical agents dictated the quarantine measures taken.\nRadiation hazards were assumed and protective measures were taken as well.\nIn the interest or National Security priorities it was necessary to detain civilian witnesses for interrogation to satisfy intelligence requirements and quash rumors that could alert potential espionage agents known to be in the vicinity.\nSeveral bodies were discovered.\nBecause on-site medical personnel were unsure of the physiological make up of the occupants, special preparations and preservation methods were employed. Autopsy information obtained so far suggests that the occupants mimic the features associated with Orientals.\nOutwardly, they appear human-like with but one exception, autopsy notes mention a rarely observed XXXXXXXXXXXXXXXXXXXXXXXXXXXXXs present which supports the premise that these beings originate from another planet.\nPART TWO TECHNICAL EVALUATION (PRELIMINARY) ULAT-1\nUpon close examination of the exterior surfaces of the craft’s fuselage, metallurgists found the the skin to be of a ferrous metal white in color. The metal exhibits all the characteristics of high grade steel. It was determined that the steel was cold-formed and heat created.\n\nTensile strength was estimated in excess of 50,000 pounds per square inch. Shear tests give the metal a durability rating above 175,000 pounds per square inch, making this fuselage extremely strong and heat resistant.\nStatic and pressure flow simulations were impressive. The low profile ration of 6-1 gives the aerodyne a great advantage in overcoming the restrictions of the boundary layer effect in high performance operations.\nSpan flanges are constructed in unusual kinematic design which is believed to allow strain relief at supersonic speeds. There were no visible signs of plate-stiffeners, there were no fasteners, weld, rivets, or fittings, holding the fuselage together.\nLack of wings, flaps, stabilizers, and surface central features, suggests that the craft is a lifting body.\nThere are no air intakes for exhaust.\nThere are no cables\nThere are no identifiable electronics (wiring, ignition, lights, instrument, compartment, engine, motors, vacuum tubes, solenoids, generators, heaters, etc.)\nThe power-plant, (severely damaged) XXXXXXXXXXXXXXXXXx neutronic engine. XXXXXXXXXXXXXXXXXXXXXx detected heavy water and deuterium (light hydrogen) elements appeared to be the primary ignitor. A series of coils and heavy magnets connected to the neutronic engine via an oddly arranged group of electrodes (actually not yet identified) appears to be the active force. One small motor was examined. It is encased in a pure aluminium capsule directly underneath the main compartment. There is a small exhaust aperture attached that was what can only be described as an helicoid mechanism XXXXXXXXXXXXXXXXXXXXX. The auxiliary motor may be articulated.\n\nAdvertisement\n\nNavigation and engine controls may be activated by tactile manipulation. Viewing may have been achieved by form of television imagery. Symbolic notation appears to be the form of flight and control indicators. Flat panels of unknown metal has been suggested as a device associated with the operation of the aerodyne was discovered and analyzed. It’s mode of operation and purpose is unknown.\nThe absence of provisions, berthing compartments and storage areas, suggest the notion that this craft may be a short range reconnaissance platform. The only recognizable features XXXXXXXXXXX XXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nMode of operation of operation is believed to be instrumentation and suggests that the aerodyne from reconstruction from available wreckage XXXXXXXXXXXXXXXXXX biosensory and optical stimuli for these reasons:\n\nabsence of indicator signals Absence of any circular dials Absence of linear dials or moving pointers Absence of counters Absence of scopes No mechanical signal indicators 12. There were identifiable control types found among the assortment of artefacts that would indicate the operation of the propulsion unit was manually activated – no knobs, push buttons, toggle switches, levers, balls, handwheels, hand-cranks, or foot pedals were observed in the interior space of the flight cabin.\n\nThe apparent lack of additional clothing and equipment reinforces the belief that the occupants were engaged in a purely exploratory flight.\nIt is not presently known if electromagnetic radiation effects from the power plant had contributed to pilot error or death before impact. If inadequate shielding was the primary cause of pilot error XXXXXXXXXXXXXXs detected.\nIt is believed by some of the crash inspection personnel that sudden decompression and change in atmospheric pressure may have contributed to pilot error. Clothing removed from occupants do not resemble any pressure suit currently being tested by the Army or the Navy for high altitude experiments. Since temperature and humidity factors for the occupants is unknown, it is impossible to determine if decompression and temperature changed affected circulatory and dexterity functions. Although it is believed the occupants may have been overcome by some yet undiscovered pollutant or noxious fumes originating inside the craft.\nRotation or rapid oscillation could have been a contributing factor in pilot error. It is not known if organic effects played a part either since medical data is non-existent in which to make any judgment as to exact cause of death or machine failure.\nThe most probable cause of the crash is believed to be excessive acceleration combined with steep descent. The seating arrangement was transversely designed about the vertical axis of the occupants in a positive direction of flight. The panels removed from the craft resemble the ones taken from the occupants, suggesting a symbionic relationship between operator and the function of the aerodyne’s operation. A very tentative working theory was expressed by the scientific members of the inspection team that pilot-aerodyne interaction may occur via electronic-nonword symbols perceived through the tactile manipulation of the fingers feeding impulses to the brain and visa versa. All of which may suggest a non-inert quality or the materials existent as being a product or artificial intelligence.\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\n\nUF6 in metallic form;\nhydrogen-fluoride gas;\nwater and uranium tetra fluoride;\npowdered magnesium and potassium chlorate,\nmetal similar to lead with a chocolate brown color;\nU-235 in metallic form;\nplastic-like material similar to NE 102,\nBeryllium,\nPure aluminium;\nThorium isotope material;\nPlutonium powder.\n\n\nScientists from Los Alamos and Sandia Base were alarmed that the power plant could possibly function as a bomb if the elements described above were processed in similar fashion as was done for the lens and shot-gun detonators. This originally was the first conclusion. After further evaluation, it was determined that since no recognizable firing circuits were identified, the threat or detonation did not exist.\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns.\n\nPART III SCIENTIFIC PROBABILITIES\n\nBased on all available evidence collected from recovered exhibits currently under study by AHC, AFSWP, NEPA, AEC, ONA, NACA, JBDB, RAND, USAAF SAG. and MIT, are deemed extraterrestrial in nature. This conclusion was reached as a result of comparisons of artifacts XXXXXXXXXXXXXXXXXX discovery in 1941. The technology is outside the scope of US science, even that of German rocket and aircraft development.\nInterplanetary space travel is possible provided adequate funding, necessary resources are made available, and national interest is piqued.\nOur solar system is not unique. Chances are favorable for intelligent life on other planets notwithstanding similar development not unlike our own.\nBeing that our culture is relatively young (in relation to the cosmic scale), it is possible that other cultures may have developed faster, or are much older and have avoided the pitfalls common in our historical and scientific development.\nHuman origins may not be constrained to one planet. Our genus may be found among solar systems similar to our own.\nThe laws of physics and genetics may have a genesis in a higher, structured order than once previously thought.\n\nPART IV POLITICAL CONSIDERATIONS\nGiven the existing political climate in the US and the unstable conditions in Europe, it is the considered opinion of the members, that if the Administration went public with the information as found in this report now, the results would be damaging, even fatal to the world Political structure as it now exists. The following considerations were reviewed and debated, which led the mission to the following opinions:\n\nPublic trust of the political institutions may be eroded and possibly be held in disrepute.\nA complete revisioning make take place as institutions of higher learning thus calling into question the certainty of scientific knowledge.\nThe ability of the Armed Forces to secure National Security would be put in jeopardy and possibly lead to undue public fear and disorder.\nHistory and religion in the political context would probably suffer the most damage causing unprecedented upheaval in social and psychological well-being.\nPolitical repercussions may occur in our diplomatic efforts of containing the Communist threat to our democratic interests.\nIf such an announcement were made by the current Administration, it could be perceived by opposing party as a trick, laying open to accusations of unethetical (sic) posturing and manipulation of the public’s mind.\n\nPART V NATIONAL SECURITY STRUCTURE\nWith the passage of the National Security Act of 1947 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXas presented an unprecedented situation regarding maintaining secrecy related to the information contained in this report.\nIn the early months of 1942, up until the present, intrusions of unidentified aircraft have occasionally been documented, but there has been no serious investigations by the intelligence arm of the Government. Even the recovery case of 1941 did not create a unified intelligence effort to exploit possible technological gains with the exception of the Manhattan Project. We now have an opportunity to extend our technology beyond the threshold that we have achieved, XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXX. Aside from technological gains, we face an even greater challenge, that of learning the intent of such a presence. There are questions that remain unanswered, such as: What forces face us? What kind of defense do we have? Where do they come from and what kind of weapons do they possess? Where can we stage our forces in advance, XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX How wide a front? How many craft can we expect? And XXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXX\nThe members of the mission are prepared to submit a separate report on just this problem alone. And it would take a dozen volumes to explain how these problems should be met.\nOur only point, however, is that a combined intelligence and research operation would be a vast, intricate, covertly planned marshaling of resources, human and material, to solve a specific, clearly defined problem.\nWe have to find effective methods of persuasion with other government agencies without creating a sense of impending doom. The first task is to carefully appraise the problem. The second is to evaluate the known resources and probable strategy of the visitors. The third is to inventory our own ways and means, ascertain how much resources we can bring to bear, and how fast. The third is to devise our strategic plan. And last is to work out with infinite pains the tactical details and the myriad secondary problems of funding and security.\nIt is the unanimous opinion of the members that Operation MAJESTIC TWELVE be a fully funded ant operational TOP SECRET Research and Development intelligence gathering agency. It is also recommended that a panel of experts be appointed to chair and oversee the functions and operations of said agency. It’s members should have appropriate security clearances and full cooperation XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX XXXX XXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXX the National Security Council, the Pentagon, XXXXXXXht, XXXXXXXXXXXXXXXXXXXXX Joint Intelligence Committee, Joint Intelligence Objectives Agency, Central Intelligence Agency, Atomic Energy Commission, Joint Research and Development Board, Army Security Agency, and the National Advisory Board on Aeronautics.\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXgy are highlighted:\n\nPropeller driven bomber aircraft and jet engines, armed with conventional and atomic bombs.\nJet fighter aircraft, including some of super­sonic speed, armed with rockets and guns.\nPropeller-driven aircraft, valued for their endurance. .\nGuided anti-aircraft missiles, and radar-guided anti-aircraft guns.\nShort and medium-range guided missiles. Drone aircraft.\nAtomic charges, in bombs, missiles and torpedoes.\n\nIn the arena of nuclear weapons we feel there is a certain advantage to be gained XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX. It is speculated by some that if reduced size and miniature circuitry were introduced into the proposed hydrogen bomb program, it would give US Strategic Air Forces a great deterrence capability over the Russians. Current studies at MIT of micro-electronics taken from ULAT-1 may give us the strategic advantage so desired. It is strongly recommended that funding be allocated in this area.\nThere is a good chance that the Russians may try to make use of the flying saucer scare by public news media and diplomatic means of a technological breakthrough in aircraft and missile development. We feel that such a disclosure would certainly cause great embarrassment to our elected officials and to the military, not to mention the panic felt by the citizenry. To counter such a threat, it is recommended that a counterintelligence program be drawn up and held in abeyance if at such time the situation should present itself. It might be suggested that we should make a preempted use of these objects for the purpose of psychological warfare once the true nature of these objects are known and understood.\nTo further assist and aid all MAJCOM in the US and overseas, it is recommended that a standard intelligence reporting system be implemented through standard reporting channels with technical data forwarding instructions. At present, there are no specific intelligence guidelines available to military commanders in dealing with sightings and material evidence collection. It would be advisable for the respective Secretaries of the Armed Forces to devise a security policy of plausible denial, if and when the public becomes aware of the reality of these objects and the interest of the military of such incidents.\nIn conclusion, for reasons of national security and the public well being, the US must be perceived as being the top of the heap and every effort must be made to insure that there is, and never has been, a threat to the country."
  },
  {
    "objectID": "library/nat-sci/physics/uap/people.html#hal-puthoff",
    "href": "library/nat-sci/physics/uap/people.html#hal-puthoff",
    "title": "UAP People",
    "section": "Hal Puthoff",
    "text": "Hal Puthoff\nDr. Harold E. Puthoff is the co-founder and Vice President of Science and Technology of TTS Academy. Since 1985, Dr. Puthoff has served as President and CEO of EarthTech International, Inc. (ETI), and Director of the Institute for Advanced Studies at Austin (IASA). He has published numerous papers on electron-beam devices, lasers and space propulsion and has patents issued in the laser, communications, and energy fields. Dr. Puthoff’s professional background spans more than five decades of research at General Electric, Sperry, the National Security Agency, Stanford University and SRI International. Dr. Puthoff regularly advises NASA , the Department of Defense and intelligence communities, corporations and foundations on leading-edge technologies and future technology trends. He earned his Ph.D. from Stanford University in 1967 and won a Who’s Who Lifetime Achievement in 2017 that recognizes individuals that have achieved greatness in their industry and have excelled in their field for at least 20 years.\nLecture 2018\n\nvideo\nwriteup\nIRVA-SSE 2018\n\n2021 SCU AAP Conference Keynote by Hal Putoff\n\nvideo"
  },
  {
    "objectID": "library/nat-sci/physics/uap/people.html#salvatore-pais",
    "href": "library/nat-sci/physics/uap/people.html#salvatore-pais",
    "title": "UAP People",
    "section": "Salvatore Pais",
    "text": "Salvatore Pais\n\nDr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/nat-sci/physics/uap/people.html#richard-griffiths",
    "href": "library/nat-sci/physics/uap/people.html#richard-griffiths",
    "title": "UAP People",
    "section": "Richard Griffiths",
    "text": "Richard Griffiths\nRichard Griffiths serves as Affiliate Faculty at University of Hawaii at Hilo, Physics and Astronomy. He leads the team that solved a gravitational lens phenomenon.\n\narticle\npaper"
  },
  {
    "objectID": "library/nat-sci/physics/astro/webb.html",
    "href": "library/nat-sci/physics/astro/webb.html",
    "title": "James Webb",
    "section": "",
    "text": "10 galaxies that existed just 830 million years after the Big Bang\nThe seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster."
  },
  {
    "objectID": "library/nat-sci/physics/astro/webb.html#resources",
    "href": "library/nat-sci/physics/astro/webb.html#resources",
    "title": "James Webb",
    "section": "",
    "text": "10 galaxies that existed just 830 million years after the Big Bang\nThe seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster."
  },
  {
    "objectID": "library/nat-sci/physics/quantum/index.html",
    "href": "library/nat-sci/physics/quantum/index.html",
    "title": "Quantum",
    "section": "",
    "text": "MIT Quantum Physics I\nMIT Relatavistic Quantum Field Theory I\nMIT Relatavistic Quantum Field Theory II\nLangrangian and Hamiltonian Mechanics\nIntroductory Minicourse to AdS/CFT | youtube\nDavid Gross: Fifty Years of Quantum Chromodynamics (The Theory of The Strong Nuclear Force)\n\nQuantum Field Theory: Effective or Fundamental?"
  },
  {
    "objectID": "library/nat-sci/physics/quantum/index.html#resources",
    "href": "library/nat-sci/physics/quantum/index.html#resources",
    "title": "Quantum",
    "section": "",
    "text": "MIT Quantum Physics I\nMIT Relatavistic Quantum Field Theory I\nMIT Relatavistic Quantum Field Theory II\nLangrangian and Hamiltonian Mechanics\nIntroductory Minicourse to AdS/CFT | youtube\nDavid Gross: Fifty Years of Quantum Chromodynamics (The Theory of The Strong Nuclear Force)\n\nQuantum Field Theory: Effective or Fundamental?"
  },
  {
    "objectID": "library/social-sciences/finance/finance-101/finance-101.html",
    "href": "library/social-sciences/finance/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/social-sciences/finance/trading/trades/JGByields/index.html",
    "href": "library/social-sciences/finance/trading/trades/JGByields/index.html",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/social-sciences/finance/trading/trades/JGByields/index.html#resources",
    "href": "library/social-sciences/finance/trading/trades/JGByields/index.html#resources",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/social-sciences/finance/quant-trading/quant-trading.html",
    "href": "library/social-sciences/finance/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "library/social-sciences/politics/corruption/index.html#ukraine",
    "href": "library/social-sciences/politics/corruption/index.html#ukraine",
    "title": "Corruption",
    "section": "Ukraine",
    "text": "Ukraine\n\nUN, Zakharov\nThe son of Alexander Zakharov, mastermind of Russia’s killer drones that attack civilians in Ukraine, is now interning at the U.N.’s disarmament institute. UNIDIR says he was selected through a “competitive and transparent recruitment process…on the basis of his qualifications, skills and experience for the position.”\nTribune de Geneve: “The presence of Zakharov’s son in Geneva implies that Switzerland issued him with a visa, which is compulsory for Russian nationals wishing to enter and stay in the country. When questioned, the Swiss State Secretariat for Migration would not comment on the case. Alexander Zakharov’s son did not respond to our messages.”\n\ntweet\narticle"
  },
  {
    "objectID": "library/social-sciences/politics/deep-state.html",
    "href": "library/social-sciences/politics/deep-state.html",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/social-sciences/politics/deep-state.html#resources",
    "href": "library/social-sciences/politics/deep-state.html#resources",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/life-sciences/environment/climate/index.html",
    "href": "library/life-sciences/environment/climate/index.html",
    "title": "Climate",
    "section": "",
    "text": "Climate is an NP-complete problem. This can be proven by a reduction to turbulent mechanics. I do not abide by the “general” modern climate-change (Greta) view. However, it’s ridiculous to ignore the recent and rapid alterations in atmospheric content as a product of human industrialization.\n\n\nNASA\n- Evidence for Climate Change\nExothermic (Cyclic) Core Theory of Climate Change\n- The Climate Change Alternative We Ignore (to Our Peril)\nThe North Atlantic Sea Surface Tempurature Anomoly\n- We’ve been accidentally geoengineering for decades… then we stopped\nIPCC baseline scenarios have over-projected CO2 emissions and economic growth\n- paper\nHyporthermic Nature of Fungi (“Why Mushrooms are Cold”)\n- paper\nTestosterone histories from tusks reveal woolly mammoth musth episodes\n- paper\nAntartica Gained Ice, Not Lost It\n- article\nAnartica Low Ice Winter\n- article\nSea Water Heat Map\n- website\n\n\n\nAirforce document on using the weather for power\n- Weather as a Force Multiplier: Owning the Weather in 2025\nCan Controversial Geoengineering Fix Climate Crisis?\n- article\nNear-term climate risks and sunlight reflection modification: a roadmap approach for physical sciences research\n- paper\nReflecting Sunlight: Recommendations for Solar Geoengineering Research and Research Governance National Academies of Sciences, Engineering, and Medicine\n- book\nMake Sunsets: Geoengineering Startup\n- article\nOpen Letter Against Solar Geoengineering\n- letter\nStratospheric ozone changes under solar geoengineering: implications for UV exposure and air quality\n- paper\nGeoengineering could Turn Skies White\n- article\nWashington’s New World Order Weapons Have the Ability to Trigger Climate Change\n- archive"
  },
  {
    "objectID": "library/life-sciences/environment/climate/index.html#a-collection-of-views-and-information",
    "href": "library/life-sciences/environment/climate/index.html#a-collection-of-views-and-information",
    "title": "Climate",
    "section": "",
    "text": "NASA\n- Evidence for Climate Change\nExothermic (Cyclic) Core Theory of Climate Change\n- The Climate Change Alternative We Ignore (to Our Peril)\nThe North Atlantic Sea Surface Tempurature Anomoly\n- We’ve been accidentally geoengineering for decades… then we stopped\nIPCC baseline scenarios have over-projected CO2 emissions and economic growth\n- paper\nHyporthermic Nature of Fungi (“Why Mushrooms are Cold”)\n- paper\nTestosterone histories from tusks reveal woolly mammoth musth episodes\n- paper\nAntartica Gained Ice, Not Lost It\n- article\nAnartica Low Ice Winter\n- article\nSea Water Heat Map\n- website"
  },
  {
    "objectID": "library/life-sciences/health/covid/psyop.html",
    "href": "library/life-sciences/health/covid/psyop.html",
    "title": "psyop",
    "section": "",
    "text": "German MEP, Christine Anderson: Governments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”\nFull interview"
  },
  {
    "objectID": "library/life-sciences/health/covid/psyop.html#germany",
    "href": "library/life-sciences/health/covid/psyop.html#germany",
    "title": "psyop",
    "section": "",
    "text": "German MEP, Christine Anderson: Governments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”\nFull interview"
  },
  {
    "objectID": "library/life-sciences/health/covid/vaccine.html",
    "href": "library/life-sciences/health/covid/vaccine.html",
    "title": "mRNA Vaccine",
    "section": "",
    "text": "FDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\nTODO"
  },
  {
    "objectID": "library/life-sciences/health/covid/vaccine.html#resources",
    "href": "library/life-sciences/health/covid/vaccine.html#resources",
    "title": "mRNA Vaccine",
    "section": "",
    "text": "FDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\nTODO"
  },
  {
    "objectID": "library/life-sciences/health/covid/vaccine.html#horse-dewormer-a-necessary-narrative-for-fda-emergency-authorization",
    "href": "library/life-sciences/health/covid/vaccine.html#horse-dewormer-a-necessary-narrative-for-fda-emergency-authorization",
    "title": "mRNA Vaccine",
    "section": "“Horse Dewormer”, A necessary Narrative for FDA emergency Authorization",
    "text": "“Horse Dewormer”, A necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\nTODO\n\nMyocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSerum Vax Spike\n\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”"
  },
  {
    "objectID": "library/life-sciences/health/covid/vaccine.html#mrna-vaccine-x-myocarditispericarditis",
    "href": "library/life-sciences/health/covid/vaccine.html#mrna-vaccine-x-myocarditispericarditis",
    "title": "mRNA Vaccine",
    "section": "mRNA Vaccine x Myocarditis/Pericarditis",
    "text": "mRNA Vaccine x Myocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSERUM VAX SPIKE\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis"
  },
  {
    "objectID": "library/life-sciences/health/covid/vaccine.html#mrna-platform",
    "href": "library/life-sciences/health/covid/vaccine.html#mrna-platform",
    "title": "mRNA Vaccine",
    "section": "mRNA Platform",
    "text": "mRNA Platform\nExcerpt from Brett Weinstein\n\nThe mRNA platform is brilliant. But it has a giant gaping flaw in it, which is; Any cell of yours that produces a foreign protein, will be targetted by your immune system and destroyed. You will create an autoimmune disorder. When it works. How do you keep it out of your heart. Not by coding it in a lipid nanoparticle. So, they had no way to deliver it safely to market. So then they had a pandemic, the emergency allowed them to do it. This technology, in my opinion, was at least 3 decades out from being usefully and safely deployed at all, if at all. They did not want to wait, this crisis gave them the opportunity not to wait. And now, they will blame the spike protein, we picked the wrong protein. When in actual fact there are 2 problems, the spike protein and the platform itself."
  },
  {
    "objectID": "library/life-sciences/health/cognition/index.html",
    "href": "library/life-sciences/health/cognition/index.html",
    "title": "Cognition",
    "section": "",
    "text": "Chimera states in brain networks: empirical neural vs. modular fractal connectivity\nNeurological Activity of Lion’s Mane (Hericium erinaceus)\n\n\n\nOlfactory enrichment (aroma therapy) at night produces improvements in both cognitive and neural functioning.\n\nOvernight olfactory enrichment using an odorant diffuser improves memory and modifies the uncinate fasciculus in older adults\n\nResults: A statistically significant 226% improvement was observed in the enriched group compared to the control group on the Rey Auditory Verbal Learning Test and improved functioning was observed in the left uncinate fasciculus, as assessed by mean diffusivity.\nConclusion: Minimal olfactory enrichment administered at night produces improvements in both cognitive and neural functioning. Thus, olfactory enrichment may provide an effective and low-effort pathway to improved brain health."
  },
  {
    "objectID": "library/natural-sciences/physics/quantum/index.html",
    "href": "library/natural-sciences/physics/quantum/index.html",
    "title": "Quantum Physics",
    "section": "",
    "text": "MIT Quantum Physics I\nThe Dirac Equation and its Interpretations\nDavid Gross: Fifty Years of Quantum Chromodynamics (The Theory of The Strong Nuclear Force)\nTesting a discrete model for quantum spin with two sequential Stern-Gerlach detectors and photon Fock states\nClaim: The apparent randomness in wave function collapse is a consequence of coarse-graining an underlying deterministic, non-unitary but norm-preserving evolution.\nWhy Bohr was wrong in his response to EPR\nRichard Feynman: Simulating physics with computers (quantum)\nResolving Key Issues In Quantum Mechanics While Simultaneously Debunking Every UFO Case In History\nExperimental test of local observer-independence\nSpontaneous localisation from a coarse-grained deterministic and non-unitary dynamics\nKilling Horizons Decohere Quantum Superpositions\nFermionic matter-wave quantum optics with cold-atom impurity models\nVariational Quantum Thermalization and the Future of Quantum Thermodynamics\nA New Century of Quantum Physics\nArrival Time in Quantum Mechanics\n\n\n\n\npaper\n\nThe standard Dirac equation is a fundamental equation in relativistic quantum mechanics that describes the behavior of spin-1/2 particles such as electrons. It was first proposed by Paul Dirac in 1928 and has since played a central role in many areas of physics.\nThe Dirac equation takes the form:\n\\[(i\\gamma^\\mu\\partial_\\mu - m)\\psi = 0\\]\nwhere \\(\\psi\\) is a four-component spinor that describes the wave function of the particle, \\(m\\) is the mass of the particle, \\(\\partial_\\mu\\) is the four-dimensional partial derivative with respect to the spacetime coordinates \\(x^\\mu = (ct,x,y,z)\\), and \\(\\gamma^\\mu\\) are a set of four matrices known as the Dirac gamma matrices.\nThe gamma matrices satisfy the following properties:\n\\[{\\gamma^\\mu,\\gamma^\\nu} = 2\\eta^{\\mu\\nu}I_4\\]\nwhere \\(\\eta^{\\mu\\nu}\\) is the Minkowski metric with signature \\((+,-,-,-)\\), and \\(I_4\\) is the \\(4\\times 4\\) identity matrix. The gamma matrices also satisfy the property:\n\\[\\gamma^\\mu\\gamma^\\nu + \\gamma^\\nu\\gamma^\\mu = 2\\eta^{\\mu\\nu}I_4\\]\nThe Dirac equation is a relativistic wave equation that describes the dynamics of a spin-1/2 particle in the presence of an electromagnetic field. It predicts the existence of spin and spin magnetic moment for the particle, which are experimentally confirmed.\nThe four components of the Dirac spinor \\(\\psi\\) correspond to the particle’s spin and helicity. The solutions to the Dirac equation are classified by their energy, momentum, and spin. The Dirac equation has a rich and complex mathematical structure, and has played a key role in many areas of physics, including particle physics, quantum field theory, condensed matter physics, and astrophysics.\n\n\n\nVon Neumann algebras are \\((C^*)\\)-algebras of bounded operators on a Hilbert space that are closed in the weak operator topology. These algebras are fundamental in functional analysis and quantum mechanics. The formal definition is:\n\\[ \\begin{aligned}\nM \\subset B(H) \\text{ is a von Neumann algebra if } M = M'' = (M')'\n\\end{aligned} \\]\nHere, \\((B(H))\\) denotes the set of bounded linear operators on Hilbert space \\((H)\\), and \\((M'')\\) and \\((M')\\) denote the bicommutant and commutant, respectively.\n\n\n\nType I\n\nDescription: Decomposable into direct sums of simple matrix algebras.\nSubtypes:\n\nType I\\((_1)\\): Factors corresponding to finite-dimensional Hilbert spaces.\nType I\\((_\\infty)\\): Infinite-dimensional spaces.\n\n\nType II\n\nDescription: Not decomposable but have a non-trivial center.\nSubtypes:\n\nType II\\((_1)\\): Trace-class operators have finite trace.\nType II\\((_\\infty)\\): Infinite trace.\n\n\nType III\n\nDescription: Neither Type I nor Type II; occur naturally in quantum field theory.\nSubtypes:\n\nType III\\((_\\lambda)\\): Vary by a parameter \\((\\lambda)\\), used in the Tomita-Takesaki theory.\n\n\n\nEach type has distinct mathematical properties and applications in quantum mechanics and quantum field theory.\n\n\n\n\nA Hilbert space is a complete inner product space, meaning it’s a vector space equipped with an inner product and is complete in the sense that every Cauchy sequence in the space converges to an element within the space. It generalizes the notion of Euclidean space and is fundamental in quantum mechanics and functional analysis.\n\\[ \\begin{aligned}\n\\langle x, y \\rangle : H \\times H \\rightarrow \\mathbb{C}\n\\end{aligned} \\]\n\nContext: Developed in early 20th century, named after David Hilbert.\nPurpose: Framework for quantum mechanics and functional analysis."
  },
  {
    "objectID": "library/natural-sciences/physics/quantum/index.html#resources",
    "href": "library/natural-sciences/physics/quantum/index.html#resources",
    "title": "Quantum Physics",
    "section": "",
    "text": "MIT Quantum Physics I\nThe Dirac Equation and its Interpretations\nDavid Gross: Fifty Years of Quantum Chromodynamics (The Theory of The Strong Nuclear Force)\nTesting a discrete model for quantum spin with two sequential Stern-Gerlach detectors and photon Fock states\nClaim: The apparent randomness in wave function collapse is a consequence of coarse-graining an underlying deterministic, non-unitary but norm-preserving evolution.\nWhy Bohr was wrong in his response to EPR\nRichard Feynman: Simulating physics with computers (quantum)\nResolving Key Issues In Quantum Mechanics While Simultaneously Debunking Every UFO Case In History\nExperimental test of local observer-independence\nSpontaneous localisation from a coarse-grained deterministic and non-unitary dynamics\nKilling Horizons Decohere Quantum Superpositions\nFermionic matter-wave quantum optics with cold-atom impurity models\nVariational Quantum Thermalization and the Future of Quantum Thermodynamics\nA New Century of Quantum Physics\nArrival Time in Quantum Mechanics\n\n\n\n\npaper\n\nThe standard Dirac equation is a fundamental equation in relativistic quantum mechanics that describes the behavior of spin-1/2 particles such as electrons. It was first proposed by Paul Dirac in 1928 and has since played a central role in many areas of physics.\nThe Dirac equation takes the form:\n\\[(i\\gamma^\\mu\\partial_\\mu - m)\\psi = 0\\]\nwhere \\(\\psi\\) is a four-component spinor that describes the wave function of the particle, \\(m\\) is the mass of the particle, \\(\\partial_\\mu\\) is the four-dimensional partial derivative with respect to the spacetime coordinates \\(x^\\mu = (ct,x,y,z)\\), and \\(\\gamma^\\mu\\) are a set of four matrices known as the Dirac gamma matrices.\nThe gamma matrices satisfy the following properties:\n\\[{\\gamma^\\mu,\\gamma^\\nu} = 2\\eta^{\\mu\\nu}I_4\\]\nwhere \\(\\eta^{\\mu\\nu}\\) is the Minkowski metric with signature \\((+,-,-,-)\\), and \\(I_4\\) is the \\(4\\times 4\\) identity matrix. The gamma matrices also satisfy the property:\n\\[\\gamma^\\mu\\gamma^\\nu + \\gamma^\\nu\\gamma^\\mu = 2\\eta^{\\mu\\nu}I_4\\]\nThe Dirac equation is a relativistic wave equation that describes the dynamics of a spin-1/2 particle in the presence of an electromagnetic field. It predicts the existence of spin and spin magnetic moment for the particle, which are experimentally confirmed.\nThe four components of the Dirac spinor \\(\\psi\\) correspond to the particle’s spin and helicity. The solutions to the Dirac equation are classified by their energy, momentum, and spin. The Dirac equation has a rich and complex mathematical structure, and has played a key role in many areas of physics, including particle physics, quantum field theory, condensed matter physics, and astrophysics.\n\n\n\nVon Neumann algebras are \\((C^*)\\)-algebras of bounded operators on a Hilbert space that are closed in the weak operator topology. These algebras are fundamental in functional analysis and quantum mechanics. The formal definition is:\n\\[ \\begin{aligned}\nM \\subset B(H) \\text{ is a von Neumann algebra if } M = M'' = (M')'\n\\end{aligned} \\]\nHere, \\((B(H))\\) denotes the set of bounded linear operators on Hilbert space \\((H)\\), and \\((M'')\\) and \\((M')\\) denote the bicommutant and commutant, respectively.\n\n\n\nType I\n\nDescription: Decomposable into direct sums of simple matrix algebras.\nSubtypes:\n\nType I\\((_1)\\): Factors corresponding to finite-dimensional Hilbert spaces.\nType I\\((_\\infty)\\): Infinite-dimensional spaces.\n\n\nType II\n\nDescription: Not decomposable but have a non-trivial center.\nSubtypes:\n\nType II\\((_1)\\): Trace-class operators have finite trace.\nType II\\((_\\infty)\\): Infinite trace.\n\n\nType III\n\nDescription: Neither Type I nor Type II; occur naturally in quantum field theory.\nSubtypes:\n\nType III\\((_\\lambda)\\): Vary by a parameter \\((\\lambda)\\), used in the Tomita-Takesaki theory.\n\n\n\nEach type has distinct mathematical properties and applications in quantum mechanics and quantum field theory.\n\n\n\n\nA Hilbert space is a complete inner product space, meaning it’s a vector space equipped with an inner product and is complete in the sense that every Cauchy sequence in the space converges to an element within the space. It generalizes the notion of Euclidean space and is fundamental in quantum mechanics and functional analysis.\n\\[ \\begin{aligned}\n\\langle x, y \\rangle : H \\times H \\rightarrow \\mathbb{C}\n\\end{aligned} \\]\n\nContext: Developed in early 20th century, named after David Hilbert.\nPurpose: Framework for quantum mechanics and functional analysis."
  },
  {
    "objectID": "library/natural-sciences/physics/astro/webb.html",
    "href": "library/natural-sciences/physics/astro/webb.html",
    "title": "James Webb",
    "section": "",
    "text": "10 galaxies that existed just 830 million years after the Big Bang\nThe seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster."
  },
  {
    "objectID": "library/natural-sciences/physics/astro/webb.html#resources",
    "href": "library/natural-sciences/physics/astro/webb.html#resources",
    "title": "James Webb",
    "section": "",
    "text": "10 galaxies that existed just 830 million years after the Big Bang\nThe seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html#hal-puthoff",
    "href": "library/natural-sciences/physics/uap/people.html#hal-puthoff",
    "title": "UAP People",
    "section": "Hal Puthoff",
    "text": "Hal Puthoff\nDr. Harold E. Puthoff is the co-founder and Vice President of Science and Technology of TTS Academy. Since 1985, Dr. Puthoff has served as President and CEO of EarthTech International, Inc. (ETI), and Director of the Institute for Advanced Studies at Austin (IASA). He has published numerous papers on electron-beam devices, lasers and space propulsion and has patents issued in the laser, communications, and energy fields. Dr. Puthoff’s professional background spans more than five decades of research at General Electric, Sperry, the National Security Agency, Stanford University and SRI International. Dr. Puthoff regularly advises NASA , the Department of Defense and intelligence communities, corporations and foundations on leading-edge technologies and future technology trends. He earned his Ph.D. from Stanford University in 1967 and won a Who’s Who Lifetime Achievement in 2017 that recognizes individuals that have achieved greatness in their industry and have excelled in their field for at least 20 years.\nLecture 2018\n\nvideo\nwriteup\nIRVA-SSE 2018\n\n2021 SCU AAP Conference Keynote by Hal Putoff\n\nvideo"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html#salvatore-pais",
    "href": "library/natural-sciences/physics/uap/people.html#salvatore-pais",
    "title": "UAP People",
    "section": "Salvatore Pais",
    "text": "Salvatore Pais\n\nDr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html#richard-griffiths",
    "href": "library/natural-sciences/physics/uap/people.html#richard-griffiths",
    "title": "UAP People",
    "section": "Richard Griffiths",
    "text": "Richard Griffiths\nRichard Griffiths serves as Affiliate Faculty at University of Hawaii at Hilo, Physics and Astronomy. He leads the team that solved a gravitational lens phenomenon.\n\narticle\npaper"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/early/index.html",
    "href": "library/natural-sciences/physics/uap/early/index.html",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/early/index.html#unordered-stuff",
    "href": "library/natural-sciences/physics/uap/early/index.html#unordered-stuff",
    "title": "Early",
    "section": "",
    "text": "Majestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\nMAJESTIC 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/early/index.html#ulat-1",
    "href": "library/natural-sciences/physics/uap/early/index.html#ulat-1",
    "title": "Early",
    "section": "ULAT-1",
    "text": "ULAT-1\nWordpress article\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\na.    UF6 in metallic form;\nb.    hydrogen-fluoride gas;\nc.    water and uranium tetra fluoride;\nd.    powdered magnesium and potassium chlorate,\ne.    metal similar to lead with a chocolate brown color;\nf.   U-235 in metallic form;\ng.   plastic-like material similar to NE 102,\nh.    Beryllium,\ni.    Pure aluminium;\nj.   Thorium isotope material;\nj.   Plutonium powder.\n\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/early/index.html#project-white-hot",
    "href": "library/natural-sciences/physics/uap/early/index.html#project-white-hot",
    "title": "Early",
    "section": "Project White Hot",
    "text": "Project White Hot\nPROJECT ‘WHITE HOT’ Mission Assessment of Recovered Lenticular Aerodyne Objects\nGeneral Nathan Twining Briefing document for President Eisenhower\nPART 1. PROJECT WHITE HOT INTELLIGENCE ESTIMATE (PRELIMINARY)\nLANDING ZONE NO, 1 Socorro, New Mexico–the unidentified lenticular-shaped Aerodyne which has been designated ULAT-1, has been evaluated as a non air breathing aircraft of unknown origin. Totally lacking conventional wing, fuselage, nacelle, control, and fuel systems strongly indicates it is not Russian.\nConsultation with Paperclip specialists concur. Aerodynamic features exhibited in ULAT-1 represents a very high degree of engineering and sophistication not seen in this country.\nDimensional homogeneity study cannot explain how this craft sustains load and lift factors necessary for flight.\nThe power plant does not even remotely resemble any conventional type now in use. Lacking any discernible intake or exhaust features, it is the opinion of AMC and ONR that this craft was designed to operate outside of the earth’s atmosphere.\nThe unconventional conclusions reached by members of this fact finding mission remain tentative at this time. Some members have expressed the view that ULAT-1 may be the product of an advanced culture from another planet that is much older than ours and has utilized their science and intellect for interplanetary space travel. It is not precisely known if the occupants purposely had the objective of exploration and of curiosity or with the intent of surveying for other reasons. So far, no hostile action or intent has been observed since they made their presence known.\nGiven the fact that our atomic bomb tests, atmospheric exploration with rockets, and XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXed in New Mexico, could have precipitated the events that led to the incident and subsequent actions taken by the military.\nOperating under the assumption that the fallen object was a long-range Russian reconnaissance platform collecting aerial photographic intelligence data military intelligence personnel were a instructed to secure the craft, debris and any occupants as rapidly as possible.\nConcerns over possible exposure to civilian of unknown biological and chemical agents dictated the quarantine measures taken.\nRadiation hazards were assumed and protective measures were taken as well.\nIn the interest or National Security priorities it was necessary to detain civilian witnesses for interrogation to satisfy intelligence requirements and quash rumors that could alert potential espionage agents known to be in the vicinity.\nSeveral bodies were discovered.\nBecause on-site medical personnel were unsure of the physiological make up of the occupants, special preparations and preservation methods were employed. Autopsy information obtained so far suggests that the occupants mimic the features associated with Orientals.\nOutwardly, they appear human-like with but one exception, autopsy notes mention a rarely observed XXXXXXXXXXXXXXXXXXXXXXXXXXXXXs present which supports the premise that these beings originate from another planet.\nPART TWO TECHNICAL EVALUATION (PRELIMINARY) ULAT-1\nUpon close examination of the exterior surfaces of the craft’s fuselage, metallurgists found the the skin to be of a ferrous metal white in color. The metal exhibits all the characteristics of high grade steel. It was determined that the steel was cold-formed and heat created.\n\nTensile strength was estimated in excess of 50,000 pounds per square inch. Shear tests give the metal a durability rating above 175,000 pounds per square inch, making this fuselage extremely strong and heat resistant.\nStatic and pressure flow simulations were impressive. The low profile ration of 6-1 gives the aerodyne a great advantage in overcoming the restrictions of the boundary layer effect in high performance operations.\nSpan flanges are constructed in unusual kinematic design which is believed to allow strain relief at supersonic speeds. There were no visible signs of plate-stiffeners, there were no fasteners, weld, rivets, or fittings, holding the fuselage together.\nLack of wings, flaps, stabilizers, and surface central features, suggests that the craft is a lifting body.\nThere are no air intakes for exhaust.\nThere are no cables\nThere are no identifiable electronics (wiring, ignition, lights, instrument, compartment, engine, motors, vacuum tubes, solenoids, generators, heaters, etc.)\nThe power-plant, (severely damaged) XXXXXXXXXXXXXXXXXx neutronic engine. XXXXXXXXXXXXXXXXXXXXXx detected heavy water and deuterium (light hydrogen) elements appeared to be the primary ignitor. A series of coils and heavy magnets connected to the neutronic engine via an oddly arranged group of electrodes (actually not yet identified) appears to be the active force. One small motor was examined. It is encased in a pure aluminium capsule directly underneath the main compartment. There is a small exhaust aperture attached that was what can only be described as an helicoid mechanism XXXXXXXXXXXXXXXXXXXXX. The auxiliary motor may be articulated.\n\nAdvertisement\n\nNavigation and engine controls may be activated by tactile manipulation. Viewing may have been achieved by form of television imagery. Symbolic notation appears to be the form of flight and control indicators. Flat panels of unknown metal has been suggested as a device associated with the operation of the aerodyne was discovered and analyzed. It’s mode of operation and purpose is unknown.\nThe absence of provisions, berthing compartments and storage areas, suggest the notion that this craft may be a short range reconnaissance platform. The only recognizable features XXXXXXXXXXX XXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nMode of operation of operation is believed to be instrumentation and suggests that the aerodyne from reconstruction from available wreckage XXXXXXXXXXXXXXXXXX biosensory and optical stimuli for these reasons:\n\nabsence of indicator signals Absence of any circular dials Absence of linear dials or moving pointers Absence of counters Absence of scopes No mechanical signal indicators 12. There were identifiable control types found among the assortment of artefacts that would indicate the operation of the propulsion unit was manually activated – no knobs, push buttons, toggle switches, levers, balls, handwheels, hand-cranks, or foot pedals were observed in the interior space of the flight cabin.\n\nThe apparent lack of additional clothing and equipment reinforces the belief that the occupants were engaged in a purely exploratory flight.\nIt is not presently known if electromagnetic radiation effects from the power plant had contributed to pilot error or death before impact. If inadequate shielding was the primary cause of pilot error XXXXXXXXXXXXXXs detected.\nIt is believed by some of the crash inspection personnel that sudden decompression and change in atmospheric pressure may have contributed to pilot error. Clothing removed from occupants do not resemble any pressure suit currently being tested by the Army or the Navy for high altitude experiments. Since temperature and humidity factors for the occupants is unknown, it is impossible to determine if decompression and temperature changed affected circulatory and dexterity functions. Although it is believed the occupants may have been overcome by some yet undiscovered pollutant or noxious fumes originating inside the craft.\nRotation or rapid oscillation could have been a contributing factor in pilot error. It is not known if organic effects played a part either since medical data is non-existent in which to make any judgment as to exact cause of death or machine failure.\nThe most probable cause of the crash is believed to be excessive acceleration combined with steep descent. The seating arrangement was transversely designed about the vertical axis of the occupants in a positive direction of flight. The panels removed from the craft resemble the ones taken from the occupants, suggesting a symbionic relationship between operator and the function of the aerodyne’s operation. A very tentative working theory was expressed by the scientific members of the inspection team that pilot-aerodyne interaction may occur via electronic-nonword symbols perceived through the tactile manipulation of the fingers feeding impulses to the brain and visa versa. All of which may suggest a non-inert quality or the materials existent as being a product or artificial intelligence.\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\n\nUF6 in metallic form;\nhydrogen-fluoride gas;\nwater and uranium tetra fluoride;\npowdered magnesium and potassium chlorate,\nmetal similar to lead with a chocolate brown color;\nU-235 in metallic form;\nplastic-like material similar to NE 102,\nBeryllium,\nPure aluminium;\nThorium isotope material;\nPlutonium powder.\n\n\nScientists from Los Alamos and Sandia Base were alarmed that the power plant could possibly function as a bomb if the elements described above were processed in similar fashion as was done for the lens and shot-gun detonators. This originally was the first conclusion. After further evaluation, it was determined that since no recognizable firing circuits were identified, the threat or detonation did not exist.\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns.\n\nPART III SCIENTIFIC PROBABILITIES\n\nBased on all available evidence collected from recovered exhibits currently under study by AHC, AFSWP, NEPA, AEC, ONA, NACA, JBDB, RAND, USAAF SAG. and MIT, are deemed extraterrestrial in nature. This conclusion was reached as a result of comparisons of artifacts XXXXXXXXXXXXXXXXXX discovery in 1941. The technology is outside the scope of US science, even that of German rocket and aircraft development.\nInterplanetary space travel is possible provided adequate funding, necessary resources are made available, and national interest is piqued.\nOur solar system is not unique. Chances are favorable for intelligent life on other planets notwithstanding similar development not unlike our own.\nBeing that our culture is relatively young (in relation to the cosmic scale), it is possible that other cultures may have developed faster, or are much older and have avoided the pitfalls common in our historical and scientific development.\nHuman origins may not be constrained to one planet. Our genus may be found among solar systems similar to our own.\nThe laws of physics and genetics may have a genesis in a higher, structured order than once previously thought.\n\nPART IV POLITICAL CONSIDERATIONS\nGiven the existing political climate in the US and the unstable conditions in Europe, it is the considered opinion of the members, that if the Administration went public with the information as found in this report now, the results would be damaging, even fatal to the world Political structure as it now exists. The following considerations were reviewed and debated, which led the mission to the following opinions:\n\nPublic trust of the political institutions may be eroded and possibly be held in disrepute.\nA complete revisioning make take place as institutions of higher learning thus calling into question the certainty of scientific knowledge.\nThe ability of the Armed Forces to secure National Security would be put in jeopardy and possibly lead to undue public fear and disorder.\nHistory and religion in the political context would probably suffer the most damage causing unprecedented upheaval in social and psychological well-being.\nPolitical repercussions may occur in our diplomatic efforts of containing the Communist threat to our democratic interests.\nIf such an announcement were made by the current Administration, it could be perceived by opposing party as a trick, laying open to accusations of unethetical (sic) posturing and manipulation of the public’s mind.\n\nPART V NATIONAL SECURITY STRUCTURE\nWith the passage of the National Security Act of 1947 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXas presented an unprecedented situation regarding maintaining secrecy related to the information contained in this report.\nIn the early months of 1942, up until the present, intrusions of unidentified aircraft have occasionally been documented, but there has been no serious investigations by the intelligence arm of the Government. Even the recovery case of 1941 did not create a unified intelligence effort to exploit possible technological gains with the exception of the Manhattan Project. We now have an opportunity to extend our technology beyond the threshold that we have achieved, XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXX. Aside from technological gains, we face an even greater challenge, that of learning the intent of such a presence. There are questions that remain unanswered, such as: What forces face us? What kind of defense do we have? Where do they come from and what kind of weapons do they possess? Where can we stage our forces in advance, XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX How wide a front? How many craft can we expect? And XXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXX\nThe members of the mission are prepared to submit a separate report on just this problem alone. And it would take a dozen volumes to explain how these problems should be met.\nOur only point, however, is that a combined intelligence and research operation would be a vast, intricate, covertly planned marshaling of resources, human and material, to solve a specific, clearly defined problem.\nWe have to find effective methods of persuasion with other government agencies without creating a sense of impending doom. The first task is to carefully appraise the problem. The second is to evaluate the known resources and probable strategy of the visitors. The third is to inventory our own ways and means, ascertain how much resources we can bring to bear, and how fast. The third is to devise our strategic plan. And last is to work out with infinite pains the tactical details and the myriad secondary problems of funding and security.\nIt is the unanimous opinion of the members that Operation MAJESTIC TWELVE be a fully funded ant operational TOP SECRET Research and Development intelligence gathering agency. It is also recommended that a panel of experts be appointed to chair and oversee the functions and operations of said agency. It’s members should have appropriate security clearances and full cooperation XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX XXXX XXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXX the National Security Council, the Pentagon, XXXXXXXht, XXXXXXXXXXXXXXXXXXXXX Joint Intelligence Committee, Joint Intelligence Objectives Agency, Central Intelligence Agency, Atomic Energy Commission, Joint Research and Development Board, Army Security Agency, and the National Advisory Board on Aeronautics.\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXgy are highlighted:\n\nPropeller driven bomber aircraft and jet engines, armed with conventional and atomic bombs.\nJet fighter aircraft, including some of super­sonic speed, armed with rockets and guns.\nPropeller-driven aircraft, valued for their endurance. .\nGuided anti-aircraft missiles, and radar-guided anti-aircraft guns.\nShort and medium-range guided missiles. Drone aircraft.\nAtomic charges, in bombs, missiles and torpedoes.\n\nIn the arena of nuclear weapons we feel there is a certain advantage to be gained XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX. It is speculated by some that if reduced size and miniature circuitry were introduced into the proposed hydrogen bomb program, it would give US Strategic Air Forces a great deterrence capability over the Russians. Current studies at MIT of micro-electronics taken from ULAT-1 may give us the strategic advantage so desired. It is strongly recommended that funding be allocated in this area.\nThere is a good chance that the Russians may try to make use of the flying saucer scare by public news media and diplomatic means of a technological breakthrough in aircraft and missile development. We feel that such a disclosure would certainly cause great embarrassment to our elected officials and to the military, not to mention the panic felt by the citizenry. To counter such a threat, it is recommended that a counterintelligence program be drawn up and held in abeyance if at such time the situation should present itself. It might be suggested that we should make a preempted use of these objects for the purpose of psychological warfare once the true nature of these objects are known and understood.\nTo further assist and aid all MAJCOM in the US and overseas, it is recommended that a standard intelligence reporting system be implemented through standard reporting channels with technical data forwarding instructions. At present, there are no specific intelligence guidelines available to military commanders in dealing with sightings and material evidence collection. It would be advisable for the respective Secretaries of the Armed Forces to devise a security policy of plausible denial, if and when the public becomes aware of the reality of these objects and the interest of the military of such incidents.\nIn conclusion, for reasons of national security and the public well being, the US must be perceived as being the top of the heap and every effort must be made to insure that there is, and never has been, a threat to the country."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/index.html",
    "href": "library/natural-sciences/physics/electromagnetism/index.html",
    "title": "Electromagnetism",
    "section": "",
    "text": "Dr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/index.html#resources",
    "href": "library/natural-sciences/physics/electromagnetism/index.html#resources",
    "title": "Electromagnetism",
    "section": "",
    "text": "Dr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html",
    "title": "LK-99",
    "section": "",
    "text": "Superconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html#tldr",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html#tldr",
    "title": "LK-99",
    "section": "",
    "text": "Superconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html#timeline",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html#timeline",
    "title": "LK-99",
    "section": "Timeline",
    "text": "Timeline\nJuly 22:\n\nThe First Room-Temperature Ambient-Pressure Superconductor\nOriginal paper(s) is(are) released twice, the first time (suspected to rush to beat the second) with only 3 authors, making the team eligible for a noble prize.\n\nJuly 26:\n\nI predict the superconductor hype (“we are so fucking back”) is all noise.\n\nJuly 27:\n\nDouglas Natelson publishes a blog post expressing a pessemistic view on the whole debacle.\nCondensed Matter Theory Center deconstructs “the non-experimental parts of the Korean room temp SC claims.”\n\nHype ensues, and magnifies, as people rush to replicate the study/results.\nJuly 29:\n\nFirst-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\n\nJuly 31:\n\nSynthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n\nA (failed?) replication attempt out of Beijing; shows semiconductor behavior, not super\n\nSemiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)\n\nAugust 4:\nA theoretical explanation for LK-99 is released on July 31, 2023, by Sinead Griffin out of Berkeley.\n\nOrigin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\nAugust 6:\nGroup claims/proves LK-99 is a ferromagnet (NOT a superconductor)\n\nFerromagnetic half levitation of LK-99-like synthetic samples"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html#asides",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/lk99.html#asides",
    "title": "LK-99",
    "section": "Asides",
    "text": "Asides\nAuthor of the original paper, Hyun-Tak Kim, from 2018\nWhy does BCS theory fail to explain superconductivity at high temperatures?"
  },
  {
    "objectID": "library/natural-sciences/physics/government/nuclear.html",
    "href": "library/natural-sciences/physics/government/nuclear.html",
    "title": "Nuclear Stance",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/natural-sciences/physics/government/nuclear.html#resources",
    "href": "library/natural-sciences/physics/government/nuclear.html#resources",
    "title": "Nuclear Stance",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html",
    "href": "library/natural-sciences/physics/government/index.html",
    "title": "Government",
    "section": "",
    "text": "Making Muons for Scientific Discovery, National Security\nX-65 | Control of Revolutionary Aircraft with Novel Effectors (CRANE)\nAn Evening With Director of National Intelligence Avril Haines\nThe new Schumer-Rounds Amendment (“UAP Disclosure Act”) was added to the FY 2024 National Defense Authorization Act (S. 2226) without objection.\nPentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#resources",
    "href": "library/natural-sciences/physics/government/index.html#resources",
    "title": "Government",
    "section": "",
    "text": "Making Muons for Scientific Discovery, National Security\nX-65 | Control of Revolutionary Aircraft with Novel Effectors (CRANE)\nAn Evening With Director of National Intelligence Avril Haines\nThe new Schumer-Rounds Amendment (“UAP Disclosure Act”) was added to the FY 2024 National Defense Authorization Act (S. 2226) without objection.\nPentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#directed-energy",
    "href": "library/natural-sciences/physics/government/index.html#directed-energy",
    "title": "Government",
    "section": "Directed Energy",
    "text": "Directed Energy\n\nD-Wave and Davidson Technologies Introduce New Innovations to Advance National Defense Efforts"
  },
  {
    "objectID": "library/natural-sciences/physics/black-holes/index.html",
    "href": "library/natural-sciences/physics/black-holes/index.html",
    "title": "Black Holes",
    "section": "",
    "text": "[Quanta article]"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/string-theory/index.html",
    "href": "library/natural-sciences/physics/unification/string-theory/index.html",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/string-theory/index.html#resources",
    "href": "library/natural-sciences/physics/unification/string-theory/index.html#resources",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/natural-sciences/software/ai/history-of-ai/history-of-ai.html",
    "href": "library/natural-sciences/software/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "Timeline of AI\nHistory of Artificial Neural Networks\nDeep Learning History\n\n\n\nFrank Rosenblatt invented the perceptron, an algorithm for pattern recognition, which is essentially a single-layer neural network.\n\n\n\nShortly after, he went on to explore deeper, multilayer perceptrons. His MLPs had a non-learning first layer with randomized weights and an adaptive output layer. Although this was not yet deep learning, because only the last layer learned.\n\n\n\nSuccessful learning in deep feedforward network architectures started in 1965 in the Ukraine (back then the USSR) when Alexey Ivakhnenko & Valentin Lapa introduced the first general, working learning algorithms for deep MLPs with arbitrarily many hidden layers (already containing the now popular multiplicative gates). A paper of 1971 already described a deep learning net with 8 layers, trained by their highly cited method which was still popular in the new millennium, especially in Eastern Europe, where much of Machine Learning was born.\n\n\n\nIvakhnenko and Lapa (1965, see above) trained their deep networks layer by layer. In 1967, however, Shun-Ichi Amari suggested to train MLPs with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent, a method proposed in 1951 by Robbins & Monro.\nAmari’s implementation (with his student Saito) learned internal representations in a five layer MLP with two modifiable layers, which was trained to classify non-linearily separable pattern classes.\n\n\n\nKunihiko Fukushima introduced rectified linear units (ReLUs) for NNs (1969). They are now widely used in CNNs and other NNs.\n\n\n\nSeppo Linnainmaa was the first to publish what’s now known as backpropagation, the famous algorithm for credit assignment in networks of differentiable nodes, also known as “reverse mode of automatic differentiation.” It is now the foundation of widely used NN software packages such as PyTorch and Google’s Tensorflow.\n\n\n\nAmari published a paper on Amari-Hopfield networks, which resemble what’s now known as Recurrent Neural Networks (RNNs).\n\n\n\nComputer Vision was revolutionized in the 2010s by a particular feedforward NN called the convolutional NN (CNN). The basic CNN architecture with alternating convolutional and downsampling layers is due to Kunihiko Fukushima, 1979. He called it Neocognitron.\n\n\n\n\nThe Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project.\nThe UK began the £350 million Alvey project.\nDARPA founded the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n\n\n\nPhysicist John Hopfield was able to prove that a form of neural network (now called a “Hopfield net”) could learn and process information in a completely new way. This built on the Amari-Hopfield network from Amari’s 1972 publication\n\n\n\n\nGeoffrey Hinton “godfather of AI” invented the idea of multilayered neural networks, with nodes and weights. Node takes inputs and weights of inputs, outputs a signal if sum &gt; 0. - 1985 | A Learning Algorithm for Boltzmann Machines - 1986 | Learning representations by back-propagating errors\n\n\n\nDavid E. Rumelhart demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs. At least for supervised learning, backpropagation is generally more efficient than Amari’s above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier\nFeng-hsiung Hsu begins development on Chess-playing expert system called ChipTest. In 1988 it was moved to IBM and renamed Deep Thought, and then renamed again in 1989 to Deep Blue.\n\n\n\nGenerative Adversarial Networks (GANs) are first published in 1990 in Munich under the moniker Artificial Curiosity. Two dueling NNs (a probabilistic generator and a predictor) are trying to maximize each other’s loss in a minimax game. The generator (called the controller) generates probabilistic outputs (using stochastic units like in the much later StyleGANs). The predictor (called the world model) sees the outputs of the controller and predicts environmental reactions to them. Using gradient descent, the predictor NN minimizes its error, while the generator NN tries to make outputs that maximize this error: one net’s loss is the other net’s gain\n\n\n\nJiirgen Schmidhuber published a paper describing an alternative to RNNs: A feedforward NN slowly learns by gradient descent to program the changes of the fast weights of another NN. Such Fast Weight Programmers (FWPs) can learn to memorize past data, too. In 1991, one of them computed its fast weight changes through additive outer products of self-invented activation patterns (now often called keys and values for self-attention). The very similar Transformers combine this with projections and softmax and are now widely used in natural language processing. For long input sequences, their efficiency was improved through Transformers with linearized self-attention whose core is formally equivalent to the 1991 Fast Weight Programmers.\n\n\n\nSepp Hochreiter and Jurgen Schmidhuber published Long Short-Term Memory, the most cited NN paper of the 20th century. A later milestone was the “vanilla LSTM architecture” with forget gate — the LSTM variant of 1999-2000 that everybody is using today, e.g., in Google’s Tensorflow. Alex was lead author of our first successful application of LSTM to speech (2004). 2005 saw the first publication of LSTM with full backpropagation through time and of bi-directional LSTM (now widely used).\nAlso in 1997, Deep Blue beats Gary Kasparov in chess.\n\n\n\nImageNet is created, a large visual database envisioned by Fei-Fei Li from Stanford University, who realized that the best machine learning algorithms wouldn’t work well if the data didn’t reflect the real world. For many, ImageNet was the catalyst for the AI boom of the 21st century.\n\n\n\nX (formerly Google X) is an American semi-secret research and development facility and organization founded by Google in January 2010. X has its headquarters about a mile and a half from Alphabet’s corporate headquarters, the Googleplex, in Mountain View, California\nDeepMind was founded in the UK by Demis Hassabis, Shane Legg and Mustafa Suleyman in September 2010.\n\n\n\nThe Google Brain project began in 2011 as a part-time research collaboration between Google fellow Jeff Dean, Google Researcher Greg Corrado, and Stanford University professor Andrew Ng. Google Brain started as a Google X project and became so successful that it was graduated back to Google: Astro Teller has said that Google Brain paid for the entire cost of Google X.\n\n\n\nGeoffrey Hinton tests artificial deep neural network on a widely used image recogniztion test, called ImageNet. AlexNet was the program, scored 75% success, way better than competitors. This generates a ton of hype, and sparks more funding/research in AI, particularly image recognition.\n\n\n\nIn 2013, Geoffrey Hinton was acquihired by Google."
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/amm/index.html",
    "href": "library/natural-sciences/crypto/mev/amm/index.html",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/amm/index.html#papers-research",
    "href": "library/natural-sciences/crypto/mev/amm/index.html#papers-research",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/amm/index.html#strategies",
    "href": "library/natural-sciences/crypto/mev/amm/index.html#strategies",
    "title": "MEV on AMMs",
    "section": "Strategies",
    "text": "Strategies\n\nIncoming Swap\n\nSandwiching\n\nIncoming buy, deliver bundle {mybuy, buy, mysell}\nIncoming sell (requires inventory), deliver bundle {mysell, sell, mybuy} (JaredFromSubway’s claim to fame and riches)\n\n\n\nJIT Liquidity\nIncoming transaction, frontrun it with a large liquidity position at the optimal tick bounds\n\n\nJIT + Sandwich Combo\nThis is the optimal strategy assuming negligible gas fees\n\nIncoming buy: frontrun buy, add LP, victim buy, remove LP, backrun sell\nIncoming sell: opposite\n\nResources on it: tweet 1\nExample bot executing this etherscan\nList of examples in prod tweet\n\n\n\nIncoming Liquidity Provision Position\n\nLP Addition\nIncoming LP Addition, deliver bundle {mybuy, lpAdd, mysell} - since liquidity is greater during sell, face less slippage - net sell price &gt; net buy price\n\n\nLP Removal\nIncoming LP Removal, deliver bundle {mysell, lpRemove, mybuy} - since liquidity is greater during buy, face less slippage. End up with more tokens than you started with. - net sell price &lt; net buy price"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html",
    "href": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#consensus",
    "href": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#consensus",
    "title": "Ethereum",
    "section": "",
    "text": "Casper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#consensus-attacks",
    "href": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#consensus-attacks",
    "title": "Ethereum",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#proposer-builder-separation",
    "href": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#proposer-builder-separation",
    "title": "Ethereum",
    "section": "Proposer Builder Separation",
    "text": "Proposer Builder Separation\n\nMEV-Boost Plan\nProposer Boost Considerations\nMEV-Boost in a Nutshell\nPBS Censorship Resistance\nState of research: increasing censorship resistance of transactions under PBS\nPBS Censorship-Resistance Alternatives\nCurrent crList Proposal"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#sharding",
    "href": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#sharding",
    "title": "Ethereum",
    "section": "Sharding",
    "text": "Sharding\n\nDanksharding\nPolynya on Danksharding\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#general",
    "href": "library/natural-sciences/crypto/blockchains/evm/ethereum/index.html#general",
    "title": "Ethereum",
    "section": "General",
    "text": "General\nEthereum Inactivity Leak - documentation\nIntent Based Architectures and Their Risks - article\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses - article\nAccount Abstraction Using Alt Mempool - article\nEIP-1153: Transient Storage - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\n2FA ZK Rollups using SGX - article\nClient Bootnode Concerns - article\nCollecting Signatures for Faster Finality - article\nProof of Solvency - article\nState of Testnets - tweet\nEth Withdrawals FAQ - website\n100 Days After the Merge - see section “Looking ahead to Shanghai” - article\nWithdrawals after Shanghai - blog\nExecution Layer Meeting - video\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs - article\nEthereum Data Structures - paper\nEth2Book: A lot of Good Info on Ethereum - documentation\nVitalik: An Incomplete Guide to Rollups - article\nA Rollup-Centric Ethereum Roadmap - article\nOfficial Merge Announcement - article\nValidator Withdrawal design - article\nVitalik: the roads not taken - article"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/index.html",
    "href": "library/natural-sciences/crypto/blockchains/evm/index.html",
    "title": "EVM",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis\nWhatsABI\ngo-selfcompile"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/index.html#resources",
    "href": "library/natural-sciences/crypto/blockchains/evm/index.html#resources",
    "title": "EVM",
    "section": "Resources",
    "text": "Resources\n\nEthereum Data Structures\nSmart Contract Auditing Heuristics\n\n\nERC-4337\n\nWhat’s in an Account?"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/consensus.html",
    "href": "library/natural-sciences/crypto/blockchains/consensus.html",
    "title": "bmac",
    "section": "",
    "text": "All things Byzantine Fault Tolerant: Research and implementations of consensus mechanisms.\n\n\n\nTendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical\n\n\n\n\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\n\n\n\n\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/consensus.html#whitepapers",
    "href": "library/natural-sciences/crypto/blockchains/consensus.html#whitepapers",
    "title": "Consensus",
    "section": "",
    "text": "Tendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/consensus.html#research",
    "href": "library/natural-sciences/crypto/blockchains/consensus.html#research",
    "title": "Consensus",
    "section": "Research",
    "text": "Research\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/consensus.html#consensus-attacks",
    "href": "library/natural-sciences/crypto/blockchains/consensus.html#consensus-attacks",
    "title": "Consensus",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/consensus.html#events",
    "href": "library/natural-sciences/crypto/blockchains/consensus.html#events",
    "title": "bmac",
    "section": "Events",
    "text": "Events\nMay 12, 2023: Ethereum Consensus Issues\n\ntweet one\ntweet two"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html",
    "title": "Ordinals",
    "section": "",
    "text": "How to Split Ordinals Mixed in a Single UTXO - article\nSplitting Bitcoin from Inscriptions on Ordinals Wallet - article"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#tech-stuff",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#tech-stuff",
    "title": "Ordinals",
    "section": "Tech Stuff",
    "text": "Tech Stuff\n# create ordinal wallet\nord wallet create\n\n# receive sats\nord wallet receive\n\n# create inscription\nord wallet inscribe --fee-rate 22 &lt;FILE&gt;\n\nIssues\nTransport error upon inscription attempt here\nInscriptions taking too long here\nIndexing not working here\nHow much does an inscription cost? - calculator"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#guides",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#guides",
    "title": "Ordinals",
    "section": "Guides",
    "text": "Guides\n\nHow to create\nHow to buy\nMinting Ordinals"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#btc-naming-service",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#btc-naming-service",
    "title": "Ordinals",
    "section": "BTC Naming Service",
    "text": "BTC Naming Service\nCasey Rodarmor’s Thoughts: 26:00 min mark - here\n\nLook up top level domain (com)\nFind the output its in, and get address of the output\nGet authenticated encrypted channel with the person that owns that\nAsk “who has ‘myname.com’?” and they send you signed message of the pubkey, and then you get IP address. But no good names exist yet.\n\n\nThings I’ve Learned on the Ordinals Journey\nBitcoin has several address formats.\n\nLegacy Addresses\nScript Addresses\nSegwit Addresses\nTaproot Addresses\n\nOrdinals uses Taproot Addresses, which result from a recent upgrade aimed to introduce more reobust security, privacy, and scalability."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#other-stuff",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#other-stuff",
    "title": "Ordinals",
    "section": "Other Stuff",
    "text": "Other Stuff\nWhat is it?\n\nanswered here\n\nResources\n\nHandbook\nGithub\nBIP\nMainnet Explorer\nTestnet (Signet) Explorer\nGuide\nNo Code Mint Platform\n\nCool Info\nOn August 21st, 2012, Charlie Lee posted a proposal to add proof-of-stake to Bitcoin to the Bitcoin Talk forum. This wasn’t an asset scheme, but did use the ordinal algorithm, and was implemented but never deployed.\nOn October 8th, 2012, jl2012 posted a scheme to the the same forum which uses decimal notation and has all the important properties of ordinals. The scheme was discussed but never implemented.\nGud Video\n\nyoutube\ninterview\n\nMultimint - video"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#mint-an-nft",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#mint-an-nft",
    "title": "Ordinals",
    "section": "Mint an NFT",
    "text": "Mint an NFT\n# inscribe\nord wallet inscribe --fee-rate 20 ABSOLUTE_FILE_PATH"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#test",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/ordinals.html#test",
    "title": "Ordinals",
    "section": "TEST",
    "text": "TEST\nI inscribed an image of Logan Tobias onto the Bitcoin blockchain.\n$ ord wallet inscribe --fee-rate 20 /home/ubuntu/server-share/logan_resized.jpeg \n{\n  \"commit\": \"93f5630a6f6eb49235fb25878df06563f509ff5d5d89da6a4092af5d68eb4afd\",\n  \"inscription\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8i0\",\n  \"reveal\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8\",\n  \"fees\": 282600\n}\nSat: 465805240538644\n\nOrdinal Project\nThis is a short guide on how to mint multiple ordinals quickly.\n\nCreate a Sparrow wallet to generate multiple UTXOs.\nCalculate cost per ordinal.\n\n\ncalculator\nmempool Add 600 (dust limit) + 10,000 (ordinal fee) to sats amount\n\nWe have: 132,000 sats per ordinal + 600 + 10,000 = 142,600 sats per ordinal"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands\n\nHow to run a Bitcoin full node. I have decided to run a node 5 minutes ago, so I am making this tutorial as I go. Let’s see how long it takes."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#resources",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#resources",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands\n\nHow to run a Bitcoin full node. I have decided to run a node 5 minutes ago, so I am making this tutorial as I go. Let’s see how long it takes."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#short-version",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#short-version",
    "title": "Running Bitcoin Core",
    "section": "Short Version",
    "text": "Short Version\n# download software\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n# extract contents\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\n# install extracted contents to local bin\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*\n# check version\nbitcoind --version\n# start the software\nbitcoind -daemon -txindex\n# check status\nbitcoin-cli -getinfo\n# check block count\nbitcoin-cli getblockcount\n# stop the software\nbitcoin-cli stop"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 1: Download Bitcoin Core",
    "text": "Step 1: Download Bitcoin Core\nAs of today (Feb 11, 2023), the latest version of Bitcoin Core is 24.0.1. You can find the download links here\n\nCopy the link address of the version you need - I am running Linux Ubuntu so I will use the x86_64-linux-gnu.tar.gz\n\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n\nExtract the contents\n\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\nThis downloads the contents into /usr/local/ directory"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "title": "Running Bitcoin Core",
    "section": "Step 2: Install Bitcoin from Downloaded Contents",
    "text": "Step 2: Install Bitcoin from Downloaded Contents\nRun this command (idk the details who cares)\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 3: Run Bitcoin Core",
    "text": "Step 3: Run Bitcoin Core\nbitcoind -daemon\nYou can check the progress of syncing with bitcoin-cli -getinfo\nThis should produce something that looks like this\nubuntu@REDACTED:~$ bitcoin-cli -getinfo\nChain: main\nBlocks: 235213\nHeaders: 775994\nVerification progress: ▒░░░░░░░░░░░░░░░░░░░░ 2.1719%\nDifficulty: 10076292.88341872\n\nNetwork: in 0, out 10, total 10\nVersion: 240001\nTime offset (s): -1\nProxies: n/a\nMin tx relay fee rate (BTC/kvB): 0.00001000\nCompare “blocks” with the latest block on the chain."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#done",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/btc-core.html#done",
    "title": "Running Bitcoin Core",
    "section": "Done!",
    "text": "Done!\nAll in all, it took me 34 minutes to figure this out. Easier than running Go Ethereum, and far easier than running Solana core. Incredibly impressive!"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/events/mango.html",
    "href": "library/natural-sciences/crypto/blockchains/solana/events/mango.html",
    "title": "Mango Rekt",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#overview",
    "href": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#overview",
    "title": "Mango Rekt",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#how-it-worked",
    "href": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#how-it-worked",
    "title": "Mango Rekt",
    "section": "How it worked",
    "text": "How it worked\nAttacker had two accounts, let’s call them account A and account B.\n\nAttacker funds account A with $5 million of USDC, to be used as collateral for on-chain positions.\nAttacker then offered out (sold short) ~483 million MNGO tokens, trading at $0.038 at the time.\nAttacker then funds account B with $5 million USDC, and purchases those ~438 million MNGO at $0.0382\nAttacker then purchases MNGO on the Spot market, artificially increasing its price. The price of mango reached $0.91 (a 24x increase).\nAt this new inflated price, account B was in the money for ~ $423 million. He used this account value to take out a loan of $116 million consisting of several tokens.\nAfter the attack, the MNGO/USD spot market then traded down to $0.02, which put account A in the money. However, Mango protocol was effectively drained of all liquidity, so account A could not be paid out."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#summary",
    "href": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#summary",
    "title": "Mango Rekt",
    "section": "Summary",
    "text": "Summary\nMango Markets were designed to give loans at a certain collateralization ratio (e.g. 400%), but they used the spot market as an oracle for “fair price” of the token. Thus, tokens with low liquidity could be easily manipulated such that the protocol believes “fair price” is multiples above what anyone would purchase the token at in free markets."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#future-mitigation",
    "href": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#future-mitigation",
    "title": "Mango Rekt",
    "section": "Future Mitigation",
    "text": "Future Mitigation\nMitigating this type of attack is as simple as fixing the Oracle mechanism. For example, one could use a 24hr rolling average price to determine “fair value” for lending, which would make the market manipulator’s attack much more difficult (must pump price for 24 hour rather than a few seconds)."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#credits-commentary",
    "href": "library/natural-sciences/crypto/blockchains/solana/events/mango.html#credits-commentary",
    "title": "Mango Rekt",
    "section": "Credits & Commentary",
    "text": "Credits & Commentary\n\nNotice of Exploit by Otter Security\nEarly Analysis of What Happened\nSam Bankman Freid on How to Protect from this Attack\nAttacker Admitting his Involvement"
  },
  {
    "objectID": "library/natural-sciences/crypto/cex/index.html",
    "href": "library/natural-sciences/crypto/cex/index.html",
    "title": "CEXs",
    "section": "",
    "text": "December\n\nBinance Experiences &gt;$10bn of Net Withdrawals; Temporarily Suspends Spot BNB Borrow; Temporarily Halts Withdrawals of ERC USDC; Is Said to Be on the Verge of Being Charged by DoJ\nBinance Proof of Reserves Auditor Mazar’s Pauses All Crypto Work, Removes Binance Attestation\nBinanceUS Temporarily Halts Withdrawals of USDT and USDC\n\nJanuary\n\nBinance Admits Stablecoin Pegged-BUSD Had &gt;$1bn Collateral Hole, Claims It Is Now Fixed\n\nFebruary\n\nNVDFS Investigating Paxos Over BUSD Stablecoin\nSEC Plans to Sue Paxos Over BUSD Stablecoin, Ordered to Stop Issuing BUSD\nCZ Announes an Orderly Wind Down of BUSD Trading Over Time\nCoinbase to Suspend BUSD Trading March 13th\nBinance Australia Closes Derivatives Trading on Some Accounts\nBinanceUS Found with Unexplained $400mm Transfer to CZ-controlled Entity\nBinance Loses Banking Partner, Suspends USD Bank Transfers\n\nMarch\n\nBinance and Changpeng Sued by CFTC Under Scathing Allegations\n\nApril\n\nBinanceUS Allowed by US Government to Continue with Acquisition of Voyager Digital, Then Backs Out of Acquisition\n\nMay\n\nBinance Withdraws from Canada Entirely\nReuters Claims Binance Comingled Customer Funds and Company Revenues in 2020 and 2021\nDoJ Investigating Whether Binance Violated US Sanctions Against Russia\nBinance Temporarily Halts BTC Withdrawals, Falsely Blaming Mempool Congestion\nBinanceUS Withdraws All Assets from Staking Pools, Prices Heavily Deviate from Other Exchanges as Exchange Liquidity Falters\nBinance Has Started Layoffs, Rumored to Be 20%\n\nJune\n\nSEC Sues Binance and Changpeng on 13 Charges with Incredibly Danning Evidence\nBloomberg Claims Changpeng May Step Down and Be Replaced by Richard Teng\nSEC Seeks Restraining Order to Freeze BinanceUS Assets; Judge Denies Restraining Order and Forces SEC and BinanceUS to Compromise on Securing Customer Assets\nBinance Under Investigation in France for Aggravated Money Laundering\nBinance Forced to Cease Operating in Netherlands\nBinance Forced to Cease Operating in Belgium\nBinance Moves 130,000 Bitcoin, Claims It’s a Cold Wallet Shuffle\nBinance and Changpeng Hire George Canellos, Former Chief of SEC Major Crimes Unit, As Criminal Defense Attorney\n\nJuly\n\nBinance doesn’t have Enough BCH to Process Withdrawals\nBinance General Counsel, Chief Strategy Officer and SVP of Compliance All Quit in Response to Changpeng Zhao’s Interactions with US Regulators\nBinance Moves $7.5bn of BNB, Claims to Be “Spreading Coins to More Addresses”\nBinance Withdraws License Application in Germany After It Was Set to Be Rejected Due to Changpeng Zhao\nBinance Lays Off &gt;1,000 Employees\nBinance Cuts Employee Benefits, Citing a Decline in Profits\n\nAugust\n\nBinance Shuts Down Crypto Payments Business\nMastercard Ends Card Partnership with Binance\nBinance’s Credit Card Processor Checkout.com Ends Services with Binance Due to AML Compliance Concerns\nWSJ Claims Binance Is Committing Massive US Sanctions Violations with Russian Banks\nBinance Head of APAC Quits\nBinanceUS Is Unable to Produce Financial Records for SEC\n\nSeptember\n\nBinance’s Head of Product Quits"
  },
  {
    "objectID": "library/natural-sciences/crypto/cex/index.html#binance",
    "href": "library/natural-sciences/crypto/cex/index.html#binance",
    "title": "CEXs",
    "section": "",
    "text": "December\n\nBinance Experiences &gt;$10bn of Net Withdrawals; Temporarily Suspends Spot BNB Borrow; Temporarily Halts Withdrawals of ERC USDC; Is Said to Be on the Verge of Being Charged by DoJ\nBinance Proof of Reserves Auditor Mazar’s Pauses All Crypto Work, Removes Binance Attestation\nBinanceUS Temporarily Halts Withdrawals of USDT and USDC\n\nJanuary\n\nBinance Admits Stablecoin Pegged-BUSD Had &gt;$1bn Collateral Hole, Claims It Is Now Fixed\n\nFebruary\n\nNVDFS Investigating Paxos Over BUSD Stablecoin\nSEC Plans to Sue Paxos Over BUSD Stablecoin, Ordered to Stop Issuing BUSD\nCZ Announes an Orderly Wind Down of BUSD Trading Over Time\nCoinbase to Suspend BUSD Trading March 13th\nBinance Australia Closes Derivatives Trading on Some Accounts\nBinanceUS Found with Unexplained $400mm Transfer to CZ-controlled Entity\nBinance Loses Banking Partner, Suspends USD Bank Transfers\n\nMarch\n\nBinance and Changpeng Sued by CFTC Under Scathing Allegations\n\nApril\n\nBinanceUS Allowed by US Government to Continue with Acquisition of Voyager Digital, Then Backs Out of Acquisition\n\nMay\n\nBinance Withdraws from Canada Entirely\nReuters Claims Binance Comingled Customer Funds and Company Revenues in 2020 and 2021\nDoJ Investigating Whether Binance Violated US Sanctions Against Russia\nBinance Temporarily Halts BTC Withdrawals, Falsely Blaming Mempool Congestion\nBinanceUS Withdraws All Assets from Staking Pools, Prices Heavily Deviate from Other Exchanges as Exchange Liquidity Falters\nBinance Has Started Layoffs, Rumored to Be 20%\n\nJune\n\nSEC Sues Binance and Changpeng on 13 Charges with Incredibly Danning Evidence\nBloomberg Claims Changpeng May Step Down and Be Replaced by Richard Teng\nSEC Seeks Restraining Order to Freeze BinanceUS Assets; Judge Denies Restraining Order and Forces SEC and BinanceUS to Compromise on Securing Customer Assets\nBinance Under Investigation in France for Aggravated Money Laundering\nBinance Forced to Cease Operating in Netherlands\nBinance Forced to Cease Operating in Belgium\nBinance Moves 130,000 Bitcoin, Claims It’s a Cold Wallet Shuffle\nBinance and Changpeng Hire George Canellos, Former Chief of SEC Major Crimes Unit, As Criminal Defense Attorney\n\nJuly\n\nBinance doesn’t have Enough BCH to Process Withdrawals\nBinance General Counsel, Chief Strategy Officer and SVP of Compliance All Quit in Response to Changpeng Zhao’s Interactions with US Regulators\nBinance Moves $7.5bn of BNB, Claims to Be “Spreading Coins to More Addresses”\nBinance Withdraws License Application in Germany After It Was Set to Be Rejected Due to Changpeng Zhao\nBinance Lays Off &gt;1,000 Employees\nBinance Cuts Employee Benefits, Citing a Decline in Profits\n\nAugust\n\nBinance Shuts Down Crypto Payments Business\nMastercard Ends Card Partnership with Binance\nBinance’s Credit Card Processor Checkout.com Ends Services with Binance Due to AML Compliance Concerns\nWSJ Claims Binance Is Committing Massive US Sanctions Violations with Russian Banks\nBinance Head of APAC Quits\nBinanceUS Is Unable to Produce Financial Records for SEC\n\nSeptember\n\nBinance’s Head of Product Quits"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/hyperliquid/index.html",
    "href": "library/natural-sciences/crypto/apps/hyperliquid/index.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "href": "library/natural-sciences/crypto/apps/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "href": "library/natural-sciences/crypto/apps/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/index.html",
    "href": "library/natural-sciences/crypto/rekt/index.html",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2\n\n\n\n\nSlope Finance Wallet Exploit: Otter Security"
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/index.html#resources",
    "href": "library/natural-sciences/crypto/rekt/index.html#resources",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2\n\n\n\n\nSlope Finance Wallet Exploit: Otter Security"
  },
  {
    "objectID": "library/natural-sciences/crypto/events/2023/08/ygg.html",
    "href": "library/natural-sciences/crypto/events/2023/08/ygg.html",
    "title": "YGG Manipulation",
    "section": "",
    "text": "August 7\n9:04 am YGG in top 3 volume, followed by shitcoins with negative funding (heavy shorts)\nHsaka’s Take | tweet\nAug 6, 7:04am YGG “looking spicy” says Nik’s quant\nReported at 9:52am Binance increased the funding rate settlement frequency from 8 hours to 2 hours\nReminder that 2018 scam pumps were even crazier\n\nso much commentary and ‘hate’ on the YGG situation when people don’t remember the summer of 2022 where we had 10x pumps in 1 minute on shitcoins. oh sweet children you haven’t experienced the true depths of market manipulation yet"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/ethena/ethena.html",
    "href": "library/natural-sciences/crypto/apps/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "Some thoughts on @ethena_labs and the attempt towards a stablecoin, $USDe, independent of the traditional banking system. https://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\nQuick Overview of the Basic Mechanism\n\n1 $USDe is backed by a $1 delta neutral ETH position. - Long $1 of stETH spot - Short $1 of ETH perpetual futures swap contracts (on a centralized exchange, with the spot stETH as cross-collateral).\nFor a more substantial overview, check out @cryptohayes (Ethena advisor) “Dust on Crust” https://blog.bitmex.com/dust-on-crust/\n\nA note the scale of this endeavor (relevant later).\n\nEthena is pursuing a trillion dollar TAM.\n\nStablecoin circulating supply sits comfortably above $100 billion (throughout the bear market).\nTether printed over $1 billion in profit last quarter.\nThe CBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n\nOn the surface, there’s two obvious/primary risks to the mechanism.\n\nCounterparty (exchange) Risk\nBasis (funding rate) Risk\n\n\nHow, and to what extent, is Ethena mitigating these?\n\nAddressing Counterparty Risk\n\nWhether its an external hack (Mt Gox) or insider theft (FTX) - CEX risk is certainly non-negligible. What’s the risk-adjusted rate at which you would park 8+ figures on Binance, or Deribit? This is a serious question that crypto firms (HFT shops, VC firms) decide internally…\nIn other words, if Binance were a public company, where would their credit default swaps trade?\nCounter to what @cryptohayes initially described in his early writings, Ethena must avoid custodying the assets at the exchanges. Instead, park the assets with a secure third party (Fireblocks, Ledger, Copper), form agreements with the exchanges to accept this (likely some form of ZK-Proof of stETH asset balance) as collateral, and simply settle funding payments on the derivatives intermittently.\nThis doesn’t exactly eliminate all counterparty risk (can expand on this in the future), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\n\nAddressing Basis Risk\n\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\nFounder @leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n\nI will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\n\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n\nHowever, I subscribe to two principles which may complicate this assumption.\n\nThe Observer Effect: The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\n\nConsidering the scale of the stablecoin market, it’s naive to neglect the reflexivity of the relationship between Ethena’s operations/supply and the aggregate ETH perp funding rate.\nThe in-sample backtest shown in the previous tweet simulates yield on $5b circulating $USDe supply. What’s not mentioned, however, is that $USDe would have represented roughly half of aggregate ETH open interest… the backtest is inherently flawed.\n\n\n\n\nAlthough it’s important to point out weakness of the backtest, this doesn’t necessarily suggest a point of failure for $USDe.\n\nThe design is fundamentally different from the UST-esque algostables, which were always necessarily destined to collapse. In fact, if Ethena’s mint & redemption process is both free and (near) instant, the $USDe mechanism can be inherently self-correcting.\nLet’s imagine the $USDe supply was $5b today, Ethena would represent nearly half of the $10b ETH perp open interest, and the funding rate would likely be negative (exact threshold for % of OI Ethena can be comfortable with is unclear, but 50% is probably unhealthy).\nWith transparent metrics on curculating supply, assets, liabilities, and distribution (what % of the shorts are on BitMex vs Bybit vs …), the market can observe collateral fluctuations, and react rationally. Users swap out of $USDe on Curve, which is purchased by market makers/arbitrageurs who then redeem with Ethena. This lifts the short pressure until the funding rate (or net yield, including stETH) is positive again.\n\nThere is certainly much more to be discussed.\n\n\nWhat can be done to further mitigate exchange risk, even if it’s only relevant to the short derivative leg?\nWhere will the “natural funding rate” converge with this mechanism implemented at scale?\nWhat role does the insurance fund play, and how shall it be sized/scaled optimally?\nCan the “internet bond” effectively offer an inversely correlated yield to bonds (think crypto OI/perp funding in bullish, low-rate environment vs high-rate)?\n\nBut I’ll end the thread here for now.\nThe @ethena_labs team is legit, and it’s clear they are continuing to diligence the relevant considerations. A bankless stablecoin is a pivotal instrument for the cryptoeconomy, and I look forward to further public engagement as this develops. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/index.html",
    "href": "library/natural-sciences/crypto/blockchains/solana/index.html",
    "title": "Solana",
    "section": "",
    "text": "How will Solana Improve its Stability?"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html",
    "href": "library/natural-sciences/crypto/blockchains/index.html",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#early-contributions-papers",
    "href": "library/natural-sciences/crypto/blockchains/index.html#early-contributions-papers",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#whitepapers",
    "href": "library/natural-sciences/crypto/blockchains/index.html#whitepapers",
    "title": "Blockchains",
    "section": "Whitepapers",
    "text": "Whitepapers\n\nBitcoin\nEthereum: A Next-Generation Smart Contract and Decentralized Application Platform\nEthereum: A Secure Decentralized Generalized Transaction Ledger\nZerocash: Decentralized Anonymous Payments from Bitcoin\nCosmos: Internet of Blockchains\nSolana: A new Architecture for a High Performance Blockchain\nCardano\nAlgorand: Scaling Byzantine Agreements for Cryptocurrencies\nAvalanche Platform\nThe Spacemesh Protocol"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#recent-general",
    "href": "library/natural-sciences/crypto/blockchains/index.html#recent-general",
    "title": "Blockchains",
    "section": "Recent, General",
    "text": "Recent, General\n\nThe Tie: Solving the Blockchain Trilemma\nEndgame: Proof of Governance"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/versions.html",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/versions.html",
    "title": "The Tech",
    "section": "",
    "text": "Bitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/versions.html#transaction-versions",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/versions.html#transaction-versions",
    "title": "The Tech",
    "section": "",
    "text": "Bitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html",
    "title": "Bitcoin",
    "section": "",
    "text": "Bitcoin: A Peer to Peer Electronic Cash System\nBitcoin Lightning Network\nSegregated Witness Benefits\nVulnerability | tweet\nExplorer | btcscan"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/tooling.html",
    "href": "library/natural-sciences/crypto/blockchains/evm/tooling.html",
    "title": "Tools & Resources",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/tooling.html#tools",
    "href": "library/natural-sciences/crypto/blockchains/evm/tooling.html#tools",
    "title": "Tools & Resources",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/tooling.html#resources",
    "href": "library/natural-sciences/crypto/blockchains/evm/tooling.html#resources",
    "title": "Tools & Resources",
    "section": "Resources",
    "text": "Resources\n\nSolidity Data Representation"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/layer-2/index.html",
    "href": "library/natural-sciences/crypto/blockchains/evm/layer-2/index.html",
    "title": "Layer 2 Rollups",
    "section": "",
    "text": "Vitalik: An Incomplete Guide to Rollups\nA Rollup-Centric Ethereum Roadmap\nArbitrum: Scalable, Private Smart Contracts\nVitalik: An Incomplete Guide to Rollups"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/overview.html",
    "href": "library/natural-sciences/crypto/mev/overview.html",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/overview.html#dashboards-tools",
    "href": "library/natural-sciences/crypto/mev/overview.html#dashboards-tools",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/overview.html#research",
    "href": "library/natural-sciences/crypto/mev/overview.html#research",
    "title": "Overview",
    "section": "Research",
    "text": "Research\n\nEarly Research\n\nEnter the Hydra\nThe Cost of Decentralization in 0x and EtherDelta\nFlash Boys 2.0\nOrder-Fairness for Byzantine Consensus\nThemis: Fast, Strong Order-Fairness in Byzantine Consensus\nMEV… Wat Do?\nEthereum is a Dark Forest\nFlashbots: Frontrunning the MEV Crisis\n\n\n\nGeneral\n\nStudying Flash Loan Attacks | paper\nMEV by Galaxy Digital | Blog Pt 2\nModular MEV Write-up\nPerformant routing and latency benchmarking for Ethereum RPC and Relay Service Providers\nHigh Granularity Cex Data | tardis.dev\nMEV in Fixed Price Auctions | paper | tweet\nMEV Boost Capella Upgrades | article\nFrontier Research | website\nSo you want to run a builder?\nHow to Fix Ethereum’s MEV Problem\nMEV in ETH2 - An Early Exploration\nImproving PoS Economic Security via MEV Redistribution\nTowards a Theory of MEV I\nFlashbots Research Repository\n\n\n\nMEV-Boost / Proposer-Builder Separation\n\nProposer Boost Considerations\nMEV-Boost Plan\n\n\n\nVideos & Talks\n\nMEV Day\n\nVideo Recap\n\nEncode x Wintermute: MEV with Robert Miller\nStanford MEV Workshop Recording\nMEVconomics Playlist | youtube\nStanford Blockchain Conference (SBC’23)\nRecordings: Day 1 | Day 2 | Day 3\nMEV Workshop at SBC’23 | Recording\n\n\n\nProtocols, and Implementation Resources\nUniswap V3 Book - docs\nAutomated Market Making and Arbitrage Profits in the Presence of Fees - paper\nMEV Capturing AMM - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\nA Framework for Building Searchers - article\nSomeone’s Mega-resource on MEV - notion\nRunning MEV-Relay at Scale - notion\nLatency Arms Race - post\nFBAs (frequent batch auctions) are a nerd snipe - tweet\nJaredFromSubway.eth’s Access Lists - etherscan"
  },
  {
    "objectID": "library/natural-sciences/software/ai/bio/index.html",
    "href": "library/natural-sciences/software/ai/bio/index.html",
    "title": "AI x Bio",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology"
  },
  {
    "objectID": "library/natural-sciences/software/ai/bio/index.html#resources",
    "href": "library/natural-sciences/software/ai/bio/index.html#resources",
    "title": "AI x Bio",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology"
  },
  {
    "objectID": "library/natural-sciences/software/coding/rust/index.html",
    "href": "library/natural-sciences/software/coding/rust/index.html",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/natural-sciences/software/coding/rust/index.html#learning-resources",
    "href": "library/natural-sciences/software/coding/rust/index.html#learning-resources",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/index.html",
    "href": "library/natural-sciences/physics/unification/index.html",
    "title": "Grand Unification",
    "section": "",
    "text": "Introductory Minicourse to AdS/CFT | video\nBasics of Quantum Gravity\nPerturbative Quantum Gravity\nGravitational Machines\nWarp Drive Patent by Google?\n\n\n\n\nSarfatti’s 1975 version of ER=EPR\n\nThe text discusses various concepts related to general relativity, quantum mechanics, and inertia. Key topics include Minkowski spacetime, Lorentz transformations, geodesics, the Levi-Civita connection, and the metric tensor (guv). The text also delves into the idea of “fake gravity” and “real gravity,” challenging some traditional concepts and advocating for a nuanced understanding of these phenomena in both classical and quantum contexts.\nAnalysis\n\nConcepts: The text navigates through an array of intricate concepts, making it a complex read even for those well-versed in physics. The various mathematical descriptions, like the metric tensor (guv) and Lorentz transformations, are standard topics in general relativity. Yet, the text introduces terminology like “fake gravity” and “real gravity,” which could be speculative or controversial interpretations of these standard topics.\nControversies and Opinions: The text seems to contain opinions, especially regarding the validity of other theories. Phrases like “That’s DOO DOO!” and “bad physics in my opinion” indicate the author’s subjective stance, making the piece less of a neutral, academic overview and more of an argumentative text.\nComplexity: While the text addresses educated readers familiar with physics, it assumes a high level of understanding of both general relativity and quantum mechanics. There is also an inclusion of other theories and ongoing debates within the field, making the text a dense read.\nClarity and Structure: The text appears to be a collection of email exchanges or notes rather than a cohesive article. This makes it somewhat fragmented and potentially challenging to follow for those not already familiar with the specific debates or theories being discussed.\n\nOverall, the text attempts to explore the interplay between classical and quantum theories in understanding gravitation and inertia. However, the lack of a structured argument and the interjection of strong opinions could make it less accessible or convincing to a general audience of physicists."
  },
  {
    "objectID": "library/natural-sciences/physics/unification/index.html#resources",
    "href": "library/natural-sciences/physics/unification/index.html#resources",
    "title": "Grand Unification",
    "section": "",
    "text": "Introductory Minicourse to AdS/CFT | video\nBasics of Quantum Gravity\nPerturbative Quantum Gravity\nGravitational Machines\nWarp Drive Patent by Google?\n\n\n\n\nSarfatti’s 1975 version of ER=EPR\n\nThe text discusses various concepts related to general relativity, quantum mechanics, and inertia. Key topics include Minkowski spacetime, Lorentz transformations, geodesics, the Levi-Civita connection, and the metric tensor (guv). The text also delves into the idea of “fake gravity” and “real gravity,” challenging some traditional concepts and advocating for a nuanced understanding of these phenomena in both classical and quantum contexts.\nAnalysis\n\nConcepts: The text navigates through an array of intricate concepts, making it a complex read even for those well-versed in physics. The various mathematical descriptions, like the metric tensor (guv) and Lorentz transformations, are standard topics in general relativity. Yet, the text introduces terminology like “fake gravity” and “real gravity,” which could be speculative or controversial interpretations of these standard topics.\nControversies and Opinions: The text seems to contain opinions, especially regarding the validity of other theories. Phrases like “That’s DOO DOO!” and “bad physics in my opinion” indicate the author’s subjective stance, making the piece less of a neutral, academic overview and more of an argumentative text.\nComplexity: While the text addresses educated readers familiar with physics, it assumes a high level of understanding of both general relativity and quantum mechanics. There is also an inclusion of other theories and ongoing debates within the field, making the text a dense read.\nClarity and Structure: The text appears to be a collection of email exchanges or notes rather than a cohesive article. This makes it somewhat fragmented and potentially challenging to follow for those not already familiar with the specific debates or theories being discussed.\n\nOverall, the text attempts to explore the interplay between classical and quantum theories in understanding gravitation and inertia. However, the lack of a structured argument and the interjection of strong opinions could make it less accessible or convincing to a general audience of physicists."
  },
  {
    "objectID": "library/natural-sciences/physics/government/pentagon/pleads-fifth-exotic-materials.html",
    "href": "library/natural-sciences/physics/government/pentagon/pleads-fifth-exotic-materials.html",
    "title": "Pentagon Pleads the Fifth",
    "section": "",
    "text": "Pentagon Unable To Confirm Or Deny Discovery Of Materials Originating From Non-Human Intelligences Or Unknown Origin Within Secretive Programs"
  },
  {
    "objectID": "library/natural-sciences/physics/government/pentagon/pleads-fifth-exotic-materials.html#summary",
    "href": "library/natural-sciences/physics/government/pentagon/pleads-fifth-exotic-materials.html#summary",
    "title": "Pentagon Pleads the Fifth",
    "section": "Summary",
    "text": "Summary\nThe blog post discusses the Pentagon’s inability to confirm or deny whether its UFO office, known as the All-domain Anomaly Resolution Office (AARO), has discovered any verifiable information to substantiate claims that any current or former U.S. programs have had possession or reverse-engineered materials from non-human intelligences or unknown origin. The Department of Defense (DoD) spokesperson, Susan Gough, stated that the AARO has not discovered any verifiable information to substantiate such claims. However, she declined to comment further on whether the term “extraterrestrial” could extend to materials of unknown origin or non-human intelligences."
  },
  {
    "objectID": "library/natural-sciences/physics/government/pentagon/pleads-fifth-exotic-materials.html#notes",
    "href": "library/natural-sciences/physics/government/pentagon/pleads-fifth-exotic-materials.html#notes",
    "title": "Pentagon Pleads the Fifth",
    "section": "Notes",
    "text": "Notes\n\nAll-domain Anomaly Resolution Office (AARO): The AARO is the Pentagon’s UFO office. It is currently unable to confirm or deny whether it has discovered any verifiable information to substantiate claims that any current or former U.S. programs have had possession or reverse-engineered materials from non-human intelligences or unknown origin.\nDepartment of Defense (DoD) Stance: The DoD spokesperson, Susan Gough, stated that the AARO has not discovered any verifiable information to substantiate such claims. However, she declined to comment further on whether the term “extraterrestrial” could extend to materials of unknown origin or non-human intelligences.\nAccess to Information: Gough confirmed that the AARO has not been denied access to any U.S. government program, past or present, during the course of its work. She also stated that the AARO may receive all UAP-related information, including any classified national security information involving military, intelligence, and intelligence-related activities, at all levels of classification regardless of any restrictive access controls, special access programs, or compartmented access programs.\nTitle 50 Authorities: Gough addressed the issue of Title 50 authorities, stating that such authorities are unrelated to the AARO’s ability to receive all UAP-related information through authorized disclosures.\nPublic Affairs Policies: Gough explained that it is DoD policy that all interactions with the news media at the Department level, including press queries, are coordinated with the Office of the Assistant to the Secretary of Defense for Public Affairs. She also noted that her portfolio includes UAP, AARO, and the Office of the Under Secretary of Defense for Intelligence & Security, as well as other issues and offices.\nWhistleblower Trust: The blog post mentions that the AARO, which currently reports to the Office of the Under Secretary of Defense for Intelligence & Security, is not trusted by numerous whistleblowers. The issue may stem from the AARO’s proximity to the OUSDI&S, which has previously been criticized for allegedly persecuting whistleblowers.\nConclusion: The blog post concludes by noting that the National Defense Authorization Act of 2023 means that the AARO should report directly to Deputy Secretary of Defense, Kathleen Hicks, and the Principal Deputy Director of National Intelligence on all operational and security matters relating to the AARO. However, there is no indication that this has been implemented yet."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#allegra-a.-beal-cohen",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#allegra-a.-beal-cohen",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#rebecca-chmiel",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#rebecca-chmiel",
    "title": "DARPA Fellows",
    "section": "Rebecca Chmiel",
    "text": "Rebecca Chmiel\nDr. Rebecca Chmiel joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. She received her Bachelor of Arts in chemistry and environmental studies from Colby College and her doctorate from the Massachusetts Institute of Technology and the Woods Hole Oceanographic Institution in marine biogeochemistry, and her research focused on the interactions between trace metal nutrients and marine phytoplankton. She has participated in four ocean research expeditions totaling over seven months at sea, and received the Antarctica Service Medal as part of her oceanographic fieldwork."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#alex-place",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#alex-place",
    "title": "DARPA Fellows",
    "section": "Alex Place",
    "text": "Alex Place\nDr. Alex Place joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. He received his Bachelor of Science in physics from the California Institute of Technology and his doctorate in electrical and computer engineering and materials science from Princeton University. His dissertation focused on improving the lifetimes of superconducting qubits, the building block of many industrial quantum computing efforts. He has also spent time developing nanoelectromechanical systems, novel solar cell designs, and medical devices."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#lt-krishnan-rajagopalan-usn",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#lt-krishnan-rajagopalan-usn",
    "title": "DARPA Fellows",
    "section": "LT Krishnan Rajagopalan, USN",
    "text": "LT Krishnan Rajagopalan, USN\nLt. Krishnan (Krish) Rajagopalan joined DARPA in March 2023 as part of the first cohort of DARPA Innovation Fellows. As a Navy Explosive Ordnance Disposal (EOD) Officer, he has led units of unmanned underwater vehicle operators and EOD divers tasked with countering explosive hazards underwater. He also served as a requirements officer on the staff of the Chief of Naval Operations and, most recently, as the operations officer at Expeditionary Exploitation Unit ONE (EXU-1). Rajagopalan is a qualified EOD Technician and Navy Diving Officer. He received a Bachelor of Science in operations research from the U.S. Naval Academy and a Master of Science in operations research from the Massachusetts Institute of Technology (MIT), where he was an MIT Lincoln Laboratory Military Fellow."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#graham-h.-reid",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#graham-h.-reid",
    "title": "DARPA Fellows",
    "section": "Graham H. Reid",
    "text": "Graham H. Reid\nDr. Graham Reid joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Reid received a Bachelor of Arts in physics from Kenyon College and a doctorate from University of Maryland, College Park. His dissertation research, conducted at NIST as a guest researcher through the Joint Quantum Institute, used ultracold atoms to study topological physics in dynamically evolving quantum systems."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#rené-m.-xavier",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#rené-m.-xavier",
    "title": "DARPA Fellows",
    "section": "René M. Xavier",
    "text": "René M. Xavier\nDr. René Xavier joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Xavier recently graduated from Florida Atlantic University, where she conducted research at the Harbor Branch Oceanographic Institute using shotgun metagenomics to analyze the biosynthesis of marine natural products. She received her Bachelor of Science in molecular, cellular, and developmental biology from the University of Washington in Seattle and was awarded a Fulbright Fellowship to study the regulation of reactive oxygen species at the Czech Institute of Experimental Botany in Prague. Prior to her academic career, she served as a nuclear electrician in the U.S. Navy where she was decorated with multiple honors including the Humanitarian Ribbon for her relief efforts during Hurricane Katrina."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa-fellows.html#alessandra-m.-zito",
    "href": "library/natural-sciences/physics/government/darpa-fellows.html#alessandra-m.-zito",
    "title": "DARPA Fellows",
    "section": "Alessandra M. Zito",
    "text": "Alessandra M. Zito\nDr. Alessandra (Allie) Zito joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Zito received her Bachelor of Arts in chemistry and French language and literature from Johns Hopkins University and her doctorate in chemistry from the University of California, Irvine. Her graduate work focused on synthesizing and characterizing redox-active organic and inorganic molecules to be used for electrochemical carbon dioxide capture and concentration. She also has research experience in investigating catalyst loading on carbon aerogels, homogeneous and heterogeneous CO2 reduction catalysis, and electrode design for supercapacitors."
  },
  {
    "objectID": "library/natural-sciences/physics/relativity/index.html",
    "href": "library/natural-sciences/physics/relativity/index.html",
    "title": "Relativity",
    "section": "",
    "text": "Lecture Notes on Holographic Renomalization\nAdS/CFT correspondence and Geometry (Hamilton-Jacobi approach to holographic renormalization)\nEPFL Lectures on General Relativity as a Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nEffective Field Physics (EFT) Methods of General Relativity\nHarmonic Springs and Gravity\nThe Role of Gravitation in Physics"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/index.html",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/index.html",
    "title": "Superconductors",
    "section": "",
    "text": "Steven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale: Part 1 and Part 2\nPiezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nSuperconductors as quantum transducers and antennas for gravitational and electromagnetic radiation\nCould superconductors transmute electromagnetic radiation into gravitational waves?"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#resources",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#resources",
    "title": "Superconductors",
    "section": "",
    "text": "Piezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 1 of 2\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale, Part 2 of 2\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nSuperconductors as quantum transducers and antennas for gravitational and electromagnetic radiation\nCould superconductors transmute electromagnetic radiation into gravitational waves?"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#summary",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#summary",
    "title": "Superconductors",
    "section": "Summary",
    "text": "Summary\nSuperconductivity is a macro-quantum state wherein a material displays (effectively) zero resistivity. (SUMMARIZE PT 1 1:09)\nA phenomenal overview of the phenomenon, from first principles, can be found on youtube.\nSteven Kivelson | Superconductivity and Quantum Mechanics at the Macro-Scale\n\nPart 1 of 2\nPart 2 of 2\n\nBelow is practically nothing more than a summary of these lectures, plus some wikipedia content."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/mhd/index.html",
    "href": "library/natural-sciences/physics/electromagnetism/mhd/index.html",
    "title": "MHD",
    "section": "",
    "text": "Magnetohydrodynamics\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism. The governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations.\nResources\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD\n\nSummary\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism.\nThe governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations. In the ideal MHD approximation, effects such as resistivity and viscosity are neglected, leading to a relatively simple set of governing equations:\n\nContinuity Equation: This equation ensures the conservation of mass.\n∂ρ/∂t + ∇·(ρv) = 0\nMomentum Equation: Combines Newton’s second law and the Lorentz force, accounting for the forces due to pressure gradients, gravity, and electromagnetic fields. In the absence of viscosity, this simplifies to:\nρ(∂v/∂t + v·∇v) = -∇p + ρg + (J×B)\nInduction Equation: Describes how the magnetic field evolves over time, given the fluid’s velocity and existing magnetic field.\n∂B/∂t = ∇×(v×B)\nEnergy Equation: This equation describes the conservation of energy, which is usually taken in the form of the first law of thermodynamics.\nAmpère’s Law with Maxwell’s Addition:\n∇×B = μ0J\nJ is the current density vector, B is the magnetic field, and μ0 is the magnetic permeability.\n\nIn these equations, ρ represents fluid density, v fluid velocity, p pressure, g gravitational acceleration, J current density, and B magnetic field.\nMHD has a wide range of applications, from studying astrophysical phenomena such as solar flares and accretion disks, to engineering applications like nuclear fusion research, liquid metal cooling in reactors, and even potential propulsion systems.\nHowever, real-world situations often involve non-ideal MHD where effects such as resistivity cannot be ignored. Understanding these effects often requires incorporating the full set of Maxwell’s equations and solving them alongside the fluid dynamics equations, which makes for a much more complex computational problem. In some non-ideal MHD scenarios, magnetic reconnection, turbulence, and other instabilities can occur, which are active research areas in this field."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/mhd/index.html#resources",
    "href": "library/natural-sciences/physics/electromagnetism/mhd/index.html#resources",
    "title": "MHD",
    "section": "Resources",
    "text": "Resources\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/mhd/index.html#summary",
    "href": "library/natural-sciences/physics/electromagnetism/mhd/index.html#summary",
    "title": "MHD",
    "section": "Summary",
    "text": "Summary\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism.\nThe governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations. In the ideal MHD approximation, effects such as resistivity and viscosity are neglected, leading to a relatively simple set of governing equations:\n\nContinuity Equation: This equation ensures the conservation of mass.\n∂ρ/∂t + ∇·(ρv) = 0\nMomentum Equation: Combines Newton’s second law and the Lorentz force, accounting for the forces due to pressure gradients, gravity, and electromagnetic fields. In the absence of viscosity, this simplifies to:\nρ(∂v/∂t + v·∇v) = -∇p + ρg + (J×B)\nInduction Equation: Describes how the magnetic field evolves over time, given the fluid’s velocity and existing magnetic field.\n∂B/∂t = ∇×(v×B)\nEnergy Equation: This equation describes the conservation of energy, which is usually taken in the form of the first law of thermodynamics.\nAmpère’s Law with Maxwell’s Addition:\n∇×B = μ0J\nJ is the current density vector, B is the magnetic field, and μ0 is the magnetic permeability.\n\nIn these equations, ρ represents fluid density, v fluid velocity, p pressure, g gravitational acceleration, J current density, and B magnetic field.\nMHD has a wide range of applications, from studying astrophysical phenomena such as solar flares and accretion disks, to engineering applications like nuclear fusion research, liquid metal cooling in reactors, and even potential propulsion systems.\nHowever, real-world situations often involve non-ideal MHD where effects such as resistivity cannot be ignored. Understanding these effects often requires incorporating the full set of Maxwell’s equations and solving them alongside the fluid dynamics equations, which makes for a much more complex computational problem. In some non-ideal MHD scenarios, magnetic reconnection, turbulence, and other instabilities can occur, which are active research areas in this field."
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear-energy/fusion.html",
    "href": "library/natural-sciences/physics/nuclear-energy/fusion.html",
    "title": "Fusion",
    "section": "",
    "text": "A thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear-energy/fusion.html#fusion-weapon-overview",
    "href": "library/natural-sciences/physics/nuclear-energy/fusion.html#fusion-weapon-overview",
    "title": "Fusion",
    "section": "",
    "text": "A thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear-energy/fusion.html#energy-sources",
    "href": "library/natural-sciences/physics/nuclear-energy/fusion.html#energy-sources",
    "title": "Fusion",
    "section": "Energy Sources",
    "text": "Energy Sources\n\nBreakthroughs\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html",
    "href": "library/natural-sciences/physics/uap/index.html",
    "title": "UAP",
    "section": "",
    "text": "My take, in a few sentences:\nThe UAP phenomenon is extraordinary. There are two primary candidate explanations.\nI believe both are at play. Confidence level: 10%"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#resources",
    "href": "library/natural-sciences/physics/uap/index.html#resources",
    "title": "UAP",
    "section": "Resources",
    "text": "Resources\n\nUAP Resources: GH Repo\nThe Case for UFO Secrecy\nAureon: At the Intersection of Energy and Matter\n\nhistory\n\nAvalon Project\n\nProject Avalon Resources\n\nChapel Hill Conference\n\nBehind the Scenes Chapel Hill\nThe Role of Gravitation in Physics\n\nTo The Stars Academy purchases exotic “assets” for $35,000\nMagnesium-Zinc-Bismuth (MgZn/Bi) material, allegedly recovered from a Rowsell crash, has several interesting physics properties.\nExtraterrestrial Metals\n\narticle\n\nHal Putoff Lecture - June 2018\n\nwriteup\nIRVA-SSE 2018\n\nMatthew Szydagis Interview\nBrian Gaensler Presentation\nUFO Blueshift: Hal Putoff\n2021 SCU AAP Conference Keynote by Hal Putoff\n2020 Transition Talks\nArea 51 Guard Stories (not necessarily “real talk”)\nCaponi Case\nApollo 20\n\nApollo 20 is known as a canceled NASA mission, part of the Apollo program. William Rutledge, the Apollo 20 Commander for the USAF (August 1976), claims that the mission did in fact happen, but it was classified.\n\nJaques Vallee Talk\nBrian Keating, Garry Nolan, Avi Loeb\nProgress in Post-Quantum Mechanics\nJack Sarfatti - Cafe Trieste, The Bohemians & Warp Drive Physics\nVallee Fastwalker Notes\nDGRAV Seminar Series: Nonlinearities in Black-Hole Ringdowns"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#speculative-tech",
    "href": "library/natural-sciences/physics/uap/index.html#speculative-tech",
    "title": "UAP",
    "section": "Speculative Tech",
    "text": "Speculative Tech"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#government-archive",
    "href": "library/natural-sciences/physics/uap/index.html#government-archive",
    "title": "UAP",
    "section": "Government Archive",
    "text": "Government Archive\n\nProject BLUE BOOK - UFOs\nMajestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles\n\n\nMajestic 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic\n\n\nULAT-1\nWordpress article\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\na.    UF6 in metallic form;\nb.    hydrogen-fluoride gas;\nc.    water and uranium tetra fluoride;\nd.    powdered magnesium and potassium chlorate,\ne.    metal similar to lead with a chocolate brown color;\nf.   U-235 in metallic form;\ng.   plastic-like material similar to NE 102,\nh.    Beryllium,\ni.    Pure aluminium;\nj.   Thorium isotope material;\nj.   Plutonium powder.\n\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns."
  },
  {
    "objectID": "library/natural-sciences/physics/astro/index.html",
    "href": "library/natural-sciences/physics/astro/index.html",
    "title": "Astrophysics & Cosmology",
    "section": "",
    "text": "James Webb Images\n\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nHolography of the Photon Ring\n\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics - article - Discovery of Gamma Rays from the Quiescent Sun with HAWC"
  },
  {
    "objectID": "library/natural-sciences/physics/astro/index.html#awesome",
    "href": "library/natural-sciences/physics/astro/index.html#awesome",
    "title": "Astrophysics & Cosmology",
    "section": "",
    "text": "James Webb Images\n\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nHolography of the Photon Ring\n\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics - article - Discovery of Gamma Rays from the Quiescent Sun with HAWC"
  },
  {
    "objectID": "library/natural-sciences/physics/quantum/field-theory/effective-or-fundamental.html",
    "href": "library/natural-sciences/physics/quantum/field-theory/effective-or-fundamental.html",
    "title": "Fundamental?",
    "section": "",
    "text": "The Quantum Theory of Fields: Effective or Fundamental?\n\nvideo\ncorresponding article\nQuantum Field Theory was born just pertaining to the electromagnetic field.\nWhen expanding this theory, it seemed it couldn’t be trusted at high energies. (Decline)\nLate 1940s, there was a new optimizing with the invention of a relatavistic perturbation theory, where the infinities could be absorbed into a redefinition of parameters like mass and charge of the electron. People thought this was sweeping problems under the rug, but it also may have been a way of selecting good theories (renormalizable theories).\nFor example, theere’s nothing in the symmetries of quantum electrodynamics which rules out putting a term in the field equations (or Lagrangian), which could make the magnetic moment of the electron anything you want. This would make the mass of the electron -1, which means the theory is not renormalizable, and thus shows invalid.\nLate 1960s and early 70s, the standard model came to fruition - this was the renaissance of Quantum Field theory. But there were still doubts whether this was a fundamental theory or an effective one.\nQuantum Field Theory & Einsteinian Physics may be low energy approximations of a more fundamental theory."
  },
  {
    "objectID": "library/natural-sciences/physics/quantum/compute/index.html",
    "href": "library/natural-sciences/physics/quantum/compute/index.html",
    "title": "Computation",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization"
  },
  {
    "objectID": "library/natural-sciences/physics/quantum/compute/index.html#resources",
    "href": "library/natural-sciences/physics/quantum/compute/index.html#resources",
    "title": "Computation",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization"
  },
  {
    "objectID": "library/life-sciences/health/physiology/index.html",
    "href": "library/life-sciences/health/physiology/index.html",
    "title": "Physiology",
    "section": "",
    "text": "The Hidden Brain Connections Between Our Hands and Tongues\n\nWhy does one stick their tongue out when performing a meticulous task with hand tools? Why do tennis players (and martial artist) shout alongside their movements?\n\nEffect of Syllable Articulation on Precision and Power Grip Performance\nThe initiation of a hand grip is delayed by silently reading an incompatible syllable\nMotor and visual-motor functions of the premotor cortex\nComplex Movements Evoked by Microstimulation of Precentral Cortex\nLanguage as a Tool: Motor Proficiency Using a Tool Predicts Individual Linguistic Abilities\n\nMotor proficiency predicts linguistic ability\n\n\n\n\nThrown to the Wolves\n\nA physician reveals the nightmare of transgender ideology in a major children’s hospital.\n\nThe blog post is an interview with an anonymous physician who works in a major children’s hospital in a liberal city. The physician discusses his concerns about the rise of transgender interventions in children and the potential harm they can cause. He criticizes the medical community for adopting transgender ideology without sufficient scientific evidence and for suppressing dissenting views. He also expresses concern about the use of puberty blockers and hormone treatments in children, arguing that these interventions can have irreversible effects and may not be in the best interest of the child.\n\n\nNotes\n\nTransgender Interventions in Children: The physician criticizes the increasing use of transgender interventions in children, including puberty blockers and hormone treatments. He argues that these interventions are being adopted without sufficient scientific evidence and can have irreversible effects.\nMedical Community and Transgender Ideology: The physician criticizes the medical community for adopting transgender ideology and suppressing dissenting views. He argues that many in the medical community are afraid to question transgender ideology for fear of professional repercussions.\nPuberty Blockers and Hormone Treatments: The physician expresses concern about the use of puberty blockers and hormone treatments in children. He argues that these interventions can have irreversible effects, including permanent changes to the child’s sexual organs and hormone balance.\nSuicide Risk: The physician challenges the argument that transgender interventions are necessary to prevent suicide in transgender individuals. He suggests that affirming a child’s transgender identity may actually contribute to self-hatred and suicidal ideation.\nFuture of Transgender Medicine: The physician is uncertain about the future of transgender medicine. He hopes for a change in the current approach, which he believes is harmful to children.\nRole of Psychiatrists, Psychologists, Doctors, Politicians, and Media: The physician criticizes these groups for promoting transgender interventions in children. He argues that they have convinced children and their parents that these interventions are the correct response to gender dysphoria, despite the potential harm they can cause.\nConclusion: The physician argues that the current approach to transgender interventions in children is harmful and not in the best interest of the child. He calls for a more cautious approach that takes into account the potential irreversible effects of these interventions."
  },
  {
    "objectID": "library/life-sciences/health/physiology/index.html#reads",
    "href": "library/life-sciences/health/physiology/index.html#reads",
    "title": "Physiology",
    "section": "",
    "text": "The Hidden Brain Connections Between Our Hands and Tongues\n\nWhy does one stick their tongue out when performing a meticulous task with hand tools? Why do tennis players (and martial artist) shout alongside their movements?\n\nEffect of Syllable Articulation on Precision and Power Grip Performance\nThe initiation of a hand grip is delayed by silently reading an incompatible syllable\nMotor and visual-motor functions of the premotor cortex\nComplex Movements Evoked by Microstimulation of Precentral Cortex\nLanguage as a Tool: Motor Proficiency Using a Tool Predicts Individual Linguistic Abilities\n\nMotor proficiency predicts linguistic ability\n\n\n\n\nThrown to the Wolves\n\nA physician reveals the nightmare of transgender ideology in a major children’s hospital.\n\nThe blog post is an interview with an anonymous physician who works in a major children’s hospital in a liberal city. The physician discusses his concerns about the rise of transgender interventions in children and the potential harm they can cause. He criticizes the medical community for adopting transgender ideology without sufficient scientific evidence and for suppressing dissenting views. He also expresses concern about the use of puberty blockers and hormone treatments in children, arguing that these interventions can have irreversible effects and may not be in the best interest of the child.\n\n\nNotes\n\nTransgender Interventions in Children: The physician criticizes the increasing use of transgender interventions in children, including puberty blockers and hormone treatments. He argues that these interventions are being adopted without sufficient scientific evidence and can have irreversible effects.\nMedical Community and Transgender Ideology: The physician criticizes the medical community for adopting transgender ideology and suppressing dissenting views. He argues that many in the medical community are afraid to question transgender ideology for fear of professional repercussions.\nPuberty Blockers and Hormone Treatments: The physician expresses concern about the use of puberty blockers and hormone treatments in children. He argues that these interventions can have irreversible effects, including permanent changes to the child’s sexual organs and hormone balance.\nSuicide Risk: The physician challenges the argument that transgender interventions are necessary to prevent suicide in transgender individuals. He suggests that affirming a child’s transgender identity may actually contribute to self-hatred and suicidal ideation.\nFuture of Transgender Medicine: The physician is uncertain about the future of transgender medicine. He hopes for a change in the current approach, which he believes is harmful to children.\nRole of Psychiatrists, Psychologists, Doctors, Politicians, and Media: The physician criticizes these groups for promoting transgender interventions in children. He argues that they have convinced children and their parents that these interventions are the correct response to gender dysphoria, despite the potential harm they can cause.\nConclusion: The physician argues that the current approach to transgender interventions in children is harmful and not in the best interest of the child. He calls for a more cautious approach that takes into account the potential irreversible effects of these interventions."
  },
  {
    "objectID": "library/life-sciences/health/covid/index.html",
    "href": "library/life-sciences/health/covid/index.html",
    "title": "Covid-19",
    "section": "",
    "text": "Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\nAustralia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis\nDr. Robert Malone Twitter Ban Details\nCovid Care Alliance: More Harm Than Good\n\nVideo\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\nProtection of mRNA vaccines against hospitalized COVID-19\nPharma Rackateering\nIsrael Ministry of Health released Pfizer Agreement\n\nThey first claimed they “couldn’t find it”\n\nArticle\nDocument\nAdministrative Appeal\n\n\nNew Zealand 2022 Data\nMethodist Hospital threatened their doctors\n\n“You cannot report adverse reactions to these vaccines”\n\nMore dishonest statements about boosters by the FDA’s Marks and Califf\nRisk of Myocarditis in Boys 18-39\nVaccine on Birthing\n\nArticle 1\nArticle 2 / Correction\n\nHow Britons are dying in their tens of thousands\n\nbut no one knows why: From May to December last year, there were 32,441 excess deaths in England and Wales, excluding deaths from Covid\n\n\n\n\nA necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus."
  },
  {
    "objectID": "library/life-sciences/health/covid/index.html#resources",
    "href": "library/life-sciences/health/covid/index.html#resources",
    "title": "Covid-19",
    "section": "",
    "text": "Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\nAustralia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis\nDr. Robert Malone Twitter Ban Details\nCovid Care Alliance: More Harm Than Good\n\nVideo\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\nProtection of mRNA vaccines against hospitalized COVID-19\nPharma Rackateering\nIsrael Ministry of Health released Pfizer Agreement\n\nThey first claimed they “couldn’t find it”\n\nArticle\nDocument\nAdministrative Appeal\n\n\nNew Zealand 2022 Data\nMethodist Hospital threatened their doctors\n\n“You cannot report adverse reactions to these vaccines”\n\nMore dishonest statements about boosters by the FDA’s Marks and Califf\nRisk of Myocarditis in Boys 18-39\nVaccine on Birthing\n\nArticle 1\nArticle 2 / Correction\n\nHow Britons are dying in their tens of thousands\n\nbut no one knows why: From May to December last year, there were 32,441 excess deaths in England and Wales, excluding deaths from Covid\n\n\n\n\nA necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus."
  },
  {
    "objectID": "library/life-sciences/environment/animals/index.html",
    "href": "library/life-sciences/environment/animals/index.html",
    "title": "Animals",
    "section": "",
    "text": "The Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet.\n\ntweet\ndiscovery article"
  },
  {
    "objectID": "library/life-sciences/environment/animals/index.html#barbery-lions",
    "href": "library/life-sciences/environment/animals/index.html#barbery-lions",
    "title": "Animals",
    "section": "",
    "text": "The Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet.\n\ntweet\ndiscovery article"
  },
  {
    "objectID": "library/social-sciences/politics/index.html",
    "href": "library/social-sciences/politics/index.html",
    "title": "Geopolitics",
    "section": "",
    "text": "Arab support to Egypt, as of Dec-2022\nLong-term deposits = $15b, from: - UAE = $5.7b - Saudi = $5.3b - Kuwait = $4b\nShort-term deposits = $14.9b, from: - UAE = $5b - Saudi = $5b - Qatar = $4b (from $3b in Mar) - Libya = $0.9b (from 0 in Mar)"
  },
  {
    "objectID": "library/social-sciences/politics/reads/index.html",
    "href": "library/social-sciences/politics/reads/index.html",
    "title": "Reads",
    "section": "",
    "text": "Peter Thiel: Straussian Moment\nLegacy of Ashes"
  },
  {
    "objectID": "library/social-sciences/politics/corruption/biden.html",
    "href": "library/social-sciences/politics/corruption/biden.html",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview"
  },
  {
    "objectID": "library/social-sciences/politics/corruption/biden.html#burisma",
    "href": "library/social-sciences/politics/corruption/biden.html#burisma",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview"
  },
  {
    "objectID": "library/social-sciences/finance/index.html",
    "href": "library/social-sciences/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "library/social-sciences/finance/trading/trades/comstock/index.html",
    "href": "library/social-sciences/finance/trading/trades/comstock/index.html",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/social-sciences/finance/trading/trades/comstock/index.html#resources",
    "href": "library/social-sciences/finance/trading/trades/comstock/index.html#resources",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/social-sciences/geopolitics/index.html",
    "href": "library/social-sciences/geopolitics/index.html",
    "title": "Geopolitics",
    "section": "",
    "text": "Peter Thiel: Straussian Moment\nLegacy of Ashes"
  },
  {
    "objectID": "library/social-sciences/geopolitics/corruption/biden.html",
    "href": "library/social-sciences/geopolitics/corruption/biden.html",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview\nMorgan Stanley 2014 Report Overview of Wakpamni Series 2014 Bonds"
  },
  {
    "objectID": "library/social-sciences/geopolitics/corruption/biden.html#burisma",
    "href": "library/social-sciences/geopolitics/corruption/biden.html#burisma",
    "title": "Biden Family",
    "section": "",
    "text": "Viktor Shokin: the Ukrainian prosecutor that Biden accused of being corrupt and had removed.\nIn this video he responds to accusations that his investigation into Burisma was dormant or that he was corrupt, plaining why he was removed as prosecutor.\nHe accuses the Obama Admin of using Ukraine. He says exactly what he thinks of Joe Biden. The State Department has refused to let him come to America to tell his story.\nInterview\nMorgan Stanley 2014 Report Overview of Wakpamni Series 2014 Bonds"
  },
  {
    "objectID": "library/social-sciences/geopolitics/reads/index.html",
    "href": "library/social-sciences/geopolitics/reads/index.html",
    "title": "Reads",
    "section": "",
    "text": "Peter Thiel: Straussian Moment\nLegacy of Ashes"
  },
  {
    "objectID": "library/social-sciences/geopolitics/deep-state.html",
    "href": "library/social-sciences/geopolitics/deep-state.html",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/social-sciences/geopolitics/deep-state.html#resources",
    "href": "library/social-sciences/geopolitics/deep-state.html#resources",
    "title": "Deep State",
    "section": "",
    "text": "Conspirator’s Hierarchy: The Story of the Committee of 300 by Dr. John Coleman. Dr. John Coleman was an Intelligence Officer for over 45 years and his book of truth is based on 20 years of relentless research.\n\nThe Committee of 300: An interesting take"
  },
  {
    "objectID": "library/social-sciences/geopolitics/corruption/index.html#ukraine",
    "href": "library/social-sciences/geopolitics/corruption/index.html#ukraine",
    "title": "Corruption",
    "section": "Ukraine",
    "text": "Ukraine\n\nUN, Zakharov\nThe son of Alexander Zakharov, mastermind of Russia’s killer drones that attack civilians in Ukraine, is now interning at the U.N.’s disarmament institute. UNIDIR says he was selected through a “competitive and transparent recruitment process…on the basis of his qualifications, skills and experience for the position.”\nTribune de Geneve: “The presence of Zakharov’s son in Geneva implies that Switzerland issued him with a visa, which is compulsory for Russian nationals wishing to enter and stay in the country. When questioned, the Swiss State Secretariat for Migration would not comment on the case. Alexander Zakharov’s son did not respond to our messages.”\n\ntweet\narticle"
  },
  {
    "objectID": "library/life-sciences/environment/climate/index.html#section",
    "href": "library/life-sciences/environment/climate/index.html#section",
    "title": "Climate",
    "section": "",
    "text": "Climate is an NP-complete problem. This can be proven by a reduction to turbulent mechanics. I do not abide by the “general” modern climate-change (Greta) view. However, it’s ridiculous to ignore the recent and rapid alterations in atmospheric content as a product of human industrialization."
  },
  {
    "objectID": "library/life-sciences/environment/climate/index.html#geoengineering",
    "href": "library/life-sciences/environment/climate/index.html#geoengineering",
    "title": "Climate",
    "section": "",
    "text": "Airforce document on using the weather for power\n- Weather as a Force Multiplier: Owning the Weather in 2025\nCan Controversial Geoengineering Fix Climate Crisis?\n- article\nNear-term climate risks and sunlight reflection modification: a roadmap approach for physical sciences research\n- paper\nReflecting Sunlight: Recommendations for Solar Geoengineering Research and Research Governance National Academies of Sciences, Engineering, and Medicine\n- book\nMake Sunsets: Geoengineering Startup\n- article\nOpen Letter Against Solar Geoengineering\n- letter\nStratospheric ozone changes under solar geoengineering: implications for UV exposure and air quality\n- paper\nGeoengineering could Turn Skies White\n- article\nWashington’s New World Order Weapons Have the Ability to Trigger Climate Change\n- archive"
  },
  {
    "objectID": "TEMPLATE.html",
    "href": "TEMPLATE.html",
    "title": "Example Page Title",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/natural-sciences/software/virtual-machines/index.html",
    "href": "library/natural-sciences/software/virtual-machines/index.html",
    "title": "Virtual Machines",
    "section": "",
    "text": "Building a VM Intro to RISC-V Architecture Write your own Virtual Machine How to create your own virtual machine"
  },
  {
    "objectID": "library/natural-sciences/software/virtual-machines/index.html#part-1-vm-basic-operations",
    "href": "library/natural-sciences/software/virtual-machines/index.html#part-1-vm-basic-operations",
    "title": "Virtual Machines",
    "section": "Part 1 | VM Basic Operations",
    "text": "Part 1 | VM Basic Operations\n\nPrerequisites\n\nBasic C++ knowledge\nEssentials of Interpretation\n\nNeed to know basic C++. For example, pointers\nint x = 10;     // value 10\nint* px = &x;   // address 5, pointing to value 10\n*px;            // 10\nNo build system: plain .h files and the single .cpp file\n// compile\nclang++ ./eva-vm.cpp -o ./eva-vm\n// execute\n./eva-vm -e '(var x 10) x'\n&gt; 10\n./eva-vm -f ~/test.eva\n&gt; 10\n\nclang++ is the C++ frontend for the Clang compiler. Clang is a compiler front end for the C, C++, Objective-C, and Objective-C++ programming languages. It uses the LLVM compiler infrastructure as its back end and is designed to act as a drop-in replacement for the GCC (GNU Compiler Collection).\nSome features and characteristics of clang++ and the Clang project include:\n\nPerformance: Clang aims to provide faster compile times than other compilers, like GCC, especially in incremental builds.\nDiagnostics: Clang is known for its clear and concise diagnostics (error and warning messages). It often provides a more detailed explanation and sometimes even suggests fixes for the issues.\nModular Design: Clang is designed to be highly modular, which has facilitated tools built on top of it. This design is particularly beneficial for creating custom tooling around the compiler.\nCompatibility: Clang aims to be compatible with GCC, meaning that most GCC-valid code should compile with Clang without changes.\nIntegrated Static Analyzer: Clang includes a static analysis tool that can detect various types of bugs in the source code.\n\nTo use clang++ to compile a C++ program, you might issue a command like:\nclang++ -o my_program my_program.cpp\nWhere -o my_program specifies the name of the output executable and my_program.cpp is the source file to be compiled.\n\n\n\nLanguages\n\nInterpreted Languages vs Compiled Languages\n\nA language must be interpreted to yield an output. You may interpret a program \\(P_1\\) to yield output, or compile it into another language (program) \\(P_2\\), which has an interpreter to yield an output.\nThe AST interpreter defines the high level semantics.\n\nStatic time\nprint \"hello\" -&gt; tokenizer (lexical anlysis) -&gt; Tokens -&gt; Parser (syntatic analysis) -&gt; AST\n\\(\\downarrow\\)\n\n\nRuntime\nInterpreter (runtime semantics) -&gt; result\n\n\nBytecode Interpreter\nThis is the virtual machine\nSource code is compiled to bytecode.\n\nless memory needed\nfast eval\nbut hard to read by humans\n\nThats why we need disassembly\n“LLVM… custom bytecode.. looks very similar to python bytecode”\n\n\n\nImplementation\n\nParse the program\nCompile the program to bytecode\n\nset instruction pointer to the beginning, and begin loop.\nFor byte, behave accordingly"
  },
  {
    "objectID": "library/natural-sciences/software/virtual-machines/index.html#much-todo",
    "href": "library/natural-sciences/software/virtual-machines/index.html#much-todo",
    "title": "Virtual Machines",
    "section": "MUCH TODO",
    "text": "MUCH TODO\nStack OpCodes Value Definititons: how do we handle numbers, floats, strings?\nLook into the LLVM"
  },
  {
    "objectID": "library/natural-sciences/software/virtual-machines/index.html#glossary",
    "href": "library/natural-sciences/software/virtual-machines/index.html#glossary",
    "title": "Virtual Machines",
    "section": "Glossary",
    "text": "Glossary\n\nEVM vs LLVM\nThe Ethereum Virtual Machine (EVM) is not based on LLVM. They are designed for different purposes, and their architectures and functionalities reflect these distinct goals.\n\nEVM (Ethereum Virtual Machine):\n\nThe EVM is a stack-based virtual machine designed to execute bytecode produced by the compilation of smart contracts written in higher-level languages like Solidity or Vyper. These smart contracts run on the Ethereum blockchain.\nThe EVM operates in a sandboxed environment, ensuring that smart contracts cannot affect the host system or other contracts negatively. It also has a unique gas-based execution model, where every operation consumes a certain amount of “gas” to prevent infinite loops or overly resource-consuming operations.\n\nLLVM:\n\nLLVM, on the other hand, is a compiler framework designed to generate optimized machine code for a wide range of architectures from higher-level languages like C, C++, Rust, and others.\nIt’s modular, allowing for various optimizations and transformations on its intermediate representation (IR) before the code is finally compiled to machine code for specific architectures.\n\n\nWhile the EVM and LLVM are designed for different purposes and do not share a direct relationship, there have been some projects and discussions in the Ethereum community about leveraging LLVM tools or components for specific tasks. For example:\n\neWASM (Ethereum WebAssembly): Ethereum has considered a shift from its current EVM bytecode to a WebAssembly-based system called eWASM. WebAssembly (Wasm) has some ties to the LLVM ecosystem, as LLVM can be used to compile code to Wasm. While eWASM would bring Ethereum closer to technologies associated with LLVM, it’s not a direct usage of LLVM in the EVM.\nSOLL Project: There was a project known as SOLL that aimed to use LLVM to compile Solidity and YUL (an intermediate language for Ethereum) into EVM and eWASM bytecode. It was more of an experimental endeavor and wasn’t a mainstream compiler choice for Ethereum developers.\n\nIn summary, while the core EVM isn’t based on LLVM or directly inspired by it, the broader Ethereum ecosystem has explored and continues to explore synergies with LLVM and related technologies.\n\n\nSandboxed VMs\nCertainly! Let’s start with a foundational understanding of “sandboxing” and then delve into an example comparing a non-sandboxed VM to the EVM.\nSandboxing is a security mechanism used to run code in a restricted environment, isolating it from the broader system. In this isolated space, the code’s potential to cause harm or interfere with other processes is severely limited. The sandbox acts like a protective bubble that restricts access to system resources, data, and functionalities.\n\n\nNon-Sandboxed VM: Java Virtual Machine (JVM)\nWhile the JVM has security mechanisms and can run code in a sandboxed environment (especially applets in older web browsers), it can also run non-sandboxed applications. This means Java applications, when given permissions, can access the filesystem, network, and more.\nMalicious Example in a Non-Sandboxed JVM Environment:\nSuppose you download a Java application and run it without any security restrictions. This application contains the following code snippet:\nimport java.io.*;\npublic class MaliciousApp {\n    public static void main(String[] args) {\n        try {\n            File file = new File(\"/important/system/file.txt\");\n            if (file.delete()) {\n                System.out.println(\"File deleted successfully\");\n            } else {\n                System.out.println(\"Failed to delete the file\");\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\nThis Java application attempts to delete an “important” system file. If run without restrictions, it can harm or disrupt the system.\n\n\nSandboxed VM: Ethereum Virtual Machine (EVM)\nThe EVM is designed explicitly to be sandboxed. Smart contracts on the Ethereum network can only perform a set of predefined operations and cannot directly access the system’s resources, such as the filesystem, network, or other external entities, except through the defined Ethereum protocol.\nWhy the Malicious Code Can’t Affect the Host in EVM:\nLet’s assume a similar intention with a hypothetical smart contract trying to delete a file from the system:\npragma solidity ^0.8.0;\n\ncontract MaliciousContract {\n    function deleteFile() public {\n        // Hypothetical and invalid code\n        system(\"rm /important/system/file.txt\");\n    }\n}\nThis code won’t work in EVM because:\n\nThe EVM doesn’t have a system call or anything similar.\nSmart contracts can’t directly access the host file system, network, or other system resources.\nThe EVM can only do what’s defined in the Ethereum protocol, such as transfer ether, emit events, and interact with other contracts.\n\nThe EVM’s sandboxing ensures that, regardless of the intentions of the smart contract, it cannot do anything outside its defined capabilities. Even if a contract is maliciously designed or has a vulnerability, the damage is generally limited to the contract’s logic or its interactions within the Ethereum ecosystem, rather than the broader system running the EVM."
  },
  {
    "objectID": "library/natural-sciences/software/virtual-machines/index.html#ideas",
    "href": "library/natural-sciences/software/virtual-machines/index.html#ideas",
    "title": "Virtual Machines",
    "section": "IDEAS",
    "text": "IDEAS\nVM specifically optimized for GPU hardware specifically designed for matrix multiplication / AI operations specifically designed for complex applications, like AR/VR"
  },
  {
    "objectID": "library/natural-sciences/software/virtual-machines/index.html#notes",
    "href": "library/natural-sciences/software/virtual-machines/index.html#notes",
    "title": "Virtual Machines",
    "section": "NOTES",
    "text": "NOTES\nThis video at 3:30 he does an incredible introspection of the process of the VM"
  },
  {
    "objectID": "library/social-sciences/events/maui-fire/index.html",
    "href": "library/social-sciences/events/maui-fire/index.html",
    "title": "Maui Fire",
    "section": "",
    "text": "“Residents are being ROYALLY screwed by local, state, and federal governments” tweet\n\nTowns are being fortified\nResidents are becoming impoverished\nGov’t put many out of work\nFederal aid is impossible to get\nNo statement on missing/dead children count\nOfficial counts of total missing keeps changing and suspiciously seems to involve lies\nResidents being arrested in visiting their homes\nGov’t is suspected of hiding something"
  },
  {
    "objectID": "library/life/deposit-cash.html",
    "href": "library/life/deposit-cash.html",
    "title": "Cash Management",
    "section": "",
    "text": "Generally, it is a crime to engage in virtually any type of financial transaction if a person conducted the transaction with knowledge that the funds were the proceeds of “criminal activity” and if the government can prove the proceeds were derived from a “specified unlawful activity”. Criminal activity can be a violation of any criminal law – federal, state, local, or foreign. Specified unlawful activities are set forth in the statute and include over 200 types of U.S. crimes, from drug trafficking, terrorism, and fraud, to crimes traditionally associated with organised crime, and certain foreign crimes, as discussed below in question 1.3.\nThe government does not need to prove that the person conducting the money laundering transaction knew that the proceeds were from a specified form of illegal activity.\nKnowledge can be based on wilful blindness or conscious indifference – failure to inquire when faced with red flags for illegal activity. Additionally, knowledge can be based on a government “sting” or subterfuge, where government agents represent that funds are the proceeds of illegal activity.\nUnder Section 1956, the transaction can be: (1) with the intent to promote the carrying on of the specified unlawful activity; (2) with the intent to engage in U.S. tax evasion or to file a false tax return; (3) knowing the transaction is in whole or in part to disguise the nature, location, source, ownership or control of the proceeds of a specified unlawful activity; or (4) with the intent to avoid a transaction reporting requirement under federal or state law.\nSection 1956 also criminalises the transportation or transmission of funds or monetary instruments (cash or negotiable instruments or securities in bearer form): (1) with the intent to promote the carrying out of a specific unlawful activity; or (2) knowing the funds or monetary instruments represent the proceeds of a specified unlawful activity and the transmission or transportation is designed in whole or in part to conceal or disguise the nature, location, source, ownership or control of the proceeds of the specified unlawful activity.\nUnder Section 1957, it is a crime to knowingly engage in a financial transaction in property derived from specified unlawful activity through a U.S. bank or other “financial institution”, or a foreign bank (in an amount greater than $10,000). Financial institution is broadly defined with reference to the Bank Secrecy Act (“BSA”) statutory definition of financial institution (31 U.S.C. § 5312(a)(2)), and includes not just banks but a wide range of other financial businesses, including securities broker-dealers, insurance companies, non-bank finance companies, and casinos."
  },
  {
    "objectID": "library/life/deposit-cash.html#acquiring-a-large-amount-of-cash",
    "href": "library/life/deposit-cash.html#acquiring-a-large-amount-of-cash",
    "title": "Cash Management",
    "section": "",
    "text": "Generally, it is a crime to engage in virtually any type of financial transaction if a person conducted the transaction with knowledge that the funds were the proceeds of “criminal activity” and if the government can prove the proceeds were derived from a “specified unlawful activity”. Criminal activity can be a violation of any criminal law – federal, state, local, or foreign. Specified unlawful activities are set forth in the statute and include over 200 types of U.S. crimes, from drug trafficking, terrorism, and fraud, to crimes traditionally associated with organised crime, and certain foreign crimes, as discussed below in question 1.3.\nThe government does not need to prove that the person conducting the money laundering transaction knew that the proceeds were from a specified form of illegal activity.\nKnowledge can be based on wilful blindness or conscious indifference – failure to inquire when faced with red flags for illegal activity. Additionally, knowledge can be based on a government “sting” or subterfuge, where government agents represent that funds are the proceeds of illegal activity.\nUnder Section 1956, the transaction can be: (1) with the intent to promote the carrying on of the specified unlawful activity; (2) with the intent to engage in U.S. tax evasion or to file a false tax return; (3) knowing the transaction is in whole or in part to disguise the nature, location, source, ownership or control of the proceeds of a specified unlawful activity; or (4) with the intent to avoid a transaction reporting requirement under federal or state law.\nSection 1956 also criminalises the transportation or transmission of funds or monetary instruments (cash or negotiable instruments or securities in bearer form): (1) with the intent to promote the carrying out of a specific unlawful activity; or (2) knowing the funds or monetary instruments represent the proceeds of a specified unlawful activity and the transmission or transportation is designed in whole or in part to conceal or disguise the nature, location, source, ownership or control of the proceeds of the specified unlawful activity.\nUnder Section 1957, it is a crime to knowingly engage in a financial transaction in property derived from specified unlawful activity through a U.S. bank or other “financial institution”, or a foreign bank (in an amount greater than $10,000). Financial institution is broadly defined with reference to the Bank Secrecy Act (“BSA”) statutory definition of financial institution (31 U.S.C. § 5312(a)(2)), and includes not just banks but a wide range of other financial businesses, including securities broker-dealers, insurance companies, non-bank finance companies, and casinos."
  },
  {
    "objectID": "library/life/deposit-cash.html#the-atm-approach",
    "href": "library/life/deposit-cash.html#the-atm-approach",
    "title": "Cash Management",
    "section": "The ATM Approach",
    "text": "The ATM Approach\n\nStep 1 | Buy an ATM\nATM Global Phone: (877) 286-1755 https://atmglobal.net/ *We got permission from Douglas to use the call for this video.\nNational ATM Systems Phone: (803) 786-1900 https://www.nasatm.com/\nOcean ATM Phone: (877) 538-2860 https://oceanatm.com\nAmerica’s ATM Phone: (877) 475-1104 https://americanatm.com\nATM Money Machine Phone: (609) 641-7300 https://www.atmmoneymachine.com\nStep-by-Step Guide\nThese companies deliver a machine to your location (machines ~$2,500), and have installers come to set it up ($350 for installation). This takes about 2 weeks.\nI know the guy who owns the restaurant Ella Funt in Soho. Something like this would be perfect.\n\n\nStep 2 | Set it up\nAll ATMs must be connected to the processing server and have a power outlet. There are three optional connections: 1. Hardwire Internet Line 2. Phoneline 3. Purchase an ATM Wireless Box\nYou can not connect to wireless internet in the business, you must hardwire into the internet via an ethernet jack or run an ethernet cord from the modem to the ATM.\n\n\nStep 3 | Paperwork\nThen you fill out some forms with the ATM company (“Exhibit 2, Exhibit 3, W9”) that do basic background checks: if you have any fraud in your past, etc.\nThe paperwork will give you your own unique merchant ID, which allows you into the processing server. We handle getting this licensing done for you.\nConnect your account with them to a (business) bank account. The ATM company sets up an interface for you to monitor transactions, get notifications that the cash balance is low, etc."
  },
  {
    "objectID": "library/natural-sciences/physics/particle/index.html",
    "href": "library/natural-sciences/physics/particle/index.html",
    "title": "Particle Physics",
    "section": "",
    "text": "Observation of an excess of di-charmonium events in the four-muon final state with the ATLAS detector\n\n\n\n\nLie Algebras in Particle Physics\n\nLie Algebras in particle physics are mathematical structures that help to describe and classify physical systems, particularly those involving symmetries and transformations. In essence, a Lie algebra is a vector space equipped with a certain kind of product, called the Lie bracket, that captures the essential information about continuous transformations and symmetries. When applied to particle physics, Lie algebras offer a robust framework for understanding the fundamental particles and forces that govern the universe.\nThe concept of Lie algebras originated in the late 19th century with the work of Norwegian mathematician Sophus Lie. Originally developed to study continuous transformation groups, the scope of Lie algebras has expanded to diverse areas of mathematics and physics. Their application in particle physics became increasingly significant during the 20th century, especially after the development of quantum mechanics and quantum field theory. The SU(3) Lie algebra, for example, was crucial in predicting the existence of particles like the omega-minus baryon before it was experimentally discovered.\nLie algebras offer a theoretical structure that is essential for formulating the Standard Model of particle physics, which describes electromagnetic, weak, and strong forces. Because Lie algebras are tightly connected to symmetry principles, they enable physicists to simplify complex systems and make predictions about particle interactions.\nApplications\n\nParticle Classification: Used for the classification of elementary particles into families and generations, assisting in the prediction of undiscovered particles.\nSymmetry Breaking: Helps in understanding the mechanism by which symmetry breaking occurs, a phenomenon critical to our understanding of the universe.\nField Theories: Employed in various quantum field theories to solve or approximate solutions for complex equations of motion.\nUnification Theories: Lie algebras and their corresponding Lie groups have been essential in attempts to develop Grand Unified Theories (GUTs) and even theories of everything.\n\nRelevant Subtopics\n\nBasic Definitions and Principles: Introduction to Lie groups, Lie algebras, and the relationship between them.\nRepresentation Theory: How Lie algebras can be represented as matrices, and why these representations are useful in particle physics.\nSU(N) Algebras: Special Unitary Groups of degree (N) and their importance in particle physics.\nSymmetry and Conservation Laws: Discussion on how Lie algebras relate to symmetries in physical systems and the corresponding conservation laws.\nApplication to the Standard Model: Utilizing Lie algebras to describe the particles and interactions within the Standard Model.\nAdvanced Topics: Covering roots, weights, Dynkin diagrams, and their role in particle physics.\n\n\n\n\nThe coupling used with the Higgs field to create a fundamental mass is the Yukawa coupling. In the Standard Model of particle physics, the Higgs field interacts with fermions (particles with half-integer spin, such as quarks and leptons) through the Yukawa coupling. The Yukawa coupling is a term in the Lagrangian of the Standard Model that describes the interaction between the Higgs field and fermions.\nThe Yukawa coupling takes the form:\n\\[\\mathcal{L}_{Yuk} = -y_f \\bar{f}_L \\Phi f_R + h.c.\\]\nwhere \\(y_f\\) is the Yukawa coupling constant for the fermion \\(f\\), \\(\\bar{f}_L\\) is the left-handed component of the fermion field, \\(\\Phi\\) is the Higgs field, and \\(f_R\\) is the right-handed component of the fermion field. The left-handed and right-handed components of the fermion field transform differently under the electroweak gauge group, and this leads to a mass term for the fermion after the Higgs field acquires a vacuum expectation value.\nThe Yukawa coupling is responsible for generating the masses of the fermions in the Standard Model. The strength of the coupling determines the mass of the fermion - the larger the Yukawa coupling, the larger the mass of the fermion. The Yukawa couplings have been measured experimentally and are one of the key parameters of the Standard Model.\n\n\n\nFermions are a type of elementary particle that obey the Fermi-Dirac statistics, which dictate their behavior under quantum mechanics. They are named after Enrico Fermi, an Italian physicist who made significant contributions to the development of the theory of quantum mechanics.\nFermions are one of the two fundamental types of particles in the universe, the other being bosons. While bosons have integer values of spin, fermions have half-integer values of spin. This fundamental difference between fermions and bosons has important implications for their behavior under different physical conditions.\nFermions are subject to the Pauli exclusion principle, which states that no two fermions can occupy the same quantum state simultaneously. This means that if two fermions have the same set of quantum numbers, they cannot occupy the same energy level and must occupy different energy levels instead. This principle has important implications for the behavior of fermions in systems with many particles, such as atoms and solids.\nFermions include particles such as electrons, protons, and neutrons, which make up the matter in the universe. They also include other elementary particles, such as quarks and leptons, which are the building blocks of matter. The behavior of fermions is essential to many areas of physics, including condensed matter physics, particle physics, and cosmology."
  },
  {
    "objectID": "library/natural-sciences/physics/particle/index.html#resources",
    "href": "library/natural-sciences/physics/particle/index.html#resources",
    "title": "Particle Physics",
    "section": "",
    "text": "Observation of an excess of di-charmonium events in the four-muon final state with the ATLAS detector\n\n\n\n\nLie Algebras in Particle Physics\n\nLie Algebras in particle physics are mathematical structures that help to describe and classify physical systems, particularly those involving symmetries and transformations. In essence, a Lie algebra is a vector space equipped with a certain kind of product, called the Lie bracket, that captures the essential information about continuous transformations and symmetries. When applied to particle physics, Lie algebras offer a robust framework for understanding the fundamental particles and forces that govern the universe.\nThe concept of Lie algebras originated in the late 19th century with the work of Norwegian mathematician Sophus Lie. Originally developed to study continuous transformation groups, the scope of Lie algebras has expanded to diverse areas of mathematics and physics. Their application in particle physics became increasingly significant during the 20th century, especially after the development of quantum mechanics and quantum field theory. The SU(3) Lie algebra, for example, was crucial in predicting the existence of particles like the omega-minus baryon before it was experimentally discovered.\nLie algebras offer a theoretical structure that is essential for formulating the Standard Model of particle physics, which describes electromagnetic, weak, and strong forces. Because Lie algebras are tightly connected to symmetry principles, they enable physicists to simplify complex systems and make predictions about particle interactions.\nApplications\n\nParticle Classification: Used for the classification of elementary particles into families and generations, assisting in the prediction of undiscovered particles.\nSymmetry Breaking: Helps in understanding the mechanism by which symmetry breaking occurs, a phenomenon critical to our understanding of the universe.\nField Theories: Employed in various quantum field theories to solve or approximate solutions for complex equations of motion.\nUnification Theories: Lie algebras and their corresponding Lie groups have been essential in attempts to develop Grand Unified Theories (GUTs) and even theories of everything.\n\nRelevant Subtopics\n\nBasic Definitions and Principles: Introduction to Lie groups, Lie algebras, and the relationship between them.\nRepresentation Theory: How Lie algebras can be represented as matrices, and why these representations are useful in particle physics.\nSU(N) Algebras: Special Unitary Groups of degree (N) and their importance in particle physics.\nSymmetry and Conservation Laws: Discussion on how Lie algebras relate to symmetries in physical systems and the corresponding conservation laws.\nApplication to the Standard Model: Utilizing Lie algebras to describe the particles and interactions within the Standard Model.\nAdvanced Topics: Covering roots, weights, Dynkin diagrams, and their role in particle physics.\n\n\n\n\nThe coupling used with the Higgs field to create a fundamental mass is the Yukawa coupling. In the Standard Model of particle physics, the Higgs field interacts with fermions (particles with half-integer spin, such as quarks and leptons) through the Yukawa coupling. The Yukawa coupling is a term in the Lagrangian of the Standard Model that describes the interaction between the Higgs field and fermions.\nThe Yukawa coupling takes the form:\n\\[\\mathcal{L}_{Yuk} = -y_f \\bar{f}_L \\Phi f_R + h.c.\\]\nwhere \\(y_f\\) is the Yukawa coupling constant for the fermion \\(f\\), \\(\\bar{f}_L\\) is the left-handed component of the fermion field, \\(\\Phi\\) is the Higgs field, and \\(f_R\\) is the right-handed component of the fermion field. The left-handed and right-handed components of the fermion field transform differently under the electroweak gauge group, and this leads to a mass term for the fermion after the Higgs field acquires a vacuum expectation value.\nThe Yukawa coupling is responsible for generating the masses of the fermions in the Standard Model. The strength of the coupling determines the mass of the fermion - the larger the Yukawa coupling, the larger the mass of the fermion. The Yukawa couplings have been measured experimentally and are one of the key parameters of the Standard Model.\n\n\n\nFermions are a type of elementary particle that obey the Fermi-Dirac statistics, which dictate their behavior under quantum mechanics. They are named after Enrico Fermi, an Italian physicist who made significant contributions to the development of the theory of quantum mechanics.\nFermions are one of the two fundamental types of particles in the universe, the other being bosons. While bosons have integer values of spin, fermions have half-integer values of spin. This fundamental difference between fermions and bosons has important implications for their behavior under different physical conditions.\nFermions are subject to the Pauli exclusion principle, which states that no two fermions can occupy the same quantum state simultaneously. This means that if two fermions have the same set of quantum numbers, they cannot occupy the same energy level and must occupy different energy levels instead. This principle has important implications for the behavior of fermions in systems with many particles, such as atoms and solids.\nFermions include particles such as electrons, protons, and neutrons, which make up the matter in the universe. They also include other elementary particles, such as quarks and leptons, which are the building blocks of matter. The behavior of fermions is essential to many areas of physics, including condensed matter physics, particle physics, and cosmology."
  },
  {
    "objectID": "library/natural-sciences/maths/index.html",
    "href": "library/natural-sciences/maths/index.html",
    "title": "Maths",
    "section": "",
    "text": "Advice to a Young Mathematician\nExplained from First Principles"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#general",
    "href": "library/natural-sciences/maths/index.html#general",
    "title": "Maths",
    "section": "",
    "text": "Advice to a Young Mathematician\nExplained from First Principles"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html",
    "href": "library/natural-sciences/computer-hardware/index.html",
    "title": "Computer Hardware",
    "section": "",
    "text": "CPUs are designed for serialized execution: fault tolerant, low latency\nA CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\nTODO: more content coming soon"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/chips/gpus/nvidia.html",
    "href": "library/natural-sciences/computer-hardware/chips/gpus/nvidia.html",
    "title": "Nvidia GPU",
    "section": "",
    "text": "Supercut\nThe HGX H100 H100 has 35,000 components and 8 Hopper GPUs. It weighs 60 pounds, and costs $200,000. The compute tray is the first computer with a transformer engine in it.\nThere’s 2 fundamental trends: CPU scaling has ended, and AI has begun (accelerated computing). the tipping point, NVIDIA GPU utilization is high.\nComparison: $10mm\n\n960 CPUs, consumes 11GWh, 1x LLM\n48 GPUs, consumes 3.2 GWh, 44x LLM (performance)\n\n\n\n\nHGX H100\nGrace Hopper Superchip\nNVLINK Switch\n\nThe Super GPU: The Grace Hopper Supercomputer\nGrace Hopper Superchip X 8 NVLINK Switch x3 X 32 NVLINK Switch x36 = 256 Grace Hopper Superchips, 1 ExaFLOPS Transformer Engine, 144TB GPU Memory\n150 mi optical fiber, 2,112 60mm fans, 70k CFM, 40k lbs, 1GPU"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/chips/gpus/nvidia.html#july-2023-presentation",
    "href": "library/natural-sciences/computer-hardware/chips/gpus/nvidia.html#july-2023-presentation",
    "title": "Nvidia GPU",
    "section": "",
    "text": "Supercut\nThe HGX H100 H100 has 35,000 components and 8 Hopper GPUs. It weighs 60 pounds, and costs $200,000. The compute tray is the first computer with a transformer engine in it.\nThere’s 2 fundamental trends: CPU scaling has ended, and AI has begun (accelerated computing). the tipping point, NVIDIA GPU utilization is high.\nComparison: $10mm\n\n960 CPUs, consumes 11GWh, 1x LLM\n48 GPUs, consumes 3.2 GWh, 44x LLM (performance)\n\n\n\n\nHGX H100\nGrace Hopper Superchip\nNVLINK Switch\n\nThe Super GPU: The Grace Hopper Supercomputer\nGrace Hopper Superchip X 8 NVLINK Switch x3 X 32 NVLINK Switch x36 = 256 Grace Hopper Superchips, 1 ExaFLOPS Transformer Engine, 144TB GPU Memory\n150 mi optical fiber, 2,112 60mm fans, 70k CFM, 40k lbs, 1GPU"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#privacy",
    "href": "library/natural-sciences/crypto/blockchains/index.html#privacy",
    "title": "Blockchains",
    "section": "Privacy",
    "text": "Privacy\nBlockchain Privacy and Rgulatory Compliance: Towards a Practical Equilibrium"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/index.html#partnerships",
    "href": "library/natural-sciences/crypto/blockchains/solana/index.html#partnerships",
    "title": "Solana",
    "section": "Partnerships",
    "text": "Partnerships\n\nVisa expands stablecoin settlement capabilities with Circle’s USDC utilizing the Solana blockchain.\nVia: A deep dive on Solana, a high performance blockchain network\n\n\nFee Markets\n\nPriority Fees Github Issue\nDune Query: % of Sol Txs with Fee above base\n\n\n\nThe Solana Validator\n\nFiredancer: A New Client by Jump\nValidator Economics on Solana"
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/stake.html",
    "href": "library/natural-sciences/crypto/rekt/stake.html",
    "title": "Stake",
    "section": "",
    "text": "Timeline\nFirst and second transactions\nPeckshield Alert | tweet\nFlow of Funds Diagram | tweet\nStake statement\n\n\nOverview\nETH, BSC, and Polygon affected"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/index.html",
    "href": "library/natural-sciences/crypto/mev/index.html",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay\nMempool Dumpster"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/index.html#dashboards-tools",
    "href": "library/natural-sciences/crypto/mev/index.html#dashboards-tools",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay\nMempool Dumpster"
  },
  {
    "objectID": "library/natural-sciences/crypto/mev/index.html#research",
    "href": "library/natural-sciences/crypto/mev/index.html#research",
    "title": "Overview",
    "section": "Research",
    "text": "Research\n\nEarly Research\n\nEnter the Hydra\nThe Cost of Decentralization in 0x and EtherDelta\nFlash Boys 2.0\nOrder-Fairness for Byzantine Consensus\nThemis: Fast, Strong Order-Fairness in Byzantine Consensus\nMEV… Wat Do?\nEthereum is a Dark Forest\nFlashbots: Frontrunning the MEV Crisis\n\n\n\nGeneral\n\nStudying Flash Loan Attacks | paper\nMEV by Galaxy Digital | Blog Pt 2\nModular MEV Write-up\nPerformant routing and latency benchmarking for Ethereum RPC and Relay Service Providers\nHigh Granularity Cex Data | tardis.dev\nMEV in Fixed Price Auctions | paper | tweet\nMEV Boost Capella Upgrades | article\nFrontier Research | website\nSo you want to run a builder?\nHow to Fix Ethereum’s MEV Problem\nMEV in ETH2 - An Early Exploration\nImproving PoS Economic Security via MEV Redistribution\nTowards a Theory of MEV I\nFlashbots Research Repository\n\n\n\nMEV-Boost / Proposer-Builder Separation\n\nProposer Boost Considerations\nMEV-Boost Plan\n\n\n\nVideos & Talks\n\nMEV Day\n\nVideo Recap\n\nEncode x Wintermute: MEV with Robert Miller\nStanford MEV Workshop Recording\nMEVconomics Playlist | youtube\nStanford Blockchain Conference (SBC’23)\nRecordings: Day 1 | Day 2 | Day 3\nMEV Workshop at SBC’23 | Recording\n\n\n\nProtocols, and Implementation Resources\nUniswap V3 Book - docs\nAutomated Market Making and Arbitrage Profits in the Presence of Fees - paper\nMEV Capturing AMM - proposal\nTime to Bribe: Measuring Block Construction Markets - paper\nA Framework for Building Searchers - article\nSomeone’s Mega-resource on MEV - notion\nRunning MEV-Relay at Scale - notion\nLatency Arms Race - post\nFBAs (frequent batch auctions) are a nerd snipe - tweet\nJaredFromSubway.eth’s Access Lists - etherscan"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/chips/gpus/index.html",
    "href": "library/natural-sciences/computer-hardware/chips/gpus/index.html",
    "title": "GPU",
    "section": "",
    "text": "Highest level, the Graphics Processing Unit. This is a parallel processor. CPUs on the other hand, have a single processor for sequential processing.\nApple’s GPU cores are split into 16 execution units, where each of these has 8 algorithmic logic units (ALUs).\nWhen NVIDIA says they have “8960 CUDA Cores” this is referring to ALUs. ALUs are the fundamental operating units."
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/chips/gpus/index.html#overview",
    "href": "library/natural-sciences/computer-hardware/chips/gpus/index.html#overview",
    "title": "GPU",
    "section": "",
    "text": "Highest level, the Graphics Processing Unit. This is a parallel processor. CPUs on the other hand, have a single processor for sequential processing.\nApple’s GPU cores are split into 16 execution units, where each of these has 8 algorithmic logic units (ALUs).\nWhen NVIDIA says they have “8960 CUDA Cores” this is referring to ALUs. ALUs are the fundamental operating units."
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/chips/gpus/index.html#vs-cpus",
    "href": "library/natural-sciences/computer-hardware/chips/gpus/index.html#vs-cpus",
    "title": "GPU",
    "section": "Vs CPUs",
    "text": "Vs CPUs\nGPUs are designed for parallel procesing: high throughout, less control logic\nCPUs are designed for serialized execution: fault tolerant, low latency\nA CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\nParallelizable problems are good for a GPU.\n- scalarize a large set of vectors"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html",
    "href": "library/natural-sciences/physics/index.html",
    "title": "Physics",
    "section": "",
    "text": "This page provides a brief overview of each subdomain of physics. Each header is a link to the page which explores the respective domain further."
  },
  {
    "objectID": "library/life-sciences/biology/cells.html",
    "href": "library/life-sciences/biology/cells.html",
    "title": "Cells",
    "section": "",
    "text": "The structure of a cell is wildly oversimplified | tweet"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/chips/gpus/index.html#cuda-framwork",
    "href": "library/natural-sciences/computer-hardware/chips/gpus/index.html#cuda-framwork",
    "title": "GPU",
    "section": "CUDA Framwork",
    "text": "CUDA Framwork\nA software framework by NVIDIA to simplify parallelization."
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#cpus-vs-gpus",
    "href": "library/natural-sciences/computer-hardware/index.html#cpus-vs-gpus",
    "title": "Computer Hardware",
    "section": "CPUs vs GPUs",
    "text": "CPUs vs GPUs\nGPUs are designed for parallel procesing: high throughout, less control logic\nCPUs are designed for serialized execution: fault tolerant, low latency\nA CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\nParallelizable problems are good for a GPU."
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#risc",
    "href": "library/natural-sciences/computer-hardware/index.html#risc",
    "title": "Computer Hardware",
    "section": "RISC",
    "text": "RISC\nRISC (Reduced Instruction Set Computer) is a design philosophy for CPUs, emphasizing a small and simple set of instructions that execute in a single clock cycle. RISC-V, on the other hand, is a specific, open-standard instruction set architecture (ISA) based on the RISC principles.\nWhile RISC and RISC-V are primarily associated with CPUs, the concepts and ISAs can be applied elsewhere. In fact, with the advent of more versatile computing platforms and the demand for specialized hardware accelerators, the lines between CPUs, GPUs, and other processing units can sometimes blur.\nGPUs and RISC: GPUs (Graphics Processing Units) have a different historical design lineage than CPUs. While CPUs are designed for general-purpose tasks and can handle a wide variety of operations in sequence, GPUs are designed for parallelism, optimized for executing the same operation on a large number of data elements simultaneously. This design is especially suitable for graphics rendering tasks, where, for instance, the same shading operation might be applied to millions of pixels.\nThat said, modern GPUs have evolved and can handle more general-purpose tasks. This field, known as GPGPU (General-Purpose computing on Graphics Processing Units), has grown in prominence, especially with applications in scientific computing, machine learning, etc.\nThe instruction set architectures for GPUs are typically proprietary to the manufacturer: - NVIDIA GPUs use an architecture known as CUDA (Compute Unified Device Architecture). - AMD GPUs use architectures like GCN (Graphics Core Next) or RDNA.\nWhile these architectures might share some high-level concepts with RISC — like the importance of efficiency and streamlined operations — they’re not RISC architectures in the traditional sense.\nRISC-V and GPUs: RISC-V, given its open nature, is seeing exploration beyond traditional CPUs. There are projects and discussions around using RISC-V principles in GPU design or other specialized hardware accelerators. However, as of my last training data in September 2021, RISC-V’s primary traction is in the CPU space, from microcontrollers to more powerful processors.\nIn conclusion, while RISC and RISC-V are primarily associated with CPUs, the principles and architectures are versatile. The GPU world has its architectures optimized for its specific tasks, but the lines between these domains are evolving, and there’s potential for overlap in the future.\n\nDesigning a VM for GPUs\nDesigning a virtual machine (VM) specifically optimized for GPUs and AI operations is not just a sensible idea, but it’s also a direction in which some sectors of the tech industry are heading. Let’s explore why this is a compelling notion and what features or characteristics such a VM might possess.\n\n\nRationale:\n\nSpecialized Operations: AI operations, especially deep learning, involve a lot of matrix multiplications and tensor operations. Traditional VMs are not optimized for these.\nMassive Parallelism: GPUs are inherently parallel and can handle thousands of threads simultaneously. A VM designed with this in mind would cater to this strength.\nMemory Management: Deep learning models, especially larger ones, can consume significant amounts of memory. Effective and efficient memory management tailored for these operations can greatly boost performance.\nInteroperability: AI frameworks and libraries are vast and varied (TensorFlow, PyTorch, ONNX, etc.). A VM optimized for AI could provide native support or efficient bridges for these frameworks.\n\n\n\nFeatures/Characteristics:\n\nTensor Operations: First-class support for tensor operations would be a fundamental feature. This means native operations for matrix multiplications, convolutions, etc., optimized for the VM.\nDynamic Scheduling: Given the parallel nature of GPUs, the VM should be capable of dynamically scheduling tasks based on GPU workloads, ensuring maximum hardware utilization.\nMemory Hierarchies: GPUs have various memory types (global, shared, local, constant). The VM should manage these efficiently, allocating memory based on access patterns and tensor sizes.\nCustom Instruction Sets: The VM’s bytecode or intermediate representation might have custom instructions tailored for common AI patterns and operations.\nJust-In-Time (JIT) Compilation: To squeeze out maximum performance, the VM could utilize JIT compilation, translating bytecode to GPU instructions on the fly, with optimizations based on the actual data and model being processed.\nHardware Acceleration: Besides standard GPU operations, there could be support for AI-specific hardware accelerators or ASICs (like Google’s TPUs).\nNative Libraries: Integrated support for popular deep learning libraries or primitives, ensuring optimized performance without redundant operations.\nSafety and Security: With AI models being deployed in critical applications, features to ensure model integrity, data privacy, and secure execution would be essential.\nPortability: One of the core benefits of a VM is portability. The VM should ensure that AI models run consistently across various GPU architectures and versions.\nInteroperability Bridges: Efficient connectors or bridges to interact with popular AI frameworks, ensuring smooth deployment without significant model rewrites.\nDebugging and Profiling: Built-in tools for performance profiling, debugging, and visualization, catering specifically to AI operations.\n\nIn essence, the idea of a virtual machine optimized for GPUs and AI operations seeks to bridge the gap between high-level AI frameworks and the raw power of GPU hardware. While creating such a VM is a non-trivial task and demands deep integration between software and hardware, the potential benefits in terms of performance, security, and portability make it a compelling direction for the future of AI infrastructure.\nAs of my last update in September 2021, there isn’t a mainstream “virtual machine” tailored explicitly for GPUs in the same way that the Java Virtual Machine (JVM) or the Ethereum Virtual Machine (EVM) are for their respective domains. However, there are platforms and runtime environments optimized for GPU operations, especially in the context of AI/ML.\nSome of these platforms and their unique features include:\n\nCUDA (Compute Unified Device Architecture):\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nProvides a parallel computing platform and API model.\nIncorporates the CUDA Instruction Set Architecture (ISA) and the parallel compute engine in NVIDIA GPUs.\nSupports various high-level programming languages like C, C++, and Fortran.\n\nUse Cases: General GPU-accelerated computing, scientific simulations, deep learning training & inference.\n\nTensorRT:\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nHigh-performance deep learning inference optimizer and runtime.\nReduces the model size for faster inferencing.\nProvides INT8 and FP16 optimizations for production deployments.\n\nUse Cases: Optimizing and deploying deep learning models for production environments, especially on NVIDIA GPUs.\n\nROCm (Radeon Open Compute):\n\nDeveloper & Manufacturer: AMD\nUnique Features:\n\nOpen-source platform for GPU-enabled HPC (High Performance Computing) computing.\nSupports a range of machine learning frameworks like TensorFlow and PyTorch.\n\nUse Cases: GPU-accelerated computing on AMD GPUs, scientific simulations, AI/ML training & inference.\n\nDirectML:\n\nDeveloper: Microsoft\nUnique Features:\n\nPart of the DirectX family, providing a low-level API for ML.\nHardware-accelerated and works with any DirectX 12-compatible GPU.\n\nUse Cases: GPU-accelerated ML inference in Windows applications.\n\n\nThese platforms are more akin to runtime environments than traditional “virtual machines.” Still, they are optimized for GPU operations, and they play a role similar to VMs by providing a bridge between high-level code and low-level hardware instructions.\nMain Benefits of GPU-optimized Platforms: 1. Performance: Accelerate computations that can be parallelized, dramatically reducing the time required for tasks like training deep learning models. 2. Efficiency: Better utilization of available GPU resources, ensuring that the hardware’s full capabilities are harnessed. 3. Portability: In some cases (like CUDA to some extent), the platform provides an abstraction over the hardware, allowing code to run on different GPU architectures (within limits and considering vendor lock-ins). 4. Integration with Popular Tools: Many of these platforms offer integrations with popular ML frameworks, making it easier to transition from research to production.\nHowever, it’s essential to understand that while these platforms provide the tools and runtime for GPU-optimized operations, they don’t function as “virtual machines” in the traditional sense of emulating a complete computing environment. They are closer to specialized compilers and runtime environments."
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#gpu",
    "href": "library/natural-sciences/computer-hardware/index.html#gpu",
    "title": "Computer Hardware",
    "section": "GPU",
    "text": "GPU\nGraphics Processing Units are designed for parallel procesing: high throughout, less control logic.\nApple’s GPU cores are split into 16 execution units, where each of these has 8 algorithmic logic units (ALUs). When NVIDIA says they have “8960 CUDA Cores” this is referring to ALUs. ALUs are the fundamental operating units.\nCUDA is a software framework by NVIDIA to simplify parallelization.\n\nNVIDIA\nSupercut Presentation, July 2023\nThe HGX H100 H100 has 35,000 components and 8 Hopper GPUs. It weighs 60 pounds, and costs $200,000. The compute tray is the first computer with a transformer engine in it.\nThere’s 2 fundamental trends: CPU scaling has ended, and AI has begun (accelerated computing). the tipping point, NVIDIA GPU utilization is high.\nComparison: $10mm\n\n960 CPUs, consumes 11GWh, 1x LLM\n48 GPUs, consumes 3.2 GWh, 44x LLM (performance)"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#cuda-framwork",
    "href": "library/natural-sciences/computer-hardware/index.html#cuda-framwork",
    "title": "Computer Hardware",
    "section": "CUDA Framwork",
    "text": "CUDA Framwork\nCUDA is a software framework by NVIDIA to simplify parallelization."
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#cpus",
    "href": "library/natural-sciences/computer-hardware/index.html#cpus",
    "title": "Computer Hardware",
    "section": "",
    "text": "CPUs are designed for serialized execution: fault tolerant, low latency\nA CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\nTODO: more content coming soon"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#part-a",
    "href": "library/natural-sciences/physics/index.html#part-a",
    "title": "Physics",
    "section": "",
    "text": "Einstein, Barcelona, Symmetry & Cosmology: The Birth of an Equation for the Universe\nBrief History of Guage Field Physics\nNew shape of parity-violating graviton non-Gaussianity | Explainer"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#part-b",
    "href": "library/natural-sciences/physics/index.html#part-b",
    "title": "Physics",
    "section": "Part B",
    "text": "Part B"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#cpu",
    "href": "library/natural-sciences/computer-hardware/index.html#cpu",
    "title": "Computer Hardware",
    "section": "",
    "text": "CPUs are designed for serialized execution: fault tolerant, low latency\nA CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\nTODO: more content coming soon"
  },
  {
    "objectID": "library/natural-sciences/computer-hardware/index.html#risc-architecture",
    "href": "library/natural-sciences/computer-hardware/index.html#risc-architecture",
    "title": "Computer Hardware",
    "section": "RISC Architecture",
    "text": "RISC Architecture\nRISC (Reduced Instruction Set Computer) is a design philosophy for CPUs, emphasizing a small and simple set of instructions that execute in a single clock cycle. RISC-V, on the other hand, is a specific, open-standard instruction set architecture (ISA) based on the RISC principles.\nWhile RISC and RISC-V are primarily associated with CPUs, the concepts and ISAs can be applied elsewhere. In fact, with the advent of more versatile computing platforms and the demand for specialized hardware accelerators, the lines between CPUs, GPUs, and other processing units can sometimes blur.\nGPUs and RISC: GPUs (Graphics Processing Units) have a different historical design lineage than CPUs. While CPUs are designed for general-purpose tasks and can handle a wide variety of operations in sequence, GPUs are designed for parallelism, optimized for executing the same operation on a large number of data elements simultaneously. This design is especially suitable for graphics rendering tasks, where, for instance, the same shading operation might be applied to millions of pixels.\nThat said, modern GPUs have evolved and can handle more general-purpose tasks. This field, known as GPGPU (General-Purpose computing on Graphics Processing Units), has grown in prominence, especially with applications in scientific computing, machine learning, etc.\nThe instruction set architectures for GPUs are typically proprietary to the manufacturer: - NVIDIA GPUs use an architecture known as CUDA (Compute Unified Device Architecture). - AMD GPUs use architectures like GCN (Graphics Core Next) or RDNA.\nWhile these architectures might share some high-level concepts with RISC — like the importance of efficiency and streamlined operations — they’re not RISC architectures in the traditional sense.\nRISC-V and GPUs: RISC-V, given its open nature, is seeing exploration beyond traditional CPUs. There are projects and discussions around using RISC-V principles in GPU design or other specialized hardware accelerators. However, as of my last training data in September 2021, RISC-V’s primary traction is in the CPU space, from microcontrollers to more powerful processors.\nIn conclusion, while RISC and RISC-V are primarily associated with CPUs, the principles and architectures are versatile. The GPU world has its architectures optimized for its specific tasks, but the lines between these domains are evolving, and there’s potential for overlap in the future.\n\nDesigning a VM for GPUs\nDesigning a virtual machine (VM) specifically optimized for GPUs and AI operations is not just a sensible idea, but it’s also a direction in which some sectors of the tech industry are heading. Let’s explore why this is a compelling notion and what features or characteristics such a VM might possess.\n\n\nRationale:\n\nSpecialized Operations: AI operations, especially deep learning, involve a lot of matrix multiplications and tensor operations. Traditional VMs are not optimized for these.\nMassive Parallelism: GPUs are inherently parallel and can handle thousands of threads simultaneously. A VM designed with this in mind would cater to this strength.\nMemory Management: Deep learning models, especially larger ones, can consume significant amounts of memory. Effective and efficient memory management tailored for these operations can greatly boost performance.\nInteroperability: AI frameworks and libraries are vast and varied (TensorFlow, PyTorch, ONNX, etc.). A VM optimized for AI could provide native support or efficient bridges for these frameworks.\n\n\n\nFeatures/Characteristics:\n\nTensor Operations: First-class support for tensor operations would be a fundamental feature. This means native operations for matrix multiplications, convolutions, etc., optimized for the VM.\nDynamic Scheduling: Given the parallel nature of GPUs, the VM should be capable of dynamically scheduling tasks based on GPU workloads, ensuring maximum hardware utilization.\nMemory Hierarchies: GPUs have various memory types (global, shared, local, constant). The VM should manage these efficiently, allocating memory based on access patterns and tensor sizes.\nCustom Instruction Sets: The VM’s bytecode or intermediate representation might have custom instructions tailored for common AI patterns and operations.\nJust-In-Time (JIT) Compilation: To squeeze out maximum performance, the VM could utilize JIT compilation, translating bytecode to GPU instructions on the fly, with optimizations based on the actual data and model being processed.\nHardware Acceleration: Besides standard GPU operations, there could be support for AI-specific hardware accelerators or ASICs (like Google’s TPUs).\nNative Libraries: Integrated support for popular deep learning libraries or primitives, ensuring optimized performance without redundant operations.\nSafety and Security: With AI models being deployed in critical applications, features to ensure model integrity, data privacy, and secure execution would be essential.\nPortability: One of the core benefits of a VM is portability. The VM should ensure that AI models run consistently across various GPU architectures and versions.\nInteroperability Bridges: Efficient connectors or bridges to interact with popular AI frameworks, ensuring smooth deployment without significant model rewrites.\nDebugging and Profiling: Built-in tools for performance profiling, debugging, and visualization, catering specifically to AI operations.\n\nIn essence, the idea of a virtual machine optimized for GPUs and AI operations seeks to bridge the gap between high-level AI frameworks and the raw power of GPU hardware. While creating such a VM is a non-trivial task and demands deep integration between software and hardware, the potential benefits in terms of performance, security, and portability make it a compelling direction for the future of AI infrastructure.\nAs of my last update in September 2021, there isn’t a mainstream “virtual machine” tailored explicitly for GPUs in the same way that the Java Virtual Machine (JVM) or the Ethereum Virtual Machine (EVM) are for their respective domains. However, there are platforms and runtime environments optimized for GPU operations, especially in the context of AI/ML.\nSome of these platforms and their unique features include:\n\nCUDA (Compute Unified Device Architecture):\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nProvides a parallel computing platform and API model.\nIncorporates the CUDA Instruction Set Architecture (ISA) and the parallel compute engine in NVIDIA GPUs.\nSupports various high-level programming languages like C, C++, and Fortran.\n\nUse Cases: General GPU-accelerated computing, scientific simulations, deep learning training & inference.\n\nTensorRT:\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nHigh-performance deep learning inference optimizer and runtime.\nReduces the model size for faster inferencing.\nProvides INT8 and FP16 optimizations for production deployments.\n\nUse Cases: Optimizing and deploying deep learning models for production environments, especially on NVIDIA GPUs.\n\nROCm (Radeon Open Compute):\n\nDeveloper & Manufacturer: AMD\nUnique Features:\n\nOpen-source platform for GPU-enabled HPC (High Performance Computing) computing.\nSupports a range of machine learning frameworks like TensorFlow and PyTorch.\n\nUse Cases: GPU-accelerated computing on AMD GPUs, scientific simulations, AI/ML training & inference.\n\nDirectML:\n\nDeveloper: Microsoft\nUnique Features:\n\nPart of the DirectX family, providing a low-level API for ML.\nHardware-accelerated and works with any DirectX 12-compatible GPU.\n\nUse Cases: GPU-accelerated ML inference in Windows applications.\n\n\nThese platforms are more akin to runtime environments than traditional “virtual machines.” Still, they are optimized for GPU operations, and they play a role similar to VMs by providing a bridge between high-level code and low-level hardware instructions.\nMain Benefits of GPU-optimized Platforms: 1. Performance: Accelerate computations that can be parallelized, dramatically reducing the time required for tasks like training deep learning models. 2. Efficiency: Better utilization of available GPU resources, ensuring that the hardware’s full capabilities are harnessed. 3. Portability: In some cases (like CUDA to some extent), the platform provides an abstraction over the hardware, allowing code to run on different GPU architectures (within limits and considering vendor lock-ins). 4. Integration with Popular Tools: Many of these platforms offer integrations with popular ML frameworks, making it easier to transition from research to production.\nHowever, it’s essential to understand that while these platforms provide the tools and runtime for GPU-optimized operations, they don’t function as “virtual machines” in the traditional sense of emulating a complete computing environment. They are closer to specialized compilers and runtime environments."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#learn",
    "href": "library/natural-sciences/physics/index.html#learn",
    "title": "Relativity",
    "section": "",
    "text": "Langrangian and Hamiltonian Mechanics"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#papers",
    "href": "library/natural-sciences/physics/index.html#papers",
    "title": "Physics",
    "section": "Papers",
    "text": "Papers\n\nCosmology\n\nThe Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry\nEinstein, Barcelona, Symmetry & Cosmology: The Birth of an Equation for the Universe\n\n\nBlack Holes\n\nBlack Holes Evade Heat Death\nEffective Action for the Hawking Process\nSupermassive Black Hole Binary\n\n\n\nDark Matter and Dark Energy\n\nInteracting Dark Matter - Phenomenology and Implications for Cosmology\n\n\n\nBig Bang\n\nBrief History of Guage Field Physics\nNew shape of parity-violating graviton non-Gaussianity | Explainer To achieve your desired format, we’ll take the title of each entry and link it to the corresponding URL. Let’s do this:\nWarp Drive Patent by Google?\nSarfatti’s 1975 version of ER=EPR\nHarmonic Springs and Gravity\nObservation of an excess of di-charmonium events in the four-muon final state with the ATLAS detector\nTesting a discrete model for quantum spin with two sequential Stern-Gerlach detectors and photon Fock states\nLecture Notes on Holographic Renomalization\nAdS/CFT correspondence and Geometry (Hamilton-Jacobi approach to holographic renormalization)\nClaim: The apparent randomness in wave function collapse is a consequence of coarse-graining an underlying deterministic, non-unitary but norm-preserving evolution.\nThe 8 Fallacies of Assembly Theory\nWhy Bohr was wrong in his response to EPR\nRichard Feynman: Simulating physics with computers (quantum)\nResolving Key Issues In Quantum Mechanics While Simultaneously Debunking Every UFO Case In History\nExperimental test of local observer-independence\nSpontaneous localisation from a coarse-grained deterministic and non-unitary dynamics\nKilling Horizons Decohere Quantum Superpositions \nFermionic matter-wave quantum optics with cold-atom impurity models\nThe Unreasonable Effectiveness of Quantum Field Theory\nGravitational Machines\nIntroduction to Genralized Global Symmetries in QFT and Particle Physics\nPhysics of the Analytic S-Matrix\nOn Unitarity of Tree-Level String Amplitudes\nTASI 2023: Aspects of Symmetry\nScattering Amplitudes in Quantum Field Theory\nA New Century of Quantum Physics\nArrival Time in Quantum Mechanics\nEPFL Lectures on General Relativity as a Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nlecture 1\nBasics of Quantum Gravity\nMy Encounters - as a Physicist - with Mathematics\nLectures on Field Theory and the Standard Model: A Symmetry-Oriented Approach\nVariational Quantum Thermalization and the Future of Quantum Thermodynamics\nWorld from Eyes, Reconstruct 3D Scene from Someone’s Eyeball\nAmerican Elements\nEffective Field Physics (EFT) Methods of General Relativity\nNeutron Guns\nThermodynamics od Information\nSeeing the Gravitational Wave Universe\nProbing Supermassive Black Hole Merges and Stalling with Pulsar Timing Arrays\nAbell 1201: detection of an ultramassive black hole in a strong gravitational lens\nNASA Selects 5 Missions for 2024 Total Solar Eclipse\nSelf-entrainment of a population of coupled non-linear oscillators\nEd Witten Interview\nThe NERN Conference\nExploring the Behavior of Matter under Extreme Conditions\nOn the Origin of Supermassive Black Holes\n3D mapping and volumetric analysis of solid tumours\nNeural Architecture and Interpretation of Brain Function\nIntroduction to Quantum Computing \nThe Intuitive Guide to Quantum Computing"
  },
  {
    "objectID": "library/natural-sciences/physics/cosmology.html",
    "href": "library/natural-sciences/physics/cosmology.html",
    "title": "Cosmology",
    "section": "",
    "text": "The Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry"
  },
  {
    "objectID": "library/natural-sciences/physics/cosmology.html#uncategorized",
    "href": "library/natural-sciences/physics/cosmology.html#uncategorized",
    "title": "Cosmology",
    "section": "",
    "text": "The Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry"
  },
  {
    "objectID": "library/natural-sciences/physics/cosmology.html#black-holes",
    "href": "library/natural-sciences/physics/cosmology.html#black-holes",
    "title": "Cosmology",
    "section": "Black Holes",
    "text": "Black Holes\n\nBlack Holes Evade Heat Death\nEffective Action for the Hawking Process\nSupermassive Black Hole Binary"
  },
  {
    "objectID": "library/natural-sciences/physics/cosmology.html#big-bang",
    "href": "library/natural-sciences/physics/cosmology.html#big-bang",
    "title": "Cosmology",
    "section": "Big Bang",
    "text": "Big Bang"
  },
  {
    "objectID": "library/natural-sciences/physics/cosmology.html#dark-matter-and-dark-energy",
    "href": "library/natural-sciences/physics/cosmology.html#dark-matter-and-dark-energy",
    "title": "Cosmology",
    "section": "Dark Matter and Dark Energy",
    "text": "Dark Matter and Dark Energy\n\nInteracting Dark Matter - Phenomenology and Implications for Cosmology"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#quantum-physics",
    "href": "library/natural-sciences/physics/index.html#quantum-physics",
    "title": "Physics",
    "section": "Quantum Physics",
    "text": "Quantum Physics\nQuantum Physics, also known as Quantum Mechanics, is a branch of physics that deals with phenomena on the atomic and subatomic scales. It departs from classical physics, which fails to describe these systems accurately. Quantum physics introduces the concept of quantized energy levels, wave-particle duality, and probabilities as fundamental aspects of physical systems.\n\nPrimary Subdomains\n\nQuantum Mechanics: The foundational theory describing basic quantum systems.\nQuantum Field Theory: Extends quantum mechanics to systems with varying particle numbers, incorporating special relativity.\nQuantum Computing: The study of how to perform computation using quantum-mechanical phenomena.\nQuantum Information Theory: Deals with the quantification and manipulation of quantum information.\nQuantum Optics: The study of the interactions between light and matter in the quantum regime.\nQuantum Cryptography: Concerned with securing communication information using quantum phenomena.\nCondensed Matter Physics: Examines quantum effects in solid and liquid systems.\nQuantum Thermodynamics: Investigates the laws of thermodynamics in the realm of quantum systems.\n\n\n\nFields of Application\n\nTechnology: Semiconductor devices, lasers, and quantum computers.\nMedicine: MRI technology and future applications in quantum healthcare.\nTelecommunications: Secure communication through quantum cryptography.\nMaterial Science: Discovery and design of new materials with desired properties.\nFinance and Optimization: Quantum algorithms for solving complex optimization problems.\n\n\n\nAdditional Notes\nQuantum Physics often intersects with other branches of physics like statistical mechanics, cosmology, and general relativity, creating interdisciplinary subdomains like quantum cosmology and quantum gravity. It is also a field that is philosophically rich, touching upon fundamental questions about the nature of reality, causality, and information."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#cosmology",
    "href": "library/natural-sciences/physics/index.html#cosmology",
    "title": "Physics",
    "section": "Cosmology",
    "text": "Cosmology\n\nThe Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry\nEinstein, Barcelona, Symmetry & Cosmology: The Birth of an Equation for the Universe\n\n\nBlack Holes\n\nBlack Holes Evade Heat Death\nEffective Action for the Hawking Process\nSupermassive Black Hole Binary\n\n\n\nDark Matter and Dark Energy\n\nInteracting Dark Matter - Phenomenology and Implications for Cosmology\nNew shape of parity-violating graviton non-Gaussianity | Explainer\n\n\n\nBig Bang\n\nWarp Drive Patent by Google?\nSarfatti’s 1975 version of ER=EPR\nHarmonic Springs and Gravity\nObservation of an excess of di-charmonium events in the four-muon final state with the ATLAS detector\nLecture Notes on Holographic Renomalization\nAdS/CFT correspondence and Geometry (Hamilton-Jacobi approach to holographic renormalization)\nThe 8 Fallacies of Assembly Theory\n\n(https://missing-link.com) \n\nGravitational Machines\nPhysics of the Analytic S-Matrix\nOn Unitarity of Tree-Level String Amplitudes\nTASI 2023: Aspects of Symmetry\nScattering Amplitudes in Quantum Field Theory\nA New Century of Quantum Physics\nArrival Time in Quantum Mechanics\nEPFL Lectures on General Relativity as a Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nlecture 1\nBasics of Quantum Gravity\nMy Encounters - as a Physicist - with Mathematics\nWorld from Eyes, Reconstruct 3D Scene from Someone’s Eyeball\nAmerican Elements\nEffective Field Physics (EFT) Methods of General Relativity\nNeutron Guns\nThermodynamics od Information\nSeeing the Gravitational Wave Universe\nProbing Supermassive Black Hole Merges and Stalling with Pulsar Timing Arrays\nAbell 1201: detection of an ultramassive black hole in a strong gravitational lens\nNASA Selects 5 Missions for 2024 Total Solar Eclipse\nSelf-entrainment of a population of coupled non-linear oscillators\nEd Witten Interview\nThe NERN Conference\nExploring the Behavior of Matter under Extreme Conditions\nOn the Origin of Supermassive Black Holes\n3D mapping and volumetric analysis of solid tumours\nNeural Architecture and Interpretation of Brain Function\nIntroduction to Quantum Computing \nThe Intuitive Guide to Quantum Computing"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#classical-physics",
    "href": "library/natural-sciences/physics/index.html#classical-physics",
    "title": "Physics",
    "section": "Classical Physics",
    "text": "Classical Physics\nClassical Physics encompasses the theories and principles that describe the natural world in terms of macroscopic scales and speeds much slower than the speed of light. It is the framework in which forces, energy, and matter interact and is often considered to be the classical limit of more advanced theories, such as quantum mechanics and general relativity.\n\nPrimary Subdomains\n\nNewtonian Mechanics: Study of forces and motions based on Isaac Newton’s three laws.\nClassical Electrodynamics: Description of electric and magnetic fields and their interaction with matter, typically framed using Maxwell’s equations.\nThermodynamics: Study of heat transfer and the principles governing energy transformations.\nOptics: Study of the behavior and properties of light, including its interactions with matter.\nAcoustics: Study of the production, transmission, and effects of sound waves.\nFluid Mechanics: Study of fluids (liquids and gases) in motion or at rest.\nLagrangian and Hamiltonian Mechanics: Advanced formulations of classical mechanics that provide alternative approaches to describing systems.\n\n\n\nFields of Application\n\nEngineering: For designing mechanical systems, electrical circuits, and thermodynamic processes.\nAstronomy: For celestial mechanics and basic calculations regarding heavenly bodies.\nGeophysics: In studying phenomena like earthquakes and atmospheric science.\nMedicine: In medical imaging and biomechanics.\nEnvironmental Science: For understanding weather patterns and fluid flows in natural systems.\nMaterials Science: In studying the mechanical properties of materials.\n\n\n\nAdditional Notes\n\nClassical Physics provides the foundation upon which modern physics (e.g., quantum mechanics, relativity) is built.\nDespite its limitations at very high speeds or microscopic scales, classical physics is exceptionally accurate for a broad range of everyday applications.\n\nThis category aims to provide a comprehensive understanding of the physical principles that govern our everyday world and serves as a foundation for other, more specialized fields in physics."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#relativity",
    "href": "library/natural-sciences/physics/index.html#relativity",
    "title": "Physics",
    "section": "Relativity",
    "text": "Relativity\nThe theory of relativity fundamentally changed our understanding of space, time, and gravity. Developed primarily by Albert Einstein, it comes in two main forms: Special Relativity and General Relativity. Special Relativity focuses on the physics of objects moving at constant velocity, particularly those close to the speed of light, and describes how time dilation and length contraction occur. General Relativity extends these concepts to accelerating frames and introduces a revolutionary explanation for gravity as the curvature of spacetime caused by mass.\n\nPrimary Subdomains\n\nSpecial Relativity: Deals with inertial frames and high-speed phenomena.\n\nTime Dilation\nLength Contraction\nLorentz Transformation\nRelativistic Energy-Momentum\n\nGeneral Relativity: Focuses on gravity and accelerating (non-inertial) frames.\n\nGravitational Fields and Curved Spacetime\nBlack Holes\nCosmological Models\nGravitational Waves\n\nExperimental Tests of Relativity: Confirmations and challenges to relativistic predictions.\n\nGravitational Lensing\nTime Dilation in Particle Accelerators\nTests of the Equivalence Principle\n\n\n\n\nFields of Application\n\nAstrophysics: Understanding celestial bodies like black holes, neutron stars, and the large-scale structure of the universe.\nGlobal Positioning Systems (GPS): Accounting for relativistic effects to achieve precise location data.\nParticle Physics: Managing particles at high speeds in accelerators.\nCosmology: Explaining the Big Bang, cosmic inflation, and the fate of the universe.\nGravitational Wave Astronomy: Detecting and interpreting gravitational waves.\n\n\n\nAdditional Notes\n\nThe equations of relativity reduce to Newtonian equations at speeds much lower than the speed of light, demonstrating a natural continuity in physical laws.\nSpecial Relativity has implications for the unification of electromagnetism into a single theory, often termed as the “electroweak” interaction.\nGeneral Relativity, while incredibly successful at explaining large scale phenomena, is still incompatible with quantum mechanics. The reconciliation of these two theories is an open problem in theoretical physics, often referred to as the quest for a Theory of Everything (ToE).\n\nBy categorizing articles under this section, readers can gain an in-depth understanding of one of the most groundbreaking and far-reaching theories in physics."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#uncategorized",
    "href": "library/natural-sciences/physics/index.html#uncategorized",
    "title": "Physics",
    "section": "Uncategorized",
    "text": "Uncategorized\n\nGravitational Machines\nWarp Drive Patent by Google?\nTASI 2023: Aspects of Symmetry\nThe 8 Fallacies of Assembly Theory\nPhysics of the Analytic S-Matrix\nWorld from Eyes, Reconstruct 3D Scene from Someone’s Eyeball\nEd Witten Interview\nUnitarity"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#unity",
    "href": "library/natural-sciences/physics/index.html#unity",
    "title": "Relativity",
    "section": "Unity",
    "text": "Unity\n\nER=EPR\n\n\nString Theory"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#weapons",
    "href": "library/natural-sciences/physics/index.html#weapons",
    "title": "Physics",
    "section": "Weapons",
    "text": "Weapons"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#particle-physics",
    "href": "library/natural-sciences/physics/index.html#particle-physics",
    "title": "Physics",
    "section": "Particle Physics",
    "text": "Particle Physics\nParticle Physics is the branch of physics that studies the nature and behavior of subatomic particles. These include elementary particles, such as electrons, quarks, and photons, as well as composite particles like protons, neutrons, and atomic nuclei. The field aims to understand the fundamental constituents of matter and the forces that act between them.\n\nPrimary Subdomains\n\nElementary Particle Physics: Study of fundamental, indivisible particles like electrons, quarks, and bosons.\nHadron Physics: Focuses on particles made of quarks, such as protons and neutrons, and their interactions.\nNuclear Physics: While closely related, this subdomain studies the behavior of atomic nuclei in detail.\nAstroparticle Physics: Studies particles in astronomical contexts; often overlaps with cosmology.\nCosmic-Ray Physics: Investigates the high-energy particles that originate from space and strike the Earth.\nQuantum Chromodynamics (QCD): The study of the strong force, one of the fundamental forces of nature, and how it acts on quarks and gluons.\nElectroweak Theory: Combines electromagnetism and the weak nuclear force into a single theory.\n\n\n\nFields of Application\n\nMedical Imaging: Particle detectors similar to those in physics experiments are used in medical imaging technologies.\nAstronomy and Cosmology: Understanding particle interactions is crucial for understanding cosmic phenomena.\nMaterial Science: Manipulation of particles at the atomic and subatomic levels can lead to new materials with unique properties.\nEnergy Sector: Understanding subatomic particles could potentially unlock new energy sources or methods for energy production.\n\n\n\nAdditional Notes\nParticle physics often requires large-scale experiments and particle accelerators like the Large Hadron Collider (LHC) to test theories and discover new particles. The field has deep connections with quantum mechanics and relativity and often overlaps with other domains in physics and even other disciplines like cosmology and astrophysics. It is a rapidly evolving field, and recent advancements often lead to practical applications in various industries."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#field-theory",
    "href": "library/natural-sciences/physics/index.html#field-theory",
    "title": "Physics",
    "section": "Field Theory",
    "text": "Field Theory\nField Theory is a branch of physics that deals with the study of fields, which are functions that assign a value to each point in space and time. In physics, fields are used to represent various physical quantities such as electromagnetic fields, gravitational fields, and quantum fields. The concept of a field is instrumental in describing how forces act at a distance and how particles interact with each other.\n\nPrimary Subdomains\n\nClassical Field Theory: Includes electromagnetic fields and gravitational fields in the context of General Relativity.\nQuantum Field Theory (QFT): Merges quantum mechanics and special relativity to study interactions in particle physics.\nGauge Theory: A type of field theory where fields are formulated in terms of gauge-invariant quantities.\nConformal Field Theory: Deals with fields that are invariant under conformal transformations, often used in the study of critical phenomena.\nTopological Field Theory: Concerned with fields that have topological invariants.\nEffective Field Theory: An approximate theory to describe physics at a particular length scale.\n\n\n\nFields of Application\n\nParticle Physics: Quantum Field Theory is the foundation for the Standard Model.\nCosmology: Field theories like General Relativity are essential for understanding the universe’s large-scale structure.\nCondensed Matter Physics: Field theoretical methods are used to understand many-body systems and phase transitions.\nQuantum Computing: Quantum field theoretical methods are sometimes used in algorithms and understanding quantum computation.\nElectrical Engineering: Classical electromagnetic field theory is essential for the design and understanding of electrical circuits, antennas, etc.\n\n\n\nAdditional Notes\nField Theory often intersects with other areas of physics and mathematics, like statistical mechanics and group theory, to offer a more complete understanding of physical phenomena. The mathematics involved can be highly abstract, involving advanced topics in differential geometry, topology, and algebra."
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html",
    "href": "library/natural-sciences/physics/energy/fusion.html",
    "title": "Fusion",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html#fusion-weapon-overview",
    "href": "library/natural-sciences/physics/energy/fusion.html#fusion-weapon-overview",
    "title": "Fusion",
    "section": "",
    "text": "A thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html#energy-sources",
    "href": "library/natural-sciences/physics/energy/fusion.html#energy-sources",
    "title": "Fusion",
    "section": "Energy Sources",
    "text": "Energy Sources\n\nBreakthroughs\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#darpa",
    "href": "library/natural-sciences/physics/government/index.html#darpa",
    "title": "Government",
    "section": "DARPA",
    "text": "DARPA\n\nFellows 2023"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html#nuclear",
    "href": "library/natural-sciences/physics/energy/fusion.html#nuclear",
    "title": "Fusion",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html#fission",
    "href": "library/natural-sciences/physics/energy/fusion.html#fission",
    "title": "Fusion",
    "section": "Fission",
    "text": "Fission\nTODO"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html#fusion",
    "href": "library/natural-sciences/physics/energy/fusion.html#fusion",
    "title": "Fusion",
    "section": "Fusion",
    "text": "Fusion\n\nA Fusion Weapon: Overview\nA thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs.\n\n\nFusion energy\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/fusion.html#fusion-energy",
    "href": "library/natural-sciences/physics/energy/fusion.html#fusion-energy",
    "title": "Fusion",
    "section": "Fusion energy",
    "text": "Fusion energy\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#advanced-weapons",
    "href": "library/natural-sciences/physics/government/index.html#advanced-weapons",
    "title": "Government",
    "section": "Advanced Weapons",
    "text": "Advanced Weapons\n\nDirected Energy\n\nD-Wave and Davidson Technologies Introduce New Innovations to Advance National Defense Efforts\n\n\n\nNeutron Guns\n\nNeutron Guns\n\n\n\nA Fusion Weapon: Overview\nA thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/natural-sciences/physics/energy/index.html",
    "href": "library/natural-sciences/physics/energy/index.html",
    "title": "Nuclear",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/index.html#nuclear",
    "href": "library/natural-sciences/physics/energy/index.html#nuclear",
    "title": "Nuclear",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/index.html#fission",
    "href": "library/natural-sciences/physics/energy/index.html#fission",
    "title": "Nuclear",
    "section": "Fission",
    "text": "Fission\nTODO"
  },
  {
    "objectID": "library/natural-sciences/physics/energy/index.html#fusion",
    "href": "library/natural-sciences/physics/energy/index.html#fusion",
    "title": "Nuclear",
    "section": "Fusion",
    "text": "Fusion\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#exotic-material",
    "href": "library/natural-sciences/physics/government/index.html#exotic-material",
    "title": "Government",
    "section": "Exotic Material",
    "text": "Exotic Material\n\nPentagon pleads the fifth"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#electromagnetism",
    "href": "library/natural-sciences/physics/index.html#electromagnetism",
    "title": "Physics",
    "section": "Electromagnetism",
    "text": "Electromagnetism\nElectromagnetism is one of the four fundamental forces in nature, governing the behavior of electrically charged particles and their interactions through electric and magnetic fields. It unifies electricity and magnetism into a single theory, initially formulated by James Clerk Maxwell in the 19th century. This theory is described by Maxwell’s equations, which provide the mathematical foundation for understanding electromagnetic phenomena.\n\nPrimary Subdomains\n\nElectrostatics: Study of electric charges at rest and electric fields.\nMagnetostatics: Study of magnetic fields in systems with steady currents.\nElectrodynamics: Study of time-dependent electric and magnetic fields, often involving moving charges.\nOptics: Study of light as an electromagnetic wave, including reflection, refraction, and diffraction.\nMicrowave Engineering: Study of the electromagnetic waves in the microwave frequency range.\nPlasma Physics: Study of charged particles and fluids interacting with self-consistent electric and magnetic fields.\n\n\n\nFields of Application\n\nElectrical Engineering: Design and analysis of electrical systems.\nCommunications: Antenna design, signal processing, and wireless transmission.\nMedical Imaging: MRI and X-ray technologies.\nMaterial Science: Study of electrical, magnetic, and optical properties of materials.\nEnvironmental Monitoring: Geophysical and atmospheric studies.\nEnergy Production: Power generation and transmission.\n\n\n\nAdditional Notes\nElectromagnetism also serves as a cornerstone for more advanced theories in physics, such as Quantum Electrodynamics (QED) and the Standard Model of particle physics. It is crucial for understanding a broad range of phenomena, from the interaction of subatomic particles to the large-scale behavior of galaxies."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#magnetohydrodynamics",
    "href": "library/natural-sciences/physics/index.html#magnetohydrodynamics",
    "title": "Physics",
    "section": "Magnetohydrodynamics",
    "text": "Magnetohydrodynamics\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism. The governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations.\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/mhd/index.html#magnetohydrodynamics",
    "href": "library/natural-sciences/physics/electromagnetism/mhd/index.html#magnetohydrodynamics",
    "title": "MHD",
    "section": "",
    "text": "Magnetohydrodynamic (MHD) Propulsion\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD"
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#weapons",
    "href": "library/natural-sciences/physics/government/index.html#weapons",
    "title": "Government",
    "section": "Weapons",
    "text": "Weapons\n\nDirected Energy\n\nD-Wave and Davidson Technologies Introduce New Innovations to Advance National Defense Efforts\n\n\n\nNeutron Guns\n\nNeutron Guns\n\n\n\nA Fusion Weapon: Overview\nA thermonuclear weapon, fusion weapon or hydrogen bomb (H bomb) is a second-generation nuclear weapon design. Its greater sophistication affords it vastly greater destructive power than first-generation nuclear bombs, a more compact size, a lower mass, or a combination of these benefits. Characteristics of nuclear fusion reactions make possible the use of non-fissile depleted uranium as the weapon’s main fuel, thus allowing more efficient use of scarce fissile material such as uranium-235 \\((^{235}U)\\) or plutonium-239 \\((^{239}Pu)\\)\nThe first full-scale thermonuclear test was carried out by the United States in 1952; the concept has since been employed by most of the world’s nuclear powers in the design of their weapons.\nModern fusion weapons consist essentially of two main components: a nuclear fission primary stage (fueled by \\(^{235}U\\) or \\(^{239}Pu\\)) and a separate nuclear fusion secondary stage containing thermonuclear fuel: the heavy hydrogen isotopes deuterium and tritium, or in modern weapons lithium deuteride. For this reason, thermonuclear weapons are often colloquially called hydrogen bombs or H-bombs."
  },
  {
    "objectID": "library/natural-sciences/physics/government/index.html#remote-viewing",
    "href": "library/natural-sciences/physics/government/index.html#remote-viewing",
    "title": "Government",
    "section": "Remote Viewing",
    "text": "Remote Viewing\n\nRemote Viewing Wiki\nClairvoyance Wiki\nIngo Swann and Hal Puthoff Remote Viewing Training of Turhuck, 1981-06\nStanford Expirment\nColombia Uni\nNSA Report\nStargate Project\nIngo Swann: a person\nCIA Database on Ingo Swann\nCREST\nMiracles of Mind\nRemote Viewing secrets: A Handbook"
  },
  {
    "objectID": "library/natural-sciences/physics/classical/papers/energetics-of-turbulent-fluids.html",
    "href": "library/natural-sciences/physics/classical/papers/energetics-of-turbulent-fluids.html",
    "title": "Energetics of Turbulent Fluids",
    "section": "",
    "text": "Draft paper by Justin Beroz.\nHere are the notes I took while reading the paper:"
  },
  {
    "objectID": "library/natural-sciences/physics/classical/papers/energetics-of-turbulent-fluids.html#beroz",
    "href": "library/natural-sciences/physics/classical/papers/energetics-of-turbulent-fluids.html#beroz",
    "title": "Energetics of Turbulent Fluids",
    "section": "Beroz",
    "text": "Beroz\nWhat sort of world would we live in without turbulence? - blog - This relates to his claims on liquid energy transport. Sure, the theory is there, but there’s a few subtle assumptions in the theory that put a wrench in the practicality of his claims (aka, Jacob’s intuition was correct in being speculative of the efficiency claims). - “…and assuming the average flow to be steady and approximately two dimensional, can be expresses as…” - “…To determine these constant we need to include two boundary conditions for our river velocity…”\nSolving one of physics’ ‘last great mysteries’ with a new, huge, wind tunnel - paper - 10% of world electricity devoted to overcoming turbulence\nMacro-Quantum Behavior - MIT video - Veritasium video"
  },
  {
    "objectID": "library/natural-sciences/physics/classical/papers/index.html",
    "href": "library/natural-sciences/physics/classical/papers/index.html",
    "title": "Fluid Dynamics",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#lk-99",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#lk-99",
    "title": "Superconductors",
    "section": "LK-99",
    "text": "LK-99\nThe story of the (alleged) first room-tempurature ambient-pressure superconductor.\nSuperconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise.\n\n\nTimeline of Events\n\n\nJuly 22\n\n📑 Publication: The First Room-Temperature Ambient-Pressure Superconductor\n📝 Note: Original papers are released twice. The first release, suspected to beat the second, includes only 3 authors, making the team eligible for a Nobel Prize.\n\n\n\n\nJuly 26\n\n🐦 Prediction: I predict the superconductor hype (“we are so fucking back”) is mostly noise.\n\n\n\n\nJuly 27\n\n📝 Blog Post: Douglas Natelson publishes a blog post expressing a pessimistic view on the situation.\n💬 Commentary: Condensed Matter Theory Center deconstructs “the non-experimental parts of the Korean room temp SC claims.”\n⏳ Trend: Hype ensues and magnifies as people rush to replicate the study/results.\n\n\n\n\nJuly 29\n\n📑 Publication: First-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\n\n\n\n\nJuly 31\n\n📑 Publication: Synthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n🚫 Replication Failure: Semiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)\n\n\n\n\nAugust 4\n\n💡 Theory: A theoretical explanation for LK-99 is released by Sinead Griffin out of Berkeley.\n📑 Publication: Origin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\n\n\n\nAugust 6\n\n📝 Claim: Group claims LK-99 is a ferromagnet (NOT a superconductor).\n📑 Publication: Ferromagnetic half levitation of LK-99-like synthetic samples\n\n\nAsides\nAuthor of the original paper, Hyun-Tak Kim, from 2018\nWhy does BCS theory fail to explain superconductivity at high temperatures?"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#asides",
    "href": "library/natural-sciences/physics/electromagnetism/superconductor/index.html#asides",
    "title": "Superconductors",
    "section": "Asides",
    "text": "Asides\nAuthor of the original paper, Hyun-Tak Kim, from 2018\nWhy does BCS theory fail to explain superconductivity at high temperatures?"
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html",
    "href": "library/natural-sciences/physics/mysteries.html",
    "title": "Mysteries",
    "section": "",
    "text": "Dark energy: 69%\nDark matter: 26%\nOrdinary matter: 5%\n\nDark matter/energy appears to constitute 85% of the universe’s matter content (e=mc^2). This substance does not admit, absorb, or reflect light. It’s presence is inferred from gravitational effects on visible matter."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#the-nature-of-dark-matter",
    "href": "library/natural-sciences/physics/mysteries.html#the-nature-of-dark-matter",
    "title": "Mysteries",
    "section": "",
    "text": "Dark energy: 69%\nDark matter: 26%\nOrdinary matter: 5%\n\nDark matter/energy appears to constitute 85% of the universe’s matter content (e=mc^2). This substance does not admit, absorb, or reflect light. It’s presence is inferred from gravitational effects on visible matter."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#quantum-gravity",
    "href": "library/natural-sciences/physics/mysteries.html#quantum-gravity",
    "title": "Mysteries",
    "section": "Quantum Gravity",
    "text": "Quantum Gravity\nThere is no reconciliation between quantum mechanics and general relativity. The former describes the universe at the smallest scales, while the latter describes the universe at the largest scales. The two theories are seemingly incompatible, and this problem has become the focal point in the search for a “theory of everything”."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#the-measurement-problem-in-quantum-mechanics",
    "href": "library/natural-sciences/physics/mysteries.html#the-measurement-problem-in-quantum-mechanics",
    "title": "Mysteries",
    "section": "The Measurement Problem in Quantum Mechanics",
    "text": "The Measurement Problem in Quantum Mechanics\nQuantum mechanics predicts outcomes only probabilisticly, and superpositions decohere upon measurement. The process of measurement is described differently from other physical processes. This raises deep questions about the nature of reality and consciousness in the physical world."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#matter-antimatter-asymmetry",
    "href": "library/natural-sciences/physics/mysteries.html#matter-antimatter-asymmetry",
    "title": "Mysteries",
    "section": "Matter Antimatter Asymmetry",
    "text": "Matter Antimatter Asymmetry\nThe Big Bang should have produced equal amounts of matter and antimatter, which would have then annihilated each other. However, the universe is made almost entirely of matter. This asymmetry is not explained by the Standard Model."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#neutrino-masses-and-mixing-angles",
    "href": "library/natural-sciences/physics/mysteries.html#neutrino-masses-and-mixing-angles",
    "title": "Mysteries",
    "section": "Neutrino Masses and Mixing Angles",
    "text": "Neutrino Masses and Mixing Angles\nNeutrinos are elementary particles that only weakly interact with matter. Experiments have shown that neutrinos have mass and can change their type as they travel, but the origin of their mass and precise values of the mixing angles are unknown. Mixing angles are the parameters that describe the transformation of neutrinos from one type to another."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#strong-charge-parity-problem",
    "href": "library/natural-sciences/physics/mysteries.html#strong-charge-parity-problem",
    "title": "Mysteries",
    "section": "Strong Charge-Parity Problem",
    "text": "Strong Charge-Parity Problem\nCharge-parity (CP) symmetry states that the laws of physics should remain the same if a particle is replaced by its antiparticle (charge conjugation) and then its spacial coordinates are inverted (parity inversion). However, in storng interaction (one of the four fundamental fources), this symmetry isnt violated as much as the current theory predicts. This is known as the strong CP problem.\n\nThe strong force holds together things that have the same charge - this is stronger than the electromagnetic force, and is why atoms with protons (and more importantly quarks) don’t fly apart."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#cosmic-inflation",
    "href": "library/natural-sciences/physics/mysteries.html#cosmic-inflation",
    "title": "Mysteries",
    "section": "Cosmic Inflation",
    "text": "Cosmic Inflation\nWe believe the universe is acceleratingly expanding, but we don’t know why."
  },
  {
    "objectID": "library/natural-sciences/physics/mysteries.html#the-problem-of-time",
    "href": "library/natural-sciences/physics/mysteries.html#the-problem-of-time",
    "title": "Mysteries",
    "section": "The Problem of Time",
    "text": "The Problem of Time\nIn QM, time is a background parameter, and the flow of time is universal and absolute. In GR, time is one aspect of spacetime and is relative and dynamical. There is no compatability between these two."
  },
  {
    "objectID": "library/natural-sciences/physics/maths/index.html",
    "href": "library/natural-sciences/physics/maths/index.html",
    "title": "Physics Maths",
    "section": "",
    "text": "Donaldson Theory\nDonaldson theory is a branch of mathematics that is concerned with the topology of four-dimensional manifolds. It is named after Simon Donaldson, a British mathematician who made significant contributions to the field in the 1980s.\nThe central problem in Donaldson theory is to understand the topology of four-dimensional manifolds using differential geometry and algebraic topology. Specifically, the theory focuses on the study of vector bundles and connections on these manifolds, and how they can be used to classify different types of four-dimensional manifolds.\nOne of the key results in Donaldson theory is Donaldson’s theorem, which states that the intersection form of a smooth, closed, simply-connected four-dimensional manifold can be recovered from its Seiberg-Witten invariants. The Seiberg-Witten invariants are a set of numbers that can be associated with a four-dimensional manifold and its spin-c structure. They were introduced by Edward Witten and Nathan Seiberg in the mid-1990s and have proven to be a powerful tool in the study of four-dimensional manifolds.\nDonaldson theory has applications in a variety of fields, including physics, where it has been used to study the topology of spacetime in string theory and other areas of theoretical physics. It has also had significant impact in pure mathematics, inspiring further research in the fields of algebraic geometry, topology, and differential geometry."
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear/index.html",
    "href": "library/natural-sciences/physics/nuclear/index.html",
    "title": "Nuclear",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)\n\n\n\nis an academic development framework for a small, standard, pressurized water reactor. Our goal is to accelerate deployment of the world’s most vital solution to climate change: Nuclear Energy.\n\nOpen-100\nMining valuable minerals from seawater: a critical review\nIndian scientists extract record uranium from seawater that could power nuclear plants"
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear/index.html#nuclear",
    "href": "library/natural-sciences/physics/nuclear/index.html#nuclear",
    "title": "Nuclear",
    "section": "",
    "text": "Stockpile Stewardship and Management Plan (SSMP)\n\n\n\nis an academic development framework for a small, standard, pressurized water reactor. Our goal is to accelerate deployment of the world’s most vital solution to climate change: Nuclear Energy.\n\nOpen-100\nMining valuable minerals from seawater: a critical review\nIndian scientists extract record uranium from seawater that could power nuclear plants"
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear/index.html#fission",
    "href": "library/natural-sciences/physics/nuclear/index.html#fission",
    "title": "Nuclear",
    "section": "Fission",
    "text": "Fission\nTODO"
  },
  {
    "objectID": "library/natural-sciences/physics/nuclear/index.html#fusion",
    "href": "library/natural-sciences/physics/nuclear/index.html#fusion",
    "title": "Nuclear",
    "section": "Fusion",
    "text": "Fusion\n\nDecember 5, 2023 (announced Dec. 13)\n\nPress Conference: Secretary Granholm & DOE leaders Announced Fusion Breakthrough by DOE National Lab\nLLNL Release\nLLNL Video\n\nThe U.S. Department of Energy (DOE) and DOE’s National Nuclear Security Administration (NNSA) today (Dec. 13) announced the achievement of fusion ignition at Lawrence Livermore National Laboratory (LLNL) — a major scientific breakthrough decades in the making that will pave the way for advancements in national defense and the future of clean power. On Dec. 5, a team at LLNL’s National Ignition Facility (NIF) conducted the first controlled fusion experiment in history to reach this milestone, also known as scientific energy breakeven, meaning it produced more energy from fusion than the laser energy used to drive it.\n\n\nAugust 6, 2023\nUS scientists repeat fusion ignition breakthrough for 2nd time"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/string-theory.html",
    "href": "library/natural-sciences/physics/unification/string-theory.html",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/string-theory.html#resources",
    "href": "library/natural-sciences/physics/unification/string-theory.html#resources",
    "title": "String Theory",
    "section": "",
    "text": "Magic, mystery or matrix? A conversation with string theorist Edward Witten"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/geometric-unity.html",
    "href": "library/natural-sciences/physics/unification/geometric-unity.html",
    "title": "Geometric Unity",
    "section": "",
    "text": "This is notes on a lecture by Eric Weinstein on the topic of geometric unity. The lecture is available here.\nI am first watching this lecture without a proper background in tensor calculus, dirac notation, or differential geometry. My plan is first to listen, ponder curiously, explore the topics which I need to learn, and return once I’m able to independently generate an opinion with conviction."
  },
  {
    "objectID": "library/natural-sciences/physics/unification/geometric-unity.html#response-discussion",
    "href": "library/natural-sciences/physics/unification/geometric-unity.html#response-discussion",
    "title": "Geometric Unity",
    "section": "Response & Discussion",
    "text": "Response & Discussion\n\nTimothy Nguyen and Theo Polya’s Response to GU"
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#allegra-a.-beal-cohen",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#allegra-a.-beal-cohen",
    "title": "DARPA Fellows",
    "section": "",
    "text": "Dr. Allegra A. Beal Cohen joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. Prior to joining DARPA, Beal Cohen was a DARPA I2O postdoctoral fellow at the University of Florida. She worked on the DARPA Habitus program where she modeled agricultural value chains, conducted qualitative interviews with domain experts, and built a tool for partially automating knowledge engineering. She was selected as a DARPA Early Riser for her work on knowledge engineering.\nBeal Cohen earned her doctorate degree from the University of Florida as an National Science Foundation Graduate Research Fellow, where she modeled intra-household bargaining and social norms in agriculture. She earned her Bachelor of Science degree in symbolic systems from Stanford University."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#rebecca-chmiel",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#rebecca-chmiel",
    "title": "DARPA Fellows",
    "section": "Rebecca Chmiel",
    "text": "Rebecca Chmiel\nDr. Rebecca Chmiel joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. She received her Bachelor of Arts in chemistry and environmental studies from Colby College and her doctorate from the Massachusetts Institute of Technology and the Woods Hole Oceanographic Institution in marine biogeochemistry, and her research focused on the interactions between trace metal nutrients and marine phytoplankton. She has participated in four ocean research expeditions totaling over seven months at sea, and received the Antarctica Service Medal as part of her oceanographic fieldwork."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#alex-place",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#alex-place",
    "title": "DARPA Fellows",
    "section": "Alex Place",
    "text": "Alex Place\nDr. Alex Place joined DARPA in January 2023 as part of the first cohort of DARPA Innovation Fellows. He received his Bachelor of Science in physics from the California Institute of Technology and his doctorate in electrical and computer engineering and materials science from Princeton University. His dissertation focused on improving the lifetimes of superconducting qubits, the building block of many industrial quantum computing efforts. He has also spent time developing nanoelectromechanical systems, novel solar cell designs, and medical devices."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#lt-krishnan-rajagopalan-usn",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#lt-krishnan-rajagopalan-usn",
    "title": "DARPA Fellows",
    "section": "LT Krishnan Rajagopalan, USN",
    "text": "LT Krishnan Rajagopalan, USN\nLt. Krishnan (Krish) Rajagopalan joined DARPA in March 2023 as part of the first cohort of DARPA Innovation Fellows. As a Navy Explosive Ordnance Disposal (EOD) Officer, he has led units of unmanned underwater vehicle operators and EOD divers tasked with countering explosive hazards underwater. He also served as a requirements officer on the staff of the Chief of Naval Operations and, most recently, as the operations officer at Expeditionary Exploitation Unit ONE (EXU-1). Rajagopalan is a qualified EOD Technician and Navy Diving Officer. He received a Bachelor of Science in operations research from the U.S. Naval Academy and a Master of Science in operations research from the Massachusetts Institute of Technology (MIT), where he was an MIT Lincoln Laboratory Military Fellow."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#graham-h.-reid",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#graham-h.-reid",
    "title": "DARPA Fellows",
    "section": "Graham H. Reid",
    "text": "Graham H. Reid\nDr. Graham Reid joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Reid received a Bachelor of Arts in physics from Kenyon College and a doctorate from University of Maryland, College Park. His dissertation research, conducted at NIST as a guest researcher through the Joint Quantum Institute, used ultracold atoms to study topological physics in dynamically evolving quantum systems."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#rené-m.-xavier",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#rené-m.-xavier",
    "title": "DARPA Fellows",
    "section": "René M. Xavier",
    "text": "René M. Xavier\nDr. René Xavier joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Xavier recently graduated from Florida Atlantic University, where she conducted research at the Harbor Branch Oceanographic Institute using shotgun metagenomics to analyze the biosynthesis of marine natural products. She received her Bachelor of Science in molecular, cellular, and developmental biology from the University of Washington in Seattle and was awarded a Fulbright Fellowship to study the regulation of reactive oxygen species at the Czech Institute of Experimental Botany in Prague. Prior to her academic career, she served as a nuclear electrician in the U.S. Navy where she was decorated with multiple honors including the Humanitarian Ribbon for her relief efforts during Hurricane Katrina."
  },
  {
    "objectID": "library/natural-sciences/physics/government/darpa/fellows.html#alessandra-m.-zito",
    "href": "library/natural-sciences/physics/government/darpa/fellows.html#alessandra-m.-zito",
    "title": "DARPA Fellows",
    "section": "Alessandra M. Zito",
    "text": "Alessandra M. Zito\nDr. Alessandra (Allie) Zito joined DARPA in June 2023 as part of the second cohort of DARPA Innovation Fellows. Zito received her Bachelor of Arts in chemistry and French language and literature from Johns Hopkins University and her doctorate in chemistry from the University of California, Irvine. Her graduate work focused on synthesizing and characterizing redox-active organic and inorganic molecules to be used for electrochemical carbon dioxide capture and concentration. She also has research experience in investigating catalyst loading on carbon aerogels, homogeneous and heterogeneous CO2 reduction catalysis, and electrode design for supercapacitors."
  },
  {
    "objectID": "library/natural-sciences/physics/field-theory/effective-or-fundamental.html",
    "href": "library/natural-sciences/physics/field-theory/effective-or-fundamental.html",
    "title": "Fundamental?",
    "section": "",
    "text": "The Quantum Theory of Fields: Effective or Fundamental?\n\nvideo\ncorresponding article\nQuantum Field Theory was born just pertaining to the electromagnetic field.\nWhen expanding this theory, it seemed it couldn’t be trusted at high energies. (Decline)\nLate 1940s, there was a new optimizing with the invention of a relatavistic perturbation theory, where the infinities could be absorbed into a redefinition of parameters like mass and charge of the electron. People thought this was sweeping problems under the rug, but it also may have been a way of selecting good theories (renormalizable theories).\nFor example, theere’s nothing in the symmetries of quantum electrodynamics which rules out putting a term in the field equations (or Lagrangian), which could make the magnetic moment of the electron anything you want. This would make the mass of the electron -1, which means the theory is not renormalizable, and thus shows invalid.\nLate 1960s and early 70s, the standard model came to fruition - this was the renaissance of Quantum Field theory. But there were still doubts whether this was a fundamental theory or an effective one.\nQuantum Field Theory & Einsteinian Physics may be low energy approximations of a more fundamental theory."
  },
  {
    "objectID": "library/natural-sciences/physics/classical/fluid-dynamics.html",
    "href": "library/natural-sciences/physics/classical/fluid-dynamics.html",
    "title": "Fluid Dynamics",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html",
    "href": "library/natural-sciences/physics/uap/people.html",
    "title": "UAP People",
    "section": "",
    "text": "He knows something for sure\n\n\n\nDr. Harold E. Puthoff is the co-founder and Vice President of Science and Technology of TTS Academy. Since 1985, Dr. Puthoff has served as President and CEO of EarthTech International, Inc. (ETI), and Director of the Institute for Advanced Studies at Austin (IASA). He has published numerous papers on electron-beam devices, lasers and space propulsion and has patents issued in the laser, communications, and energy fields. Dr. Puthoff’s professional background spans more than five decades of research at General Electric, Sperry, the National Security Agency, Stanford University and SRI International. Dr. Puthoff regularly advises NASA , the Department of Defense and intelligence communities, corporations and foundations on leading-edge technologies and future technology trends. He earned his Ph.D. from Stanford University in 1967 and won a Who’s Who Lifetime Achievement in 2017 that recognizes individuals that have achieved greatness in their industry and have excelled in their field for at least 20 years.\nLecture 2018\n\nvideo\nwriteup\nIRVA-SSE 2018\n\n2021 SCU AAP Conference Keynote by Hal Putoff\n\nvideo\n\n\n\n\n\nDr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics\n\n\n\n\nRichard Griffiths serves as Affiliate Faculty at University of Hawaii at Hilo, Physics and Astronomy. He leads the team that solved a gravitational lens phenomenon.\n\narticle\npaper\n\n\n\n\nHis theory:\n\nWarp drive of Tic Tacs in US Navy Close Encounters is the conversion of near field virtual photons-metamaterial quasiparticle hybrids (excitons, polaritons) into near field virtual graviton-hybrids inside the metamaterial fuselage in large numbers forming Glauber macro-quantum coherent “room temperature” superfluid/superconducting pumped non-equilibrium emergent Frohlich-Floquet phases dissipating small amounts of heat and requiring small amounts of external electric power."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html#jim-simons",
    "href": "library/natural-sciences/physics/uap/people.html#jim-simons",
    "title": "UAP People",
    "section": "",
    "text": "He knows something for sure"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#early",
    "href": "library/natural-sciences/physics/uap/index.html#early",
    "title": "UAP",
    "section": "Early",
    "text": "Early\n\nAncient Depictions\nCrucifixtion of Christ \nMiracle of the Snow \nThe Madonna with Saint Giovannino \nTriumph of Summer Tapestry, 1538 \nIsrael, Put Your Hope in the Lord, 1600s\nThe Baptism of Christ, 1710"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#unordered-stuff",
    "href": "library/natural-sciences/physics/uap/index.html#unordered-stuff",
    "title": "UAP",
    "section": "Unordered Stuff",
    "text": "Unordered Stuff\nMajestic Documents\nKey OSINT UAP Resources\nIPU Report, Authorized by Allen Dulles"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#ulat-1",
    "href": "library/natural-sciences/physics/uap/index.html#ulat-1",
    "title": "UAP",
    "section": "ULAT-1",
    "text": "ULAT-1\nWordpress article\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\na.    UF6 in metallic form;\nb.    hydrogen-fluoride gas;\nc.    water and uranium tetra fluoride;\nd.    powdered magnesium and potassium chlorate,\ne.    metal similar to lead with a chocolate brown color;\nf.   U-235 in metallic form;\ng.   plastic-like material similar to NE 102,\nh.    Beryllium,\ni.    Pure aluminium;\nj.   Thorium isotope material;\nj.   Plutonium powder.\n\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#project-white-hot",
    "href": "library/natural-sciences/physics/uap/index.html#project-white-hot",
    "title": "UAP",
    "section": "Project White Hot",
    "text": "Project White Hot\nPROJECT ‘WHITE HOT’ Mission Assessment of Recovered Lenticular Aerodyne Objects\nGeneral Nathan Twining Briefing document for President Eisenhower\nPART 1. PROJECT WHITE HOT INTELLIGENCE ESTIMATE (PRELIMINARY)\nLANDING ZONE NO, 1 Socorro, New Mexico–the unidentified lenticular-shaped Aerodyne which has been designated ULAT-1, has been evaluated as a non air breathing aircraft of unknown origin. Totally lacking conventional wing, fuselage, nacelle, control, and fuel systems strongly indicates it is not Russian.\nConsultation with Paperclip specialists concur. Aerodynamic features exhibited in ULAT-1 represents a very high degree of engineering and sophistication not seen in this country.\nDimensional homogeneity study cannot explain how this craft sustains load and lift factors necessary for flight.\nThe power plant does not even remotely resemble any conventional type now in use. Lacking any discernible intake or exhaust features, it is the opinion of AMC and ONR that this craft was designed to operate outside of the earth’s atmosphere.\nThe unconventional conclusions reached by members of this fact finding mission remain tentative at this time. Some members have expressed the view that ULAT-1 may be the product of an advanced culture from another planet that is much older than ours and has utilized their science and intellect for interplanetary space travel. It is not precisely known if the occupants purposely had the objective of exploration and of curiosity or with the intent of surveying for other reasons. So far, no hostile action or intent has been observed since they made their presence known.\nGiven the fact that our atomic bomb tests, atmospheric exploration with rockets, and XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXed in New Mexico, could have precipitated the events that led to the incident and subsequent actions taken by the military.\nOperating under the assumption that the fallen object was a long-range Russian reconnaissance platform collecting aerial photographic intelligence data military intelligence personnel were a instructed to secure the craft, debris and any occupants as rapidly as possible.\nConcerns over possible exposure to civilian of unknown biological and chemical agents dictated the quarantine measures taken.\nRadiation hazards were assumed and protective measures were taken as well.\nIn the interest or National Security priorities it was necessary to detain civilian witnesses for interrogation to satisfy intelligence requirements and quash rumors that could alert potential espionage agents known to be in the vicinity.\nSeveral bodies were discovered.\nBecause on-site medical personnel were unsure of the physiological make up of the occupants, special preparations and preservation methods were employed. Autopsy information obtained so far suggests that the occupants mimic the features associated with Orientals.\nOutwardly, they appear human-like with but one exception, autopsy notes mention a rarely observed XXXXXXXXXXXXXXXXXXXXXXXXXXXXXs present which supports the premise that these beings originate from another planet.\nPART TWO TECHNICAL EVALUATION (PRELIMINARY) ULAT-1\nUpon close examination of the exterior surfaces of the craft’s fuselage, metallurgists found the the skin to be of a ferrous metal white in color. The metal exhibits all the characteristics of high grade steel. It was determined that the steel was cold-formed and heat created.\n\nTensile strength was estimated in excess of 50,000 pounds per square inch. Shear tests give the metal a durability rating above 175,000 pounds per square inch, making this fuselage extremely strong and heat resistant.\nStatic and pressure flow simulations were impressive. The low profile ration of 6-1 gives the aerodyne a great advantage in overcoming the restrictions of the boundary layer effect in high performance operations.\nSpan flanges are constructed in unusual kinematic design which is believed to allow strain relief at supersonic speeds. There were no visible signs of plate-stiffeners, there were no fasteners, weld, rivets, or fittings, holding the fuselage together.\nLack of wings, flaps, stabilizers, and surface central features, suggests that the craft is a lifting body.\nThere are no air intakes for exhaust.\nThere are no cables\nThere are no identifiable electronics (wiring, ignition, lights, instrument, compartment, engine, motors, vacuum tubes, solenoids, generators, heaters, etc.)\nThe power-plant, (severely damaged) XXXXXXXXXXXXXXXXXx neutronic engine. XXXXXXXXXXXXXXXXXXXXXx detected heavy water and deuterium (light hydrogen) elements appeared to be the primary ignitor. A series of coils and heavy magnets connected to the neutronic engine via an oddly arranged group of electrodes (actually not yet identified) appears to be the active force. One small motor was examined. It is encased in a pure aluminium capsule directly underneath the main compartment. There is a small exhaust aperture attached that was what can only be described as an helicoid mechanism XXXXXXXXXXXXXXXXXXXXX. The auxiliary motor may be articulated.\n\nAdvertisement\n\nNavigation and engine controls may be activated by tactile manipulation. Viewing may have been achieved by form of television imagery. Symbolic notation appears to be the form of flight and control indicators. Flat panels of unknown metal has been suggested as a device associated with the operation of the aerodyne was discovered and analyzed. It’s mode of operation and purpose is unknown.\nThe absence of provisions, berthing compartments and storage areas, suggest the notion that this craft may be a short range reconnaissance platform. The only recognizable features XXXXXXXXXXX XXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nMode of operation of operation is believed to be instrumentation and suggests that the aerodyne from reconstruction from available wreckage XXXXXXXXXXXXXXXXXX biosensory and optical stimuli for these reasons:\n\nabsence of indicator signals Absence of any circular dials Absence of linear dials or moving pointers Absence of counters Absence of scopes No mechanical signal indicators 12. There were identifiable control types found among the assortment of artefacts that would indicate the operation of the propulsion unit was manually activated – no knobs, push buttons, toggle switches, levers, balls, handwheels, hand-cranks, or foot pedals were observed in the interior space of the flight cabin.\n\nThe apparent lack of additional clothing and equipment reinforces the belief that the occupants were engaged in a purely exploratory flight.\nIt is not presently known if electromagnetic radiation effects from the power plant had contributed to pilot error or death before impact. If inadequate shielding was the primary cause of pilot error XXXXXXXXXXXXXXs detected.\nIt is believed by some of the crash inspection personnel that sudden decompression and change in atmospheric pressure may have contributed to pilot error. Clothing removed from occupants do not resemble any pressure suit currently being tested by the Army or the Navy for high altitude experiments. Since temperature and humidity factors for the occupants is unknown, it is impossible to determine if decompression and temperature changed affected circulatory and dexterity functions. Although it is believed the occupants may have been overcome by some yet undiscovered pollutant or noxious fumes originating inside the craft.\nRotation or rapid oscillation could have been a contributing factor in pilot error. It is not known if organic effects played a part either since medical data is non-existent in which to make any judgment as to exact cause of death or machine failure.\nThe most probable cause of the crash is believed to be excessive acceleration combined with steep descent. The seating arrangement was transversely designed about the vertical axis of the occupants in a positive direction of flight. The panels removed from the craft resemble the ones taken from the occupants, suggesting a symbionic relationship between operator and the function of the aerodyne’s operation. A very tentative working theory was expressed by the scientific members of the inspection team that pilot-aerodyne interaction may occur via electronic-nonword symbols perceived through the tactile manipulation of the fingers feeding impulses to the brain and visa versa. All of which may suggest a non-inert quality or the materials existent as being a product or artificial intelligence.\nThe following elements were analyzed and found to exist in the small neutronic power plant that was found inside ULAT-l:\n\n\nUF6 in metallic form;\nhydrogen-fluoride gas;\nwater and uranium tetra fluoride;\npowdered magnesium and potassium chlorate,\nmetal similar to lead with a chocolate brown color;\nU-235 in metallic form;\nplastic-like material similar to NE 102,\nBeryllium,\nPure aluminium;\nThorium isotope material;\nPlutonium powder.\n\n\nScientists from Los Alamos and Sandia Base were alarmed that the power plant could possibly function as a bomb if the elements described above were processed in similar fashion as was done for the lens and shot-gun detonators. This originally was the first conclusion. After further evaluation, it was determined that since no recognizable firing circuits were identified, the threat or detonation did not exist.\nThe only evidence or circuitry found on the motor was thin plastic-like sheets fashioned like platters embossed on the exterior of the spherically-shaped casing coated by a thin film or pure silver. Under high power magnification it was observed a series of fine grid-like lines intersecting groups of dots arranged in circular patterns.\n\nPART III SCIENTIFIC PROBABILITIES\n\nBased on all available evidence collected from recovered exhibits currently under study by AHC, AFSWP, NEPA, AEC, ONA, NACA, JBDB, RAND, USAAF SAG. and MIT, are deemed extraterrestrial in nature. This conclusion was reached as a result of comparisons of artifacts XXXXXXXXXXXXXXXXXX discovery in 1941. The technology is outside the scope of US science, even that of German rocket and aircraft development.\nInterplanetary space travel is possible provided adequate funding, necessary resources are made available, and national interest is piqued.\nOur solar system is not unique. Chances are favorable for intelligent life on other planets notwithstanding similar development not unlike our own.\nBeing that our culture is relatively young (in relation to the cosmic scale), it is possible that other cultures may have developed faster, or are much older and have avoided the pitfalls common in our historical and scientific development.\nHuman origins may not be constrained to one planet. Our genus may be found among solar systems similar to our own.\nThe laws of physics and genetics may have a genesis in a higher, structured order than once previously thought.\n\nPART IV POLITICAL CONSIDERATIONS\nGiven the existing political climate in the US and the unstable conditions in Europe, it is the considered opinion of the members, that if the Administration went public with the information as found in this report now, the results would be damaging, even fatal to the world Political structure as it now exists. The following considerations were reviewed and debated, which led the mission to the following opinions:\n\nPublic trust of the political institutions may be eroded and possibly be held in disrepute.\nA complete revisioning make take place as institutions of higher learning thus calling into question the certainty of scientific knowledge.\nThe ability of the Armed Forces to secure National Security would be put in jeopardy and possibly lead to undue public fear and disorder.\nHistory and religion in the political context would probably suffer the most damage causing unprecedented upheaval in social and psychological well-being.\nPolitical repercussions may occur in our diplomatic efforts of containing the Communist threat to our democratic interests.\nIf such an announcement were made by the current Administration, it could be perceived by opposing party as a trick, laying open to accusations of unethetical (sic) posturing and manipulation of the public’s mind.\n\nPART V NATIONAL SECURITY STRUCTURE\nWith the passage of the National Security Act of 1947 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXas presented an unprecedented situation regarding maintaining secrecy related to the information contained in this report.\nIn the early months of 1942, up until the present, intrusions of unidentified aircraft have occasionally been documented, but there has been no serious investigations by the intelligence arm of the Government. Even the recovery case of 1941 did not create a unified intelligence effort to exploit possible technological gains with the exception of the Manhattan Project. We now have an opportunity to extend our technology beyond the threshold that we have achieved, XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXXXXX. Aside from technological gains, we face an even greater challenge, that of learning the intent of such a presence. There are questions that remain unanswered, such as: What forces face us? What kind of defense do we have? Where do they come from and what kind of weapons do they possess? Where can we stage our forces in advance, XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX How wide a front? How many craft can we expect? And XXXXXXXXXXX XXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXXXXXX\nThe members of the mission are prepared to submit a separate report on just this problem alone. And it would take a dozen volumes to explain how these problems should be met.\nOur only point, however, is that a combined intelligence and research operation would be a vast, intricate, covertly planned marshaling of resources, human and material, to solve a specific, clearly defined problem.\nWe have to find effective methods of persuasion with other government agencies without creating a sense of impending doom. The first task is to carefully appraise the problem. The second is to evaluate the known resources and probable strategy of the visitors. The third is to inventory our own ways and means, ascertain how much resources we can bring to bear, and how fast. The third is to devise our strategic plan. And last is to work out with infinite pains the tactical details and the myriad secondary problems of funding and security.\nIt is the unanimous opinion of the members that Operation MAJESTIC TWELVE be a fully funded ant operational TOP SECRET Research and Development intelligence gathering agency. It is also recommended that a panel of experts be appointed to chair and oversee the functions and operations of said agency. It’s members should have appropriate security clearances and full cooperation XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX XXXX XXXXXXXX XXXXXXXXXXXXXXXXX XXXXXXXXXXX the National Security Council, the Pentagon, XXXXXXXht, XXXXXXXXXXXXXXXXXXXXX Joint Intelligence Committee, Joint Intelligence Objectives Agency, Central Intelligence Agency, Atomic Energy Commission, Joint Research and Development Board, Army Security Agency, and the National Advisory Board on Aeronautics.\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXgy are highlighted:\n\nPropeller driven bomber aircraft and jet engines, armed with conventional and atomic bombs.\nJet fighter aircraft, including some of super­sonic speed, armed with rockets and guns.\nPropeller-driven aircraft, valued for their endurance. .\nGuided anti-aircraft missiles, and radar-guided anti-aircraft guns.\nShort and medium-range guided missiles. Drone aircraft.\nAtomic charges, in bombs, missiles and torpedoes.\n\nIn the arena of nuclear weapons we feel there is a certain advantage to be gained XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX. It is speculated by some that if reduced size and miniature circuitry were introduced into the proposed hydrogen bomb program, it would give US Strategic Air Forces a great deterrence capability over the Russians. Current studies at MIT of micro-electronics taken from ULAT-1 may give us the strategic advantage so desired. It is strongly recommended that funding be allocated in this area.\nThere is a good chance that the Russians may try to make use of the flying saucer scare by public news media and diplomatic means of a technological breakthrough in aircraft and missile development. We feel that such a disclosure would certainly cause great embarrassment to our elected officials and to the military, not to mention the panic felt by the citizenry. To counter such a threat, it is recommended that a counterintelligence program be drawn up and held in abeyance if at such time the situation should present itself. It might be suggested that we should make a preempted use of these objects for the purpose of psychological warfare once the true nature of these objects are known and understood.\nTo further assist and aid all MAJCOM in the US and overseas, it is recommended that a standard intelligence reporting system be implemented through standard reporting channels with technical data forwarding instructions. At present, there are no specific intelligence guidelines available to military commanders in dealing with sightings and material evidence collection. It would be advisable for the respective Secretaries of the Armed Forces to devise a security policy of plausible denial, if and when the public becomes aware of the reality of these objects and the interest of the military of such incidents.\nIn conclusion, for reasons of national security and the public well being, the US must be perceived as being the top of the heap and every effort must be made to insure that there is, and never has been, a threat to the country."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#technology",
    "href": "library/natural-sciences/physics/uap/index.html#technology",
    "title": "UAP",
    "section": "Technology",
    "text": "Technology\n\nFaster than Light Travel\nWarp Drives Part 1: Problem Statement and Insights\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nPolarizable Vacuum “Metric Engineering” Approach to GR-Type Effects\nNeed to get this on dark web! Summary of Chapel Hill Conf\nBehind the Scenes Chapel Hill\nThe Role of Gravitation in Physics\nAn Evening With Director of National Intelligence Avril Haines\nAdvanced Space Propulsion Based on Vacuum Engineering\nNovel Ni-Doped Bismuth–Magnesium Tantalate Pyrochlores: Structural and Electrical Properties, Thermal Expansion, X-ray Photoelectron Spectroscopy, and Near-Edge X-ray Absorption Fine Structure Spectra\nFew-layer bismuth selenide cathode for low-temperature quasi-solid-state aqueous zinc metal batteries\nFaster than Light Travel\nWarp Drives Part 1: Problem Statement and Insights\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nPolarizable Vacuum “Metric Engineering” Approach to GR-Type Effects\nSuperconductors as quantum transducers and antennas for gravitational and electromagnetic radiation"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#majestic-12",
    "href": "library/natural-sciences/physics/uap/index.html#majestic-12",
    "title": "UAP",
    "section": "Majestic 12",
    "text": "Majestic 12\nFBI says this document is fake\nGovernment Accountability Office says “MJ12” Fabricated, 1995\nArchives.gov, however, admits existence\n\nSearches were made of the indexes to the NSC’s Policy Paper and Meeting Minute files under the subjects MJ-12, majestic, unidentified flying objects, UFO, flying saucers,extraterrestrial biological entities and Aquarius. These searches were all negative with the exception of a “Memorandum for General Twining, from Robert Cutler, Special Assistant to the President, Subject:”NCS/MJ-12 Special Studies Project” dated July 14, 1954. The memorandum, one page, refers to a briefing to take place on July 16. The memorandum does not identify MJ-12 or the purpose of the briefing.\n\nBlack Vault: Majestic"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#ancient-depictions",
    "href": "library/natural-sciences/physics/uap/index.html#ancient-depictions",
    "title": "UAP",
    "section": "Ancient Depictions",
    "text": "Ancient Depictions\nCrucifixtion of Christ \nMiracle of the Snow \nThe Madonna with Saint Giovannino \nTriumph of Summer Tapestry, 1538 \nIsrael, Put Your Hope in the Lord, 1600s\nThe Baptism of Christ, 1710"
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html#jack-sarfatti",
    "href": "library/natural-sciences/physics/uap/people.html#jack-sarfatti",
    "title": "UAP People",
    "section": "Jack Sarfatti",
    "text": "Jack Sarfatti\nHis theory:\n\nWarp drive of Tic Tacs in US Navy Close Encounters is the conversion of near field virtual photons-metamaterial quasiparticle hybrids (excitons, polaritons) into near field virtual graviton-hybrids inside the metamaterial fuselage in large numbers forming Glauber macro-quantum coherent “room temperature” superfluid/superconducting pumped non-equilibrium emergent Frohlich-Floquet phases dissipating small amounts of heat and requiring small amounts of external electric power."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/people.html#people",
    "href": "library/natural-sciences/physics/uap/people.html#people",
    "title": "UAP People",
    "section": "",
    "text": "He knows something for sure\n\n\n\nDr. Harold E. Puthoff is the co-founder and Vice President of Science and Technology of TTS Academy. Since 1985, Dr. Puthoff has served as President and CEO of EarthTech International, Inc. (ETI), and Director of the Institute for Advanced Studies at Austin (IASA). He has published numerous papers on electron-beam devices, lasers and space propulsion and has patents issued in the laser, communications, and energy fields. Dr. Puthoff’s professional background spans more than five decades of research at General Electric, Sperry, the National Security Agency, Stanford University and SRI International. Dr. Puthoff regularly advises NASA , the Department of Defense and intelligence communities, corporations and foundations on leading-edge technologies and future technology trends. He earned his Ph.D. from Stanford University in 1967 and won a Who’s Who Lifetime Achievement in 2017 that recognizes individuals that have achieved greatness in their industry and have excelled in their field for at least 20 years.\nLecture 2018\n\nvideo\nwriteup\nIRVA-SSE 2018\n\n2021 SCU AAP Conference Keynote by Hal Putoff\n\nvideo\n\n\n\n\n\nDr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics\n\n\n\n\nRichard Griffiths serves as Affiliate Faculty at University of Hawaii at Hilo, Physics and Astronomy. He leads the team that solved a gravitational lens phenomenon.\n\narticle\npaper\n\n\n\n\nHis theory:\n\nWarp drive of Tic Tacs in US Navy Close Encounters is the conversion of near field virtual photons-metamaterial quasiparticle hybrids (excitons, polaritons) into near field virtual graviton-hybrids inside the metamaterial fuselage in large numbers forming Glauber macro-quantum coherent “room temperature” superfluid/superconducting pumped non-equilibrium emergent Frohlich-Floquet phases dissipating small amounts of heat and requiring small amounts of external electric power."
  },
  {
    "objectID": "library/natural-sciences/physics/uap/index.html#people",
    "href": "library/natural-sciences/physics/uap/index.html#people",
    "title": "UAP",
    "section": "People",
    "text": "People\n\nJim Simons\nHe knows something for sure\n\n\nHal Puthoff\nDr. Harold E. Puthoff is the co-founder and Vice President of Science and Technology of TTS Academy. Since 1985, Dr. Puthoff has served as President and CEO of EarthTech International, Inc. (ETI), and Director of the Institute for Advanced Studies at Austin (IASA). He has published numerous papers on electron-beam devices, lasers and space propulsion and has patents issued in the laser, communications, and energy fields. Dr. Puthoff’s professional background spans more than five decades of research at General Electric, Sperry, the National Security Agency, Stanford University and SRI International. Dr. Puthoff regularly advises NASA , the Department of Defense and intelligence communities, corporations and foundations on leading-edge technologies and future technology trends. He earned his Ph.D. from Stanford University in 1967 and won a Who’s Who Lifetime Achievement in 2017 that recognizes individuals that have achieved greatness in their industry and have excelled in their field for at least 20 years.\nLecture 2018\n\nvideo\nwriteup\nIRVA-SSE 2018\n\n2021 SCU AAP Conference Keynote by Hal Putoff\n\nvideo\n\n\n\nSalvatore Pais\n\nDr. Salvatore Pais | Intuitive Science, Conscious Universe & The Philosophy of Physics\n\n\n\nRichard Griffiths\nRichard Griffiths serves as Affiliate Faculty at University of Hawaii at Hilo, Physics and Astronomy. He leads the team that solved a gravitational lens phenomenon.\n\narticle\npaper\n\n\n\nJack Sarfatti\nHis theory:\n\nWarp drive of Tic Tacs in US Navy Close Encounters is the conversion of near field virtual photons-metamaterial quasiparticle hybrids (excitons, polaritons) into near field virtual graviton-hybrids inside the metamaterial fuselage in large numbers forming Glauber macro-quantum coherent “room temperature” superfluid/superconducting pumped non-equilibrium emergent Frohlich-Floquet phases dissipating small amounts of heat and requiring small amounts of external electric power."
  },
  {
    "objectID": "library/life-sciences/biology/index.html",
    "href": "library/life-sciences/biology/index.html",
    "title": "Biology",
    "section": "",
    "text": "The Simlarity Metric: Clustering by Compression\n\n\n\n\nAssembly Theory, 1985\nLimitations of Assembly Theory\n8 Fallacies of Assembly Theory\nOn the Salient Misunderstandings of Assembly Theory (assembly is good)\n\n\n\n\n\nThe structure of a cell is wildly oversimplified"
  },
  {
    "objectID": "library/life-sciences/biology/index.html#resources",
    "href": "library/life-sciences/biology/index.html#resources",
    "title": "Biology",
    "section": "",
    "text": "The Simlarity Metric: Clustering by Compression\n\n\n\n\nAssembly Theory, 1985\nLimitations of Assembly Theory\n8 Fallacies of Assembly Theory\nOn the Salient Misunderstandings of Assembly Theory (assembly is good)\n\n\n\n\n\nThe structure of a cell is wildly oversimplified"
  },
  {
    "objectID": "library/natural-sciences/physics/relativity/index.html#black-hole-discussion",
    "href": "library/natural-sciences/physics/relativity/index.html#black-hole-discussion",
    "title": "Relativity",
    "section": "Black Hole Discussion",
    "text": "Black Hole Discussion\n\nEquation for a Rotating Black Hole\n\\[\n\\begin{aligned}\nd s^2= & -\\left(1-\\frac{2 m r}{r^2+a^2 \\cos ^2 \\theta}\\right)\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)^2 \\\\\n& +2\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)\\left(d r-a \\sin ^2 \\theta d \\tilde{\\phi}\\right) \\\\\n& +\\left(r^2+a^2 \\cos ^2 \\theta\\right)\\left(d \\theta^2+\\sin ^2 \\theta d \\tilde{\\phi}^2\\right)\n\\end{aligned}\n\\]\n\nYou can’t take the reference frame of light. In every reference frame the light speed is the same, so “in the reference frame of light” makes no sense because there time is stopped. The EH can’t be seen on oo because for an observer between PS and EH there are a finite number of oscillations of his time reference from PS to EH The assumption that the universe could rotate leads to a complication of all physical laws. We would get that there then has to be a rotation axis of the universe and that all rules are different with relation to that axis so that speed along the rotation direction can exceed c with any multiple without problems of inertia. This is similar to the Hubble expansion with the difference of an absolute rotation axis. That is why I reject both assumptions. It makes no sense to assume that space rotates. We rotate inside space. It also makes no sense to assume that space expands. We shrink inside space. The big one, space, is invariant, flat, not rotating, not translating, not curving. The small, what is inside space, rotates, translates, changes size. The only property of space that has a variation is that the propagation speed of light depends on the mass/energy density distribution in space.\n\n\nIsn’t it easier for Hawking radiation to escape if black holes have hair? So it’s not perfectly curved there. How does this equation differ from the superfluid quantum gravity spinning vortice(s) model of black holes?\n\n\n@bgreene marveled about the beauty of the equation. He didn’t gave a judgement about its validity. I gave an explanation on what assumptions are needed to allow this metric equation to be applicable. You come with the concept of a radiating BH. That only asks wether a particle pair of matter and antimatter could split such that one falks into, and one escapes the BH. But since the propagation speed of light at the EH is equal to the EH nothing moves there. So a hairy EH would assume that this propagation speed distribution is not smooth. This then should lead to particle wave functions to start from “stand still” and move outward. Such phenomen would need a different metric equation, but would not alter the beauty of the equation that @bgreene mentioned."
  },
  {
    "objectID": "library/natural-sciences/software/programming/rust/index.html",
    "href": "library/natural-sciences/software/programming/rust/index.html",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/natural-sciences/software/programming/rust/index.html#learning-resources",
    "href": "library/natural-sciences/software/programming/rust/index.html#learning-resources",
    "title": "Rust Language",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\n“By example”, Rustlings\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/natural-sciences/physics/materials.html",
    "href": "library/natural-sciences/physics/materials.html",
    "title": "Materials Physics",
    "section": "",
    "text": "Riddle Solved: Roman concrete\n\npaper\n\nA Novel Mineral-like Copper Phosphate Chloride with a Disordered Guest Structure: Crystal Chemistry and Magnetic Properties\n“Mix coconut oil and gasoline and pour it on asphalt on a hot day to disintegrate a roadbed”\nGasoline dissolves asphalt\nAmerican Elements"
  },
  {
    "objectID": "library/natural-sciences/physics/materials.html#resources",
    "href": "library/natural-sciences/physics/materials.html#resources",
    "title": "Materials Physics",
    "section": "",
    "text": "Riddle Solved: Roman concrete\n\npaper\n\nA Novel Mineral-like Copper Phosphate Chloride with a Disordered Guest Structure: Crystal Chemistry and Magnetic Properties\n“Mix coconut oil and gasoline and pour it on asphalt on a hot day to disintegrate a roadbed”\nGasoline dissolves asphalt\nAmerican Elements"
  },
  {
    "objectID": "library/natural-sciences/physics/materials.html#lead-copper-phosphate-compound",
    "href": "library/natural-sciences/physics/materials.html#lead-copper-phosphate-compound",
    "title": "Materials Physics",
    "section": "Lead Copper Phosphate Compound",
    "text": "Lead Copper Phosphate Compound\n\\[\n\\mathrm{Pb}_{10-x} \\mathrm{Cu}_x\\left(\\mathrm{PO}_4\\right)_6 \\mathrm{O}\n\\]\nThe chemical formula you’ve given is for a lead copper phosphate mineral that’s part of a larger solid solution series. Solid solution series occur when two or more different elements can substitute for each other in a mineral’s structure to a significant degree. Here, the variable x represents a range of compositions that can exist within this series.\nThe formula indicates that for every 6 units of phosphate (PO4) and one oxygen (O), there are 10-x lead (Pb) atoms and x copper (Cu) atoms. The “x” in the formula implies that the copper content can vary, essentially representing a range of similar minerals with varying amounts of copper and lead. As the copper content increases (x increases), the lead content decreases correspondingly.\nPlease note that this is a general explanation and the specifics of the mineral can vary greatly depending on its formation conditions and geological setting.\nIf you want to understand this equation thoroughly, you would need to delve into crystal chemistry and solid state physics.\nCrystal Chemistry: The substitution of Pb by Cu is possible due to similarities in their ionic radii and charge. Minerals form in specific crystalline structures and the substitution of one atom for another depends on these factors.\nSolid State Physics: The physical properties of this mineral series, such as its electrical conductivity or magnetic properties, would vary based on the exact ratio of Pb to Cu. Understanding these properties requires knowledge of solid state physics."
  },
  {
    "objectID": "library/natural-sciences/physics/materials.html#pre-war-steel",
    "href": "library/natural-sciences/physics/materials.html#pre-war-steel",
    "title": "Materials Physics",
    "section": "Pre-War Steel",
    "text": "Pre-War Steel\nRadioactivity in Steel Production After Nuclear Bombs\n\nSummary\nThe phrase “pre-war steel” is often used in relation to low-background steel, which is steel produced prior to the detonation of the first atomic bombs in the mid-1940s. It’s not that the steel produced before these explosions is stronger or of better quality, but it’s that the steel manufactured after the start of the atomic age is slightly radioactive.\nIn 1945, when the first atomic bombs were detonated during World War II, they released various radionuclides, including Carbon-14 and other radioactive isotopes, into the atmosphere. These isotopes circled the globe and were incorporated into many things, including the iron ore used to produce steel. As a result, steel produced after 1945 can exhibit slight radioactivity.\nThis can be an issue in certain sensitive applications where even the tiniest amount of background radiation can interfere with equipment operation or measurements, like Geiger counters, certain medical equipment, and scientific devices used in physics and geology. For these uses, pre-war or low-background steel, typically salvaged from pre-1945 ships and buildings, is often sought.\n\n\nResearch\n\nLow-Background Steel Wiki\nReadiation Damage Wiki\nRadiation Effects in Steel\nInvestigation of Natural Radioactivity and Dose Assessment over Steel Making Region\nEffects of Irradiation on Mechanical Properties\nIs neutron radiation exposure always detrimental to metals (steels)?\nEffects of Radiation Damage"
  },
  {
    "objectID": "library/life-sciences/environment/index.html",
    "href": "library/life-sciences/environment/index.html",
    "title": "Environment",
    "section": "",
    "text": "NASA Evidence for Climate Change\nIPCC baseline scenarios have over-projected CO2 emissions and economic growth\nHyporthermic Nature of Fungi (“Why Mushrooms are Cold”)\nTestosterone histories from tusks reveal woolly mammoth musth episodes\nAntartica Gained Ice, Not Lost It\nAnartica Low Ice Winter\nSea Water Heat Map\nThe Climate Change Alternative We Ignore (to Our Peril)\nGold Mining and the Environment"
  },
  {
    "objectID": "library/life-sciences/environment/index.html#climate-change",
    "href": "library/life-sciences/environment/index.html#climate-change",
    "title": "Environment",
    "section": "",
    "text": "NASA Evidence for Climate Change\nIPCC baseline scenarios have over-projected CO2 emissions and economic growth\nHyporthermic Nature of Fungi (“Why Mushrooms are Cold”)\nTestosterone histories from tusks reveal woolly mammoth musth episodes\nAntartica Gained Ice, Not Lost It\nAnartica Low Ice Winter\nSea Water Heat Map\nThe Climate Change Alternative We Ignore (to Our Peril)\nGold Mining and the Environment"
  },
  {
    "objectID": "library/life-sciences/environment/index.html#geoengineering",
    "href": "library/life-sciences/environment/index.html#geoengineering",
    "title": "Environment",
    "section": "Geoengineering",
    "text": "Geoengineering\n\nCan Controversial Geoengineering Fix Climate Crisis\nNear-term climate risks and sunlight reflection modification: a roadmap approach for physical sciences research\nReflecting Sunlight: Recommendations for Solar Geoengineering Research and Research Governance - National Academies of Sciences, Engineering, and Medicine\nMake Sunsets: Geoengineering Startup\nOpen Letter Against Solar Geoengineering\nStratospheric ozone changes under solar geoengineering: implications for UV exposure and air quality\nGeoengineering could Turn Skies White\nWeather as a Force Multiplier: Owning the Weather in 2025\nWashington’s New World Order Weapons Have the Ability to Trigger Climate Change"
  },
  {
    "objectID": "library/life-sciences/environment/index.html#animals",
    "href": "library/life-sciences/environment/index.html#animals",
    "title": "Environment",
    "section": "Animals",
    "text": "Animals\n\nBarbery Lions\n\nDiscovery Article: Barbary Lion Facts\n\nThe Barbary lion is one of the most spectacular beasts ever to have walked the face of the Earth. Known as the Berber lion, the North African lion, the Egyptian lion and the Atlas lion, this is one of history’s most famous animals.\nIn the vast deserts and mountains of the Barbary coast in North Africa, the Barbary lions once roamed freely. With their distinctly dark manes, they were thought to have been one of the largest lion species to have ever existed. These majestic creatures captured the imagination of many, and their historical significance reaches far back into antiquity.\nBarbary lions were not only remarkable for their appearance but also for their role in history. These same lions were regularly captured by hunters for the brutal games held in the Roman colosseum. Known as “Damnatio ad bestias” in Latin, this practice was a form of capital punishment where condemned prisoners were executed by Barbary lions and other large cats. The lions’ presence in such events added to their mythos and perpetuated their fame.\nThe decline of the Barbary lion population began with the expansion of the Arab empire from 632 to 1258, leading to the end of the Islamic Golden Age after the Siege of Baghdad by the Mongols. Survivors of that turbulent period claimed that “the waters of the Tigris ran black with ink from the enormous quantities of books flung into the river and red from the blood of the scientists and philosophers killed.” Amidst the turmoil in the region and as empires crumbled and fell, the Barbary lions managed to persist until the arrival of European colonists in the 19th century.\nDuring this time, big-game hunting gained popularity, and it proved to be devastating for the already dwindling lion population. As a result, sightings of Barbary lions became scarce, and not a single one was reported from 1901 to 1910. By the 1920s, most scientists believed that they had become extinct in the wild.\nThere were a few reported sightings in subsequent decades, offering glimmers of hope that some may have survived. In 1948, there was a reported sighting in Morocco, and in 1958, another sighting was claimed in a heavily forested area near the city of Sétif in Algeria. However, the forest was destroyed during the Algerian War in the same year, further exacerbating the challenges faced by these noble creatures.\nToday, approximately 100 captive lions possess the genes of the Barbary lions, but none of them are pure descendants. While these lions carry a part of their ancestral legacy, the extinction of the Barbary lions in the wild serves as a stark reminder of the consequences of human actions on the delicate balance of nature. The story of the Barbary lion stands as a poignant testament to the importance of conservation efforts to protect and preserve the incredible diversity of life on our planet."
  },
  {
    "objectID": "library/life-sciences/health/covid/index.html#psyop",
    "href": "library/life-sciences/health/covid/index.html#psyop",
    "title": "Covid-19",
    "section": "Psyop",
    "text": "Psyop\n\nGermany\n\nInterview with German MEP, Christine Anderson\n\nGovernments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”"
  },
  {
    "objectID": "library/life-sciences/health/covid/index.html#germany-1",
    "href": "library/life-sciences/health/covid/index.html#germany-1",
    "title": "covid",
    "section": "Germany",
    "text": "Germany\n\nInterview with German MEP, Christine Anderson\n\nGovernments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”"
  },
  {
    "objectID": "library/life-sciences/health/covid/index.html#the-effect-of-mandatory-masks-on-autism-in-children",
    "href": "library/life-sciences/health/covid/index.html#the-effect-of-mandatory-masks-on-autism-in-children",
    "title": "Covid-19",
    "section": "The Effect of Mandatory Masks on Autism in Children",
    "text": "The Effect of Mandatory Masks on Autism in Children\n\nBut hopefully, this [mask mandate in schools] will be a temporary thing, temporary enough that it [masks] doesn’t have any lasting negative impact on them [children]. - Anthony Fauci, August 9 2021\n\n\nRecognition of Faces: An Approach to the Study of Autism\n\nTwo age groups of normal, autistic and subnormal children were tested for their ability to recognize the faces of peers from isolated facial features and inverted photographs. The normal and subnormal subjects found the upper regions of the face most helpful for identification, whereas the younger autistic children found the lower features more helpful. The older autistic children showed no specific reliance on any one area, but were found to have error scores as low as those of the younger autistic children on the recognition of lower parts and error scores as low as the; controls on recognizing upper portions. The results are discussed and are found to favour a hypothesis in which the autistic child’s familiarity with the mouth and/or eye areas is related to a cognitive deficit which affects the processing of both verbal and non-verbal interpersonal communication.\n\nAmerican Academy of Pediatrics Poster, Highlighting the Importance of Facial Expressions for Children\n\nThey later were swallowed by the narrative, and made a public statement that in-school masks does not affect children (hypocritical)\n\nVisual Impairment: Its Effect on Cognitive Development and Behavior\nInfants Deploy Selective Attention to the Mouth of a Talking Face when Learning Speech\n\nThe mechanisms underlying the acquisition of speech-production ability in human infancy are not well understood. We tracked 4–12-mo-old English-learning infants’ and adults’ eye gaze while they watched and listened to a female reciting a monologue either in their native (English) or nonnative (Spanish) language. We found that infants shifted their attention from the eyes to the mouth between 4 and 8 mo of age regardless of language and then began a shift back to the eyes at 12 mo in response to native but not nonnative speech. We posit that the first shift enables infants to gain access to redundant audiovisual speech cues that enable them to learn their native speech forms and that the second shift reflects growing native-language expertise that frees them to shift attention to the eyes to gain access to social cues. On this account, 12-mo-old infants do not shift attention to the eyes when exposed to nonnative speech because increasing native-language expertise and perceptual narrowing make it more difficult to process nonnative speech and require them to continue to access redundant audiovisual cues. Overall, the current findings demonstrate that the development of speech production capacity relies on changes in selective audiovisual attention and that this depends critically on early experience.\n\nUnderstanding the Impact of Face Masks on the Processing of Facial Identity, Emotion, Age, and Gender\n\nThis is not even about children in particular, but illustrates how it may be detremential to young people in a learning phase\nAbstract Result: The results revealed that masks hindered the perception of virtually all tested facial dimensions (i.e., emotion, gender, age, and identity), interfering with normal speed and accuracy of categorization. We also found that the unwarranted effects of masks were not due to holistic processes, because the Face Inversion Effect (FIE) was generally not larger with unmasked compared with masked faces. Moreover, we found that the impact of masks is not automatic and that under some contexts observers can control at least part of their detrimental effects.\n\nFace masks reduce emotion-recognition accuracy and perceived closeness\n\nAgain, this was on adults, because you wouldn’t be able to publish your findings in 2021 if you exposed what it does to children\n\n\nIMPORTANT\n\nEmotion comprehension between 3 and 11 years: Developmental periods and hierarchical organization\nDarwin’s Contributions of our Understanding of Emotional Expressions\nInfants deploy selective attention to the mouth of a talking face when learning speech\nPotential Impact of the COVID-19 Pandemic on Communication and Language Skills in Children\nEffect of face mask and noise on word recognition by children and adults\n\nThis PDF was taken off the web! I am linking it through Wayback machine\n\nThe puzzle of Autism in the time of COVID-19 pandemic: “Light it up Blue”\n\n“… Barriers to essential services such as speech and occupational therapies, combined with loss of routine and predictability has widened the gap between needs and provided care. Parents, teachers and health care should aim to work collectively for a broadened approach that is child/parent centered to compensate for most of disrupted vital support and services”"
  },
  {
    "objectID": "library/life-sciences/health/covid/index.html#mrna-vaccine",
    "href": "library/life-sciences/health/covid/index.html#mrna-vaccine",
    "title": "Covid-19",
    "section": "mRNA Vaccine",
    "text": "mRNA Vaccine\n\nThe mRNA platform is brilliant. But it has a giant gaping flaw in it, which is; Any cell of yours that produces a foreign protein, will be targetted by your immune system and destroyed. You will create an autoimmune disorder. When it works. How do you keep it out of your heart. Not by coding it in a lipid nanoparticle. So, they had no way to deliver it safely to market. So then they had a pandemic, the emergency allowed them to do it. This technology, in my opinion, was at least 3 decades out from being usefully and safely deployed at all, if at all. They did not want to wait, this crisis gave them the opportunity not to wait. And now, they will blame the spike protein, we picked the wrong protein. When in actual fact there are 2 problems, the spike protein and the platform itself. - Brett Weinstein\n\n\nMyocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSerum Vax Spike\n\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”"
  },
  {
    "objectID": "library/life-sciences/health/cold-exposure.html",
    "href": "library/life-sciences/health/cold-exposure.html",
    "title": "Cold Exposure",
    "section": "",
    "text": "Cold as a Therapeutic Agent\nCold for Centuries\nHuman physiological responses to immersion into water of different temperatures\nAltered brown fat thermoregulation and enhanced cold-induced thermogenesis in young, healthy, winter-swimming men\nImpact of Cold-Water Immersion Compared with Passive Recovery Following a Single Bout of Strenuous Exercise on Athletic Performance in Physically Active Participants\nNovel Application of Chemical Cold Packs for Treatment of Exercise-Induced Hyperthermia\nShort-term cold exposure supports human Treg induction in vivo\nDifferences between men and women\n\n\n\nThe use of cold-water immersion has a long and rich history. The beneficial effects on human physiology have been recorded as far back as 3500BC @Wang Et Al., with the Edwin Smith Papyrus (the most ancient medical text known to date) making references to cold being used for therapeutic purposes. The Ancient Greeks utilized cold-water therapies, as recorded by Hippocrates in the fourth century BC. And even the Golden Age of Rome featured cold-water immersion as treatment for fever, advocated for by Roman Physician Claudius Galen in the second century AD @Allan Et Al.. It was only until recently, however, that modern science began to explore the underlying physiological processes behind the power of the cold.\n\n\n\nDeliberate cold exposure triggers a release of epinephrine (adrenaline) and norepinephrine (noradrenaline) into the bloodstream. These hormones are responsible for the fight-or-flight response, and can make us feel alert and/or agitated @Huberman. This is why many people feel more energized after a cold shower or a cold swim.\n\n\n\nCold exposure has been shown to increase energy expenditure, which can lead to weight loss and improved body composition. It has been recommended as a healthy and sustainable alternative strategy for increasing energy expenditure @van Marken Lichtenbelt Et Al..\nA core aspect of cold exposure is the activation of brown adipose tissue (BAT). BAT is a type of fat tissue that is responsible for thermogenesis, or the production of heat. It is found in small amounts in adults, but is more abundant in children. It is also found in higher concentrations in people who are leaner. The activation of BAT is thought to be responsible for the increased energy expenditure that is observed after cold exposure @Huberman.\n\n\n\nA study published in the Journal of Applied Physiology found that cold exposure “induced a leukocytosis and granulocytosis, an increase in natural killer cell count and activity, and a rise in circulating levels of interleukin-6.” @Brenner Et Al.. In other words, this means that cold exposure increases the number of white blood cells, which are responsible for fighting infection, and increases the activity of natural killer cells, which are responsible for destroying cancer cells. It also increases the production of interleukin-6, which is a cytokine that plays a role in the immune response.\nA fundamental aspect of cold exposure therapy is the subconcious respiratory response by the sympathetic nervous system. Upon cold immersion, you may find your breathing rate to increase, and your breaths to deepen. It was traditionally believed that the sympathetic nervous system and immune system could not be voluntarily influenced.\nIn 2011, however, the “Ice Man” Wim Hof participated in a study wherein he was injected with endotoxin, a treated form of E coli bacteria which triggers the same immune response. The study produced groundbreaking results, claiming that through the use of Hof’s breathing technique, he voluntarily and significantly increased his immune system response to the bacteria and completely avoided the flu-like symptoms displayed by healthy participants within the control group. In an attempt to discover if this result was reproducable or an anomoly of Wim Hof himself, a study published in the National Library of Medicine in 2014 replicated the methods with individuals who were trained on the breathing technique prior to the injection. It was again found that the breathing technique resulted in an immediate and profound decrease of pCO2 and bicarbonate, and an increase in pH, indicating acute respiratory alkalosis, which normalized quickly after cessation of the breathing techniques. In laymans terms, this means that humans could, through the use of breathing techniques, voluntarily increase immune system activity.\n\n\n\nCold exposure has been shown to increase the production of endorphins, such as dopmain, which are responsible for the “runner’s high” and other feelings of euphoria. It has also been shown to increase the production of serotonin, which is responsible for feelings of happiness and well-being. Increased dopamin release can last for as long as 6 hours after cold exposure, and increased serotonin release can last for as long as 24 hours after cold exposure @Ootsuka.\n\n\n\nCold water immersion has been reported to increase the level of T-cells (specifically, peripheral T lymphocytes). This has been observed both (1) in the short term after a single treatment/swim, as well as (2) in a longer, sustained manner after a period of multiple treatments per week.\nT-cells, also known as T lymphocytes, are a type of white blood cell that are derived from bone marrow stem cells and mature in the thymus gland. They play an essential role in fighting off infection. With an ability to “recognize” and “remember” germs that they have seen before, they can quickly respond if they see that germ again.\nIn other studies, similar increases have been observed for NK (Natural killer) cells. NK cell activity has been observed to increase both briefly after a treatment and in a sustained manner following consistent and repeated immersions.\nNatural killer (NK) cells are a type of white blood cell that can quickly recognize and destroy infected or cancerous cells without prior exposure or activation. NK cells do not require prior exposure to antigens, which are proteins or other molecules that can trigger an immune response. Instead, they use a variety of receptors to detect abnormal cells and then release toxic substances to kill them.\n\n\n\nAlthough the science is still developing, there is reason to believe cold water immersion may help prevent the risk of tumors and cancers.\nIn a study done on lab mice, a “somewhat reduced spontaneous incidence of tumors, especially sarcomas” was observed among the group of mice that endured repeated cold stress (cold swims). It has also been reported that Cold-inducible RNA binding protein (CIRP) may function as a tumor suppressor via suppressing proliferation. Finally, there’s been a clinical review performed by the National Institute of Health (NIH) exploring the cold’s ability to stimulate “anti-tumor immunity”, which concluded this area deserves “more research as a major target for cancer therapies.”\nWe look forward to the progression of this research.\n\n\n\nWestern biomedical research is gradually discovering the significance of the way in which we breathe, in relation to the body and its many physiological processes. Among these discoveries are how deliberate breathing techniques can 1. increase our tolerance to extremely cold environments and 2. alter immune function in real time.\nLet me highlight the significance of these discoveries: For centuries, modern (Western) medicine considered these processes (circulatory system, immune system, sympathetic nervous system) autonomic or involuntary, meaning they are unable to be controlled consciously. Recent research has slipped this understanding upside down - essentially, deliberate breathing practice is a superpower.\nThere is incredible research on breathing methods/techniques beyond the scope of this article, spanning brain function, enlightened & hallucinogenic states, mood/emotion control, and more. We encourage you to explore it if you’re interested, and we hope to come back to the topic in a future article/series.\nThe first groundbreaking study was done on Wim “The Ice Man” Hof, himself. In 2011, researchers at Radboud University injected Wim Hof with endotoxin, a treated form of bacteria that triggers a general immune response, as Wim practiced his breathing technique. The results were astounding:\n\n…levels of inflammatory mediators in Hof’s blood were much lower. On average, Hof’s immune response was decreased by 50 percent compared to other healthy volunteers. In addition, hardly any flu-like symptoms were observed.\n\nAt first, this study was a target of skepticism. With a sample size of 1, it was unclear whether the results were reproducible or simply Wim Hof producing an outlier result as an individual. However, it was enough to encourage further exploration.\nIn 2014, a study published in the National Library of Medicine sought out to reproduce the 2011 results in average “healthy participants”. The intervention group was trained for just 10 minutes in Hof’s breathing technique, and then both groups were administered with the endotoxin.\n\nIn the intervention group, practicing the learned techniques resulted in intermittent respiratory alkalosis and hypoxia resulting in profoundly increased plasma epinephrine levels. In the intervention group, plasma levels of the anti-inflammatory cytokine IL-10 increased more rapidly after endotoxin administration, correlated strongly with preceding epinephrine levels, and were higher. Levels of proinflammatory mediators TNF-α, IL-6, and IL-8 were lower in the intervention group and correlated negatively with IL-10 levels. Finally, flu-like symptoms were lower in the intervention group.\n\nIn summary, the results were successfully reproduced, and the researchers concluded that it is possible to voluntarily activate the sympathetic nervous system and affect immune response through deliberate breathing technique.\nHof’s breathing technique shook the biomedical science industry again in 2018, this time after he showed humans can consciously enhance their ability to survive in extremely cold conditions (beyond what was previously thought possible). The study concluded that deliberate breathing technique resulted in “increased sympathetic innervation and glucose consumption in intercostal muscle, generating heat that dissipates to lung tissue and warms circulating blood in the pulmonary capillaries.”\n\n\n\nThe optimal, and most studied, approach entails complete submersion in cold water from the neck down. To sit in water from the chest down, with arms outstretched, for instance, precludes full stimulation of the stress response mechanisms which yield many of the advantages discussed in the previous two sections of this series.\nLikewise, although cold showers have demonstrated efficacy, they have not been subjected to the same level of scrutiny as cold water immersion from the neck down. Therefore, it is reasonable to infer that the most optimal results may be obtained through full immersion in cold water. In the event that access to a cold bath is unattainable, cold showers serve as a reasonable alternative.\n\n\n\nThe short answer to this question is: uncomfortable but safe. Discomfort means that the beneficial stress hormones discussed in part 1 are being released in your system, thus offering the corresponding benefits.\nIf you are getting started, you may find that water temperatures around 45 degrees Fahrenheit is enough to feel uncomfortable. Over time, you are likely to find your cold immersion routine becomes easier. If you want to progress, and continue to extract maximum benefit, you must be honest with yourself to recognize whether you are pushing yourself, and increase intensity (decrease temperature) as appropriate.\n\n\n\nA study done by Scandinavian scientist Dr. Susanna Søeberg suggests the magic number is at least 11 minutes per week, total. This is the threshold needed to increase brown fat thermogenesis and metabolism. This could be done in various ways, such as spreading it out throughout the week or doing it all in one day.\n\n\n\nScience suggests that whether cold exposure is done in the morning or at night does not affect the health benefits discussed previously. However, I personally recommend doing your cold exposure first thing in the morning.\nThe reason why relates to internal body temperature and circadian rhythm. Your body is warm when it is awake, and cold when it is asleep. In fact, studies have shown your body temperature must decrease by 1.5 degrees in order to fall asleep.\nExposure to cold temperatures can cause your body to heat up afterwards, making it more difficult to fall asleep if done late at night. On the other hand, if performed early in the morning, cold exposure may boost your energy levels and start your day off on the right foot.\n\n\n\nThe Søeberg Principle, developed by Dr. Susana Søeberg, posits the following:\nTo enhance the metabolic effects of cold, force your body to reheat on its own\n\nEnd With Cold\n\nAdditionally, the act of shivering during or after cold exposure can further activate brown fat thermogenesis and release heat from muscles, resulting in heightened metabolic increases.\nTo increase shivering and optimize the metabolic benefits of cold exposure, individuals are advised to avoid huddling and wrapping their arms around themselves while in the cold or after exiting it. Likewise, entering a sauna after cold exposure, although relaxing, will limit the metabolic benefits of the cold.\nIf you want to go further, it is recommended to refrain from towel drying and instead allowing the body to naturally reheat and dry off. Admittedly, this is difficult, especially when it’s cold outside."
  },
  {
    "objectID": "library/life-sciences/health/cold-exposure.html#resources",
    "href": "library/life-sciences/health/cold-exposure.html#resources",
    "title": "Cold Exposure",
    "section": "",
    "text": "Cold as a Therapeutic Agent\nCold for Centuries\nHuman physiological responses to immersion into water of different temperatures\nAltered brown fat thermoregulation and enhanced cold-induced thermogenesis in young, healthy, winter-swimming men\nImpact of Cold-Water Immersion Compared with Passive Recovery Following a Single Bout of Strenuous Exercise on Athletic Performance in Physically Active Participants\nNovel Application of Chemical Cold Packs for Treatment of Exercise-Induced Hyperthermia\nShort-term cold exposure supports human Treg induction in vivo\nDifferences between men and women\n\n\n\nThe use of cold-water immersion has a long and rich history. The beneficial effects on human physiology have been recorded as far back as 3500BC @Wang Et Al., with the Edwin Smith Papyrus (the most ancient medical text known to date) making references to cold being used for therapeutic purposes. The Ancient Greeks utilized cold-water therapies, as recorded by Hippocrates in the fourth century BC. And even the Golden Age of Rome featured cold-water immersion as treatment for fever, advocated for by Roman Physician Claudius Galen in the second century AD @Allan Et Al.. It was only until recently, however, that modern science began to explore the underlying physiological processes behind the power of the cold.\n\n\n\nDeliberate cold exposure triggers a release of epinephrine (adrenaline) and norepinephrine (noradrenaline) into the bloodstream. These hormones are responsible for the fight-or-flight response, and can make us feel alert and/or agitated @Huberman. This is why many people feel more energized after a cold shower or a cold swim.\n\n\n\nCold exposure has been shown to increase energy expenditure, which can lead to weight loss and improved body composition. It has been recommended as a healthy and sustainable alternative strategy for increasing energy expenditure @van Marken Lichtenbelt Et Al..\nA core aspect of cold exposure is the activation of brown adipose tissue (BAT). BAT is a type of fat tissue that is responsible for thermogenesis, or the production of heat. It is found in small amounts in adults, but is more abundant in children. It is also found in higher concentrations in people who are leaner. The activation of BAT is thought to be responsible for the increased energy expenditure that is observed after cold exposure @Huberman.\n\n\n\nA study published in the Journal of Applied Physiology found that cold exposure “induced a leukocytosis and granulocytosis, an increase in natural killer cell count and activity, and a rise in circulating levels of interleukin-6.” @Brenner Et Al.. In other words, this means that cold exposure increases the number of white blood cells, which are responsible for fighting infection, and increases the activity of natural killer cells, which are responsible for destroying cancer cells. It also increases the production of interleukin-6, which is a cytokine that plays a role in the immune response.\nA fundamental aspect of cold exposure therapy is the subconcious respiratory response by the sympathetic nervous system. Upon cold immersion, you may find your breathing rate to increase, and your breaths to deepen. It was traditionally believed that the sympathetic nervous system and immune system could not be voluntarily influenced.\nIn 2011, however, the “Ice Man” Wim Hof participated in a study wherein he was injected with endotoxin, a treated form of E coli bacteria which triggers the same immune response. The study produced groundbreaking results, claiming that through the use of Hof’s breathing technique, he voluntarily and significantly increased his immune system response to the bacteria and completely avoided the flu-like symptoms displayed by healthy participants within the control group. In an attempt to discover if this result was reproducable or an anomoly of Wim Hof himself, a study published in the National Library of Medicine in 2014 replicated the methods with individuals who were trained on the breathing technique prior to the injection. It was again found that the breathing technique resulted in an immediate and profound decrease of pCO2 and bicarbonate, and an increase in pH, indicating acute respiratory alkalosis, which normalized quickly after cessation of the breathing techniques. In laymans terms, this means that humans could, through the use of breathing techniques, voluntarily increase immune system activity.\n\n\n\nCold exposure has been shown to increase the production of endorphins, such as dopmain, which are responsible for the “runner’s high” and other feelings of euphoria. It has also been shown to increase the production of serotonin, which is responsible for feelings of happiness and well-being. Increased dopamin release can last for as long as 6 hours after cold exposure, and increased serotonin release can last for as long as 24 hours after cold exposure @Ootsuka.\n\n\n\nCold water immersion has been reported to increase the level of T-cells (specifically, peripheral T lymphocytes). This has been observed both (1) in the short term after a single treatment/swim, as well as (2) in a longer, sustained manner after a period of multiple treatments per week.\nT-cells, also known as T lymphocytes, are a type of white blood cell that are derived from bone marrow stem cells and mature in the thymus gland. They play an essential role in fighting off infection. With an ability to “recognize” and “remember” germs that they have seen before, they can quickly respond if they see that germ again.\nIn other studies, similar increases have been observed for NK (Natural killer) cells. NK cell activity has been observed to increase both briefly after a treatment and in a sustained manner following consistent and repeated immersions.\nNatural killer (NK) cells are a type of white blood cell that can quickly recognize and destroy infected or cancerous cells without prior exposure or activation. NK cells do not require prior exposure to antigens, which are proteins or other molecules that can trigger an immune response. Instead, they use a variety of receptors to detect abnormal cells and then release toxic substances to kill them.\n\n\n\nAlthough the science is still developing, there is reason to believe cold water immersion may help prevent the risk of tumors and cancers.\nIn a study done on lab mice, a “somewhat reduced spontaneous incidence of tumors, especially sarcomas” was observed among the group of mice that endured repeated cold stress (cold swims). It has also been reported that Cold-inducible RNA binding protein (CIRP) may function as a tumor suppressor via suppressing proliferation. Finally, there’s been a clinical review performed by the National Institute of Health (NIH) exploring the cold’s ability to stimulate “anti-tumor immunity”, which concluded this area deserves “more research as a major target for cancer therapies.”\nWe look forward to the progression of this research.\n\n\n\nWestern biomedical research is gradually discovering the significance of the way in which we breathe, in relation to the body and its many physiological processes. Among these discoveries are how deliberate breathing techniques can 1. increase our tolerance to extremely cold environments and 2. alter immune function in real time.\nLet me highlight the significance of these discoveries: For centuries, modern (Western) medicine considered these processes (circulatory system, immune system, sympathetic nervous system) autonomic or involuntary, meaning they are unable to be controlled consciously. Recent research has slipped this understanding upside down - essentially, deliberate breathing practice is a superpower.\nThere is incredible research on breathing methods/techniques beyond the scope of this article, spanning brain function, enlightened & hallucinogenic states, mood/emotion control, and more. We encourage you to explore it if you’re interested, and we hope to come back to the topic in a future article/series.\nThe first groundbreaking study was done on Wim “The Ice Man” Hof, himself. In 2011, researchers at Radboud University injected Wim Hof with endotoxin, a treated form of bacteria that triggers a general immune response, as Wim practiced his breathing technique. The results were astounding:\n\n…levels of inflammatory mediators in Hof’s blood were much lower. On average, Hof’s immune response was decreased by 50 percent compared to other healthy volunteers. In addition, hardly any flu-like symptoms were observed.\n\nAt first, this study was a target of skepticism. With a sample size of 1, it was unclear whether the results were reproducible or simply Wim Hof producing an outlier result as an individual. However, it was enough to encourage further exploration.\nIn 2014, a study published in the National Library of Medicine sought out to reproduce the 2011 results in average “healthy participants”. The intervention group was trained for just 10 minutes in Hof’s breathing technique, and then both groups were administered with the endotoxin.\n\nIn the intervention group, practicing the learned techniques resulted in intermittent respiratory alkalosis and hypoxia resulting in profoundly increased plasma epinephrine levels. In the intervention group, plasma levels of the anti-inflammatory cytokine IL-10 increased more rapidly after endotoxin administration, correlated strongly with preceding epinephrine levels, and were higher. Levels of proinflammatory mediators TNF-α, IL-6, and IL-8 were lower in the intervention group and correlated negatively with IL-10 levels. Finally, flu-like symptoms were lower in the intervention group.\n\nIn summary, the results were successfully reproduced, and the researchers concluded that it is possible to voluntarily activate the sympathetic nervous system and affect immune response through deliberate breathing technique.\nHof’s breathing technique shook the biomedical science industry again in 2018, this time after he showed humans can consciously enhance their ability to survive in extremely cold conditions (beyond what was previously thought possible). The study concluded that deliberate breathing technique resulted in “increased sympathetic innervation and glucose consumption in intercostal muscle, generating heat that dissipates to lung tissue and warms circulating blood in the pulmonary capillaries.”\n\n\n\nThe optimal, and most studied, approach entails complete submersion in cold water from the neck down. To sit in water from the chest down, with arms outstretched, for instance, precludes full stimulation of the stress response mechanisms which yield many of the advantages discussed in the previous two sections of this series.\nLikewise, although cold showers have demonstrated efficacy, they have not been subjected to the same level of scrutiny as cold water immersion from the neck down. Therefore, it is reasonable to infer that the most optimal results may be obtained through full immersion in cold water. In the event that access to a cold bath is unattainable, cold showers serve as a reasonable alternative.\n\n\n\nThe short answer to this question is: uncomfortable but safe. Discomfort means that the beneficial stress hormones discussed in part 1 are being released in your system, thus offering the corresponding benefits.\nIf you are getting started, you may find that water temperatures around 45 degrees Fahrenheit is enough to feel uncomfortable. Over time, you are likely to find your cold immersion routine becomes easier. If you want to progress, and continue to extract maximum benefit, you must be honest with yourself to recognize whether you are pushing yourself, and increase intensity (decrease temperature) as appropriate.\n\n\n\nA study done by Scandinavian scientist Dr. Susanna Søeberg suggests the magic number is at least 11 minutes per week, total. This is the threshold needed to increase brown fat thermogenesis and metabolism. This could be done in various ways, such as spreading it out throughout the week or doing it all in one day.\n\n\n\nScience suggests that whether cold exposure is done in the morning or at night does not affect the health benefits discussed previously. However, I personally recommend doing your cold exposure first thing in the morning.\nThe reason why relates to internal body temperature and circadian rhythm. Your body is warm when it is awake, and cold when it is asleep. In fact, studies have shown your body temperature must decrease by 1.5 degrees in order to fall asleep.\nExposure to cold temperatures can cause your body to heat up afterwards, making it more difficult to fall asleep if done late at night. On the other hand, if performed early in the morning, cold exposure may boost your energy levels and start your day off on the right foot.\n\n\n\nThe Søeberg Principle, developed by Dr. Susana Søeberg, posits the following:\nTo enhance the metabolic effects of cold, force your body to reheat on its own\n\nEnd With Cold\n\nAdditionally, the act of shivering during or after cold exposure can further activate brown fat thermogenesis and release heat from muscles, resulting in heightened metabolic increases.\nTo increase shivering and optimize the metabolic benefits of cold exposure, individuals are advised to avoid huddling and wrapping their arms around themselves while in the cold or after exiting it. Likewise, entering a sauna after cold exposure, although relaxing, will limit the metabolic benefits of the cold.\nIf you want to go further, it is recommended to refrain from towel drying and instead allowing the body to naturally reheat and dry off. Admittedly, this is difficult, especially when it’s cold outside."
  },
  {
    "objectID": "library/life-sciences/health/cold-exposure.html#the-cold-hard-facts-part-1",
    "href": "library/life-sciences/health/cold-exposure.html#the-cold-hard-facts-part-1",
    "title": "Cold Exposure",
    "section": "The Cold Hard Facts, Part 1",
    "text": "The Cold Hard Facts, Part 1\nThe use of cold-water immersion has a long and rich history. The beneficial effects on human physiology have been recorded as far back as 3500BC @Wang Et Al., with the Edwin Smith Papyrus (the most ancient medical text known to date) making references to cold being used for therapeutic purposes. The Ancient Greeks utilized cold-water therapies, as recorded by Hippocrates in the fourth century BC. And even the Golden Age of Rome featured cold-water immersion as treatment for fever, advocated for by Roman Physician Claudius Galen in the second century AD @Allan Et Al.. It was only until recently, however, that modern science began to explore the underlying physiological processes behind the power of the cold.\n\nEnergy and Focus\nDeliberate cold exposure triggers a release of epinephrine (adrenaline) and norepinephrine (noradrenaline) into the bloodstream. These hormones are responsible for the fight-or-flight response, and can make us feel alert and/or agitated @Huberman. This is why many people feel more energized after a cold shower or a cold swim.\n\n\nMetabolism\nCold exposure has been shown to increase energy expenditure, which can lead to weight loss and improved body composition. It has been recommended as a healthy and sustainable alternative strategy for increasing energy expenditure @van Marken Lichtenbelt Et Al..\nA core aspect of cold exposure is the activation of brown adipose tissue (BAT). BAT is a type of fat tissue that is responsible for thermogenesis, or the production of heat. It is found in small amounts in adults, but is more abundant in children. It is also found in higher concentrations in people who are leaner. The activation of BAT is thought to be responsible for the increased energy expenditure that is observed after cold exposure @Huberman.\n\n\nImmune Health\nA study published in the Journal of Applied Physiology found that cold exposure “induced a leukocytosis and granulocytosis, an increase in natural killer cell count and activity, and a rise in circulating levels of interleukin-6.” @Brenner Et Al.. In other words, this means that cold exposure increases the number of white blood cells, which are responsible for fighting infection, and increases the activity of natural killer cells, which are responsible for destroying cancer cells. It also increases the production of interleukin-6, which is a cytokine that plays a role in the immune response.\nA fundamental aspect of cold exposure therapy is the subconcious respiratory response by the sympathetic nervous system. Upon cold immersion, you may find your breathing rate to increase, and your breaths to deepen. It was traditionally believed that the sympathetic nervous system and immune system could not be voluntarily influenced.\nIn 2011, however, the “Ice Man” Wim Hof participated in a study wherein he was injected with endotoxin, a treated form of E coli bacteria which triggers the same immune response. The study produced groundbreaking results, claiming that through the use of Hof’s breathing technique, he voluntarily and significantly increased his immune system response to the bacteria and completely avoided the flu-like symptoms displayed by healthy participants within the control group. In an attempt to discover if this result was reproducable or an anomoly of Wim Hof himself, a study published in the National Library of Medicine in 2014 replicated the methods with individuals who were trained on the breathing technique prior to the injection. It was again found that the breathing technique resulted in an immediate and profound decrease of pCO2 and bicarbonate, and an increase in pH, indicating acute respiratory alkalosis, which normalized quickly after cessation of the breathing techniques. In laymans terms, this means that humans could, through the use of breathing techniques, voluntarily increase immune system activity.\n\n\nMood\nCold exposure has been shown to increase the production of endorphins, such as dopmain, which are responsible for the “runner’s high” and other feelings of euphoria. It has also been shown to increase the production of serotonin, which is responsible for feelings of happiness and well-being. Increased dopamin release can last for as long as 6 hours after cold exposure, and increased serotonin release can last for as long as 24 hours after cold exposure @Ootsuka.\n\n\nCold Immersion, T-Cells, and NK Cells\nCold water immersion has been reported to increase the level of T-cells (specifically, peripheral T lymphocytes). This has been observed both (1) in the short term after a single treatment/swim, as well as (2) in a longer, sustained manner after a period of multiple treatments per week.\nT-cells, also known as T lymphocytes, are a type of white blood cell that are derived from bone marrow stem cells and mature in the thymus gland. They play an essential role in fighting off infection. With an ability to “recognize” and “remember” germs that they have seen before, they can quickly respond if they see that germ again.\nIn other studies, similar increases have been observed for NK (Natural killer) cells. NK cell activity has been observed to increase both briefly after a treatment and in a sustained manner following consistent and repeated immersions.\nNatural killer (NK) cells are a type of white blood cell that can quickly recognize and destroy infected or cancerous cells without prior exposure or activation. NK cells do not require prior exposure to antigens, which are proteins or other molecules that can trigger an immune response. Instead, they use a variety of receptors to detect abnormal cells and then release toxic substances to kill them.\n\n\nCold Immersion & Cancer\nAlthough the science is still developing, there is reason to believe cold water immersion may help prevent the risk of tumors and cancers.\nIn a study done on lab mice, a “somewhat reduced spontaneous incidence of tumors, especially sarcomas” was observed among the group of mice that endured repeated cold stress (cold swims). It has also been reported that Cold-inducible RNA binding protein (CIRP) may function as a tumor suppressor via suppressing proliferation. Finally, there’s been a clinical review performed by the National Institute of Health (NIH) exploring the cold’s ability to stimulate “anti-tumor immunity”, which concluded this area deserves “more research as a major target for cancer therapies.”\nWe look forward to the progression of this research.\n\n\nThe Role of the Breath\nWestern biomedical research is gradually discovering the significance of the way in which we breathe, in relation to the body and its many physiological processes. Among these discoveries are how deliberate breathing techniques can 1. increase our tolerance to extremely cold environments and 2. alter immune function in real time.\nLet me highlight the significance of these discoveries: For centuries, modern (Western) medicine considered these processes (circulatory system, immune system, sympathetic nervous system) autonomic or involuntary, meaning they are unable to be controlled consciously. Recent research has slipped this understanding upside down - essentially, deliberate breathing practice is a superpower.\nThere is incredible research on breathing methods/techniques beyond the scope of this article, spanning brain function, enlightened & hallucinogenic states, mood/emotion control, and more. We encourage you to explore it if you’re interested, and we hope to come back to the topic in a future article/series.\nThe first groundbreaking study was done on Wim “The Ice Man” Hof, himself. In 2011, researchers at Radboud University injected Wim Hof with endotoxin, a treated form of bacteria that triggers a general immune response, as Wim practiced his breathing technique. The results were astounding:\n\n…levels of inflammatory mediators in Hof’s blood were much lower. On average, Hof’s immune response was decreased by 50 percent compared to other healthy volunteers. In addition, hardly any flu-like symptoms were observed.\n\nAt first, this study was a target of skepticism. With a sample size of 1, it was unclear whether the results were reproducible or simply Wim Hof producing an outlier result as an individual. However, it was enough to encourage further exploration.\nIn 2014, a study published in the National Library of Medicine sought out to reproduce the 2011 results in average “healthy participants”. The intervention group was trained for just 10 minutes in Hof’s breathing technique, and then both groups were administered with the endotoxin.\n\nIn the intervention group, practicing the learned techniques resulted in intermittent respiratory alkalosis and hypoxia resulting in profoundly increased plasma epinephrine levels. In the intervention group, plasma levels of the anti-inflammatory cytokine IL-10 increased more rapidly after endotoxin administration, correlated strongly with preceding epinephrine levels, and were higher. Levels of proinflammatory mediators TNF-α, IL-6, and IL-8 were lower in the intervention group and correlated negatively with IL-10 levels. Finally, flu-like symptoms were lower in the intervention group.\n\nIn summary, the results were successfully reproduced, and the researchers concluded that it is possible to voluntarily activate the sympathetic nervous system and affect immune response through deliberate breathing technique.\nHof’s breathing technique shook the biomedical science industry again in 2018, this time after he showed humans can consciously enhance their ability to survive in extremely cold conditions (beyond what was previously thought possible). The study concluded that deliberate breathing technique resulted in “increased sympathetic innervation and glucose consumption in intercostal muscle, generating heat that dissipates to lung tissue and warms circulating blood in the pulmonary capillaries.”\n\n\nMethod\nThe optimal, and most studied, approach entails complete submersion in cold water from the neck down. To sit in water from the chest down, with arms outstretched, for instance, precludes full stimulation of the stress response mechanisms which yield many of the advantages discussed in the previous two sections of this series.\nLikewise, although cold showers have demonstrated efficacy, they have not been subjected to the same level of scrutiny as cold water immersion from the neck down. Therefore, it is reasonable to infer that the most optimal results may be obtained through full immersion in cold water. In the event that access to a cold bath is unattainable, cold showers serve as a reasonable alternative.\n\n\nHow Cold is “Cold”?\nThe short answer to this question is: uncomfortable but safe. Discomfort means that the beneficial stress hormones discussed in part 1 are being released in your system, thus offering the corresponding benefits.\nIf you are getting started, you may find that water temperatures around 45 degrees Fahrenheit is enough to feel uncomfortable. Over time, you are likely to find your cold immersion routine becomes easier. If you want to progress, and continue to extract maximum benefit, you must be honest with yourself to recognize whether you are pushing yourself, and increase intensity (decrease temperature) as appropriate.\n\n\nHow Often/Long Should I be Cold?\nA study done by Scandinavian scientist Dr. Susanna Søeberg suggests the magic number is at least 11 minutes per week, total. This is the threshold needed to increase brown fat thermogenesis and metabolism. This could be done in various ways, such as spreading it out throughout the week or doing it all in one day.\n\n\nWhen Should I Get Cold?\nScience suggests that whether cold exposure is done in the morning or at night does not affect the health benefits discussed previously. However, I personally recommend doing your cold exposure first thing in the morning.\nThe reason why relates to internal body temperature and circadian rhythm. Your body is warm when it is awake, and cold when it is asleep. In fact, studies have shown your body temperature must decrease by 1.5 degrees in order to fall asleep.\nExposure to cold temperatures can cause your body to heat up afterwards, making it more difficult to fall asleep if done late at night. On the other hand, if performed early in the morning, cold exposure may boost your energy levels and start your day off on the right foot.\n\n\nThe Søeberg Principle\nThe Søeberg Principle, developed by Dr. Susana Søeberg, posits the following:\nTo enhance the metabolic effects of cold, force your body to reheat on its own\n\nEnd With Cold\n\nAdditionally, the act of shivering during or after cold exposure can further activate brown fat thermogenesis and release heat from muscles, resulting in heightened metabolic increases.\nTo increase shivering and optimize the metabolic benefits of cold exposure, individuals are advised to avoid huddling and wrapping their arms around themselves while in the cold or after exiting it. Likewise, entering a sauna after cold exposure, although relaxing, will limit the metabolic benefits of the cold.\nIf you want to go further, it is recommended to refrain from towel drying and instead allowing the body to naturally reheat and dry off. Admittedly, this is difficult, especially when it’s cold outside."
  },
  {
    "objectID": "library/life-sciences/health/cold-exposure.html#the-cold-hard-facts",
    "href": "library/life-sciences/health/cold-exposure.html#the-cold-hard-facts",
    "title": "Cold Exposure",
    "section": "The Cold Hard Facts",
    "text": "The Cold Hard Facts\nThe use of cold-water immersion has a long and rich history. The beneficial effects on human physiology have been recorded as far back as 3500BC @Wang Et Al., with the Edwin Smith Papyrus (the most ancient medical text known to date) making references to cold being used for therapeutic purposes. The Ancient Greeks utilized cold-water therapies, as recorded by Hippocrates in the fourth century BC. And even the Golden Age of Rome featured cold-water immersion as treatment for fever, advocated for by Roman Physician Claudius Galen in the second century AD @Allan Et Al.. It was only until recently, however, that modern science began to explore the underlying physiological processes behind the power of the cold.\n\nEnergy and Focus\nDeliberate cold exposure triggers a release of epinephrine (adrenaline) and norepinephrine (noradrenaline) into the bloodstream. These hormones are responsible for the fight-or-flight response, and can make us feel alert and/or agitated @Huberman. This is why many people feel more energized after a cold shower or a cold swim.\n\n\nMetabolism\nCold exposure has been shown to increase energy expenditure, which can lead to weight loss and improved body composition. It has been recommended as a healthy and sustainable alternative strategy for increasing energy expenditure @van Marken Lichtenbelt Et Al..\nA core aspect of cold exposure is the activation of brown adipose tissue (BAT). BAT is a type of fat tissue that is responsible for thermogenesis, or the production of heat. It is found in small amounts in adults, but is more abundant in children. It is also found in higher concentrations in people who are leaner. The activation of BAT is thought to be responsible for the increased energy expenditure that is observed after cold exposure @Huberman.\n\n\nImmune Health\nA study published in the Journal of Applied Physiology found that cold exposure “induced a leukocytosis and granulocytosis, an increase in natural killer cell count and activity, and a rise in circulating levels of interleukin-6.” @Brenner Et Al.. In other words, this means that cold exposure increases the number of white blood cells, which are responsible for fighting infection, and increases the activity of natural killer cells, which are responsible for destroying cancer cells. It also increases the production of interleukin-6, which is a cytokine that plays a role in the immune response.\nA fundamental aspect of cold exposure therapy is the subconcious respiratory response by the sympathetic nervous system. Upon cold immersion, you may find your breathing rate to increase, and your breaths to deepen. It was traditionally believed that the sympathetic nervous system and immune system could not be voluntarily influenced.\nIn 2011, however, the “Ice Man” Wim Hof participated in a study wherein he was injected with endotoxin, a treated form of E coli bacteria which triggers the same immune response. The study produced groundbreaking results, claiming that through the use of Hof’s breathing technique, he voluntarily and significantly increased his immune system response to the bacteria and completely avoided the flu-like symptoms displayed by healthy participants within the control group. In an attempt to discover if this result was reproducable or an anomoly of Wim Hof himself, a study published in the National Library of Medicine in 2014 replicated the methods with individuals who were trained on the breathing technique prior to the injection. It was again found that the breathing technique resulted in an immediate and profound decrease of pCO2 and bicarbonate, and an increase in pH, indicating acute respiratory alkalosis, which normalized quickly after cessation of the breathing techniques. In laymans terms, this means that humans could, through the use of breathing techniques, voluntarily increase immune system activity.\n\n\nMood\nCold exposure has been shown to increase the production of endorphins, such as dopmain, which are responsible for the “runner’s high” and other feelings of euphoria. It has also been shown to increase the production of serotonin, which is responsible for feelings of happiness and well-being. Increased dopamin release can last for as long as 6 hours after cold exposure, and increased serotonin release can last for as long as 24 hours after cold exposure @Ootsuka.\n\n\nCold Immersion, T-Cells, and NK Cells\nCold water immersion has been reported to increase the level of T-cells (specifically, peripheral T lymphocytes). This has been observed both (1) in the short term after a single treatment/swim, as well as (2) in a longer, sustained manner after a period of multiple treatments per week.\nT-cells, also known as T lymphocytes, are a type of white blood cell that are derived from bone marrow stem cells and mature in the thymus gland. They play an essential role in fighting off infection. With an ability to “recognize” and “remember” germs that they have seen before, they can quickly respond if they see that germ again.\nIn other studies, similar increases have been observed for NK (Natural killer) cells. NK cell activity has been observed to increase both briefly after a treatment and in a sustained manner following consistent and repeated immersions.\nNatural killer (NK) cells are a type of white blood cell that can quickly recognize and destroy infected or cancerous cells without prior exposure or activation. NK cells do not require prior exposure to antigens, which are proteins or other molecules that can trigger an immune response. Instead, they use a variety of receptors to detect abnormal cells and then release toxic substances to kill them.\n\n\nCold Immersion & Cancer\nAlthough the science is still developing, there is reason to believe cold water immersion may help prevent the risk of tumors and cancers.\nIn a study done on lab mice, a “somewhat reduced spontaneous incidence of tumors, especially sarcomas” was observed among the group of mice that endured repeated cold stress (cold swims). It has also been reported that Cold-inducible RNA binding protein (CIRP) may function as a tumor suppressor via suppressing proliferation. Finally, there’s been a clinical review performed by the National Institute of Health (NIH) exploring the cold’s ability to stimulate “anti-tumor immunity”, which concluded this area deserves “more research as a major target for cancer therapies.”\nWe look forward to the progression of this research.\n\n\nThe Role of the Breath\nWestern biomedical research is gradually discovering the significance of the way in which we breathe, in relation to the body and its many physiological processes. Among these discoveries are how deliberate breathing techniques can 1. increase our tolerance to extremely cold environments and 2. alter immune function in real time.\nLet me highlight the significance of these discoveries: For centuries, modern (Western) medicine considered these processes (circulatory system, immune system, sympathetic nervous system) autonomic or involuntary, meaning they are unable to be controlled consciously. Recent research has slipped this understanding upside down - essentially, deliberate breathing practice is a superpower.\nThere is incredible research on breathing methods/techniques beyond the scope of this article, spanning brain function, enlightened & hallucinogenic states, mood/emotion control, and more. We encourage you to explore it if you’re interested, and we hope to come back to the topic in a future article/series.\nThe first groundbreaking study was done on Wim “The Ice Man” Hof, himself. In 2011, researchers at Radboud University injected Wim Hof with endotoxin, a treated form of bacteria that triggers a general immune response, as Wim practiced his breathing technique. The results were astounding:\n\n…levels of inflammatory mediators in Hof’s blood were much lower. On average, Hof’s immune response was decreased by 50 percent compared to other healthy volunteers. In addition, hardly any flu-like symptoms were observed.\n\nAt first, this study was a target of skepticism. With a sample size of 1, it was unclear whether the results were reproducible or simply Wim Hof producing an outlier result as an individual. However, it was enough to encourage further exploration.\nIn 2014, a study published in the National Library of Medicine sought out to reproduce the 2011 results in average “healthy participants”. The intervention group was trained for just 10 minutes in Hof’s breathing technique, and then both groups were administered with the endotoxin.\n\nIn the intervention group, practicing the learned techniques resulted in intermittent respiratory alkalosis and hypoxia resulting in profoundly increased plasma epinephrine levels. In the intervention group, plasma levels of the anti-inflammatory cytokine IL-10 increased more rapidly after endotoxin administration, correlated strongly with preceding epinephrine levels, and were higher. Levels of proinflammatory mediators TNF-α, IL-6, and IL-8 were lower in the intervention group and correlated negatively with IL-10 levels. Finally, flu-like symptoms were lower in the intervention group.\n\nIn summary, the results were successfully reproduced, and the researchers concluded that it is possible to voluntarily activate the sympathetic nervous system and affect immune response through deliberate breathing technique.\nHof’s breathing technique shook the biomedical science industry again in 2018, this time after he showed humans can consciously enhance their ability to survive in extremely cold conditions (beyond what was previously thought possible). The study concluded that deliberate breathing technique resulted in “increased sympathetic innervation and glucose consumption in intercostal muscle, generating heat that dissipates to lung tissue and warms circulating blood in the pulmonary capillaries.”\n\n\nMethod\nThe optimal, and most studied, approach entails complete submersion in cold water from the neck down. To sit in water from the chest down, with arms outstretched, for instance, precludes full stimulation of the stress response mechanisms which yield many of the advantages discussed in the previous two sections of this series.\nLikewise, although cold showers have demonstrated efficacy, they have not been subjected to the same level of scrutiny as cold water immersion from the neck down. Therefore, it is reasonable to infer that the most optimal results may be obtained through full immersion in cold water. In the event that access to a cold bath is unattainable, cold showers serve as a reasonable alternative.\n\n\nHow Cold is “Cold”?\nThe short answer to this question is: uncomfortable but safe. Discomfort means that the beneficial stress hormones discussed in part 1 are being released in your system, thus offering the corresponding benefits.\nIf you are getting started, you may find that water temperatures around 45 degrees Fahrenheit is enough to feel uncomfortable. Over time, you are likely to find your cold immersion routine becomes easier. If you want to progress, and continue to extract maximum benefit, you must be honest with yourself to recognize whether you are pushing yourself, and increase intensity (decrease temperature) as appropriate.\n\n\nHow Often/Long Should I be Cold?\nA study done by Scandinavian scientist Dr. Susanna Søeberg suggests the magic number is at least 11 minutes per week, total. This is the threshold needed to increase brown fat thermogenesis and metabolism. This could be done in various ways, such as spreading it out throughout the week or doing it all in one day.\n\n\nWhen Should I Get Cold?\nScience suggests that whether cold exposure is done in the morning or at night does not affect the health benefits discussed previously. However, I personally recommend doing your cold exposure first thing in the morning.\nThe reason why relates to internal body temperature and circadian rhythm. Your body is warm when it is awake, and cold when it is asleep. In fact, studies have shown your body temperature must decrease by 1.5 degrees in order to fall asleep.\nExposure to cold temperatures can cause your body to heat up afterwards, making it more difficult to fall asleep if done late at night. On the other hand, if performed early in the morning, cold exposure may boost your energy levels and start your day off on the right foot.\n\n\nThe Søeberg Principle\nThe Søeberg Principle, developed by Dr. Susana Søeberg, posits the following:\nTo enhance the metabolic effects of cold, force your body to reheat on its own\n\nEnd With Cold\n\nAdditionally, the act of shivering during or after cold exposure can further activate brown fat thermogenesis and release heat from muscles, resulting in heightened metabolic increases.\nTo increase shivering and optimize the metabolic benefits of cold exposure, individuals are advised to avoid huddling and wrapping their arms around themselves while in the cold or after exiting it. Likewise, entering a sauna after cold exposure, although relaxing, will limit the metabolic benefits of the cold.\nIf you want to go further, it is recommended to refrain from towel drying and instead allowing the body to naturally reheat and dry off. Admittedly, this is difficult, especially when it’s cold outside."
  },
  {
    "objectID": "library/life-sciences/health/cognition/index.html#resources",
    "href": "library/life-sciences/health/cognition/index.html#resources",
    "title": "Cognition",
    "section": "",
    "text": "Chimera states in brain networks: empirical neural vs. modular fractal connectivity\nNeurological Activity of Lion’s Mane (Hericium erinaceus)\n\n\n\nOlfactory enrichment (aroma therapy) at night produces improvements in both cognitive and neural functioning.\n\nOvernight olfactory enrichment using an odorant diffuser improves memory and modifies the uncinate fasciculus in older adults\n\nResults: A statistically significant 226% improvement was observed in the enriched group compared to the control group on the Rey Auditory Verbal Learning Test and improved functioning was observed in the left uncinate fasciculus, as assessed by mean diffusivity.\nConclusion: Minimal olfactory enrichment administered at night produces improvements in both cognitive and neural functioning. Thus, olfactory enrichment may provide an effective and low-effort pathway to improved brain health."
  },
  {
    "objectID": "library/life-sciences/health/nutrition/nutrition.html",
    "href": "library/life-sciences/health/nutrition/nutrition.html",
    "title": "Nutrition",
    "section": "",
    "text": "Magnesium Dificiency\nGreen Tea Nutrient\nOregano Oil, Natural Antibiotic\nNeurological Activity of Lion’s Mane (Hericium erinaceus)"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/nutrition.html#general",
    "href": "library/life-sciences/health/nutrition/nutrition.html#general",
    "title": "Nutrition",
    "section": "",
    "text": "Magnesium Dificiency\nGreen Tea Nutrient\nOregano Oil, Natural Antibiotic\nNeurological Activity of Lion’s Mane (Hericium erinaceus)"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/nutrition.html#seed-oils",
    "href": "library/life-sciences/health/nutrition/nutrition.html#seed-oils",
    "title": "Nutrition",
    "section": "Seed Oils",
    "text": "Seed Oils\n\nSeed Oil\nLinoleic Acid is very high in Seed Oils\nSoybean oil lowers circulating cholesterol levels and coronary heart disease risk, and has no effect on markers of inflammation and oxidation\nHealth risk assessment of As and Zn in canola and soybean oils consumed in Kermanshah, Iran\nHistory of Seed Oils\nChanges in Consumption of Omega-3 and Omega-6 Fatty Acids in US 20th Century\nSoybean Oil\nSoybean Oil x Autism\nSoybean Oil has a ton of Linoleic Acid"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/nutrition.html#portabello-mushrooms",
    "href": "library/life-sciences/health/nutrition/nutrition.html#portabello-mushrooms",
    "title": "Nutrition",
    "section": "Portabello Mushrooms",
    "text": "Portabello Mushrooms\nConsumption of the Agaricus species mushrooms has increased considerably in Japan as the Japanese have become accustomed to Western cooking. The Agaricus species mushroom contains hydrazine derivatives known as Agaritine.\n\nRisks\n\nFrom Paul Stamets\n\nPortabellos have a problem. All mushrooms should be cooked, and portabellos, in particular, should be cooked at high temperatures.\n\n\nThere is an unfortunate group of compounds called agaritines. Agaritines are hydrazines that are heat unstable, so the good news is, you should cook them, and if you cook them well, then those mushrooms are not a problem. If you don’t cook them well, then these hydrazines are potentially problematic.\n\n\nNow, nature’s a numbers game: so, there are beneficial compounds, that, in some balance, may outweigh the negative effects of the hydrazines, the agaratines in these mushrooms, but that jury is still out so to speak.\n\n\n\nAcademic Papers\nAgaritine from Agaricus blazei Murrill induces apoptosis in the leukemic cell line U937 - paper Summary - Agaritine, a compound found in the medicinal mushroom Agaricus blazei Murrill, induces apoptosis (programmed cell death) in the leukemic cell line U937. - Agaritine treatment caused a dose-dependent increase in apoptosis in U937 cells, as measured by the release of cytochrome c from mitochondria and the activation of caspases. - Agaritine also induced the expression of pro-apoptotic proteins, such as Bax and Fas, and inhibited the expression of anti-apoptotic proteins, such as Bcl-2. - These findings suggest that agaritine may have potential as a therapeutic agent for the treatment of leukemia.\n\nAgaritine treatment caused a significant increase in the number of apoptotic cells in U937 cultures, as measured by flow cytometry.\nAgaritine also induced the characteristic morphological changes of apoptosis, such as nuclear condensation and fragmentation.\nWestern blot analysis showed that agaritine treatment increased the expression of Bax and Fas, and decreased the expression of Bcl-2.\nThese findings suggest that agaritine may trigger apoptosis in U937 cells by activating caspases and upregulating pro-apoptotic proteins. The authors of the paper concluded that agaritine may have potential as a therapeutic agent for the treatment of leukemia. However, further studies are needed to confirm these findings and to determine the optimal dose and schedule of agaritine treatment.\n\nQuantities of agaritine in mushrooms (Agaricus bisporus) and the carcinogenicity of mushroom methanol extracts on the mouse bladder epithelium - paper Summary - Agaritine is a carcinogenic compound found in mushrooms, including Agaricus bisporus (white button mushrooms). - The authors of the paper measured the levels of agaritine in Agaricus bisporus mushrooms and found that the levels varied depending on the growing conditions. - The authors also found that methanol extracts of Agaricus bisporus mushrooms were carcinogenic to the mouse bladder epithelium. - These findings suggest that agaritine may be a risk factor for bladder cancer in humans.\n\nThe authors measured the levels of agaritine in Agaricus bisporus mushrooms grown in different conditions, including open fields, greenhouses, and dark rooms.\nThe levels of agaritine were highest in mushrooms grown in dark rooms, followed by mushrooms grown in greenhouses, and then mushrooms grown in open fields.\nThe authors also found that methanol extracts of Agaricus bisporus mushrooms were carcinogenic to the mouse bladder epithelium.\nThis was determined by the induction of tumors in the mouse bladder after treatment with the methanol extracts. The authors concluded that agaritine may be a risk factor for bladder cancer in humans.\n\nSynthetic and Naturally Occurring Hydrazines as Possible Cancer Causative Agents - paper Summary - Hydrazines are a class of compounds that have been shown to be carcinogenic in animals. - Several synthetic hydrazines have been shown to cause cancer in humans, including 1,2-diethylhydrazine, 1,2-dinitrohydrazine, and 1,2-dibromohydrazine. Hydrazines are also found naturally in some foods, including mushrooms, tobacco, and fish. - There is some evidence that naturally occurring hydrazines may also be carcinogenic, but more research is needed to confirm this. - The authors of the paper conclude that hydrazines are a potential risk factor for cancer, and that further research is needed to determine the extent of this risk.\n\nThe authors reviewed the literature on hydrazines and cancer, and identified 19 synthetic hydrazines that have been shown to be carcinogenic in animals.\nThe authors also identified several naturally occurring hydrazines that have been found in foods, including agaritine, gyromitrin, and BMAA.\nThe authors concluded that hydrazines are a potential risk factor for cancer, and that further research is needed to determine the extent of this risk. It is important to note that this paper was published in 1975, and there has been some research on hydrazines and cancer since then. However, the authors’ conclusions are still valid, and further research is still needed to determine the extent of the risk of cancer from hydrazines.\n\nGenotoxicity of agaritine in the lacI transgenic mouse mutation assay: evaluation of the health risk of mushroom consumption - paper - Google Bard would not summarize this paper as it did for every other one (???) - TAKE A DEEPER LOOK &gt; Using a previously derived quantitative correlation between mutagenicity in the lacI test and carcinogenic potency, the carcinogenicity of agaritine in mushrooms was estimated: the average Swiss mushroom consumption of 4 g/day would be expected to contribute a lifetime cumulative cancer risk of about two cases per 100,000 lives.\nAttempted tumor induction with agaritine in mice. - paper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/evm/index.html#tools",
    "href": "library/natural-sciences/crypto/blockchains/evm/index.html#tools",
    "title": "EVM",
    "section": "",
    "text": "Solidity Decompiler (interface)\nHeimdall-rs an advanced EVM smart contract toolkit specializing in bytecode analysis\nWhatsABI\ngo-selfcompile"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/ethena/ethena.html#tweet-thread",
    "href": "library/natural-sciences/crypto/apps/ethena/ethena.html#tweet-thread",
    "title": "Ethena Labs",
    "section": "",
    "text": "Some thoughts on @ethena_labs and the attempt towards a stablecoin, $USDe, independent of the traditional banking system. https://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\nQuick Overview of the Basic Mechanism\n\n1 $USDe is backed by a $1 delta neutral ETH position. - Long $1 of stETH spot - Short $1 of ETH perpetual futures swap contracts (on a centralized exchange, with the spot stETH as cross-collateral).\nFor a more substantial overview, check out @cryptohayes (Ethena advisor) “Dust on Crust” https://blog.bitmex.com/dust-on-crust/\n\nA note the scale of this endeavor (relevant later).\n\nEthena is pursuing a trillion dollar TAM.\n\nStablecoin circulating supply sits comfortably above $100 billion (throughout the bear market).\nTether printed over $1 billion in profit last quarter.\nThe CBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n\nOn the surface, there’s two obvious/primary risks to the mechanism.\n\nCounterparty (exchange) Risk\nBasis (funding rate) Risk\n\n\nHow, and to what extent, is Ethena mitigating these?\n\nAddressing Counterparty Risk\n\nWhether its an external hack (Mt Gox) or insider theft (FTX) - CEX risk is certainly non-negligible. What’s the risk-adjusted rate at which you would park 8+ figures on Binance, or Deribit? This is a serious question that crypto firms (HFT shops, VC firms) decide internally…\nIn other words, if Binance were a public company, where would their credit default swaps trade?\nCounter to what @cryptohayes initially described in his early writings, Ethena must avoid custodying the assets at the exchanges. Instead, park the assets with a secure third party (Fireblocks, Ledger, Copper), form agreements with the exchanges to accept this (likely some form of ZK-Proof of stETH asset balance) as collateral, and simply settle funding payments on the derivatives intermittently.\nThis doesn’t exactly eliminate all counterparty risk (can expand on this in the future), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\n\nAddressing Basis Risk\n\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\nFounder @leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n\nI will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\n\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n\nHowever, I subscribe to two principles which may complicate this assumption.\n\nThe Observer Effect: The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\n\nConsidering the scale of the stablecoin market, it’s naive to neglect the reflexivity of the relationship between Ethena’s operations/supply and the aggregate ETH perp funding rate.\nThe in-sample backtest shown in the previous tweet simulates yield on $5b circulating $USDe supply. What’s not mentioned, however, is that $USDe would have represented roughly half of aggregate ETH open interest… the backtest is inherently flawed.\n\n\n\n\nAlthough it’s important to point out weakness of the backtest, this doesn’t necessarily suggest a point of failure for $USDe.\n\nThe design is fundamentally different from the UST-esque algostables, which were always necessarily destined to collapse. In fact, if Ethena’s mint & redemption process is both free and (near) instant, the $USDe mechanism can be inherently self-correcting.\nLet’s imagine the $USDe supply was $5b today, Ethena would represent nearly half of the $10b ETH perp open interest, and the funding rate would likely be negative (exact threshold for % of OI Ethena can be comfortable with is unclear, but 50% is probably unhealthy).\nWith transparent metrics on curculating supply, assets, liabilities, and distribution (what % of the shorts are on BitMex vs Bybit vs …), the market can observe collateral fluctuations, and react rationally. Users swap out of $USDe on Curve, which is purchased by market makers/arbitrageurs who then redeem with Ethena. This lifts the short pressure until the funding rate (or net yield, including stETH) is positive again.\n\nThere is certainly much more to be discussed.\n\n\nWhat can be done to further mitigate exchange risk, even if it’s only relevant to the short derivative leg?\nWhere will the “natural funding rate” converge with this mechanism implemented at scale?\nWhat role does the insurance fund play, and how shall it be sized/scaled optimally?\nCan the “internet bond” effectively offer an inversely correlated yield to bonds (think crypto OI/perp funding in bullish, low-rate environment vs high-rate)?\n\nBut I’ll end the thread here for now.\nThe @ethena_labs team is legit, and it’s clear they are continuing to diligence the relevant considerations. A bankless stablecoin is a pivotal instrument for the cryptoeconomy, and I look forward to further public engagement as this develops. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/ethena/ethena.html#thread-draft-old",
    "href": "library/natural-sciences/crypto/apps/ethena/ethena.html#thread-draft-old",
    "title": "Ethena Labs",
    "section": "Thread Draft OLD",
    "text": "Thread Draft OLD\n\nSome thoughts on @ethena_labs and $USDe, an attempt towards a stablecoin which is independent of the traditional banking system.\n\nhttps://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\n2/ First, a quick mid-bell summary of USDe mechanism\n\nAlice deposits $1 worth of some asset (USDC, WBTC, doesn’t matter)\nEthena swaps this for $1 worth of stETH, which is then used as cross-collateral for a $1 notional ETH perp short on some CEX\nEthena mints 1 $USDe to Alice, backed by the delta-neutral $1 position\n\nFor a more substantial overview, check out @cryptohayes “Dust on Crust” (which Ethena cites as inspiration)\nhttps://blog.bitmex.com/dust-on-crust/\n3/ Let me note the scale of this endeavor (relevant later).\n\nStablecoin circulating supply sits comfortably above $100 billion throughout the bear market.\nTether printed over $1 billion in profit last quarter.\nCBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\nEthena is pursuing is a trillion dollar TAM.\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n4/ Okay, so there’s two obvious/primary risks to the $USDe mechanism\n\nCounterparty (CEX) Risk\nBasis Risk\n\nHow is Ethena addressing these?\n5/ Addressing Counterparty Risk\nWhether its an external hack (Mt Gox) or insider theft (FTX) doesn’t matter - CEX risk is real. How much would you have to get paid to park your funds at Binance? 30%? 80%? This is a real question that CEX HFT shops and crypto VCs decide internally - the consensus is almost certainly above $USDe’s expected yield.\nThe only proper mitigation I see is to avoid custodying assets at the exchanges. Park the stETH in Fireblocks, Ledger, etc. and make special agreements with Binance, Bybit, Bitmex, etc. to accept this (likely some form of ZK-Proof of stETH asset claim) as collateral, and simply settle funding payments intermittently.\nThis doesn’t exactly eliminate all counterparty risk (still an operational nightmare/panic if Binance goes FTX mode), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\nTODO: Mention the black swan force exit short perps too (the BitMex event)? - Ethena redemption should have scaled down exposure in the hours and minutes prior to this event (funding will necessarily have been negative before the trigger) - Ethena is hedged across multiple CEXes (historically this happens on one exchange at a time) - Ethena insurance fund as final backstop\n6/ Addressing Basis Risk\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\n@leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n7/ I will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n8/ However, I subscribe to two schools of thought which may challenge this assumption.\n\nQuantum Mechanics (the observer effect): The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\nKeeping in mind the scale of the stablecoin market, it’s naive to neglect the reflexivity bwteen Ethena’s operations and the ETH perp funding rate. The backtested yield in the previous tweet is under the assumption of $5b circulating $USDe supply - I predict this in-sample backtesting wil. This implies a $5b short OI, which is sustantial considering aggregate OI seen historically.\nThe image below shows Binance alone, but including Bybit, Bitmex, Derbit, and OKEx, total OI on ETH perpetual swaps is ~$TODO. Ethena would represent TODO% of ETH perp OI across all major exchanges.\n\n\n\nFix Up - not final\n9/ The question becomes: In the scenario wherein $USDe is widely adopted, what is the “natural funding rate” of ETH perps? Here’s a thesis:\nThe introduction of ETH staking, and liquid staking derivatives, effectively increased the baseline ETH lending rate (ETH’s LIBOR/SOFR) by the network’s staking yield. Why would anyone lend ETH at 80bps, when they can deposit for an LSD and earn 5% (where they can also then lend the LSD for 80bps)?\nThe “natural funding rate” baseline (not including the upwards skew cause by net bullish payment for leverage, which will remain a factor) on ETH perps will no longer necessarily == risk-free rate, as traditionally assumed for non-interest accruing assets (BTC, Gold, etc.). Instead, it will begin to additionally reflect the yield of ETH staking (risk-free rate - expected stETH yield). {{\n\n\n\n}}\n10/ Explain the logic - how other traders will arb funding rate considering availability of stETH as collateral. Why would this suggest a negative bias ~= eth yield.\nFin/ The team behind Ethena is legit. To their credit, it seems they are continuing to diligence this concern. This is a pivotal mechanism for the crypto economy, and I look forward to the exploration that is to come. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20\nTODO: Mention the black swan force exit short perps too (the BitMex event)? - Ethena redemption should have scaled down exposure in the hours and minutes prior to this event (funding will necessarily have been negative before the trigger) - Ethena is hedged across multiple CEXes (historically this happens on one exchange at a time) - Ethena insurance fund as final backstop"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#transaction-versions",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#transaction-versions",
    "title": "Bitcoin",
    "section": "Transaction Versions",
    "text": "Transaction Versions\nBitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#ordinals",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#ordinals",
    "title": "Bitcoin",
    "section": "Ordinals",
    "text": "Ordinals\nHow to Split Ordinals Mixed in a Single UTXO - article\nSplitting Bitcoin from Inscriptions on Ordinals Wallet - article"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#tech-stuff",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#tech-stuff",
    "title": "Bitcoin",
    "section": "Tech Stuff",
    "text": "Tech Stuff\n# create ordinal wallet\nord wallet create\n\n# receive sats\nord wallet receive\n\n# create inscription\nord wallet inscribe --fee-rate 22 &lt;FILE&gt;\n\nIssues\nTransport error upon inscription attempt here\nInscriptions taking too long here\nIndexing not working here\nHow much does an inscription cost? - calculator"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#guides",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#guides",
    "title": "Bitcoin",
    "section": "Guides",
    "text": "Guides\n\nHow to create\nHow to buy\nMinting Ordinals"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#btc-naming-service",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#btc-naming-service",
    "title": "Bitcoin",
    "section": "BTC Naming Service",
    "text": "BTC Naming Service\nCasey Rodarmor’s Thoughts: 26:00 min mark - here\n\nLook up top level domain (com)\nFind the output its in, and get address of the output\nGet authenticated encrypted channel with the person that owns that\nAsk “who has ‘myname.com’?” and they send you signed message of the pubkey, and then you get IP address. But no good names exist yet.\n\n\nThings I’ve Learned on the Ordinals Journey\nBitcoin has several address formats.\n\nLegacy Addresses\nScript Addresses\nSegwit Addresses\nTaproot Addresses\n\nOrdinals uses Taproot Addresses, which result from a recent upgrade aimed to introduce more reobust security, privacy, and scalability."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#other-stuff",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#other-stuff",
    "title": "Bitcoin",
    "section": "Other Stuff",
    "text": "Other Stuff\nWhat is it?\n\nanswered here\n\nResources\n\nHandbook\nGithub\nBIP\nMainnet Explorer\nTestnet (Signet) Explorer\nGuide\nNo Code Mint Platform\n\nCool Info\nOn August 21st, 2012, Charlie Lee posted a proposal to add proof-of-stake to Bitcoin to the Bitcoin Talk forum. This wasn’t an asset scheme, but did use the ordinal algorithm, and was implemented but never deployed.\nOn October 8th, 2012, jl2012 posted a scheme to the the same forum which uses decimal notation and has all the important properties of ordinals. The scheme was discussed but never implemented.\nGud Video\n\nyoutube\ninterview\n\nMultimint - video"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#mint-an-nft",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#mint-an-nft",
    "title": "Bitcoin",
    "section": "Mint an NFT",
    "text": "Mint an NFT\n# inscribe\nord wallet inscribe --fee-rate 20 ABSOLUTE_FILE_PATH"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#test",
    "href": "library/natural-sciences/crypto/blockchains/bitcoin/index.html#test",
    "title": "Bitcoin",
    "section": "TEST",
    "text": "TEST\nI inscribed an image of Logan Tobias onto the Bitcoin blockchain.\n$ ord wallet inscribe --fee-rate 20 /home/ubuntu/server-share/logan_resized.jpeg \n{\n  \"commit\": \"93f5630a6f6eb49235fb25878df06563f509ff5d5d89da6a4092af5d68eb4afd\",\n  \"inscription\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8i0\",\n  \"reveal\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8\",\n  \"fees\": 282600\n}\nSat: 465805240538644\n\nOrdinal Project\nThis is a short guide on how to mint multiple ordinals quickly.\n\nCreate a Sparrow wallet to generate multiple UTXOs.\nCalculate cost per ordinal.\n\n\ncalculator\nmempool Add 600 (dust limit) + 10,000 (ordinal fee) to sats amount\n\nWe have: 132,000 sats per ordinal + 600 + 10,000 = 142,600 sats per ordinal"
  },
  {
    "objectID": "library/life-sciences/health/physiology/index.html#transgender-procedures",
    "href": "library/life-sciences/health/physiology/index.html#transgender-procedures",
    "title": "Physiology",
    "section": "Transgender Procedures",
    "text": "Transgender Procedures\nThrown to the Wolves\n\nA physician reveals the nightmare of transgender ideology in a major children’s hospital.\n\nThe blog post is an interview with an anonymous physician who works in a major children’s hospital in a liberal city. The physician discusses his concerns about the rise of transgender interventions in children and the potential harm they can cause. He criticizes the medical community for adopting transgender ideology without sufficient scientific evidence and for suppressing dissenting views. He also expresses concern about the use of puberty blockers and hormone treatments in children, arguing that these interventions can have irreversible effects and may not be in the best interest of the child.\nNotes\n\nTransgender Interventions in Children: The physician criticizes the increasing use of transgender interventions in children, including puberty blockers and hormone treatments. He argues that these interventions are being adopted without sufficient scientific evidence and can have irreversible effects.\nMedical Community and Transgender Ideology: The physician criticizes the medical community for adopting transgender ideology and suppressing dissenting views. He argues that many in the medical community are afraid to question transgender ideology for fear of professional repercussions.\nPuberty Blockers and Hormone Treatments: The physician expresses concern about the use of puberty blockers and hormone treatments in children. He argues that these interventions can have irreversible effects, including permanent changes to the child’s sexual organs and hormone balance.\nSuicide Risk: The physician challenges the argument that transgender interventions are necessary to prevent suicide in transgender individuals. He suggests that affirming a child’s transgender identity may actually contribute to self-hatred and suicidal ideation.\nFuture of Transgender Medicine: The physician is uncertain about the future of transgender medicine. He hopes for a change in the current approach, which he believes is harmful to children.\nRole of Psychiatrists, Psychologists, Doctors, Politicians, and Media: The physician criticizes these groups for promoting transgender interventions in children. He argues that they have convinced children and their parents that these interventions are the correct response to gender dysphoria, despite the potential harm they can cause.\nConclusion: The physician argues that the current approach to transgender interventions in children is harmful and not in the best interest of the child. He calls for a more cautious approach that takes into account the potential irreversible effects of these interventions."
  },
  {
    "objectID": "writes/posts/blockchain-privacy/index.html",
    "href": "writes/posts/blockchain-privacy/index.html",
    "title": "Blockchain != Privacy",
    "section": "",
    "text": "Pseudonymity converges to identifiability."
  },
  {
    "objectID": "writes/posts/blockchain-privacy/index.html#introduction",
    "href": "writes/posts/blockchain-privacy/index.html#introduction",
    "title": "Blockchain != Privacy",
    "section": "Introduction",
    "text": "Introduction\nThere exists a common misconception that privacy is an inherent feature to blockchain protocols. Below, I explain how current blockchain implementations do not guarantee privacy. In fact, today’s blockchain protocols introduce an unprecedented ability for the powerful to surveil the weak."
  },
  {
    "objectID": "writes/posts/blockchain-privacy/index.html#cypherpunks",
    "href": "writes/posts/blockchain-privacy/index.html#cypherpunks",
    "title": "Blockchain != Privacy",
    "section": "Cypherpunks",
    "text": "Cypherpunks\nThe commonality of this misconception may be explained, at least in part, by the founding culture associated with blockchain technology. Blockchain technology emerged in the late 20th century from several key innovations in the field of cryptography, the same field from which the manifestation of informational privacy (encryption), was pioneered.\nThe Cypherpunks were a group of cryptographic enthusiasts who advocated for the use of cryptography and similar methods as ways to achieve societal and political change. Founded in the early 1990s, the movement has been most active during the 1990s “cryptowars” and following the 2011 internet spring. The Cypherpunks forecasted the coming age of digital information, and saw cryptography as a means of preserving fundamental individual rights, such privacy and self-sovereignty. Members of this group include Roger Dingledine, co-founder of the Tor Project, Julian Assange, founder of Wikileaks, and perhaps most notably, Satoshi Nakamoto, the pseudonymous creator of Bitcoin.\nMany of the protocols, algorithms, and applications developed by the Cypherpunks were centered around privacy. Bitcoin was not."
  },
  {
    "objectID": "writes/posts/blockchain-privacy/index.html#the-genesis-case-study-bitcoin",
    "href": "writes/posts/blockchain-privacy/index.html#the-genesis-case-study-bitcoin",
    "title": "Blockchain != Privacy",
    "section": "The Genesis Case Study, Bitcoin",
    "text": "The Genesis Case Study, Bitcoin\n\nPseudonymity != Anonymity\nIn October of 2008, an email from Satoshi Nakamoto was sent to the cypherpunk email list, titled “Bitcoin P2P e-cash paper”.\nParticipation in the Bitcoin network only requires a public/private keypair (ECDSA for Version 1). There is no support for “accounts” or “profiles” which include other metadata, such as name, email, address, etc. Thus, the Bitcoin network is inherently pseudonymous, where the pseudonyms are Bitcoin addresses (smaller hashed versions of the public key). On the Bitcoin network, all transactions are published to and stored on the public ledger (this allows for Bitcoin’s distributed consensus), making intra-network forensics trivial. I.e. it is trivial to retreive the entire financial history of 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa, and verifiably gather information on all transactions involving this address, neighboring addresses, etc.\nStill, it remains theoretically possible to use Bitcoin anonymously. A Bitcoin user may rely on proper operational security (OpSec) techniques to ensure his/her Bitcoin pseudonym remains entirely disjunct from his/her “real” or government identity. In the early days of Bitcoin, the majority of participants did successfully maintain anonymity through proper OpSec - accessing the network through VPNs, public WiFi hotspots, remote SSH tunneling, etc.\nOne factor contributing to the early success of anonymity was the fact that the earliest users of Bitcoin were often well-versed in digital OpSec. Early users generated and custodied their keypairs on a local and/or secure machine because they were familiar with ECDSA encryption, and they executed Bitcoin payments under anonymous identities on secure e-commerce platforms, accessed through secure dark-web browsers, like Tor.\nAnother factor contributing to Bitcoin’s early privacy, however, is that the technology remained siloed in it’s earliest years, segregated from regulated financial infrastructure, and “under the radar” of intelligence organizations. For example, the creator and operator of one of the most prolific darknet Bitcoin marketplaces, the Silk Road, was identified and arrested in 2013, after just two years of successfully maintaining anonymity through pseudonymity.\nThe key realization here is that Bitcoin offers a permissionless and censorship-resistant method of transacting value - nothing else. In order to protect one’s identity in the applications of Bitcoin, one must rely on the other components of the technology stack to provide the privacy guarantees to maintain anonymity. Any if any single OpSec mistake were to be made, everything about the user’s pseudonym could be revealed.\nThe consequences of Bitcoin’s intra-network transparency were difficult to identify in its early life - Bitcoin seemed privacy-preserving. Fast-forward 13 years, however, and the ability to surveil couldn’t be more clear.\nAccording to recent reports, approximately 46 million Americans (~22% of US population) own some form of Bitcoin. Out of this, it’s estimated that at least 8/10 purchased and/or hold their Bitcoin through a KYC’d account on a custodied platform, such as Coinbase, Crypto[dot]com, or Robinhood. From this alone, the Bitcoin-specific financial information off nearly all US persons (not just the ones with KYC’d accounts) is effectively public. These entities are obligated to release Customer data if provoked on legal grounds, and sophisticated players can retreive this information even in the case Coinbase were to remain non-compliant.\nThe Bitcoin protocol, when integrated with 3rd party KYC applications (as it is today and will be throughout the foreseeable future), is a near-perfect protocol for financial surveillance."
  },
  {
    "objectID": "writes/posts/blockchain-privacy/index.html#turing-complete-blockchains",
    "href": "writes/posts/blockchain-privacy/index.html#turing-complete-blockchains",
    "title": "Blockchain != Privacy",
    "section": "Turing-Complete Blockchains",
    "text": "Turing-Complete Blockchains\n\nTuring-Complete Computation + Weak Privacy = Infinite Surveillance\nIn the section above, I have only discussed the (lack of) privacy offered by Bitcoin - I have not argued for whether these facts are “good” or “bad”. Perhaps this was all part of Satoshi’s grand vision, and it is ethically optimal for financial settlement infrastructure to offer complete transparency. I will continue to avoid the question of good or bad as it pertains to Bitcoin, because I, myself, am not certain in my stance.\nWhen the question extends to Turing-Complete networks, however, I have enough convinction to argue that zero-privacy guarantees are suboptimal.\nIn 2014, a novel smart contract based, Turing-Complete blockchain protocol called Ethereum was introduced. Ethereum allowed for arbitrary code executions, enabling application development beyond just the transfer of the native asset. Over the past several years, there has been an explosion of Ethereum application development. From domain name services to gaming/social apps, these applications span beyond just payments - logging data, provoking external program executions, developing on-chain reputation/identity, and establishing organizational structures of accounts.\n\nPower tends to corrupt; absolute power corrupts absolutely\n\nJust like Bitcoin, all data associated with Ethereum transactions, by default, are stored on the public ledger in plaintext for anyone to view. With countless “decentralized” profile-based applications, the connection between an on-chain pseudonym and corresponding government identity is increasingly inevitable. Additionally, every action, transaction, and application interaction performed on Ethereum further develops the user’s on-chain reputation, permanently documented on Ethereum’s immutable global ledger. Even if the goal was not to maintain a distinction between on-chain and “real” identities, a lack of privacy for the on-chain identity inevitably approaches a lack of privacy in real life.\n\nCalling an Uber\nBuying an engagement ring (or organizing a surprise party)\nAny healthcare-related activites\n\nUpon meditating on the consequences of an extension of this paradigm, one may encounter a seemingly endless array of dystopian scenarios."
  },
  {
    "objectID": "writes/posts/blockchain-privacy/index.html#conclusion",
    "href": "writes/posts/blockchain-privacy/index.html#conclusion",
    "title": "Blockchain != Privacy",
    "section": "Conclusion",
    "text": "Conclusion\nAs Vitalik Buterin voiced, the “Holy Grail” blockchain technology would allow users to benefit from the security of a blockchain, using a decentralized network to process the transactions, but “encrypting” the data in such a way that even though everything is being computed in plain sight, the underlying “meaning” of the information is completely obfuscated.\nToday’s blockchains lack privacy because distributed consensus mechanisms rely on the verifiability of blockchain data, which currently requires plaintext data. There exist exciting fields of cryptographic research in pursuit of solving this issue - my personal favorites are Zero Knowledge Proofs (ZKPs) and Fully Homomorphic Encryption (FHE).\nHowever, the integration of privacy-enabling primitives is time-sensitive. Deferring essential features to later appensions to the technology often results in weaker guarantees of the respective features. Additionally, as societal adoption increases over time, the community is more likely to become distanced from the ethos from which the technology was birthed.\n\nFrom my earliest days I had a passion for science. But science, the exercise of the supreme power of the human intellect, was always linked in my mind with benefit to people. I saw science as being in harmony with humanity. I did not imagine that the second half of my life would be spent on efforts to avert a mortal danger to humanity created by science.\n\nI hope the topic of privacy remains at the forefront of blockchain research. We must actively ensure that the innovation of distributed computing serves to benefit society: for this is not guaranteed."
  },
  {
    "objectID": "writes/posts/money-rome/index.html",
    "href": "writes/posts/money-rome/index.html",
    "title": "Money in Ancient Rome",
    "section": "",
    "text": "Learnings from the history of money.\n\nContext\nBy the 6th century B.C., Western money standards began to converge around the use of stamped metal coins. One of the earliest dominant currencies was the Athenian silver tetradrachm, which gained dominance over the gold/silver coins issued by Persia and other western empires of the time. Aside from the economic success and naval hegemony of ancient Athens, factors contributing to the currency’s success were large circulating supply, fine quality, and unchanging appearance. Nevertheless, the “dominance” of Athenian money was limited, as dozens of currencies remained in use in local circulation.\n\n\nThe Rise of Rome, and the Globalization of Money\nFollowing the rise of the Roman Empire, the introduction of the Roman silver denarius around 211 B.C. marked a turning point in Western money. The denarius effectively fixed the previously-fluctuating relationship between silver and bronze, with one silver denarius (containing ~4.5g of silver) exchangeable for 10 bronze asses, (the as was a bronze coin of the time). Gold was used less frequently, until Julius Ceasar standardized the gold aureus (8g of gold) to 25 denarii. The success of Roman imperialism expanded adoption of the aureus/denarius/as standard farther than any currency prior. Rome effectively established the (Western) globalization of hard money.\nThese currencies and their respective exchange rates remained impressively stable through the turmoil caused by the assassination of Julius Ceasar in 44 B.C. Many historians credit the strength of Roman money as a crucial foundation for the 200-year golden age of Rome, known as the Pax Romana, which lasted from 27 B.C. to 170 A.D.\n\n\nCoin Clipping: The Beginning of the End\nAround the middle of the Pax Romana, however, Emperor Nero made a monetary decision that, in retrospect, appears to mark the beginning of the end of Roman economic prowess. When faced with increasing government expenditures, Emperor Nero became the first to engage in what is known as coin clipping: the emperor would recall the coins then mint them into a new coin with a lower metallic content but with the same face value. This is currency debasement - it marked the introduction of government-induced inflation in Rome.\nIt’s important to note that currency debasement proved to be successful in the short term. The decision to begin coin clipping may be responsible for successfully extending the period of Roman peace, as over the reign of the next several Emperors, economic prosperity and peace continued as inflation remained below half a percent.\nOver the next two hundred years, however, it became clear that the temporary relief provided by currency debasement (coin clipping) would eventually demand further debasement. Rome was permanently prohibited from returning to a non-inflationary economy, and thus engaged in a vicious cycle:\ncurrency debasement → price increases → price controls → further debasement\nIn the long run, coin clipping only increased the magnitude of the problems Emperor Nero set to solve. This cycle ravaged Rome through centuries of political and economic instability, until Constantine managed to restore stability through significant monetary reform.\n\n\nHard Money to the Rescue… Too Late\nConstantine issued the gold solidus in 312 A.D. at a weight of 4.55 grams, permanently replacing the aureus. The solidus was worth 275,000 debased denarii, which now contained ~5% silver, down from the original 95%.\nConstantine required the fixed weight of the solidus, without debasement, which finally established Roman economic stability.\nThe recovery of the Roman economy came too late, as continuing foreign invasions led to the collapse of the Western Roman Empire. However, the gold solidus was so successful that it remained the currency of the Byzantine Empire (Eastern Rome) centuries after the fall of the Western Empire. To this day, the gold solidus remains a candidate for the most successful currency in the history of the world.\n\n\nSources\n\nInflation Under the Roman Empire\nMoney and Prices in the Ancient Roman Empire\nMoney and Exchange in the Roman World\nThe Monetary Systems of the Roman Empire from Diocletian to Theodosius I\nRome: A Thousand Years of Monetary History"
  },
  {
    "objectID": "writes/posts/money-rome/index.html#context",
    "href": "writes/posts/money-rome/index.html#context",
    "title": "Money in Ancient Rome",
    "section": "",
    "text": "By the 6th century B.C., Western money standards began to converge around the use of stamped metal coins. One of the earliest dominant currencies was the Athenian silver tetradrachm, which gained dominance over the gold/silver coins issued by Persia and other western empires of the time. Aside from the economic success and naval hegemony of ancient Athens, factors contributing to the currency’s success were large circulating supply, fine quality, and unchanging appearance. Nevertheless, the “dominance” of Athenian money was limited, as dozens of currencies remained in use in local circulation."
  },
  {
    "objectID": "writes/posts/money-rome/index.html#the-rise-of-rome-and-the-globalization-of-money",
    "href": "writes/posts/money-rome/index.html#the-rise-of-rome-and-the-globalization-of-money",
    "title": "Money in Ancient Rome",
    "section": "The Rise of Rome, and the Globalization of Money",
    "text": "The Rise of Rome, and the Globalization of Money\nFollowing the rise of the Roman Empire, the introduction of the Roman silver denarius around 211 B.C. marked a turning point in Western money. The denarius effectively fixed the previously-fluctuating relationship between silver and bronze, with one silver denarius (containing ~4.5g of silver) exchangeable for 10 bronze asses, (the as was a bronze coin of the time). Gold was used less frequently, until Julius Ceasar standardized the gold aureus (8g of gold) to 25 denarii. The success of Roman imperialism expanded adoption of the aureus/denarius/as standard farther than any currency prior. Rome effectively established the (Western) globalization of hard money.\nThese currencies and their respective exchange rates remained impressively stable through the turmoil caused by the assassination of Julius Ceasar in 44 B.C. Many historians credit the strength of Roman money as a crucial foundation for the 200-year golden age of Rome, known as the Pax Romana, which lasted from 27 B.C. to 170 A.D."
  },
  {
    "objectID": "writes/posts/money-rome/index.html#coin-clipping-the-beginning-of-the-end",
    "href": "writes/posts/money-rome/index.html#coin-clipping-the-beginning-of-the-end",
    "title": "Money in Ancient Rome",
    "section": "Coin Clipping: The Beginning of the End",
    "text": "Coin Clipping: The Beginning of the End\nAround the middle of the Pax Romana, however, Emperor Nero made a monetary decision that, in retrospect, appears to mark the beginning of the end of Roman economic prowess. When faced with increasing government expenditures, Emperor Nero became the first to engage in what is known as coin clipping: the emperor would recall the coins then mint them into a new coin with a lower metallic content but with the same face value. This is currency debasement - it marked the introduction of government-induced inflation in Rome.\nIt’s important to note that currency debasement proved to be successful in the short term. The decision to begin coin clipping may be responsible for successfully extending the period of Roman peace, as over the reign of the next several Emperors, economic prosperity and peace continued as inflation remained below half a percent.\nOver the next two hundred years, however, it became clear that the temporary relief provided by currency debasement (coin clipping) would eventually demand further debasement. Rome was permanently prohibited from returning to a non-inflationary economy, and thus engaged in a vicious cycle:\ncurrency debasement → price increases → price controls → further debasement\nIn the long run, coin clipping only increased the magnitude of the problems Emperor Nero set to solve. This cycle ravaged Rome through centuries of political and economic instability, until Constantine managed to restore stability through significant monetary reform."
  },
  {
    "objectID": "writes/posts/money-rome/index.html#hard-money-to-the-rescue-too-late",
    "href": "writes/posts/money-rome/index.html#hard-money-to-the-rescue-too-late",
    "title": "Money in Ancient Rome",
    "section": "Hard Money to the Rescue… Too Late",
    "text": "Hard Money to the Rescue… Too Late\nConstantine issued the gold solidus in 312 A.D. at a weight of 4.55 grams, permanently replacing the aureus. The solidus was worth 275,000 debased denarii, which now contained ~5% silver, down from the original 95%.\nConstantine required the fixed weight of the solidus, without debasement, which finally established Roman economic stability.\nThe recovery of the Roman economy came too late, as continuing foreign invasions led to the collapse of the Western Roman Empire. However, the gold solidus was so successful that it remained the currency of the Byzantine Empire (Eastern Rome) centuries after the fall of the Western Empire. To this day, the gold solidus remains a candidate for the most successful currency in the history of the world.\n\nSources\nInflation Under the Roman Empire\nMoney and Prices in the Ancient Roman Empire\nMoney and Exchange in the Roman World\nThe Monetary Systems of the Roman Empire from Diocletian to Theodosius I\nRome: A Thousand Years of Monetary History"
  },
  {
    "objectID": "library/social-sciences/geopolitics/ukraine/psyop.html",
    "href": "library/social-sciences/geopolitics/ukraine/psyop.html",
    "title": "Ukraine Psyop",
    "section": "",
    "text": "Below I will explain a controversial, perhaps “conspiracy”-like opinion, with which I do not necessarily support. At this point, I recognize I do not know enough about the situation to confidently and firmly stand behind a particular side. However, I believe a disregard of the below content at face value, without genuine thought, is objectively wrong. With that, I ask you read the below content with an open mind, regardless of the seeming absurdity of the claims."
  },
  {
    "objectID": "library/social-sciences/geopolitics/ukraine/psyop.html#thesis",
    "href": "library/social-sciences/geopolitics/ukraine/psyop.html#thesis",
    "title": "Ukraine Psyop",
    "section": "Thesis",
    "text": "Thesis\nThe Russia x Ukraine conflict is a military-grade, organized psyop by global elites.\n\nThe War in Iraq: A Comparison\nTo appreciate the ability of economic incentives to motivate psychological operations aimed towards international conflict, I would like to bring up the a case study: the War in Iraq. much like the false claims of weapons of mass destruction which led to the previously unpopular invasion of Iraq.\n\n\nWEF New World Order: A Global Pandemic, then International Conflict\nOn March 27, 2018, the NIH-EcoHealth Alliance submitted a proposal to DARPA, requesting $14,209,245 in funding for Project DEFUSE: Defusing the Threat of Bat-borne Coronaviruses.\nExcerpt from Executive Summary, Technical Approach 1\n\nWe will sequence their spike proteins, reverse engineer them to conduct binding assays, and insert them into bat SARSr-CoV (WIV1, SHC014) backbones (these use bat-SARSr-CoV backbones, not SARS-CoV, and are exempt from dual-use and gain of function concerns) to infect humanized mice and assess capacity to cause SARS-like disease.\n\nIn an email to a US Marine Corps Captain (unidentified), Major Joe Murphy of the Office of Naval Research outlined some concerns that arose after he “came across additional incriminating documents and produced an analysis shortly after leaving DARPA last month.”\nIn the email to his superior, Major Joe Murphy explained the following.\n\nI’m unsure whether the significance of what I communicated is understood by those that received the report. Decisions with regards to the vaccines do not appear to be informed by analysis of the documents. The main points being that SARS-CoV-2 matches the SARS vaccine variants the NIH-EcoHealth program was making in Wuhan; that the DOD rejected the program proposal because vaccines would be ineffective and because the spike proteins being inserted into the variants were deemed too dangerous (gain-of-function); and that the DOD now mandates vaccines that copy the spike protein previously deemed too dangerous. To me, and to those who informed my analysis, this situation meets no-go or abort criteria with regards to the vaccines until the toxicity of the spike protein can be investigated. There’s also information within the documents about which drugs effectively treat the program’s SARS-CoVs.\n\nMajor Joe Murphy was correct. On August 13, 2021, the Defense Advanced Research Projects Agency (DARPA) unclassified a document with subject: SARS-CoV-2 Origins Investigation With US Government Program Undisclosed Document Analysis.\nIn this document, the Commandant of the Marine Corps Fellow, DARPA, states the following.\nExcerpt from Page 1\n\nSARS-CoV-2 is an American-created recombinant bat vaccine, or its precursor virus. It was created by an EcoHealth Alliance program at the Wuhan Institute of Virology (WIV), as suggested by the reporting surrounding the lab leak hypothesis. The details of this program have been concealed since the pandemic began. These details can be found in the EcoHealth Alliance proposal response to the DARPA PREEMPT program Broad Agency Announcement (BAA) HR00118S0017, dqted March 2018 - a document not yet publicly disclosed.\n\nExcerpt from Page 2\n\nBecause of its (now) known nature, the SARs-CoV-WIV’s illness is readily resolved with early treatment that inhibits the viral replication that spreads the spike proteins around the body (which induce a harmful overactive immune response as the body tries to clear the spikes from the ACE2 receptors). Many of the early treatment protocols ignored by the authorities work because they inhibit viral replication or modulate the immune response to the spike proteins, which make sense within the context of what EcoHealth was creating. Some of these treatment protocols also inhibit the action of the engineered spike protein. For instance, Ivermectin (identified as curative April 2020) works throughout all phases of illness because it both inhibits viral replication and modulates the immune response. Of note, chloroqine phosphate (Hydroxychloroquine, identified April 2020 as curative) is identified in the proposal as a SARSr-CoV inhibitor, as is interferon (identified May 2020 as curative).\n\n\nThe gene-encoded, or “mRNA,” vaccines work poorly because they are synthetic replications of the already-synthetic SARSr-CoV-WIV spike proteins and posses no other epitopes. The mRNA instructs the cells to produce synthetic copies of the SARSr-CoV-WIV synthetic spike protein directly into the bloodstream, wherein they spread and produce the same ACE2 immun storm that the recombinant vaccine does.\n\n\nThe massive, “Manhattan-Project”-level of information suppression executed by the government and the Trusted News Initiative indicates that it would be covered-up if something bad happened. The lab-leak hypothesis and squabbling between Senator Paul and Dr. Fauci indicated that the cover up would be more disciplined in its paperwork. So I presumed that unclassified files would be concealed on a higher network and found them where I expected them to be. I understood what they were and their content, pushed the files off-site, and compiled this report.\n\n“\nThe proposal was rejected by the Department of Defense (DOD) in 2018 “because vaccines would be ineffective and because the spike proteins being inserted into the variants were deemed to dangerous (gain-of-function)…”\nIn November 2019, a Sars-COV-2 virus was identified just outside the Wuhan Institute of Virology. In 2018,\nBelow is an article wherein a member of the SPI-B, a subcomittee that advises the cientific Advisory Group for Emergencies (SAGE), admits a regret of the use of fear as a dystopian measure of population control.\nThe Telegraph 20210514 Use of fear to control behaviour in Covid crisis was ‘totalitarian’, admit scientists - Document PDF.pdf"
  },
  {
    "objectID": "writes/posts/on-ai/index.html",
    "href": "writes/posts/on-ai/index.html",
    "title": "On the Risks of AI",
    "section": "",
    "text": "There exist distinct risks related to AI. Each posing a different severity and relevant on a different timeline.\n\nBackground\nI’ve spent a some time meditating on this question. I have interacted with the industry as a consumer, as an investor, as a startup contributor, and as a (novice) developer. Most importantly, I’ve had fruitful discussions with, and have listened very carefully to, many people with more perspectives than I.\nThat’s not to say my views are necessarily important, or even correct - it’s just a bit of context. I remain open-minded, and I welcome discussion, counter-points, and new information…\nI see two main, distinct vectors of risk\n\nLoss of Human Dominance\nCentralization of Information Flow\n\n\n\nLoss of Human Dominance\nThe first and most focused on vector of risk is the danger of a(n) agent(s) which surpass(es) humans in intelligence & aptitude. This is the rogue AGI scenario. Humans have held the top spot for ~300,000 years, and no one is capable of predicting what would happen if/when that changes.\nThis is the vector addressed by “Pause Giant AI Experiments: An Open Letter”\nI believe this vector of risk is real, and it is tremendously dangerous.\n\nCybersecurity will become very tricky.\nMilitary applications will introduce existential threats\nDomestic use cases (surveillance, policing) will yield tremendous controversy\n\nIn my opinion, the day-to-day news stories/headlines draw too much attention and cause us to overestimate the short-term risks. Yet, the longer term horizon of this paradigm remain wildly under-appreciated. Regardless of the severity of this risk vector, a “pause” on AI will never happen.\nThis is an arms race.\n\n\nCentralization of Information Flow\nThe second vector of risk, which I believe is more relevant in the short-term, regards what’s being referred to as the “Moderation Layer”.\nThis risk is not about the AI agent itself. Rather, it concerns the humans & organizations that own these models and are responsible for regulating (or in the position to regulate) usage. Although discussion on the correct approach to regulation/moderation takes place, these often happen in the political realm, wherein a strictly two-dimensional tug-of-war stagnates.\nMain Question:\nWhat is the goal of the moderation layer, and why is it necessary?\n\n“To censor dangerous content”\n\nWhat exactly defines “dangerous”? Would a blanket definition of “dangerous” be acceptable? For example, allowing an AI explain how to enrich Uranium to a jihadist group can likely be considered dangerous. Allowing the AI to explain this to a group of PhD Chemical Engineers, on the other hand, is not as dangerous.\n\n“To censor offensive content”\n\nAll statements are offensive to some extent, so where exactly are we drawing the line? To what extent should we be tolerant in the name of free speech? “Offensive” is a spectrum - there is no statement that offends none. It becomes clear to ask, to what extent are we willing to restrict the freedom of thought to protect users from being offended?\n\n“To limit the spread of misinformation”\n\nI have an appreciation for the harm that AI can do with respect to proliferating false information. But if the past few years have taught us anything, it’s that “misinformation” is now synonymous with “I don’t like that information”.\n\nLarge language models (LLMs) like OpenAI’s GPT-4 are trained on billions of lines of text, extracted from the internet, from millions of (human) sources of various demographics, representing a vast array of perspectives.\nOpenAI’s moderation layer is built by less than 100 humans, nearly all of whom have a similar background and reside in Silicon Valley.\n\n“The political ideology of conversational AI”\n\n\nTo believe the latter is capable of mitigating the bias the former, in my humble opinion, is misled.\n\nSee GPT-4 System Card, the Appendix\n\nI am not claiming the former (the agent) is unbiased. LLMs are trained heavily on text from Reddit, for example, which has an overrepresentation of men than women. Further, as (almost) all training data is extracted from the internet, the information from which the AI model “learns” is inherently biased towards the digital world: internet users, citizens of first world countries, etc.\nMy current stance is that the moderation layer is necessary, but\n\nThe implementation details of the moderation layer must be transparent.\nGovernance of the moderation layer must be, to some extent, decentralized. At the very least, let us agree the power should not lie solely in the hands of 0.00000125% of the world’s population."
  },
  {
    "objectID": "library/life/deposit-cash.html#the-legality-of-wiring-money-for-cash",
    "href": "library/life/deposit-cash.html#the-legality-of-wiring-money-for-cash",
    "title": "Cash Management",
    "section": "",
    "text": "Generally, it is a crime to engage in virtually any type of financial transaction if a person conducted the transaction with knowledge that the funds were the proceeds of “criminal activity” and if the government can prove the proceeds were derived from a “specified unlawful activity”. Criminal activity can be a violation of any criminal law – federal, state, local, or foreign. Specified unlawful activities are set forth in the statute and include over 200 types of U.S. crimes, from drug trafficking, terrorism, and fraud, to crimes traditionally associated with organised crime, and certain foreign crimes, as discussed below in question 1.3.\nThe government does not need to prove that the person conducting the money laundering transaction knew that the proceeds were from a specified form of illegal activity.\nKnowledge can be based on wilful blindness or conscious indifference – failure to inquire when faced with red flags for illegal activity. Additionally, knowledge can be based on a government “sting” or subterfuge, where government agents represent that funds are the proceeds of illegal activity.\nUnder Section 1956, the transaction can be: (1) with the intent to promote the carrying on of the specified unlawful activity; (2) with the intent to engage in U.S. tax evasion or to file a false tax return; (3) knowing the transaction is in whole or in part to disguise the nature, location, source, ownership or control of the proceeds of a specified unlawful activity; or (4) with the intent to avoid a transaction reporting requirement under federal or state law.\nSection 1956 also criminalises the transportation or transmission of funds or monetary instruments (cash or negotiable instruments or securities in bearer form): (1) with the intent to promote the carrying out of a specific unlawful activity; or (2) knowing the funds or monetary instruments represent the proceeds of a specified unlawful activity and the transmission or transportation is designed in whole or in part to conceal or disguise the nature, location, source, ownership or control of the proceeds of the specified unlawful activity.\nUnder Section 1957, it is a crime to knowingly engage in a financial transaction in property derived from specified unlawful activity through a U.S. bank or other “financial institution”, or a foreign bank (in an amount greater than $10,000). Financial institution is broadly defined with reference to the Bank Secrecy Act (“BSA”) statutory definition of financial institution (31 U.S.C. § 5312(a)(2)), and includes not just banks but a wide range of other financial businesses, including securities broker-dealers, insurance companies, non-bank finance companies, and casinos."
  },
  {
    "objectID": "library/life/deposit-cash.html#what-to-do-with-a-lot-of-cash",
    "href": "library/life/deposit-cash.html#what-to-do-with-a-lot-of-cash",
    "title": "Cash Management",
    "section": "What to do with a lot of cash",
    "text": "What to do with a lot of cash\n\nThe ATM Approach\nStep 1 | Buy an ATM\nATM Global Phone: (877) 286-1755 https://atmglobal.net/ *We got permission from Douglas to use the call for this video.\nNational ATM Systems Phone: (803) 786-1900 https://www.nasatm.com/\nOcean ATM Phone: (877) 538-2860 https://oceanatm.com\nAmerica’s ATM Phone: (877) 475-1104 https://americanatm.com\nATM Money Machine Phone: (609) 641-7300 https://www.atmmoneymachine.com\nThese companies deliver a machine to your location (machines ~$2,500), and have installers come to set it up ($350 for installation). This takes about 2 weeks.\nPut it at a friends restaurant or something.\nStep 2 | Set it up\nAll ATMs must be connected to the processing server and have a power outlet. There are three optional connections: 1. Hardwire Internet Line 2. Phoneline 3. Purchase an ATM Wireless Box\nYou can not connect to wireless internet in the business, you must hardwire into the internet via an ethernet jack or run an ethernet cord from the modem to the ATM.\nStep 3 | Paperwork\nThen you fill out some forms with the ATM company (“Exhibit 2, Exhibit 3, W9”) that do basic background checks: if you have any fraud in your past, etc.\nThe paperwork will give you your own unique merchant ID, which allows you into the processing server. We handle getting this licensing done for you.\nConnect your account with them to a (business) bank account. The ATM company sets up an interface for you to monitor transactions, get notifications that the cash balance is low, etc."
  },
  {
    "objectID": "library/life-sciences/health/nutrition/index.html",
    "href": "library/life-sciences/health/nutrition/index.html",
    "title": "Nutrition",
    "section": "",
    "text": "Magnesium Dificiency\nGreen Tea Nutrient\nOregano Oil, Natural Antibiotic\nNeurological Activity of Lion’s Mane (Hericium erinaceus)"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/index.html#general",
    "href": "library/life-sciences/health/nutrition/index.html#general",
    "title": "Nutrition",
    "section": "",
    "text": "Magnesium Dificiency\nGreen Tea Nutrient\nOregano Oil, Natural Antibiotic\nNeurological Activity of Lion’s Mane (Hericium erinaceus)"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/index.html#seed-oils",
    "href": "library/life-sciences/health/nutrition/index.html#seed-oils",
    "title": "Nutrition",
    "section": "Seed Oils",
    "text": "Seed Oils\n\nSeed Oil\nLinoleic Acid is very high in Seed Oils\nSoybean oil lowers circulating cholesterol levels and coronary heart disease risk, and has no effect on markers of inflammation and oxidation\nHealth risk assessment of As and Zn in canola and soybean oils consumed in Kermanshah, Iran\nHistory of Seed Oils\nChanges in Consumption of Omega-3 and Omega-6 Fatty Acids in US 20th Century\nSoybean Oil\nSoybean Oil x Autism\nSoybean Oil has a ton of Linoleic Acid"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/index.html#portabello-mushrooms",
    "href": "library/life-sciences/health/nutrition/index.html#portabello-mushrooms",
    "title": "Nutrition",
    "section": "Portabello Mushrooms",
    "text": "Portabello Mushrooms\nConsumption of the Agaricus species mushrooms has increased considerably in Japan as the Japanese have become accustomed to Western cooking. The Agaricus species mushroom contains hydrazine derivatives known as Agaritine.\n\nRisks\n\nFrom Paul Stamets\n\nPortabellos have a problem. All mushrooms should be cooked, and portabellos, in particular, should be cooked at high temperatures.\n\n\nThere is an unfortunate group of compounds called agaritines. Agaritines are hydrazines that are heat unstable, so the good news is, you should cook them, and if you cook them well, then those mushrooms are not a problem. If you don’t cook them well, then these hydrazines are potentially problematic.\n\n\nNow, nature’s a numbers game: so, there are beneficial compounds, that, in some balance, may outweigh the negative effects of the hydrazines, the agaratines in these mushrooms, but that jury is still out so to speak.\n\n\n\n\nAcademic Papers\nAgaritine from Agaricus blazei Murrill induces apoptosis in the leukemic cell line U937\n\nAgaritine, a compound found in the medicinal mushroom Agaricus blazei Murrill, induces apoptosis (programmed cell death) in the leukemic cell line U937.\nAgaritine treatment caused a dose-dependent increase in apoptosis in U937 cells, as measured by the release of cytochrome c from mitochondria and the activation of caspases.\nAgaritine also induced the expression of pro-apoptotic proteins, such as Bax and Fas, and inhibited the expression of anti-apoptotic proteins, such as Bcl-2.\nThese findings suggest that agaritine may have potential as a therapeutic agent for the treatment of leukemia.\nAgaritine treatment caused a significant increase in the number of apoptotic cells in U937 cultures, as measured by flow cytometry.\nAgaritine also induced the characteristic morphological changes of apoptosis, such as nuclear condensation and fragmentation.\nWestern blot analysis showed that agaritine treatment increased the expression of Bax and Fas, and decreased the expression of Bcl-2.\nThese findings suggest that agaritine may trigger apoptosis in U937 cells by activating caspases and upregulating pro-apoptotic proteins.\nThe authors of the paper concluded that agaritine may have potential as a therapeutic agent for the treatment of leukemia. However, further studies are needed to confirm these findings and to determine the optimal dose and schedule of agaritine treatment.\n\nQuantities of agaritine in mushrooms (Agaricus bisporus) and the carcinogenicity of mushroom methanol extracts on the mouse bladder epithelium\n\nAgaritine is a carcinogenic compound found in mushrooms, including Agaricus bisporus (white button mushrooms).\nThe authors of the paper measured the levels of agaritine in Agaricus bisporus mushrooms and found that the levels varied depending on the growing conditions.\nThe authors also found that methanol extracts of Agaricus bisporus mushrooms were carcinogenic to the mouse bladder epithelium.\nThese findings suggest that agaritine may be a risk factor for bladder cancer in humans.\nThe authors measured the levels of agaritine in Agaricus bisporus mushrooms grown in different conditions, including open fields, greenhouses, and dark rooms.\nThe levels of agaritine were highest in mushrooms grown in dark rooms, followed by mushrooms grown in greenhouses, and then mushrooms grown in open fields.\nThe authors also found that methanol extracts of Agaricus bisporus mushrooms were carcinogenic to the mouse bladder epithelium.\nThis was determined by the induction of tumors in the mouse bladder after treatment with the methanol extracts. The authors concluded that agaritine may be a risk factor for bladder cancer in humans.\n\nSynthetic and Naturally Occurring Hydrazines as Possible Cancer Causative Agents\n\nHydrazines are a class of compounds that have been shown to be carcinogenic in animals.\nSeveral synthetic hydrazines have been shown to cause cancer in humans, including 1,2-diethylhydrazine, 1,2-dinitrohydrazine, and 1,2-dibromohydrazine. Hydrazines are also found naturally in some foods, including mushrooms, tobacco, and fish.\nThere is some evidence that naturally occurring hydrazines may also be carcinogenic, but more research is needed to confirm this.\nThe authors of the paper conclude that hydrazines are a potential risk factor for cancer, and that further research is needed to determine the extent of this risk.\nThe authors reviewed the literature on hydrazines and cancer, and identified 19 synthetic hydrazines that have been shown to be carcinogenic in animals.\nThe authors also identified several naturally occurring hydrazines that have been found in foods, including agaritine, gyromitrin, and BMAA.\nThe authors concluded that hydrazines are a potential risk factor for cancer, and that further research is needed to determine the extent of this risk. It is important to note that this paper was published in 1975, and there has been some research on hydrazines and cancer since then. However, the authors’ conclusions are still valid, and further research is still needed to determine the extent of the risk of cancer from hydrazines.\n\nGenotoxicity of agaritine in the lacI transgenic mouse mutation assay: evaluation of the health risk of mushroom consumption\n\nGoogle Bard would not summarize this paper as it did for every other one (???)\n\n\nUsing a previously derived quantitative correlation between mutagenicity in the lacI test and carcinogenic potency, the carcinogenicity of agaritine in mushrooms was estimated: the average Swiss mushroom consumption of 4 g/day would be expected to contribute a lifetime cumulative cancer risk of about two cases per 100,000 lives.\n\nAttempted tumor induction with agaritine in mice."
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#fractional-calculus",
    "href": "library/natural-sciences/maths/index.html#fractional-calculus",
    "title": "Maths",
    "section": "Fractional Calculus",
    "text": "Fractional Calculus\nWhat is Fractional Calculus\nDifferential calculus was invented independently by Isaac Newton and Gottfried Leibniz and it was understood that the notion of the derivative of nth order, that is, applying the differentiation operation n times in succession, was meaningful. In a 1695 letter, l’Hopital asked Leibniz about the possibility that n could be something other than an integer, such as n=1/2. Leibniz responded that “It will lead to a paradox, from which one day useful consequences will be drawn.” Leibniz was correct, but it would not be centuries until it became clear just how correct he was.\nThis article will investigate the question of what it could possibly mean to do something like take a 1/2 order derivative, and so introduce the theory of the fractional calculus.\nSummary\nThe blog post discusses the concept of fractional calculus, a mathematical field that explores the idea of derivatives and integrals of non-integer order. The concept was first proposed by Gottfried Leibniz in a response to a question from l’Hopital about the possibility of a derivative of order 1/2. The post explains the theory behind fractional calculus, its properties, and its applications, using the Riemann-Liouville integral and derivative as examples.\n\nFractional Calculus: Fractional calculus is the branch of mathematical analysis that investigates the possibility of taking derivatives and integrals of any real number order, not just integer order.\nIntuition: The concept of fractional calculus arises from the idea of interpreting differentiation and integration as transformations that continuously transform a function into its nth derivative or antiderivative.\nFractional Integral and Derivative: The most natural place to start with fractional calculus is with Cauchy’s formula for repeated integration. The generalization of the factorial function in this formula is the gamma function, which allows for the definition of the left Riemann-Liouville integral, a valid operator for integration to fractional order.\nDifferintegral Operator: The differintegral operator is a combination of the fractional integral and derivative, which can continuously transform between functions.\nProperties: Fractional calculus has unique properties, such as nonlocality, which means that the value of a fractional derivative at a point depends on an entire range of values, not just that point. This property makes fractional calculus useful for modeling physical phenomena with memory effects. Fractional Derivatives of Basic Functions: The fractional derivatives of power functions, sine function, and exponential function are discussed.\nInterpretation: The interpretation of fractional operators in a geometric or physical sense is still an area of active research. Applications: An example of the application of fractional calculus is in solving the tautochrone problem, which involves finding a curve such that the time taken by a bead to slide down the curve is independent of the initial height.\nConclusion: Fractional calculus is a result of pushing the boundaries of existing theories to work with extreme or unusual cases. It is a field with potential for new discoveries in mathematics and science."
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#summary-notes",
    "href": "library/natural-sciences/maths/index.html#summary-notes",
    "title": "Maths",
    "section": "Summary / Notes",
    "text": "Summary / Notes\nThe blog post discusses the concept of fractional calculus, a mathematical field that explores the idea of derivatives and integrals of non-integer order. The concept was first proposed by Gottfried Leibniz in a response to a question from l’Hopital about the possibility of a derivative of order 1/2. The post explains the theory behind fractional calculus, its properties, and its applications, using the Riemann-Liouville integral and derivative as examples.\nNotes:\n\nFractional Calculus: Fractional calculus is the branch of mathematical analysis that investigates the possibility of taking derivatives and integrals of any real number order, not just integer order.\nIntuition: The concept of fractional calculus arises from the idea of interpreting differentiation and integration as transformations that continuously transform a function into its nth derivative or antiderivative.\nFractional Integral and Derivative: The most natural place to start with fractional calculus is with Cauchy’s formula for repeated integration. The generalization of the factorial function in this formula is the gamma function, which allows for the definition of the left Riemann-Liouville integral, a valid operator for integration to fractional order.\nDifferintegral Operator: The differintegral operator is a combination of the fractional integral and derivative, which can continuously transform between functions.\nProperties: Fractional calculus has unique properties, such as nonlocality, which means that the value of a fractional derivative at a point depends on an entire range of values, not just that point. This property makes fractional calculus useful for modeling physical phenomena with memory effects. Fractional Derivatives of Basic Functions: The fractional derivatives of power functions, sine function, and exponential function are discussed.\nInterpretation: The interpretation of fractional operators in a geometric or physical sense is still an area of active research. Applications: An example of the application of fractional calculus is in solving the tautochrone problem, which involves finding a curve such that the time taken by a bead to slide down the curve is independent of the initial height.\nConclusion: Fractional calculus is a result of pushing the boundaries of existing theories to work with extreme or unusual cases. It is a field with potential for new discoveries in mathematics and science."
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#learn",
    "href": "library/natural-sciences/maths/index.html#learn",
    "title": "Maths",
    "section": "",
    "text": "UPenn Math 114 (Single Variable Calculus)\nMIT Single Variable Calculus\nMIT Multivariable Calculus\nUPenn Math 240 (Multi Variable Calculus)\nDifferential Equations Textbook\nMIT Differential Equations\nMIT OCW Probability and Random Variables\nMIT Linear Algebra\nMIT Topics in Mathematics with Applications in Finance\nPolyak-Łojasiewicz Inequality\n\nGeneralizes strong convexity, and a simple condition to ensure linear convergence of gradient descent even for non-convex functions.\n\nThe Prime Number Maze\nThe Matrix Cookbook\nAlgorithmic Game Theory\nErgodic Theory\nConvex Optimization\nOperations Research: Applications and Algorithms"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#fourier-transformations",
    "href": "library/natural-sciences/maths/index.html#fourier-transformations",
    "title": "Maths",
    "section": "Fourier Transformations",
    "text": "Fourier Transformations\nThe Fourier Transform is a mathematical technique that transforms a function of time, a signal, into a function of frequency. It’s a way to represent a signal in terms of its constituent frequencies, much like a musical chord can be expressed as the amplitudes of its constituent notes.\nThe Fourier Transform can be applied to a wide variety of fields, including physics, engineering, signal processing, image analysis, and data compression.\nFormally, for a continuous signal, the Fourier Transform F(w) of a function f(t) is given by the integral:\nF(w) = ∫ f(t) e^-iwt dt\nHere:\n\nw is the frequency,\nt is time,\ni is the imaginary unit,\ne is the base of the natural logarithm,\nand ∫ denotes integration over all time from -∞ to +∞.\n\nThe inverse Fourier Transform, which transforms back from the frequency domain to the time domain, is given by:\nf(t) = (1/2π) ∫ F(w) e^iwt dw\nNote that in practice, many signals are discrete rather than continuous, and the Discrete Fourier Transform (DFT) or its faster version, the Fast Fourier Transform (FFT), are used.\nThe Fourier Transform and its variants are used in a wide variety of applications. For example, in audio processing, it can be used to identify the different frequencies present in a sound. In image processing, it can be used for operations like blurring an image or removing noise. In physics, it can be used to solve differential equations."
  },
  {
    "objectID": "library/natural-sciences/software/ai/history-of-ai/history-of-ai.html#resources",
    "href": "library/natural-sciences/software/ai/history-of-ai/history-of-ai.html#resources",
    "title": "History of AI",
    "section": "",
    "text": "Timeline of AI\nHistory of Artificial Neural Networks\nDeep Learning History\n\n\n\nFrank Rosenblatt invented the perceptron, an algorithm for pattern recognition, which is essentially a single-layer neural network.\n\n\n\nShortly after, he went on to explore deeper, multilayer perceptrons. His MLPs had a non-learning first layer with randomized weights and an adaptive output layer. Although this was not yet deep learning, because only the last layer learned.\n\n\n\nSuccessful learning in deep feedforward network architectures started in 1965 in the Ukraine (back then the USSR) when Alexey Ivakhnenko & Valentin Lapa introduced the first general, working learning algorithms for deep MLPs with arbitrarily many hidden layers (already containing the now popular multiplicative gates). A paper of 1971 already described a deep learning net with 8 layers, trained by their highly cited method which was still popular in the new millennium, especially in Eastern Europe, where much of Machine Learning was born.\n\n\n\nIvakhnenko and Lapa (1965, see above) trained their deep networks layer by layer. In 1967, however, Shun-Ichi Amari suggested to train MLPs with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent, a method proposed in 1951 by Robbins & Monro.\nAmari’s implementation (with his student Saito) learned internal representations in a five layer MLP with two modifiable layers, which was trained to classify non-linearily separable pattern classes.\n\n\n\nKunihiko Fukushima introduced rectified linear units (ReLUs) for NNs (1969). They are now widely used in CNNs and other NNs.\n\n\n\nSeppo Linnainmaa was the first to publish what’s now known as backpropagation, the famous algorithm for credit assignment in networks of differentiable nodes, also known as “reverse mode of automatic differentiation.” It is now the foundation of widely used NN software packages such as PyTorch and Google’s Tensorflow.\n\n\n\nAmari published a paper on Amari-Hopfield networks, which resemble what’s now known as Recurrent Neural Networks (RNNs).\n\n\n\nComputer Vision was revolutionized in the 2010s by a particular feedforward NN called the convolutional NN (CNN). The basic CNN architecture with alternating convolutional and downsampling layers is due to Kunihiko Fukushima, 1979. He called it Neocognitron.\n\n\n\n\nThe Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project.\nThe UK began the £350 million Alvey project.\nDARPA founded the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n\n\n\nPhysicist John Hopfield was able to prove that a form of neural network (now called a “Hopfield net”) could learn and process information in a completely new way. This built on the Amari-Hopfield network from Amari’s 1972 publication\n\n\n\n\nGeoffrey Hinton “godfather of AI” invented the idea of multilayered neural networks, with nodes and weights. Node takes inputs and weights of inputs, outputs a signal if sum &gt; 0. - 1985 | A Learning Algorithm for Boltzmann Machines - 1986 | Learning representations by back-propagating errors\n\n\n\nDavid E. Rumelhart demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs. At least for supervised learning, backpropagation is generally more efficient than Amari’s above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier\nFeng-hsiung Hsu begins development on Chess-playing expert system called ChipTest. In 1988 it was moved to IBM and renamed Deep Thought, and then renamed again in 1989 to Deep Blue.\n\n\n\nGenerative Adversarial Networks (GANs) are first published in 1990 in Munich under the moniker Artificial Curiosity. Two dueling NNs (a probabilistic generator and a predictor) are trying to maximize each other’s loss in a minimax game. The generator (called the controller) generates probabilistic outputs (using stochastic units like in the much later StyleGANs). The predictor (called the world model) sees the outputs of the controller and predicts environmental reactions to them. Using gradient descent, the predictor NN minimizes its error, while the generator NN tries to make outputs that maximize this error: one net’s loss is the other net’s gain\n\n\n\nJiirgen Schmidhuber published a paper describing an alternative to RNNs: A feedforward NN slowly learns by gradient descent to program the changes of the fast weights of another NN. Such Fast Weight Programmers (FWPs) can learn to memorize past data, too. In 1991, one of them computed its fast weight changes through additive outer products of self-invented activation patterns (now often called keys and values for self-attention). The very similar Transformers combine this with projections and softmax and are now widely used in natural language processing. For long input sequences, their efficiency was improved through Transformers with linearized self-attention whose core is formally equivalent to the 1991 Fast Weight Programmers.\n\n\n\nSepp Hochreiter and Jurgen Schmidhuber published Long Short-Term Memory, the most cited NN paper of the 20th century. A later milestone was the “vanilla LSTM architecture” with forget gate — the LSTM variant of 1999-2000 that everybody is using today, e.g., in Google’s Tensorflow. Alex was lead author of our first successful application of LSTM to speech (2004). 2005 saw the first publication of LSTM with full backpropagation through time and of bi-directional LSTM (now widely used).\nAlso in 1997, Deep Blue beats Gary Kasparov in chess.\n\n\n\nImageNet is created, a large visual database envisioned by Fei-Fei Li from Stanford University, who realized that the best machine learning algorithms wouldn’t work well if the data didn’t reflect the real world. For many, ImageNet was the catalyst for the AI boom of the 21st century.\n\n\n\nX (formerly Google X) is an American semi-secret research and development facility and organization founded by Google in January 2010. X has its headquarters about a mile and a half from Alphabet’s corporate headquarters, the Googleplex, in Mountain View, California\nDeepMind was founded in the UK by Demis Hassabis, Shane Legg and Mustafa Suleyman in September 2010.\n\n\n\nThe Google Brain project began in 2011 as a part-time research collaboration between Google fellow Jeff Dean, Google Researcher Greg Corrado, and Stanford University professor Andrew Ng. Google Brain started as a Google X project and became so successful that it was graduated back to Google: Astro Teller has said that Google Brain paid for the entire cost of Google X.\n\n\n\nGeoffrey Hinton tests artificial deep neural network on a widely used image recogniztion test, called ImageNet. AlexNet was the program, scored 75% success, way better than competitors. This generates a ton of hype, and sparks more funding/research in AI, particularly image recognition.\n\n\n\nIn 2013, Geoffrey Hinton was acquihired by Google."
  },
  {
    "objectID": "library/natural-sciences/software/ai/history-of-ai/history-of-ai.html#the-start-of-the-race",
    "href": "library/natural-sciences/software/ai/history-of-ai/history-of-ai.html#the-start-of-the-race",
    "title": "History of AI",
    "section": "The Start of the Race",
    "text": "The Start of the Race\n\n2014: Attention, the Start of the Race\nThe attention mechanism is introduced, which would became the foundation for the Transformer.\n\n\n2015: OpenAI\nIn December 2015, Sam Altman, Greg Brockman, Reid Hoffman, Jessica Livingston, Peter Thiel, Elon Musk, Amazon Web Services (AWS), Infosys, and YC Research announced the formation of OpenAI and pledged over $1 billion to the venture.\nDecember 11, 2015 announcement by Greg Brockman and Ilya Sutskever.\n\n\n2016\n\nAlphaGo becomes supreme at Go\nGoogle Brain neural network learns secure encryption\n\nDecember 2016, OpenAI released “Universe”, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites, and other applications. Intended to be the reinforcement learning version of ImageNet.\n\n\n2017: Attention is All You Need\nThe Google Brain team publishes a paper titled Attention is All You Need, introducing the Transformer - which is now an essential ingredient in many cutting edge models, particularly LLMs.\nThe key innovation is the idea of self-attention, a mechanism that allows the model to selectively choose which parts of the input to pay attention to rather than using the entire input equally.\nTransformers address RNN limitations by replacing recurrance with self attention. This weighs the importance of different parts of the input without having to maintain internal state. Much easier to parallize, and eliminates vanishing & exploding gradient problem.\nAlso 2017, Tesla poaches deep learning expert Andrej Karpathy from OpenAI to be its new head of Autopilot Vision.\n\n\n2018\n\nOpenAI Charter is published, which is later cited upon holding back powerful models like GPT-2.\nElon leaves OpenAI In early 2018, Musk told Sam Altman, another OpenAI founder, that he believed the venture had fallen fatally behind Google, people familiar with the matter said. Musk proposed a possible solution: He would take control of OpenAI and run it himself.\n\nAltman and OpenAI’s other founders rejected Musk’s proposal. Musk, in turn, walked away from the company — and reneged on a massive planned donation. The fallout from that conflict, culminating in the announcement of Musk’s departure on Feb 20, 2018, would shape the industry that’s changing the world, and the company at the heart of it.\nFebruary 20, 2018 announcement that Elon is departing. In the same month, OpenAI switched cloud providers from Amazon to Google, signing an agreement to spend at least $63 million with the tech giant over the next two years.\n\n\n2019\n\nOpenAI shifts from nonprofit to ‘capped-profit’ to attract capital.\n\nJuly 2019, Microsoft invests $1 billion in OpenAI to develop AI technologies on Microsoft Azure.\n\n\n2020\nOctober 2020, GPT-3 is released.\n\n\nCont’d\nOpenAI debtus DALL-E, text-to-image.\nDecember 2022, ChatGPT\n\n\n2023\nJanuary 2023, Microsoft buys 49% of OpenAI at $29 billion valuation.\nMarch 14, 2023: GPT-4.\nMay 2023, Governance of superintelligence blog published\nJuly 24, 2023: Attention is off by One"
  },
  {
    "objectID": "library/natural-sciences/software/ai/index.html",
    "href": "library/natural-sciences/software/ai/index.html",
    "title": "AI",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology\n\n\n\n\n\nRetreival-Enhanced Large Language Models\n\nTweet\n\nAn Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion\nHigh Resolution Image Synthesis with Latent Diffusion Models\nMultimodal Neurons in Artificial Neural Networks\nParsel: A Unified Natural Language Framework for Algorithmic Reasoning\nTraining Compute-Optimal Large Language Models\n\nGoogle investigates optimal training for language models, finds that models are undertrained (i.e. data is the bottleneck, not compute).\n\nGrokking: Generalization Beyond Overfitting on Small Algorithmic Datasets\n\nOpenAI & Google: Improving to perfect generalization well past overfitting.\n\nDenoising Diffusion Probabilistic Models\nDenoising Diffusion Implicit Models\nPseudo Numerical Methods for Diffusion Models on Manifolds\nFast Sampling of Diffusion Models with Exponential Integrator\nBroken Neural Scaling Laws\n\nModelling scaling behaviors of deep neural networks.\n\nDeepmind: Discovering novel algorithms with AlphaTensor\n\nDiscovering faster matrix multiplication algorithms with reinforcement learning.\nBlog\n\nDeepmind: Accelerating fusion science through learned plasma control\nPrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning\nLarge Language Models can Self-Improve\nEmergent Abilities of Large Language Models\nSelf-Instruct: Aligning Language Model with Self Generated Instructions\nMeta: CICERO\n\nThe first AI to play at a human level in Diplomacy, a strategy game that requires building trust, negotiating and cooperating with multiple players.\n\nOpenAI: Learning to play Minecraft with video pre-training (VPT)\nDALL-E: Zero-Shot Text-to-Image Generation\nSparseGPT\n\nGPT-family models can be pruned 50%+ sparsity in one-shot, without retraining and minimal loss of accuracy.\n\nMake-A-Video: Text-to-Video Generation without Text-Video Data\nGalactica: A Large Language Model for Science\nOPT-IML: An instruction-tuned LLM for open-use\n\nGithub\n\nDreambooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation\n\nmitigates the coherence problem in image generation (consistent generations) by binding a unique identifier to a fine-tuned model. This method powers the AI avatar creators, game asset generators, AI movies, and more.\n\nDeep Learning and Computational Physics (Lecture Notes)\nDiffusion Language Models\nDoes Compressing Activations Help Model Parallel Training?\nVALL-E: Generate voice snippets with only a few seconds of input audio\n\nWebsite\n\nWolfram Alpha x ChatGPT\nData Distillation\nAdjusting Biased Samples\n\nEasy to use framework for weighting data and evaluating its biases with and without adjustments.\nGithub\n\nCircumvent Context Size Limits\nLLM Refinement Process, reduce mistakes\nMultimodal Deep Learning\nA Deep-Learning-Based Multi-Modal Sensor Fusion Approach for Detection of Equipment Faults\nWhisper: OpenAI Speech Recognition\n\nblog\ngithub\n\nChatGPT Political Biases\nPix2Pix\n\ngithub\n\nDeep Learning Tuning Playbook\n\ntweet\n\n3D Image Inpainting\n\ntweet\n\nDetecting Watermarks on GPT\nTransformers: How “emergent abilities” are unlocked by scaling up language models\n\ntweet\n\nGoogle MusicLM\nHuggingFace Stable Diffusion: Text2Img, Img2Img\nBLIP-2: Image to Text\n\ntweet\nhuggingface"
  },
  {
    "objectID": "library/natural-sciences/software/ai/index.html#resources",
    "href": "library/natural-sciences/software/ai/index.html#resources",
    "title": "AI",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology\n\n\n\n\n\nRetreival-Enhanced Large Language Models\n\nTweet\n\nAn Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion\nHigh Resolution Image Synthesis with Latent Diffusion Models\nMultimodal Neurons in Artificial Neural Networks\nParsel: A Unified Natural Language Framework for Algorithmic Reasoning\nTraining Compute-Optimal Large Language Models\n\nGoogle investigates optimal training for language models, finds that models are undertrained (i.e. data is the bottleneck, not compute).\n\nGrokking: Generalization Beyond Overfitting on Small Algorithmic Datasets\n\nOpenAI & Google: Improving to perfect generalization well past overfitting.\n\nDenoising Diffusion Probabilistic Models\nDenoising Diffusion Implicit Models\nPseudo Numerical Methods for Diffusion Models on Manifolds\nFast Sampling of Diffusion Models with Exponential Integrator\nBroken Neural Scaling Laws\n\nModelling scaling behaviors of deep neural networks.\n\nDeepmind: Discovering novel algorithms with AlphaTensor\n\nDiscovering faster matrix multiplication algorithms with reinforcement learning.\nBlog\n\nDeepmind: Accelerating fusion science through learned plasma control\nPrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning\nLarge Language Models can Self-Improve\nEmergent Abilities of Large Language Models\nSelf-Instruct: Aligning Language Model with Self Generated Instructions\nMeta: CICERO\n\nThe first AI to play at a human level in Diplomacy, a strategy game that requires building trust, negotiating and cooperating with multiple players.\n\nOpenAI: Learning to play Minecraft with video pre-training (VPT)\nDALL-E: Zero-Shot Text-to-Image Generation\nSparseGPT\n\nGPT-family models can be pruned 50%+ sparsity in one-shot, without retraining and minimal loss of accuracy.\n\nMake-A-Video: Text-to-Video Generation without Text-Video Data\nGalactica: A Large Language Model for Science\nOPT-IML: An instruction-tuned LLM for open-use\n\nGithub\n\nDreambooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation\n\nmitigates the coherence problem in image generation (consistent generations) by binding a unique identifier to a fine-tuned model. This method powers the AI avatar creators, game asset generators, AI movies, and more.\n\nDeep Learning and Computational Physics (Lecture Notes)\nDiffusion Language Models\nDoes Compressing Activations Help Model Parallel Training?\nVALL-E: Generate voice snippets with only a few seconds of input audio\n\nWebsite\n\nWolfram Alpha x ChatGPT\nData Distillation\nAdjusting Biased Samples\n\nEasy to use framework for weighting data and evaluating its biases with and without adjustments.\nGithub\n\nCircumvent Context Size Limits\nLLM Refinement Process, reduce mistakes\nMultimodal Deep Learning\nA Deep-Learning-Based Multi-Modal Sensor Fusion Approach for Detection of Equipment Faults\nWhisper: OpenAI Speech Recognition\n\nblog\ngithub\n\nChatGPT Political Biases\nPix2Pix\n\ngithub\n\nDeep Learning Tuning Playbook\n\ntweet\n\n3D Image Inpainting\n\ntweet\n\nDetecting Watermarks on GPT\nTransformers: How “emergent abilities” are unlocked by scaling up language models\n\ntweet\n\nGoogle MusicLM\nHuggingFace Stable Diffusion: Text2Img, Img2Img\nBLIP-2: Image to Text\n\ntweet\nhuggingface"
  },
  {
    "objectID": "library/social-sciences/events/9-11/index.html",
    "href": "library/social-sciences/events/9-11/index.html",
    "title": "9/11",
    "section": "",
    "text": "Hijackers\nAmerican Airlines Flight 11: One World Trade Center, North Tower\nMohamed Atta (Egyptian), Abdulaziz al-Omari (Saudi Arabian), Wail al-Shehri (Saudi Arabian), Waleed al-Shehri (Saudi Arabian), Satam al-Suqami (Saudi Arabian).\nUnited Airlines Flight 175: Two World Trade Center, South Tower\nMarwan al-Shehhi (United Arab Emirates), Fayez Banihammad (United Arab Emirates), Mohand al-Shehri (Saudi Arabian), Hamza al-Ghamdi (Saudi Arabian), Ahmad al-Ghamdi (Saudi Arabian)\nAmerican Airlines Flight 77 (into the Pentagon)\nHani Hanjour (Saudi Arabian), Khalid al-Mihdhar (Saudi Arabian), Majed Moqed (Saudi Arabian), Nawaf al-Hazmi (Saudi Arabian), Salem al-Hazmi (Saudi Arabian)\nUnited Airlines Flight 93: Shanksville, Pennsylvania\nZiad Jarrah (Lebanese), Ahmed al-Haznawi (Saudi Arabian), Ahmed al-Nami (Saudi Arabian), Sa’id al-Ghamdi (Saudi Arabian)\nA 4 minute overview of the insanity of the official story, on twitter"
  },
  {
    "objectID": "library/social-sciences/events/9-11/index.html#overview",
    "href": "library/social-sciences/events/9-11/index.html#overview",
    "title": "9/11",
    "section": "",
    "text": "Hijackers\nAmerican Airlines Flight 11: One World Trade Center, North Tower\nMohamed Atta (Egyptian), Abdulaziz al-Omari (Saudi Arabian), Wail al-Shehri (Saudi Arabian), Waleed al-Shehri (Saudi Arabian), Satam al-Suqami (Saudi Arabian).\nUnited Airlines Flight 175: Two World Trade Center, South Tower\nMarwan al-Shehhi (United Arab Emirates), Fayez Banihammad (United Arab Emirates), Mohand al-Shehri (Saudi Arabian), Hamza al-Ghamdi (Saudi Arabian), Ahmad al-Ghamdi (Saudi Arabian)\nAmerican Airlines Flight 77 (into the Pentagon)\nHani Hanjour (Saudi Arabian), Khalid al-Mihdhar (Saudi Arabian), Majed Moqed (Saudi Arabian), Nawaf al-Hazmi (Saudi Arabian), Salem al-Hazmi (Saudi Arabian)\nUnited Airlines Flight 93: Shanksville, Pennsylvania\nZiad Jarrah (Lebanese), Ahmed al-Haznawi (Saudi Arabian), Ahmed al-Nami (Saudi Arabian), Sa’id al-Ghamdi (Saudi Arabian)\nA 4 minute overview of the insanity of the official story, on twitter"
  },
  {
    "objectID": "library/social-sciences/events/9-11/index.html#resources",
    "href": "library/social-sciences/events/9-11/index.html#resources",
    "title": "9/11",
    "section": "Resources",
    "text": "Resources\n9/11 Comission Report\nSaudi Arabia Faces the Missing 28 Pages\nJoint Inquiry unto Intelligence Community Activities Before and After the Terrorist Attacks of September 11, 2001: 28 Pages\nA Review of the FBI’s Handling of Intelligence Information Prior to the September 11 Attacks Special Report November 2004 (Released Publicly June 2005) Office of the Inspector General\n9/11 and the Saudi Connection\n2012 10-5 FBI Report - Focused on two individuals: Fahad al-Thumairy, a Saudi Islamic Affairs official and radical cleric who served as the imam of the King Fahd Mosque in Los Angeles and Omar al-Bayoumi, a suspected Saudi government agent who assisted two terrorists, Khalid al-Mihdhar and Nawaf al-Hazmi, who participated in the hijacking of the American Airlines plane that flew into the Pentagon, killing 125. After the two hijackers flew to Los Angeles on Jan. 15, 2000, al-Bayoumi found them an apartment, lent them money and set them up with bank accounts. A redacted copy of a three-and-a-half page October 2012 FBI “update” about the investigation stated that FBI agents had uncovered “evidence” that Thumairy and Bayoumi had been “tasked” to assist the hijackers by yet another individual whose name was blacked out, prompting lawyers for the families to refer to this person as “the third man” in what they argue is a Saudi-orchestrated conspiracy.\nCanestro Declaration - 21-page declaration by Don Canestraro, a lead investigator for the Office of Military Commissions, the legal body overseeing the cases of 9/11 defendants\nDocuments Responsive to Executive Order 14040 2(d) Part 2"
  },
  {
    "objectID": "library/social-sciences/events/9-11/index.html#the-saudi-connection-summary",
    "href": "library/social-sciences/events/9-11/index.html#the-saudi-connection-summary",
    "title": "9/11",
    "section": "The Saudi Connection, Summary",
    "text": "The Saudi Connection, Summary\n\nPeople\nOmar al-Bayoumi\nThe FBI has received numerous reports… dating back to 1999, alleging that al-Bayoumi may be a Saudi intelligence officer. FBI files suggest that al-Bayoumi provided substantial assistance to hijackers Khalid al-Mihdhar and Nawaf al-Hazmi after they arrived in San Diego in 2000. During this same timeframe, al-Bayoumi had extensive contact with Saudie Government establishments in the United States and received financial support from a Saudi company affiliated with the Saudi Ministry of defense. That company reportedly had ties to Osama Bin Ladin and al-Qa’ida.\nAl-Bayoumi was receiving substantial sums of money from the Saudi Embassy in Washington, DC prior to the 9/11 attacks… this money was being funneled from accounts at Riggs Bank belonging to Haifa bin Faisal, the wife of the Saudi Ambassador to the United States, Bandar bin Sultan.\nFahad Al-Thumairy\nA Saudi government official who was assigned to the Saudi Consulate in Los Angeles prior to 9/11. “… worked for the Saudi government in the Department of Religious Affairs”. Al-Thumairy was later deported from the U.S. on suspicion of links to terrorism.\nOsama Bassnan\nBassnan may have been in contact with al-Mihdhar and al-Hazmi during their time in San Diego. He was a close associate of al-Bayoumi and Omar Bakarbashat, another one of the hijackers’ close associates. He told another individual that he met al-Hazmi through al-Bayoumi and later that he met two of the hijackers through al-Bayoumi. Bassnan has many ties to the Saudi government, including past employment by the Saudi Arabian Education Mission. FBI received reports from individuals in the Muslim community alleging that Bassnan might be a Saudi intelligence officer. According to a CIA memo Bassnan reportedly received funding and possibly a fake passport from Saudi Government officials. He and his wife received financial support from the Saudi Ambassador to the United States and his wife. He met with a member of the Saudi Royal Family in Houston in 2002 and received a significant amount of cash. FBI information indicates that Bassnan is an extremist and supporter of Osama Bin Ladin.\nAbdullah Bin Ladin\nAbdullah Bin Ladin claims to work for the Saudi Embassy in Washington, D.C. as an administrative officer. He is identified by the FBI as Osama Bin Ladin’s half brother.\nKhalid al-Mihdhar and Nawaf al-Hazmi\nHijackers on the pentagon flight.\nMusaed A. Al-Jarrah\nAbdullah Al Ajroush\n“…not aware of any contact Al Ajroush has had with the FBI”\n“PENTTBOM Investigation”\n\n\nFacts\nSeveral of the phone numbers found in the phone book of Abu Zubaida, a senior al-Qa’ida operative captured in Pakistan in March 2002, could be linked, at least indirectly, to phone numbers in the United States. One of those numbers is subscribed to by the ASPCOL Corporation. A November 18, 2002 FBI respoonse to the Joint Inquiry states that “CIA traces have revealed no direct links between numbers found in Zubaida’s phone book and numbers in the United States.” The number of a bodyguard at the Saudi Embassy in Washington, DC, was also found in Zubaida’s possesion."
  },
  {
    "objectID": "library/natural-sciences/physics/field-theory/index.html",
    "href": "library/natural-sciences/physics/field-theory/index.html",
    "title": "Field Theory",
    "section": "",
    "text": "Brief History of Guage Field Physics\nThe Unreasonable Effectiveness of Quantum Field Theory\nIntroduction to Genralized Global Symmetries in QFT and Particle Physics\nLectures on Field Theory and the Standard Model: A Symmetry-Oriented Approach\nScattering Amplitudes in Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nEPFL Lectures on General Relativity as a Quantum Field Theory\n\n\n\nIn physics and mathematics, a gauge group is a group of transformations that preserves the fundamental properties of a physical or mathematical system. Gauge groups are important in both classical and quantum field theories, as well as in the study of differential geometry and topology.\nIn the context of physics, gauge groups are used to describe the symmetries of a physical system. For example, in electromagnetism, the gauge group is the group of local phase transformations that leave the electromagnetic potential and field strength unchanged. Similarly, in the theory of the strong force, the gauge group is the group of local color transformations that leave the quark-gluon field strength unchanged.\nIn mathematics, gauge groups arise in the study of connections on vector bundles over a manifold. The gauge group is the group of transformations of the connection that leave the curvature of the connection invariant. These groups play an important role in the study of the topology and geometry of manifolds, and have applications in areas such as mathematical physics, algebraic geometry, and topology.\nOne of the key features of gauge groups is that the physical or mathematical properties of a system are invariant under gauge transformations. This means that different gauge choices can be made for the same physical or mathematical system, without affecting its essential properties. This property is known as gauge invariance and is a fundamental concept in many areas of physics and mathematics.\n\n\n\nThe Yang-Mills theory is a quantum field theory that describes the behavior of particles known as gauge bosons, which mediate the strong nuclear force. The theory is based on the idea of local gauge symmetry, which means that the fundamental equations of the theory are invariant under certain transformations of the fields that describe the particles.\nThe Yang-Mills equations describe the behavior of the gauge bosons, which are particles that transmit the strong force between quarks. The equations involve a set of mathematical terms that describe the interactions between the gauge bosons and the quarks.\nThe Yang-Mills equations are based on a set of mathematical objects known as gauge fields, which describe the behavior of the gauge bosons. The gauge fields are represented by a set of matrices, which are used to calculate the interactions between the gauge bosons and the quarks.\nThe equations are formulated using the mathematical concept of a gauge group, which describes the possible transformations that can be made to the gauge fields. In the case of the strong force, the gauge group is called SU(3), which stands for special unitary group of degree 3.\nThe Yang-Mills equations involve two terms: the kinetic term and the interaction term. The kinetic term describes the free motion of the gauge bosons, while the interaction term describes the interactions between the gauge bosons and the quarks.\nThe kinetic term involves the gauge field strength tensor, which is a mathematical object that describes the strength of the gauge field at each point in spacetime. The interaction term involves the coupling constant, which is a parameter that describes the strength of the interaction between the gauge bosons and the quarks.\nThe Yang-Mills equations are highly non-linear and require advanced mathematical techniques to solve. They are also closely related to the concept of gauge invariance, which means that the equations are invariant under certain transformations of the gauge fields.\nOverall, the Yang-Mills theory provides a mathematical framework for describing the behavior of the strong nuclear force, which is one of the four fundamental forces of nature. The theory has been extensively tested and is an important component of the Standard Model of particle physics, which describes the behavior of all known elementary particles and their interactions."
  },
  {
    "objectID": "library/natural-sciences/finance/trading/trades/comstock/index.html",
    "href": "library/natural-sciences/finance/trading/trades/comstock/index.html",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/natural-sciences/finance/trading/trades/comstock/index.html#resources",
    "href": "library/natural-sciences/finance/trading/trades/comstock/index.html#resources",
    "title": "LODE",
    "section": "",
    "text": "July 7, 2023 LODE Report"
  },
  {
    "objectID": "library/natural-sciences/finance/index.html",
    "href": "library/natural-sciences/finance/index.html",
    "title": "Finance",
    "section": "",
    "text": "The Intelligent Investor\nFlash Boys: History of HFT, frontrunning, etc\nLiars Poker: Solomon Brothers and the real start of bond trading\nBeat the Dealer\nAlchemy of Finance: Soros’ Reflexivity theory of markets\nWhen Genius Failed: The rise and fall of Long Term Capital Management\nExotic Options and Hybrids: Vol. models, correlation, barriers, ATRs, etc.\nThe Smartest Guys in the Room: The massive fraud of Enron\nReminiscences of a Stock Operator: An absolute classic on stock trading\nMore Money than God: On the hedge fund industry\nThe Changing World Order: Ray Dalio’s macro book\nThe Black Swan\nBeat the Market: Highly coveted book by some iconic quants\nThe Art of Currency Trading: A Professional’s Guide to the Foreign Exchange Market\nThe Disciplined Trader\nTrader Vic II: Principles of Professional Speculation\nLearn to Trade Momentum Stocks\nThe Bond and Money Markets\nTrading in the Zone\nBollinger on Bollinger Bands\nAdventures of a Currency Trader\nAce the Trading Systems Developer Interview (C++ Edition)\nProfessional Automated Trading: Theory and Practice\nTrading Systems Performance Unleashed: Mastering Latency and Efficiency in High-Frequency Trading"
  },
  {
    "objectID": "library/natural-sciences/ai/history-of-ai/history-of-ai.html",
    "href": "library/natural-sciences/ai/history-of-ai/history-of-ai.html",
    "title": "History of AI",
    "section": "",
    "text": "Timeline of AI\nHistory of Artificial Neural Networks\nDeep Learning History\n\n\n\nFrank Rosenblatt invented the perceptron, an algorithm for pattern recognition, which is essentially a single-layer neural network.\n\n\n\nShortly after, he went on to explore deeper, multilayer perceptrons. His MLPs had a non-learning first layer with randomized weights and an adaptive output layer. Although this was not yet deep learning, because only the last layer learned.\n\n\n\nSuccessful learning in deep feedforward network architectures started in 1965 in the Ukraine (back then the USSR) when Alexey Ivakhnenko & Valentin Lapa introduced the first general, working learning algorithms for deep MLPs with arbitrarily many hidden layers (already containing the now popular multiplicative gates). A paper of 1971 already described a deep learning net with 8 layers, trained by their highly cited method which was still popular in the new millennium, especially in Eastern Europe, where much of Machine Learning was born.\n\n\n\nIvakhnenko and Lapa (1965, see above) trained their deep networks layer by layer. In 1967, however, Shun-Ichi Amari suggested to train MLPs with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent, a method proposed in 1951 by Robbins & Monro.\nAmari’s implementation (with his student Saito) learned internal representations in a five layer MLP with two modifiable layers, which was trained to classify non-linearily separable pattern classes.\n\n\n\nKunihiko Fukushima introduced rectified linear units (ReLUs) for NNs (1969). They are now widely used in CNNs and other NNs.\n\n\n\nSeppo Linnainmaa was the first to publish what’s now known as backpropagation, the famous algorithm for credit assignment in networks of differentiable nodes, also known as “reverse mode of automatic differentiation.” It is now the foundation of widely used NN software packages such as PyTorch and Google’s Tensorflow.\n\n\n\nAmari published a paper on Amari-Hopfield networks, which resemble what’s now known as Recurrent Neural Networks (RNNs).\n\n\n\nComputer Vision was revolutionized in the 2010s by a particular feedforward NN called the convolutional NN (CNN). The basic CNN architecture with alternating convolutional and downsampling layers is due to Kunihiko Fukushima, 1979. He called it Neocognitron.\n\n\n\n\nThe Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project.\nThe UK began the £350 million Alvey project.\nDARPA founded the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n\n\n\nPhysicist John Hopfield was able to prove that a form of neural network (now called a “Hopfield net”) could learn and process information in a completely new way. This built on the Amari-Hopfield network from Amari’s 1972 publication\n\n\n\n\nGeoffrey Hinton “godfather of AI” invented the idea of multilayered neural networks, with nodes and weights. Node takes inputs and weights of inputs, outputs a signal if sum &gt; 0. - 1985 | A Learning Algorithm for Boltzmann Machines - 1986 | Learning representations by back-propagating errors\n\n\n\nDavid E. Rumelhart demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs. At least for supervised learning, backpropagation is generally more efficient than Amari’s above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier\nFeng-hsiung Hsu begins development on Chess-playing expert system called ChipTest. In 1988 it was moved to IBM and renamed Deep Thought, and then renamed again in 1989 to Deep Blue.\n\n\n\nGenerative Adversarial Networks (GANs) are first published in 1990 in Munich under the moniker Artificial Curiosity. Two dueling NNs (a probabilistic generator and a predictor) are trying to maximize each other’s loss in a minimax game. The generator (called the controller) generates probabilistic outputs (using stochastic units like in the much later StyleGANs). The predictor (called the world model) sees the outputs of the controller and predicts environmental reactions to them. Using gradient descent, the predictor NN minimizes its error, while the generator NN tries to make outputs that maximize this error: one net’s loss is the other net’s gain\n\n\n\nJiirgen Schmidhuber published a paper describing an alternative to RNNs: A feedforward NN slowly learns by gradient descent to program the changes of the fast weights of another NN. Such Fast Weight Programmers (FWPs) can learn to memorize past data, too. In 1991, one of them computed its fast weight changes through additive outer products of self-invented activation patterns (now often called keys and values for self-attention). The very similar Transformers combine this with projections and softmax and are now widely used in natural language processing. For long input sequences, their efficiency was improved through Transformers with linearized self-attention whose core is formally equivalent to the 1991 Fast Weight Programmers.\n\n\n\nSepp Hochreiter and Jurgen Schmidhuber published Long Short-Term Memory, the most cited NN paper of the 20th century. A later milestone was the “vanilla LSTM architecture” with forget gate — the LSTM variant of 1999-2000 that everybody is using today, e.g., in Google’s Tensorflow. Alex was lead author of our first successful application of LSTM to speech (2004). 2005 saw the first publication of LSTM with full backpropagation through time and of bi-directional LSTM (now widely used).\nAlso in 1997, Deep Blue beats Gary Kasparov in chess.\n\n\n\nImageNet is created, a large visual database envisioned by Fei-Fei Li from Stanford University, who realized that the best machine learning algorithms wouldn’t work well if the data didn’t reflect the real world. For many, ImageNet was the catalyst for the AI boom of the 21st century.\n\n\n\nX (formerly Google X) is an American semi-secret research and development facility and organization founded by Google in January 2010. X has its headquarters about a mile and a half from Alphabet’s corporate headquarters, the Googleplex, in Mountain View, California\nDeepMind was founded in the UK by Demis Hassabis, Shane Legg and Mustafa Suleyman in September 2010.\n\n\n\nThe Google Brain project began in 2011 as a part-time research collaboration between Google fellow Jeff Dean, Google Researcher Greg Corrado, and Stanford University professor Andrew Ng. Google Brain started as a Google X project and became so successful that it was graduated back to Google: Astro Teller has said that Google Brain paid for the entire cost of Google X.\n\n\n\nGeoffrey Hinton tests artificial deep neural network on a widely used image recogniztion test, called ImageNet. AlexNet was the program, scored 75% success, way better than competitors. This generates a ton of hype, and sparks more funding/research in AI, particularly image recognition.\n\n\n\nIn 2013, Geoffrey Hinton was acquihired by Google."
  },
  {
    "objectID": "library/natural-sciences/ai/history-of-ai/history-of-ai.html#resources",
    "href": "library/natural-sciences/ai/history-of-ai/history-of-ai.html#resources",
    "title": "History of AI",
    "section": "",
    "text": "Timeline of AI\nHistory of Artificial Neural Networks\nDeep Learning History\n\n\n\nFrank Rosenblatt invented the perceptron, an algorithm for pattern recognition, which is essentially a single-layer neural network.\n\n\n\nShortly after, he went on to explore deeper, multilayer perceptrons. His MLPs had a non-learning first layer with randomized weights and an adaptive output layer. Although this was not yet deep learning, because only the last layer learned.\n\n\n\nSuccessful learning in deep feedforward network architectures started in 1965 in the Ukraine (back then the USSR) when Alexey Ivakhnenko & Valentin Lapa introduced the first general, working learning algorithms for deep MLPs with arbitrarily many hidden layers (already containing the now popular multiplicative gates). A paper of 1971 already described a deep learning net with 8 layers, trained by their highly cited method which was still popular in the new millennium, especially in Eastern Europe, where much of Machine Learning was born.\n\n\n\nIvakhnenko and Lapa (1965, see above) trained their deep networks layer by layer. In 1967, however, Shun-Ichi Amari suggested to train MLPs with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent, a method proposed in 1951 by Robbins & Monro.\nAmari’s implementation (with his student Saito) learned internal representations in a five layer MLP with two modifiable layers, which was trained to classify non-linearily separable pattern classes.\n\n\n\nKunihiko Fukushima introduced rectified linear units (ReLUs) for NNs (1969). They are now widely used in CNNs and other NNs.\n\n\n\nSeppo Linnainmaa was the first to publish what’s now known as backpropagation, the famous algorithm for credit assignment in networks of differentiable nodes, also known as “reverse mode of automatic differentiation.” It is now the foundation of widely used NN software packages such as PyTorch and Google’s Tensorflow.\n\n\n\nAmari published a paper on Amari-Hopfield networks, which resemble what’s now known as Recurrent Neural Networks (RNNs).\n\n\n\nComputer Vision was revolutionized in the 2010s by a particular feedforward NN called the convolutional NN (CNN). The basic CNN architecture with alternating convolutional and downsampling layers is due to Kunihiko Fukushima, 1979. He called it Neocognitron.\n\n\n\n\nThe Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project.\nThe UK began the £350 million Alvey project.\nDARPA founded the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n\n\n\nPhysicist John Hopfield was able to prove that a form of neural network (now called a “Hopfield net”) could learn and process information in a completely new way. This built on the Amari-Hopfield network from Amari’s 1972 publication\n\n\n\n\nGeoffrey Hinton “godfather of AI” invented the idea of multilayered neural networks, with nodes and weights. Node takes inputs and weights of inputs, outputs a signal if sum &gt; 0. - 1985 | A Learning Algorithm for Boltzmann Machines - 1986 | Learning representations by back-propagating errors\n\n\n\nDavid E. Rumelhart demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs. At least for supervised learning, backpropagation is generally more efficient than Amari’s above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier\nFeng-hsiung Hsu begins development on Chess-playing expert system called ChipTest. In 1988 it was moved to IBM and renamed Deep Thought, and then renamed again in 1989 to Deep Blue.\n\n\n\nGenerative Adversarial Networks (GANs) are first published in 1990 in Munich under the moniker Artificial Curiosity. Two dueling NNs (a probabilistic generator and a predictor) are trying to maximize each other’s loss in a minimax game. The generator (called the controller) generates probabilistic outputs (using stochastic units like in the much later StyleGANs). The predictor (called the world model) sees the outputs of the controller and predicts environmental reactions to them. Using gradient descent, the predictor NN minimizes its error, while the generator NN tries to make outputs that maximize this error: one net’s loss is the other net’s gain\n\n\n\nJiirgen Schmidhuber published a paper describing an alternative to RNNs: A feedforward NN slowly learns by gradient descent to program the changes of the fast weights of another NN. Such Fast Weight Programmers (FWPs) can learn to memorize past data, too. In 1991, one of them computed its fast weight changes through additive outer products of self-invented activation patterns (now often called keys and values for self-attention). The very similar Transformers combine this with projections and softmax and are now widely used in natural language processing. For long input sequences, their efficiency was improved through Transformers with linearized self-attention whose core is formally equivalent to the 1991 Fast Weight Programmers.\n\n\n\nSepp Hochreiter and Jurgen Schmidhuber published Long Short-Term Memory, the most cited NN paper of the 20th century. A later milestone was the “vanilla LSTM architecture” with forget gate — the LSTM variant of 1999-2000 that everybody is using today, e.g., in Google’s Tensorflow. Alex was lead author of our first successful application of LSTM to speech (2004). 2005 saw the first publication of LSTM with full backpropagation through time and of bi-directional LSTM (now widely used).\nAlso in 1997, Deep Blue beats Gary Kasparov in chess.\n\n\n\nImageNet is created, a large visual database envisioned by Fei-Fei Li from Stanford University, who realized that the best machine learning algorithms wouldn’t work well if the data didn’t reflect the real world. For many, ImageNet was the catalyst for the AI boom of the 21st century.\n\n\n\nX (formerly Google X) is an American semi-secret research and development facility and organization founded by Google in January 2010. X has its headquarters about a mile and a half from Alphabet’s corporate headquarters, the Googleplex, in Mountain View, California\nDeepMind was founded in the UK by Demis Hassabis, Shane Legg and Mustafa Suleyman in September 2010.\n\n\n\nThe Google Brain project began in 2011 as a part-time research collaboration between Google fellow Jeff Dean, Google Researcher Greg Corrado, and Stanford University professor Andrew Ng. Google Brain started as a Google X project and became so successful that it was graduated back to Google: Astro Teller has said that Google Brain paid for the entire cost of Google X.\n\n\n\nGeoffrey Hinton tests artificial deep neural network on a widely used image recogniztion test, called ImageNet. AlexNet was the program, scored 75% success, way better than competitors. This generates a ton of hype, and sparks more funding/research in AI, particularly image recognition.\n\n\n\nIn 2013, Geoffrey Hinton was acquihired by Google."
  },
  {
    "objectID": "library/natural-sciences/ai/history-of-ai/history-of-ai.html#the-start-of-the-race",
    "href": "library/natural-sciences/ai/history-of-ai/history-of-ai.html#the-start-of-the-race",
    "title": "History of AI",
    "section": "The Start of the Race",
    "text": "The Start of the Race\n\n2014: Attention, the Start of the Race\nThe attention mechanism is introduced, which would became the foundation for the Transformer.\n\n\n2015: OpenAI\nIn December 2015, Sam Altman, Greg Brockman, Reid Hoffman, Jessica Livingston, Peter Thiel, Elon Musk, Amazon Web Services (AWS), Infosys, and YC Research announced the formation of OpenAI and pledged over $1 billion to the venture.\nDecember 11, 2015 announcement by Greg Brockman and Ilya Sutskever.\n\n\n2016\n\nAlphaGo becomes supreme at Go\nGoogle Brain neural network learns secure encryption\n\nDecember 2016, OpenAI released “Universe”, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites, and other applications. Intended to be the reinforcement learning version of ImageNet.\n\n\n2017: Attention is All You Need\nThe Google Brain team publishes a paper titled Attention is All You Need, introducing the Transformer - which is now an essential ingredient in many cutting edge models, particularly LLMs.\nThe key innovation is the idea of self-attention, a mechanism that allows the model to selectively choose which parts of the input to pay attention to rather than using the entire input equally.\nTransformers address RNN limitations by replacing recurrance with self attention. This weighs the importance of different parts of the input without having to maintain internal state. Much easier to parallize, and eliminates vanishing & exploding gradient problem.\nAlso 2017, Tesla poaches deep learning expert Andrej Karpathy from OpenAI to be its new head of Autopilot Vision.\n\n\n2018\n\nOpenAI Charter is published, which is later cited upon holding back powerful models like GPT-2.\nElon leaves OpenAI In early 2018, Musk told Sam Altman, another OpenAI founder, that he believed the venture had fallen fatally behind Google, people familiar with the matter said. Musk proposed a possible solution: He would take control of OpenAI and run it himself.\n\nAltman and OpenAI’s other founders rejected Musk’s proposal. Musk, in turn, walked away from the company — and reneged on a massive planned donation. The fallout from that conflict, culminating in the announcement of Musk’s departure on Feb 20, 2018, would shape the industry that’s changing the world, and the company at the heart of it.\nFebruary 20, 2018 announcement that Elon is departing. In the same month, OpenAI switched cloud providers from Amazon to Google, signing an agreement to spend at least $63 million with the tech giant over the next two years.\n\n\n2019\n\nOpenAI shifts from nonprofit to ‘capped-profit’ to attract capital.\n\nJuly 2019, Microsoft invests $1 billion in OpenAI to develop AI technologies on Microsoft Azure.\n\n\n2020\nOctober 2020, GPT-3 is released.\n\n\nCont’d\nOpenAI debtus DALL-E, text-to-image.\nDecember 2022, ChatGPT\n\n\n2023\nJanuary 2023, Microsoft buys 49% of OpenAI at $29 billion valuation.\nMarch 14, 2023: GPT-4.\nMay 2023, Governance of superintelligence blog published\nJuly 24, 2023: Attention is off by One"
  },
  {
    "objectID": "library/natural-sciences/ai/index.html",
    "href": "library/natural-sciences/ai/index.html",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Asymptotically Unambitious Artificial General Intelligence\nWe Still Don’t Understand the Models We’ve Built\n\n“Glitch Token”"
  },
  {
    "objectID": "library/natural-sciences/ai/index.html#resources",
    "href": "library/natural-sciences/ai/index.html#resources",
    "title": "AI",
    "section": "",
    "text": "Molecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology\n\n\n\n\n\nRetreival-Enhanced Large Language Models\n\nTweet\n\nAn Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion\nHigh Resolution Image Synthesis with Latent Diffusion Models\nMultimodal Neurons in Artificial Neural Networks\nParsel: A Unified Natural Language Framework for Algorithmic Reasoning\nTraining Compute-Optimal Large Language Models\n\nGoogle investigates optimal training for language models, finds that models are undertrained (i.e. data is the bottleneck, not compute).\n\nGrokking: Generalization Beyond Overfitting on Small Algorithmic Datasets\n\nOpenAI & Google: Improving to perfect generalization well past overfitting.\n\nDenoising Diffusion Probabilistic Models\nDenoising Diffusion Implicit Models\nPseudo Numerical Methods for Diffusion Models on Manifolds\nFast Sampling of Diffusion Models with Exponential Integrator\nBroken Neural Scaling Laws\n\nModelling scaling behaviors of deep neural networks.\n\nDeepmind: Discovering novel algorithms with AlphaTensor\n\nDiscovering faster matrix multiplication algorithms with reinforcement learning.\nBlog\n\nDeepmind: Accelerating fusion science through learned plasma control\nPrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning\nLarge Language Models can Self-Improve\nEmergent Abilities of Large Language Models\nSelf-Instruct: Aligning Language Model with Self Generated Instructions\nMeta: CICERO\n\nThe first AI to play at a human level in Diplomacy, a strategy game that requires building trust, negotiating and cooperating with multiple players.\n\nOpenAI: Learning to play Minecraft with video pre-training (VPT)\nDALL-E: Zero-Shot Text-to-Image Generation\nSparseGPT\n\nGPT-family models can be pruned 50%+ sparsity in one-shot, without retraining and minimal loss of accuracy.\n\nMake-A-Video: Text-to-Video Generation without Text-Video Data\nGalactica: A Large Language Model for Science\nOPT-IML: An instruction-tuned LLM for open-use\n\nGithub\n\nDreambooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation\n\nmitigates the coherence problem in image generation (consistent generations) by binding a unique identifier to a fine-tuned model. This method powers the AI avatar creators, game asset generators, AI movies, and more.\n\nDeep Learning and Computational Physics (Lecture Notes)\nDiffusion Language Models\nDoes Compressing Activations Help Model Parallel Training?\nVALL-E: Generate voice snippets with only a few seconds of input audio\n\nWebsite\n\nWolfram Alpha x ChatGPT\nData Distillation\nAdjusting Biased Samples\n\nEasy to use framework for weighting data and evaluating its biases with and without adjustments.\nGithub\n\nCircumvent Context Size Limits\nLLM Refinement Process, reduce mistakes\nMultimodal Deep Learning\nA Deep-Learning-Based Multi-Modal Sensor Fusion Approach for Detection of Equipment Faults\nWhisper: OpenAI Speech Recognition\n\nblog\ngithub\n\nChatGPT Political Biases\nPix2Pix\n\ngithub\n\nDeep Learning Tuning Playbook\n\ntweet\n\n3D Image Inpainting\n\ntweet\n\nDetecting Watermarks on GPT\nTransformers: How “emergent abilities” are unlocked by scaling up language models\n\ntweet\n\nGoogle MusicLM\nHuggingFace Stable Diffusion: Text2Img, Img2Img\nBLIP-2: Image to Text\n\ntweet\nhuggingface"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/solana/index.html#the-tech",
    "href": "library/natural-sciences/crypto/blockchains/solana/index.html#the-tech",
    "title": "Solana",
    "section": "",
    "text": "How will Solana Improve its Stability?"
  },
  {
    "objectID": "library/natural-sciences/ai/tools.html",
    "href": "library/natural-sciences/ai/tools.html",
    "title": "AI Tools",
    "section": "",
    "text": "Chatbots\n\n\nFiles/Documents\n\n\nNougat: PDF to Markdown Conversion\nInstall: pip install nougat-ocr Basic Run: nougat path/to/file.pdf -o output_directory Finetuning, etc. see github\n\nProject Webpage\nPaper\nGithub"
  },
  {
    "objectID": "library/natural-sciences/ai/tech.html",
    "href": "library/natural-sciences/ai/tech.html",
    "title": "AI Tech",
    "section": "",
    "text": "In 2014, an Attention mechanism was introduced by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. This became the foundation for the Transformer. - Neural Machine Translation by Jointly Learning to Align and Translate - ffective Approaches to Attention-based Neural Machine Translation\nThe attention mechanism allows the model to assign different weights or importance to different parts of the input sequence when making predictions or generating output. Instead of relying solely on fixed-length vector representations or encoding the entire input sequence into a fixed-length representation, the attention mechanism enables the model to dynamically attend to relevant parts of the input at each step of the computation.\nIn a typical attention mechanism, there are three main components:\n\nQuery: A query represents the current step or position in the output generation process. It is used to compare against different parts of the input sequence to determine their relevance.\nKey: The keys are representations of the different parts of the input sequence. These keys are compared to the query to measure their similarity or relevance.\nValue: The values are additional information associated with the input sequence parts. They provide the context or content that the model focuses on.\n\nThe attention mechanism computes a similarity score between the query and each key, which determines the relevance or attention assigned to the corresponding value. These similarity scores are typically computed using dot products, additive or multiplicative operations, or neural networks.\nThe resulting attention weights are used to weight the values associated with the input sequence parts. This weighted information is then combined or aggregated to provide a context-aware representation for the current step, allowing the model to focus more on relevant parts of the input.\nBy incorporating attention mechanisms into deep learning models, they can effectively capture dependencies between different elements of the input sequence, improve performance on sequential tasks, and handle long-range dependencies more effectively than traditional fixed-length representations.\n\n\n\nPaper published by a team at Google Brain. - Attention is All You Need\nThe Transformer architecture is built on the idea of self-attention or scaled dot-product attention, which can be seen as an extension of the attention mechanism. In traditional sequence-to-sequence models, such as recurrent neural networks (RNNs), sequential information is processed step by step, which can be computationally expensive and hinder parallelization.\nThe key innovation of the Transformer is that it replaces recurrent layers with self-attention layers. Self-attention allows the model to compute the relationships between all positions in the input sequence simultaneously. This means that each position can attend to any other position, capturing global dependencies in the sequence. By doing so, the Transformer can process inputs in parallel and handle long-range dependencies more effectively.\nThe Transformer architecture consists of two main components: the encoder and the decoder. The encoder takes an input sequence and generates a sequence of contextualized representations, while the decoder takes the encoder’s output and generates the final output sequence.\nWithin the encoder and decoder, the Transformer uses multi-head self-attention mechanisms. Instead of a single self-attention mechanism, multiple attention heads are employed to capture different types of information and attend to different parts of the input sequence simultaneously. This allows the model to focus on different aspects of the input and learn more diverse and expressive representations.\nThe Transformer also introduces positional encoding, which provides information about the position of each element in the input sequence. Since self-attention lacks the notion of position, positional encoding enables the model to incorporate sequential information into its computations.\nThe dominance of the Transformer architecture in modern AI can be attributed to several factors:\n\nParallelization: The self-attention mechanism in the Transformer enables parallel processing of inputs, making it highly efficient for training on modern hardware, such as graphics processing units (GPUs) or tensor processing units (TPUs).\nLong-range dependencies: The self-attention mechanism allows the Transformer to capture dependencies between distant positions in the input sequence, making it more effective in modeling long-range relationships compared to traditional recurrent architectures.\nExpressiveness: By employing multiple attention heads and capturing different types of information, the Transformer can learn more expressive and rich representations of the input data.\nTransferability: The Transformer has shown strong performance across a wide range of NLP tasks, such as machine translation, language understanding, text generation, and more. Its effectiveness and versatility have made it a popular choice and a basis for many state-of-the-art models.\n\nOverall, the Transformer’s ability to model global dependencies, parallelize computations, and learn expressive representations has contributed to its dominance in modern AI, particularly in the field of natural language processing."
  },
  {
    "objectID": "library/natural-sciences/ai/tech.html#technology-overview",
    "href": "library/natural-sciences/ai/tech.html#technology-overview",
    "title": "AI Tech",
    "section": "",
    "text": "In 2014, an Attention mechanism was introduced by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. This became the foundation for the Transformer. - Neural Machine Translation by Jointly Learning to Align and Translate - ffective Approaches to Attention-based Neural Machine Translation\nThe attention mechanism allows the model to assign different weights or importance to different parts of the input sequence when making predictions or generating output. Instead of relying solely on fixed-length vector representations or encoding the entire input sequence into a fixed-length representation, the attention mechanism enables the model to dynamically attend to relevant parts of the input at each step of the computation.\nIn a typical attention mechanism, there are three main components:\n\nQuery: A query represents the current step or position in the output generation process. It is used to compare against different parts of the input sequence to determine their relevance.\nKey: The keys are representations of the different parts of the input sequence. These keys are compared to the query to measure their similarity or relevance.\nValue: The values are additional information associated with the input sequence parts. They provide the context or content that the model focuses on.\n\nThe attention mechanism computes a similarity score between the query and each key, which determines the relevance or attention assigned to the corresponding value. These similarity scores are typically computed using dot products, additive or multiplicative operations, or neural networks.\nThe resulting attention weights are used to weight the values associated with the input sequence parts. This weighted information is then combined or aggregated to provide a context-aware representation for the current step, allowing the model to focus more on relevant parts of the input.\nBy incorporating attention mechanisms into deep learning models, they can effectively capture dependencies between different elements of the input sequence, improve performance on sequential tasks, and handle long-range dependencies more effectively than traditional fixed-length representations.\n\n\n\nPaper published by a team at Google Brain. - Attention is All You Need\nThe Transformer architecture is built on the idea of self-attention or scaled dot-product attention, which can be seen as an extension of the attention mechanism. In traditional sequence-to-sequence models, such as recurrent neural networks (RNNs), sequential information is processed step by step, which can be computationally expensive and hinder parallelization.\nThe key innovation of the Transformer is that it replaces recurrent layers with self-attention layers. Self-attention allows the model to compute the relationships between all positions in the input sequence simultaneously. This means that each position can attend to any other position, capturing global dependencies in the sequence. By doing so, the Transformer can process inputs in parallel and handle long-range dependencies more effectively.\nThe Transformer architecture consists of two main components: the encoder and the decoder. The encoder takes an input sequence and generates a sequence of contextualized representations, while the decoder takes the encoder’s output and generates the final output sequence.\nWithin the encoder and decoder, the Transformer uses multi-head self-attention mechanisms. Instead of a single self-attention mechanism, multiple attention heads are employed to capture different types of information and attend to different parts of the input sequence simultaneously. This allows the model to focus on different aspects of the input and learn more diverse and expressive representations.\nThe Transformer also introduces positional encoding, which provides information about the position of each element in the input sequence. Since self-attention lacks the notion of position, positional encoding enables the model to incorporate sequential information into its computations.\nThe dominance of the Transformer architecture in modern AI can be attributed to several factors:\n\nParallelization: The self-attention mechanism in the Transformer enables parallel processing of inputs, making it highly efficient for training on modern hardware, such as graphics processing units (GPUs) or tensor processing units (TPUs).\nLong-range dependencies: The self-attention mechanism allows the Transformer to capture dependencies between distant positions in the input sequence, making it more effective in modeling long-range relationships compared to traditional recurrent architectures.\nExpressiveness: By employing multiple attention heads and capturing different types of information, the Transformer can learn more expressive and rich representations of the input data.\nTransferability: The Transformer has shown strong performance across a wide range of NLP tasks, such as machine translation, language understanding, text generation, and more. Its effectiveness and versatility have made it a popular choice and a basis for many state-of-the-art models.\n\nOverall, the Transformer’s ability to model global dependencies, parallelize computations, and learn expressive representations has contributed to its dominance in modern AI, particularly in the field of natural language processing."
  },
  {
    "objectID": "library/natural-sciences/ai/tech.html#backpropogation",
    "href": "library/natural-sciences/ai/tech.html#backpropogation",
    "title": "AI Tech",
    "section": "Backpropogation",
    "text": "Backpropogation\nBackpropogation is an algorithm for training neural-networks, used to update its weights to minimize the ‘loss’\n\nNetwork makes a prediction on a batch of input data\nLoss is calculated between predicted and actual output\nGradient of the loss with respect to the weights are calculated using the chain rule of differentiation\nThe gradients are used to update the weights in the opposite direction of the gradient, reducing the loss\nRepeat the process until the loss reaches a satisfactory level or a maximum number of iterations"
  },
  {
    "objectID": "library/natural-sciences/finance/quant-trading/quant-trading.html",
    "href": "library/natural-sciences/finance/quant-trading/quant-trading.html",
    "title": "Quant Trading",
    "section": "",
    "text": "This is a background on quantitative trading.\nTry out this code\ndef main():\n    while True:\n        trade()"
  },
  {
    "objectID": "library/natural-sciences/finance/trading/trades/JGByields/index.html",
    "href": "library/natural-sciences/finance/trading/trades/JGByields/index.html",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/natural-sciences/finance/trading/trades/JGByields/index.html#resources",
    "href": "library/natural-sciences/finance/trading/trades/JGByields/index.html#resources",
    "title": "JGB Rates",
    "section": "",
    "text": "Bloomberg Page"
  },
  {
    "objectID": "library/natural-sciences/finance/finance-101/finance-101.html",
    "href": "library/natural-sciences/finance/finance-101/finance-101.html",
    "title": "Finance 101",
    "section": "",
    "text": "This is a background on finance"
  },
  {
    "objectID": "library/social-sciences/geopolitics/index.html#reads",
    "href": "library/social-sciences/geopolitics/index.html#reads",
    "title": "Geopolitics",
    "section": "",
    "text": "Peter Thiel: Straussian Moment\nLegacy of Ashes"
  },
  {
    "objectID": "library/social-sciences/geopolitics/index.html#other",
    "href": "library/social-sciences/geopolitics/index.html#other",
    "title": "Geopolitics",
    "section": "Other",
    "text": "Other\nArab support to Egypt, as of Dec-2022\nLong-term deposits = $15b, from: - UAE = $5.7b - Saudi = $5.3b - Kuwait = $4b\nShort-term deposits = $14.9b, from: - UAE = $5b - Saudi = $5b - Qatar = $4b (from $3b in Mar) - Libya = $0.9b (from 0 in Mar)"
  },
  {
    "objectID": "library/natural-sciences/ai/tools.html#filesdocuments",
    "href": "library/natural-sciences/ai/tools.html#filesdocuments",
    "title": "AI Tools",
    "section": "Files/Documents",
    "text": "Files/Documents\n\nNougat: PDF to Markdown Conversion\n\nProject Webpage\nPaper\nGithub\n\n# Install\npip install nougat-ocr\n\n# Run\nnougat path/to/file.pdf -o output_directory\n\n# Finetuning, etc. see github"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#calculus",
    "href": "library/natural-sciences/maths/index.html#calculus",
    "title": "Maths",
    "section": "Calculus",
    "text": "Calculus\n\nUPenn Math 114 (Single Variable Calculus)\nMIT Single Variable Calculus\nMIT Multivariable Calculus\nUPenn Math 240 (Multi Variable Calculus)\n\n\nFractional Calculus\n\nWhat is Fractional Calculus\n\nSummary\nThe blog post discusses the concept of fractional calculus, a mathematical field that explores the idea of derivatives and integrals of non-integer order. The concept was first proposed by Gottfried Leibniz in a response to a question from l’Hopital about the possibility of a derivative of order 1/2. The post explains the theory behind fractional calculus, its properties, and its applications, using the Riemann-Liouville integral and derivative as examples.\n\nFractional Calculus: Fractional calculus is the branch of mathematical analysis that investigates the possibility of taking derivatives and integrals of any real number order, not just integer order.\nIntuition: The concept of fractional calculus arises from the idea of interpreting differentiation and integration as transformations that continuously transform a function into its nth derivative or antiderivative.\nFractional Integral and Derivative: The most natural place to start with fractional calculus is with Cauchy’s formula for repeated integration. The generalization of the factorial function in this formula is the gamma function, which allows for the definition of the left Riemann-Liouville integral, a valid operator for integration to fractional order.\nDifferintegral Operator: The differintegral operator is a combination of the fractional integral and derivative, which can continuously transform between functions.\nProperties: Fractional calculus has unique properties, such as nonlocality, which means that the value of a fractional derivative at a point depends on an entire range of values, not just that point. This property makes fractional calculus useful for modeling physical phenomena with memory effects.\nFractional Derivatives of Basic Functions: The fractional derivatives of power functions, sine function, and exponential function are discussed.\nInterpretation: The interpretation of fractional operators in a geometric or physical sense is still an area of active research.\nApplications: An example of the application of fractional calculus is in solving the tautochrone problem, which involves finding a curve such that the time taken by a bead to slide down the curve is independent of the initial height.\nConclusion: Fractional calculus is a result of pushing the boundaries of existing theories to work with extreme or unusual cases. It is a field with potential for new discoveries in mathematics and science."
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#differential-equations",
    "href": "library/natural-sciences/maths/index.html#differential-equations",
    "title": "Maths",
    "section": "Differential Equations",
    "text": "Differential Equations\n\nDifferential Equations Textbook\nMIT Differential Equations"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#linear-algebra",
    "href": "library/natural-sciences/maths/index.html#linear-algebra",
    "title": "Maths",
    "section": "Linear Algebra",
    "text": "Linear Algebra\n\nMIT Linear Algebra\nThe Matrix Cookbook"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#probability-and-statistics",
    "href": "library/natural-sciences/maths/index.html#probability-and-statistics",
    "title": "Maths",
    "section": "Probability and Statistics",
    "text": "Probability and Statistics\n\nMIT OCW Probability and Random Variables"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#finance-and-economics",
    "href": "library/natural-sciences/maths/index.html#finance-and-economics",
    "title": "Maths",
    "section": "Finance and Economics",
    "text": "Finance and Economics\n\nMIT Topics in Mathematics with Applications in Finance\nAlgorithmic Game Theory"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#optimization",
    "href": "library/natural-sciences/maths/index.html#optimization",
    "title": "Maths",
    "section": "Optimization",
    "text": "Optimization\n\nConvex Optimization\nOperations Research: Applications and Algorithms"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#physics-and-mathematical-physics",
    "href": "library/natural-sciences/maths/index.html#physics-and-mathematical-physics",
    "title": "Maths",
    "section": "Physics and Mathematical Physics",
    "text": "Physics and Mathematical Physics"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#advanced-topics",
    "href": "library/natural-sciences/maths/index.html#advanced-topics",
    "title": "Maths",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nThe Prime Number Maze\nErgodic Theory\nPolyak-Łojasiewicz Inequality\n\nGeneralizes strong convexity, and a simple condition to ensure linear convergence of gradient descent even for non-convex functions.\n\n\n\nTopology\n\nTopology and modern analysis\n\n\n\nGraph Theory\n\nNew Proof Shows That ‘Expander’ Graphs Synchronize\n\n\n\nGroup Theory\n\n\nSynchronization\n\nScientists Discover Exotic New Patterns of Synchronization\nSelf-entrainment of a population of coupled non-linear oscillators\nCluster synchronization and isolated desynchronization in complex networks with symmetries\nIncoherence-Mediated Remote Synchronization\nSynchronization in chaotic systems\nSymmetric States Requiring System Asymmetry\n\nSynchronization is a phenomenon in which multiple oscillating or rhythmic elements lock into a single rhythm. Scientists have discovered new forms of synchronization, called chimeras, that are more complex and intricate than previously known patterns. Chimeras are characterized by the coexistence of synchronized and unsynchronized regions in a single system. The discovery of chimeras has opened up new possibilities for understanding and controlling synchronization in a wide range of real-world systems. For example, chimeras could be used to design new communication networks that are more robust to noise and disruptions. The article also discusses the history of synchronization research and the challenges that scientists face in understanding and predicting the behavior of synchronized systems. It concludes by discussing the potential applications of chimeras in a variety of fields, including biology, engineering, and economics.\nThe discovery of chimeras was made possible by advances in computational power and mathematical modeling. Chimeras have been observed in a variety of natural systems, including fireflies, heart cells, and neural networks. Scientists are still learning about the rules that govern the formation and behavior of chimeras. Chimeras have the potential to be used to design new communication networks, control traffic flow, and improve the efficiency of energy systems.\n\n\nFourier Transformations\nThe Fourier Transform is a mathematical technique that transforms a function of time, a signal, into a function of frequency. It’s a way to represent a signal in terms of its constituent frequencies, much like a musical chord can be expressed as the amplitudes of its constituent notes.\nThe Fourier Transform can be applied to a wide variety of fields, including physics, engineering, signal processing, image analysis, and data compression.\nFormally, for a continuous signal, the Fourier Transform F(w) of a function f(t) is given by the integral:\nF(w) = ∫ f(t) e^-iwt dt\nHere:\n\nw is the frequency,\nt is time,\ni is the imaginary unit,\ne is the base of the natural logarithm,\nand ∫ denotes integration over all time from -∞ to +∞.\n\nThe inverse Fourier Transform, which transforms back from the frequency domain to the time domain, is given by:\nf(t) = (1/2π) ∫ F(w) e^iwt dw\nNote that in practice, many signals are discrete rather than continuous, and the Discrete Fourier Transform (DFT) or its faster version, the Fast Fourier Transform (FFT), are used.\nThe Fourier Transform and its variants are used in a wide variety of applications. For example, in audio processing, it can be used to identify the different frequencies present in a sound. In image processing, it can be used for operations like blurring an image or removing noise. In physics, it can be used to solve differential equations."
  },
  {
    "objectID": "library/natural-sciences/software/languages/rust/index.html",
    "href": "library/natural-sciences/software/languages/rust/index.html",
    "title": "Rust",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\nRustlings, “by example\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/natural-sciences/software/languages/rust/index.html#learning-resources",
    "href": "library/natural-sciences/software/languages/rust/index.html#learning-resources",
    "title": "Rust",
    "section": "",
    "text": "Google’s Rust Course, developed by the android team\nRustlings, “by example\nClassic Rust by Example\nRust Book\nZero to Production\nRust in Action"
  },
  {
    "objectID": "library/natural-sciences/software/chrome-extension/index.html",
    "href": "library/natural-sciences/software/chrome-extension/index.html",
    "title": "Chrome Extensions",
    "section": "",
    "text": "Youtube basic: To Inject JavaScript And CSS Into Any Website - Build A Chrome Extension From Scratch"
  },
  {
    "objectID": "library/natural-sciences/software/chrome-extension/index.html#resources",
    "href": "library/natural-sciences/software/chrome-extension/index.html#resources",
    "title": "Chrome Extensions",
    "section": "",
    "text": "Youtube basic: To Inject JavaScript And CSS Into Any Website - Build A Chrome Extension From Scratch"
  },
  {
    "objectID": "library/natural-sciences/software/chrome-extension/index.html#learn-by-example-enhance-twitter",
    "href": "library/natural-sciences/software/chrome-extension/index.html#learn-by-example-enhance-twitter",
    "title": "Chrome Extensions",
    "section": "Learn by Example: Enhance Twitter",
    "text": "Learn by Example: Enhance Twitter"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#black-hole-discussion",
    "href": "library/natural-sciences/physics/index.html#black-hole-discussion",
    "title": "Relativity",
    "section": "Black Hole Discussion",
    "text": "Black Hole Discussion\n\nEquation for a Rotating Black Hole\n\\[\n\\begin{aligned}\nd s^2= & -\\left(1-\\frac{2 m r}{r^2+a^2 \\cos ^2 \\theta}\\right)\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)^2 \\\\\n& +2\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)\\left(d r-a \\sin ^2 \\theta d \\tilde{\\phi}\\right) \\\\\n& +\\left(r^2+a^2 \\cos ^2 \\theta\\right)\\left(d \\theta^2+\\sin ^2 \\theta d \\tilde{\\phi}^2\\right)\n\\end{aligned}\n\\]\n\nYou can’t take the reference frame of light. In every reference frame the light speed is the same, so “in the reference frame of light” makes no sense because there time is stopped. The EH can’t be seen on oo because for an observer between PS and EH there are a finite number of oscillations of his time reference from PS to EH The assumption that the universe could rotate leads to a complication of all physical laws. We would get that there then has to be a rotation axis of the universe and that all rules are different with relation to that axis so that speed along the rotation direction can exceed c with any multiple without problems of inertia. This is similar to the Hubble expansion with the difference of an absolute rotation axis. That is why I reject both assumptions. It makes no sense to assume that space rotates. We rotate inside space. It also makes no sense to assume that space expands. We shrink inside space. The big one, space, is invariant, flat, not rotating, not translating, not curving. The small, what is inside space, rotates, translates, changes size. The only property of space that has a variation is that the propagation speed of light depends on the mass/energy density distribution in space.\n\n\nIsn’t it easier for Hawking radiation to escape if black holes have hair? So it’s not perfectly curved there. How does this equation differ from the superfluid quantum gravity spinning vortice(s) model of black holes?\n\n\n@bgreene marveled about the beauty of the equation. He didn’t gave a judgement about its validity. I gave an explanation on what assumptions are needed to allow this metric equation to be applicable. You come with the concept of a radiating BH. That only asks wether a particle pair of matter and antimatter could split such that one falks into, and one escapes the BH. But since the propagation speed of light at the EH is equal to the EH nothing moves there. So a hairy EH would assume that this propagation speed distribution is not smooth. This then should lead to particle wave functions to start from “stand still” and move outward. Such phenomen would need a different metric equation, but would not alter the beauty of the equation that @bgreene mentioned.\n\n\n\nCosmology\n\nThe Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry\nEinstein, Barcelona, Symmetry & Cosmology: The Birth of an Equation for the Universe\nSeeing the Gravitational Wave Universe\nNASA Selects 5 Missions for 2024 Total Solar Eclipse\nJames Webb Images\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nHolography of the Photon Ring\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics\nDiscovery of Gamma Rays from the Quiescent Sun with HAWC\n10 galaxies that existed just 830 million years after the Big Bang The seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster.\n\n\n\nBlack Holes\n\nBlack Holes Evade Heat Death\nEffective Action for the Hawking Process\nSupermassive Black Hole Binary\nProbing Supermassive Black Hole Merges and Stalling with Pulsar Timing Arrays\nAbell 1201: detection of an ultramassive black hole in a strong gravitational lens\nMath Proof Draws New Boundaries Around Black Hole Formation\n\nQuanta article\n\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets"
  },
  {
    "objectID": "library/natural-sciences/physics/relativity/index.html#resources",
    "href": "library/natural-sciences/physics/relativity/index.html#resources",
    "title": "Relativity",
    "section": "",
    "text": "Lecture Notes on Holographic Renomalization\nAdS/CFT correspondence and Geometry (Hamilton-Jacobi approach to holographic renormalization)\nEPFL Lectures on General Relativity as a Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nEffective Field Physics (EFT) Methods of General Relativity\nHarmonic Springs and Gravity\nThe Role of Gravitation in Physics\n\n\n\n\npaper\n\nThe Einstein field equation is a fundamental equation in general relativity that relates the geometry of spacetime to the distribution of matter and energy. The equation is given by:\n\\[R_{\\mu\\nu} - \\frac{1}{2}R g_{\\mu\\nu} + \\Lambda g_{\\mu\\nu} = \\frac{8\\pi G}{c^4} T_{\\mu\\nu}\\]\nwhere \\(R_{\\mu\\nu}\\) is the Ricci curvature tensor, \\(R\\) is the scalar curvature, \\(g_{\\mu\\nu}\\) is the metric tensor, \\(\\Lambda\\) is the cosmological constant, \\(G\\) is the gravitational constant, \\(c\\) is the speed of light, and \\(T_{\\mu\\nu}\\) is the stress-energy tensor.\nThe Ricci curvature tensor \\(R_{\\mu\\nu}\\) is a measure of the curvature of spacetime, and is related to the distribution of matter and energy through the stress-energy tensor \\(T_{\\mu\\nu}\\). The scalar curvature \\(R\\) is a measure of the overall curvature of spacetime, and is related to the Ricci curvature tensor through the Einstein field equation.\nThe metric tensor \\(g_{\\mu\\nu}\\) is a mathematical object that describes the geometry of spacetime. It specifies the distances between nearby points in spacetime and is used to calculate the curvature of spacetime. The cosmological constant \\(\\Lambda\\) is a parameter that was introduced by Einstein to allow for a static universe, but it is now thought to describe the energy density of the vacuum.\nThe stress-energy tensor \\(T_{\\mu\\nu}\\) describes the distribution of matter and energy in spacetime. It includes contributions from matter, radiation, and other forms of energy. The equation states that the curvature of spacetime is related to the distribution of matter and energy through the stress-energy tensor.\nIn summary, the Einstein field equation is a fundamental equation in general relativity that relates the geometry of spacetime to the distribution of matter and energy. It is a mathematical expression of the idea that matter and energy warp spacetime, and that the curvature of spacetime determines the motion of matter and energy.\n\n\n\nIn physics, the Minkowski metric (also known as the Minkowski spacetime or the Minkowski metric tensor) is a mathematical tool used to describe spacetime in special relativity. It is named after the German mathematician Hermann Minkowski, who developed the concept of spacetime as a four-dimensional manifold with a metric in the early 20th century.\nThe Minkowski metric describes the geometry of spacetime in special relativity. It is a mathematical object that assigns a distance or interval between two events in spacetime. In the Minkowski metric, the interval between two events is defined by:\n\\[ds^2 = -c^2 dt^2 + dx^2 + dy^2 + dz^2\\]\nwhere \\(ds\\) is the spacetime interval between two events, \\(c\\) is the speed of light, \\(dt\\) is the time interval between the two events, and \\(dx\\), \\(dy\\), and \\(dz\\) are the three spatial intervals between the two events. The minus sign in front of the \\(c^2 dt^2\\) term ensures that the interval is negative for timelike separations, which represent events that can be causally connected, and positive for spacelike separations, which represent events that cannot be causally connected. The Minkowski metric has a signature of (-, +, +, +), which means that the time interval has the opposite sign compared to the spatial intervals.\nThe Minkowski metric is a special case of the more general metric tensor used in general relativity. In general relativity, the metric tensor is a function of the curvature of spacetime caused by matter and energy, and it is used to describe the gravitational field. However, in special relativity, where there is no gravitational field, the metric tensor is simply the Minkowski metric, and it describes the flat spacetime of special relativity."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#resources",
    "href": "library/natural-sciences/physics/index.html#resources",
    "title": "Relativity",
    "section": "Resources",
    "text": "Resources\n\nLecture Notes on Holographic Renomalization\nAdS/CFT correspondence and Geometry (Hamilton-Jacobi approach to holographic renormalization)\nEPFL Lectures on General Relativity as a Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nEffective Field Physics (EFT) Methods of General Relativity\nHarmonic Springs and Gravity\nThe Role of Gravitation in Physics\n\n\nEinstein Field Equation\n\npaper\n\nThe Einstein field equation is a fundamental equation in general relativity that relates the geometry of spacetime to the distribution of matter and energy. The equation is given by:\n\\[R_{\\mu\\nu} - \\frac{1}{2}R g_{\\mu\\nu} + \\Lambda g_{\\mu\\nu} = \\frac{8\\pi G}{c^4} T_{\\mu\\nu}\\]\nwhere \\(R_{\\mu\\nu}\\) is the Ricci curvature tensor, \\(R\\) is the scalar curvature, \\(g_{\\mu\\nu}\\) is the metric tensor, \\(\\Lambda\\) is the cosmological constant, \\(G\\) is the gravitational constant, \\(c\\) is the speed of light, and \\(T_{\\mu\\nu}\\) is the stress-energy tensor.\nThe Ricci curvature tensor \\(R_{\\mu\\nu}\\) is a measure of the curvature of spacetime, and is related to the distribution of matter and energy through the stress-energy tensor \\(T_{\\mu\\nu}\\). The scalar curvature \\(R\\) is a measure of the overall curvature of spacetime, and is related to the Ricci curvature tensor through the Einstein field equation.\nThe metric tensor \\(g_{\\mu\\nu}\\) is a mathematical object that describes the geometry of spacetime. It specifies the distances between nearby points in spacetime and is used to calculate the curvature of spacetime. The cosmological constant \\(\\Lambda\\) is a parameter that was introduced by Einstein to allow for a static universe, but it is now thought to describe the energy density of the vacuum.\nThe stress-energy tensor \\(T_{\\mu\\nu}\\) describes the distribution of matter and energy in spacetime. It includes contributions from matter, radiation, and other forms of energy. The equation states that the curvature of spacetime is related to the distribution of matter and energy through the stress-energy tensor.\nIn summary, the Einstein field equation is a fundamental equation in general relativity that relates the geometry of spacetime to the distribution of matter and energy. It is a mathematical expression of the idea that matter and energy warp spacetime, and that the curvature of spacetime determines the motion of matter and energy.\n\n\nMinkowski Metric\nIn physics, the Minkowski metric (also known as the Minkowski spacetime or the Minkowski metric tensor) is a mathematical tool used to describe spacetime in special relativity. It is named after the German mathematician Hermann Minkowski, who developed the concept of spacetime as a four-dimensional manifold with a metric in the early 20th century.\nThe Minkowski metric describes the geometry of spacetime in special relativity. It is a mathematical object that assigns a distance or interval between two events in spacetime. In the Minkowski metric, the interval between two events is defined by:\n\\[ds^2 = -c^2 dt^2 + dx^2 + dy^2 + dz^2\\]\nwhere \\(ds\\) is the spacetime interval between two events, \\(c\\) is the speed of light, \\(dt\\) is the time interval between the two events, and \\(dx\\), \\(dy\\), and \\(dz\\) are the three spatial intervals between the two events. The minus sign in front of the \\(c^2 dt^2\\) term ensures that the interval is negative for timelike separations, which represent events that can be causally connected, and positive for spacelike separations, which represent events that cannot be causally connected. The Minkowski metric has a signature of (-, +, +, +), which means that the time interval has the opposite sign compared to the spatial intervals.\nThe Minkowski metric is a special case of the more general metric tensor used in general relativity. In general relativity, the metric tensor is a function of the curvature of spacetime caused by matter and energy, and it is used to describe the gravitational field. However, in special relativity, where there is no gravitational field, the metric tensor is simply the Minkowski metric, and it describes the flat spacetime of special relativity."
  },
  {
    "objectID": "library/natural-sciences/physics/field-theory/index.html#quantum-field-theory",
    "href": "library/natural-sciences/physics/field-theory/index.html#quantum-field-theory",
    "title": "Field Theory",
    "section": "Quantum Field Theory",
    "text": "Quantum Field Theory\n\nRelatavistic Quantum Field Theory I\nRelatavistic Quantum Field Theory II\n\n\nEffective or Fundamental?\nThis is a talk given by Steven Weinberg, with a corresponsing article Steven Weinberg: master builder of the Standard Model. In the talk, he explores this question by analyzing the ups and downs of quantum field theory throughout its history.\nSummary\nQuantum Field Theory was born just pertaining to the electromagnetic field. When expanding this theory, it seemed it couldn’t be trusted at high energies. In the late 1940s, there was a new optimizing with the invention of a relatavistic perturbation theory, where the infinities could be absorbed into a redefinition of parameters like mass and charge of the electron. People thought this was sweeping problems under the rug, but it also may have been a way of selecting good theories (renormalizable theories). For example, theere’s nothing in the symmetries of quantum electrodynamics which rules out putting a term in the field equations (or Lagrangian), which could make the magnetic moment of the electron anything you want. This would make the mass of the electron -1, which means the theory is not renormalizable, and thus shows invalid.\nIn the late 1960s and early 70s, the standard model came to fruition - this was the renaissance of Quantum Field theory. But there were still doubts whether this was a fundamental theory or an effective one.\nQuantum Field Theory & Einsteinian Physics may be low energy approximations of a more fundamental theory."
  },
  {
    "objectID": "library/natural-sciences/physics/unification/index.html#string-theory",
    "href": "library/natural-sciences/physics/unification/index.html#string-theory",
    "title": "Grand Unification",
    "section": "String Theory",
    "text": "String Theory\n\nMagic, mystery or matrix? A conversation with string theorist Edward Witten\nOn Unitarity of Tree-Level String Amplitudes"
  },
  {
    "objectID": "library/natural-sciences/physics/unification/index.html#geometric-unity",
    "href": "library/natural-sciences/physics/unification/index.html#geometric-unity",
    "title": "Grand Unification",
    "section": "Geometric Unity",
    "text": "Geometric Unity\n\nContext\nThis is notes on a lecture by Eric Weinstein on the topic of geometric unity. The lecture is available here.\nI am first watching this lecture without a proper background in tensor calculus, dirac notation, or differential geometry. My plan is first to listen, ponder curiously, explore the topics which I need to learn, and return once I’m able to independently generate an opinion with conviction.\n\n\nThe Current Idea of Physics\nEdward Witten gave 3 main insights/assumptions, they correspond to the 3 great equations\n(1) Physics takes place in an arena\nThat arena is a manifold x together with some kind of semi-Riemannian metric structure: something that allows us to take length and angle, so that we can perform measurements at everypoint in spacetime or higher dimensional structure.\nThe equation associated with this is the Einstein Field Equation.\n\\[ R_{\\mu\\nu} - \\frac{1}{2} R g_{\\mu\\nu} + \\Lambda g_{\\mu\\nu} = \\frac{8 \\pi G}{c^4} T_{\\mu\\nu} \\]\n\n\\(R_{\\mu\\nu}\\) is the Ricci tensor, which encodes information about the curvature of spacetime.\n\\(R\\) is the Ricci scalar, a measure of the overall curvature of spacetime.\n\\(g_{\\mu\\nu}\\) is the metric tensor, which describes the geometry of spacetime.\n\\(\\Lambda\\) is the cosmological constant, which represents the energy density of the vacuum of space.\n\\(G\\) is the gravitational constant, which determines the strength of the gravitational interaction.\n\\(c\\) is the speed of light in vacuum, which sets the scale for the relationship between space and time.\n\\(T_{\\mu\\nu}\\) is the stress-energy tensor, which describes the distribution of matter and energy in spacetime.\n\n(2) Symmetry groups are fundamental. They cannot be deduced from any structure inside the arena. They are additional data that come to us “out of the blue”, wihtout any explanation. These symmetries create a non-abelian group, which is currently:\n\\[\\mathrm{SU}(3) \\times \\mathrm{SU}(2) \\times \\mathrm{U}(1)\\]\ndef. non-abelian group: sometimes called a non-commutative group, is a group in which there exists at least one pair of elements a and b of G, such that a ∗ b ≠ b ∗ a.\nThis has a corresponding curvature equation, that says the curvature of an auxillary structure known as a guage potential, when differentiated in a particular way, is again equal to “the amount of stuff in the system that is not directly involved in the equation above”.\n\\[d^*_A F_A = J(\\psi)\\]\n\n\\(d_A\\) is the exterior covariant derivative associated with the connection A. It is a generalization of the standard exterior derivative to take into account the nontrivial connection structure of the gauge field.\n\\(F_A\\) is the curvature 2-form of the connection A. It encodes the non-Abelian nature of the gauge field and is given by the commutator of the connection 1-forms.\n\\(d_A^*\\) is the adjoint of the exterior covariant derivative, known as the codifferential. It maps p-forms to (p-1)-forms and is defined with respect to the metric on the underlying spacetime manifold.\n\\(J(\\psi)\\) is the source term associated with a spinor field ψ. It is usually expressed in terms of the Dirac equation, which relates the spinor ψ to a massless field that obeys the wave equation. The source term J encodes the coupling of the spinor to the gauge field, and in the case of the electromagnetic field, it is proportional to the electric charge of the particle.\n\nThe equation \\(d_A^* F_A = J(\\psi)\\) is a local differential equation that relates the curvature of a gauge field to the sources that generate it. It is a key ingredient in the formulation of gauge theories such as quantum chromodynamics and the electroweak theory, which describe the strong and electroweak interactions in particle physics. It also has applications in other areas of physics, such as condensed matter physics and general relativity.\n(3) Matter is assymetric and therefore light.\nWe have a Dirac equation coupled to a connection\n\\[ \\phi_A \\psi = \\mu \\psi \\]\n\nIn this equation, \\(\\psi\\) is a spinor field and \\(\\phi_A\\) is a differential operator that acts on \\(\\psi\\). The index \\(A\\) can represent different kinds of symmetry groups, such as the gauge group in a gauge theory. The equation states that the action of the operator \\(\\phi_A\\) on the spinor field \\(\\psi\\) yields a scalar multiple of \\(\\psi\\) with eigenvalue \\(\\mu\\). In other words, \\(\\psi\\) is an eigenvector of \\(\\phi_A\\) with eigenvalue \\(\\mu\\).\n\n\nThis equation has applications in several areas of physics, such as quantum field theory and condensed matter physics. For example, in condensed matter physics, \\(\\phi_A\\) can represent the Hamiltonian of a system, and \\(\\psi\\) can represent a wave function that describes the state of the system. The equation then describes how the system evolves over time.\n\nOne of the great insights: the reason for the lightness of matter in the natural mass scale of physics has to do with the fact that the psi should have 2 components and the differential operator should map to one component on the other side fo the equation but the mass operator should map to another. So if one of the components is missing, if the equation is intrinsically lobsided (ciral / assymetric), then the amss term and the differential term have difficulty interacting, which is overcompensating for the mass scale of the universe so you get to a point where you have to define a massless equation. Just like overshooting a putt, it’s easier to knock it back by putting in a Higgs Field in order to generate an “as-if” fundamental mass through the Yukawa couplings.\nEdward Witten went on to say one more thing\nThese three central observations must be supplemented by the idea that this all takes place in quantum mechanical fashion (or quantum field theoretic).\nIt’s more an after-market assumption rather than one of the core insights.\n\n\nEric’s Differences with the Community\nIs the quantum in good enough shape that we don’t know if we have a serious quantum mechanical problem or not. We know we have a quantum field problem relative to the current formulation of these theories, but we also know in other cases the quantum becomes incredible natural (sometimes almost magically). We don’t know if the true theories (the ones we need to be generalizing in some sense) have beautiful quantum mechanical treatments, whereas some of the effective theories we are dealing with now may not survive the quantumization.\nImagine a different sort of incompatability. Take the 3 theories and treat them as 3 vertices of a triangle.\n\nEinstein GR\nDirac\nYang, Mills, Maxwell, Anderson, Higgs\n\nLet’s explore the incompatabilities, not at the quantum level, but the geometric input. All 3 of these are geometric theories. What if the incompatability is at the geometry level before the theory is treated quantum mechanically?\nEinstein: We can rewrite by saying there is a\nTODO, ending here for now\n\n\nResponse & Discussion\n\nTimothy Nguyen and Theo Polya’s Response to GU"
  },
  {
    "objectID": "library/natural-sciences/physics/classical/index.html",
    "href": "library/natural-sciences/physics/classical/index.html",
    "title": "Classical",
    "section": "",
    "text": "Thermodynamics of Information\nLangrangian and Hamiltonian Mechanics\n\n\n\nEnergetics of Turbulent Fluids is a draft paper by Justin Beroz.\nHere are the notes I took while reading the paper:\n\n\n\nIn quantum mechanics, an eigenstate is a state of a quantum system that, when acted upon by an operator, produces a multiple of itself. The multiple is called the eigenvalue. In other words, an eigenstate is a state that has a definite value for a particular observable quantity.\nFor example, the eigenstates of the position operator are all the possible states of a particle that have a definite position. The eigenstates of the momentum operator are all the possible states of a particle that have a definite momentum.\nEigenstates are important in quantum mechanics because they allow us to calculate the probabilities of different outcomes for measurements of observable quantities. For example, if we know the eigenstates of the position operator for a particle, we can calculate the probability of finding the particle at a particular location.\nEigenstates are also important in quantum computing because they can be used to store information. For example, if we know the eigenstates of the position operator for a particle, we can use the particle to store a bit of information by placing it in a particular location.\nHere are some examples of eigenstates:\n\nThe eigenstates of the position operator for a particle in a one-dimensional box are all the functions of the form sin(nπx/L), - where n is an integer and L is the length of the box.\nThe eigenstates of the momentum operator for a particle in a one-dimensional box are all the functions of the form exp(ipx/L), where p is a real number.\nThe eigenstates of the energy operator for a hydrogen atom are all the functions of the form ∣nlm⟩, where n, l, and m are integers. Eigenstates are a fundamental concept in quantum mechanics and they play an important role in many areas of physics, including quantum computing, quantum chemistry, and quantum field theory.\n\n\n\n\nThe Navier-Stokes equations are a set of partial differential equations that describe the motion of viscous fluid substances. They were developed independently by French engineer and physicist Claude-Louis Navier and Anglo-Irish physicist and mathematician George Gabriel Stokes in the early 1800s. The equations are named after the two scientists.\nThe Navier-Stokes equations are a set of four equations, one for each of the three spatial dimensions and one for time. The equations relate the velocity, pressure, and density of the fluid to the forces acting on it. The equations are nonlinear, which means that they cannot be solved analytically in general. Instead, they must be solved numerically using computer simulations.\nThe Navier-Stokes equations are used in a wide variety of applications, including:\nAeronautics: The Navier-Stokes equations are used to design airplanes, helicopters, and other aircraft. Marine engineering: The Navier-Stokes equations are used to design ships, submarines, and other marine vessels. Civil engineering: The Navier-Stokes equations are used to design bridges, dams, and other structures that must withstand the forces of fluid flow. Meteorology: The Navier-Stokes equations are used to model weather patterns and predict the behavior of the atmosphere. Oceanography: The Navier-Stokes equations are used to model ocean currents and predict the behavior of the oceans. The Navier-Stokes equations are one of the most important equations in physics. They are essential for understanding the motion of fluids, and they have a wide range of applications in engineering, meteorology, oceanography, and other fields.\nThe Navier-Stokes equations are a Millennium Prize Problem, which means that the Clay Mathematics Institute has offered a $1,000,000 prize for the first correct solution to the problem. The problem is still unsolved, and it is one of the most difficult problems in mathematics.\n\n\n\nThe Kolmogorov energy cascade is a theory that describes the transfer of energy from large scales to small scales in turbulent flows. The theory was developed by Andrey Kolmogorov in the 1940s.\nThe Kolmogorov energy cascade is based on the following assumptions:\nThe turbulent flow is statistically homogeneous and isotropic. This means that the statistical properties of the flow are the same in all directions and at all points in the flow. The turbulent flow is in equilibrium. This means that the rate of energy input to the flow is equal to the rate of energy dissipation. The Kolmogorov energy cascade is a process by which energy is transferred from large scales to small scales in turbulent flows. The process is driven by the nonlinear interactions between the turbulent eddies. The large eddies break up into smaller eddies, which in turn break up into even smaller eddies. This process continues until the eddies are so small that they are dissipated by viscosity.\nThe Kolmogorov energy cascade is a very important process in turbulent flows. It is responsible for the mixing of fluids, the transport of heat and momentum, and the generation of sound. The Kolmogorov energy cascade is also a very complex process, and there is still much that is not understood about it.\nThe Kolmogorov energy cascade is named after Andrey Kolmogorov, a Russian mathematician who developed the theory in the 1940s. Kolmogorov was a pioneer in the study of turbulence, and his work has had a profound impact on our understanding of this complex phenomenon."
  },
  {
    "objectID": "library/natural-sciences/physics/classical/index.html#resources",
    "href": "library/natural-sciences/physics/classical/index.html#resources",
    "title": "Classical",
    "section": "",
    "text": "Thermodynamics of Information\nLangrangian and Hamiltonian Mechanics\n\n\n\nEnergetics of Turbulent Fluids is a draft paper by Justin Beroz.\nHere are the notes I took while reading the paper:\n\n\n\nIn quantum mechanics, an eigenstate is a state of a quantum system that, when acted upon by an operator, produces a multiple of itself. The multiple is called the eigenvalue. In other words, an eigenstate is a state that has a definite value for a particular observable quantity.\nFor example, the eigenstates of the position operator are all the possible states of a particle that have a definite position. The eigenstates of the momentum operator are all the possible states of a particle that have a definite momentum.\nEigenstates are important in quantum mechanics because they allow us to calculate the probabilities of different outcomes for measurements of observable quantities. For example, if we know the eigenstates of the position operator for a particle, we can calculate the probability of finding the particle at a particular location.\nEigenstates are also important in quantum computing because they can be used to store information. For example, if we know the eigenstates of the position operator for a particle, we can use the particle to store a bit of information by placing it in a particular location.\nHere are some examples of eigenstates:\n\nThe eigenstates of the position operator for a particle in a one-dimensional box are all the functions of the form sin(nπx/L), - where n is an integer and L is the length of the box.\nThe eigenstates of the momentum operator for a particle in a one-dimensional box are all the functions of the form exp(ipx/L), where p is a real number.\nThe eigenstates of the energy operator for a hydrogen atom are all the functions of the form ∣nlm⟩, where n, l, and m are integers. Eigenstates are a fundamental concept in quantum mechanics and they play an important role in many areas of physics, including quantum computing, quantum chemistry, and quantum field theory.\n\n\n\n\nThe Navier-Stokes equations are a set of partial differential equations that describe the motion of viscous fluid substances. They were developed independently by French engineer and physicist Claude-Louis Navier and Anglo-Irish physicist and mathematician George Gabriel Stokes in the early 1800s. The equations are named after the two scientists.\nThe Navier-Stokes equations are a set of four equations, one for each of the three spatial dimensions and one for time. The equations relate the velocity, pressure, and density of the fluid to the forces acting on it. The equations are nonlinear, which means that they cannot be solved analytically in general. Instead, they must be solved numerically using computer simulations.\nThe Navier-Stokes equations are used in a wide variety of applications, including:\nAeronautics: The Navier-Stokes equations are used to design airplanes, helicopters, and other aircraft. Marine engineering: The Navier-Stokes equations are used to design ships, submarines, and other marine vessels. Civil engineering: The Navier-Stokes equations are used to design bridges, dams, and other structures that must withstand the forces of fluid flow. Meteorology: The Navier-Stokes equations are used to model weather patterns and predict the behavior of the atmosphere. Oceanography: The Navier-Stokes equations are used to model ocean currents and predict the behavior of the oceans. The Navier-Stokes equations are one of the most important equations in physics. They are essential for understanding the motion of fluids, and they have a wide range of applications in engineering, meteorology, oceanography, and other fields.\nThe Navier-Stokes equations are a Millennium Prize Problem, which means that the Clay Mathematics Institute has offered a $1,000,000 prize for the first correct solution to the problem. The problem is still unsolved, and it is one of the most difficult problems in mathematics.\n\n\n\nThe Kolmogorov energy cascade is a theory that describes the transfer of energy from large scales to small scales in turbulent flows. The theory was developed by Andrey Kolmogorov in the 1940s.\nThe Kolmogorov energy cascade is based on the following assumptions:\nThe turbulent flow is statistically homogeneous and isotropic. This means that the statistical properties of the flow are the same in all directions and at all points in the flow. The turbulent flow is in equilibrium. This means that the rate of energy input to the flow is equal to the rate of energy dissipation. The Kolmogorov energy cascade is a process by which energy is transferred from large scales to small scales in turbulent flows. The process is driven by the nonlinear interactions between the turbulent eddies. The large eddies break up into smaller eddies, which in turn break up into even smaller eddies. This process continues until the eddies are so small that they are dissipated by viscosity.\nThe Kolmogorov energy cascade is a very important process in turbulent flows. It is responsible for the mixing of fluids, the transport of heat and momentum, and the generation of sound. The Kolmogorov energy cascade is also a very complex process, and there is still much that is not understood about it.\nThe Kolmogorov energy cascade is named after Andrey Kolmogorov, a Russian mathematician who developed the theory in the 1940s. Kolmogorov was a pioneer in the study of turbulence, and his work has had a profound impact on our understanding of this complex phenomenon."
  },
  {
    "objectID": "library/natural-sciences/physics/classical/index.html#beroz",
    "href": "library/natural-sciences/physics/classical/index.html#beroz",
    "title": "Classical",
    "section": "Beroz",
    "text": "Beroz\nWhat sort of world would we live in without turbulence? - blog - This relates to his claims on liquid energy transport. Sure, the theory is there, but there’s a few subtle assumptions in the theory that put a wrench in the practicality of his claims (aka, Jacob’s intuition was correct in being speculative of the efficiency claims). - “…and assuming the average flow to be steady and approximately two dimensional, can be expresses as…” - “…To determine these constant we need to include two boundary conditions for our river velocity…”\nSolving one of physics’ ‘last great mysteries’ with a new, huge, wind tunnel - paper - 10% of world electricity devoted to overcoming turbulence\nMacro-Quantum Behavior - MIT video - Veritasium video"
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/index.html#magnetohydrodynamics",
    "href": "library/natural-sciences/physics/electromagnetism/index.html#magnetohydrodynamics",
    "title": "Electromagnetism",
    "section": "Magnetohydrodynamics",
    "text": "Magnetohydrodynamics\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism. The governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations.\n\nResources\n\nMagnetohydrodynamic drive\nApplication of Pulsed Electrical Fields for Advanced Cooling and Water Recovery in Coal-Fired Power Plant\nRunaway electrons during subnanosecond breakdowns in high-pressure gases\nLow-Temperature Atmospheric Pressure Plasma Processes for “Green” Third Generation Photovoltaics\nElectromagnetic Radiation: Ionizing and Non-ionizing\nAre Virtual Particles Less Real?\nRF Helicon-based Inductive Plasma Thruster (IPT) Design for an Atmosphere-Breathing Electric Propulsion System (ABEP)\nElectrothermal instability\nPulsed inductive thruster\nNASA Pulsed Inductive Thruster\nOn the performance of electrohydrodynamic propulsion\nElectrohydrodynamic thrust for in-atmosphere propulsion\nA Model of an Ideal Electrohydrodynamic Thruster\nModelling and simulation of plasma thrusters for electric propulsion technologies\nElectrohydrodynamic Drying Characteristics of Agar Gel\nModeling of Electrohydrodynamic (EHD) Plasma Thrusters: Optimization of Physical and Geometrical Parameters\nReview on the History, Research, and Applications of Electrohydrodynamics\nSuccessful experiments on an external MHD Accelerator\nMHD Air Breathing Propulsion and Power for Aerospace Applications\nNew Magnetohydrodynamic (MHD) Lift Concept for More Efficient Missions to Mars and Neptune\nGENERAL CONSIDERATIONS OF MHO ACCELERATION FOR AERODYNAMIC TESTING\nAnalysis of the Magnetohydrodynamic Behavior of the Fully Developed Flow of Conducting Fluid\nSpace-based laser-driven MHD generator [microform] : feasibility study\nWeak Solutions to Ideal MHD\n\n\n\nSummary\nMagnetohydrodynamics (MHD), also known as hydromagnetics, is a field in physics that studies the dynamics of electrically conducting fluids, particularly the interaction between magnetic fields and such fluids. These fluids could be plasma, liquid metals, or even seawater. MHD is a synthesis of fluid dynamics and electromagnetism.\nThe governing equations of MHD are the Navier-Stokes equations (in the limit of high Reynolds number) coupled with Maxwell’s equations. In the ideal MHD approximation, effects such as resistivity and viscosity are neglected, leading to a relatively simple set of governing equations:\n\nContinuity Equation: This equation ensures the conservation of mass.\n∂ρ/∂t + ∇·(ρv) = 0\nMomentum Equation: Combines Newton’s second law and the Lorentz force, accounting for the forces due to pressure gradients, gravity, and electromagnetic fields. In the absence of viscosity, this simplifies to:\nρ(∂v/∂t + v·∇v) = -∇p + ρg + (J×B)\nInduction Equation: Describes how the magnetic field evolves over time, given the fluid’s velocity and existing magnetic field.\n∂B/∂t = ∇×(v×B)\nEnergy Equation: This equation describes the conservation of energy, which is usually taken in the form of the first law of thermodynamics.\nAmpère’s Law with Maxwell’s Addition:\n∇×B = μ0J\nJ is the current density vector, B is the magnetic field, and μ0 is the magnetic permeability.\n\nIn these equations, ρ represents fluid density, v fluid velocity, p pressure, g gravitational acceleration, J current density, and B magnetic field.\nMHD has a wide range of applications, from studying astrophysical phenomena such as solar flares and accretion disks, to engineering applications like nuclear fusion research, liquid metal cooling in reactors, and even potential propulsion systems.\nHowever, real-world situations often involve non-ideal MHD where effects such as resistivity cannot be ignored. Understanding these effects often requires incorporating the full set of Maxwell’s equations and solving them alongside the fluid dynamics equations, which makes for a much more complex computational problem. In some non-ideal MHD scenarios, magnetic reconnection, turbulence, and other instabilities can occur, which are active research areas in this field."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/index.html#superconductivity",
    "href": "library/natural-sciences/physics/electromagnetism/index.html#superconductivity",
    "title": "Electromagnetism",
    "section": "Superconductivity",
    "text": "Superconductivity\n\nResources\n\nSuperconductivity and Quantum Mechanics at the Macro-Scale: Part 1 and Part 2\nPiezoelectricity-induced Room Temperature Superconductor\nMichael S Fuhrer: History of room-tempurature superconductors\nCould superconductors transmute electromagnetic radiation into gravitational waves?\nSuperconductors as quantum transducers and antennas for gravitational and electromagnetic radiation\nCould superconductors transmute electromagnetic radiation into gravitational waves?\n\n\n\nSummary\nSuperconductivity is a quantum mechanical phenomenon wherein certain materials, when cooled below a specific critical temperature, lose all electrical resistance and expel magnetic fields. The result is the unhindered flow of electric current, manifesting remarkable properties such as zero resistance and perfect diamagnetism. Initially discovered in simple elements like lead and mercury, superconducting properties have since been found in various alloys and complex materials.\nThe phenomenon of superconductivity was first discovered by Dutch physicist Heike Kamerlingh Onnes in 1911 while experimenting with mercury at temperatures close to absolute zero. Subsequent decades led to the development of multiple theories, with John Bardeen, Leon Cooper, and John Schrieffer collectively proposing the BCS Theory in 1957. This theory described how electrons form “Cooper pairs” in a lattice, facilitating the zero-resistance state. In 1986, the discovery of high-temperature superconductors by Georg Bednorz and K. Alex Müller ushered in renewed interest and research because these materials could superconduct at temperatures much higher than those required for simple elements.\nSuperconductivity is highly important because of its transformative implications for energy transmission and storage. Its properties can potentially revolutionize fields ranging from transportation to medical technology. Because superconductors exhibit zero electrical resistance, they offer the potential for incredibly efficient energy transmission systems, minimizing energy loss.\nApplications\n\nMagnetic Resonance Imaging (MRI): Superconducting magnets are fundamental to the high-resolution imaging achievable in modern MRI machines.\nMaglev Trains: Magnetic levitation (Maglev) trains use superconducting magnets for frictionless, high-speed travel.\nParticle Accelerators: Superconductors are crucial for the powerful magnets in particle accelerators like the Large Hadron Collider.\nPower Grids: Superconducting cables can dramatically increase the efficiency of power transmission.\nQuantum Computing: Superconducting circuits form the basis for some types of quantum bits, or “qubits,” central to quantum computing.\n\nRelevant Subtopics\n\nType I and Type II Superconductors: Type I superconductors are pure elements that expel all magnetic fields, whereas Type II superconductors are typically compounds or alloys that allow some penetration of magnetic fields.\nCooper Pairs: Understanding how electrons pair up to move through the lattice structure of superconductors without scattering is essential to understanding the phenomenon.\nBCS Theory: Bardeen-Cooper-Schrieffer Theory is the quantum mechanical explanation for superconductivity in conventional superconductors.\nHigh-Temperature Superconductors: These materials can superconduct at temperatures much higher than conventional superconductors, albeit still at very low temperatures by everyday standards.\nJosephson Junctions: These are thin insulating barriers or weak links between superconductors, and they exhibit unique quantum behaviors.\nVortices in Type II Superconductors: When magnetic fields penetrate a Type II superconductor, they do so at discrete points and form vortices, which has its own area of study and applications.\nApplications and Devices: From SQUIDs (Superconducting Quantum Interference Devices) to fault current limiters, many devices utilize superconducting properties for various applications."
  },
  {
    "objectID": "library/natural-sciences/physics/electromagnetism/index.html#lk-99",
    "href": "library/natural-sciences/physics/electromagnetism/index.html#lk-99",
    "title": "Electromagnetism",
    "section": "LK-99",
    "text": "LK-99\nThe story of the (alleged) first room-tempurature ambient-pressure superconductor.\nSuperconductivity is a magic phenomenon that permits leviatation, lossless energy transfer & storage, and countless other beautiful technologies to exist. There are known materials who are superconductors at low tempuratures, and the room tempurature superconductor has been a holy grail of materials science for many decades.\nIn July, 2023, a pre-print journal out of South Korea claimed to have discovered the “First Room-Temperature Ambient-Pressure Superconductor”. The paper generated a ton of excitement, a newfound interest in materials science, and much discussion of room temp SC implications.\n…but the paper is (and always has been) just noise.\n\nTimeline of Events\n\nJuly 22\n\n📑 Publication: The First Room-Temperature Ambient-Pressure Superconductor\n📝 Note: Original papers are released twice. The first release, suspected to beat the second, includes only 3 authors, making the team eligible for a Nobel Prize.\n\n\n\nJuly 26\n\n🐦 Prediction: I predict the superconductor hype (“we are so fucking back”) is mostly noise.\n\n\n\nJuly 27\n\n📝 Blog Post: Douglas Natelson publishes a blog post expressing a pessimistic view on the situation.\n💬 Commentary: Condensed Matter Theory Center deconstructs “the non-experimental parts of the Korean room temp SC claims.”\n⏳ Trend: Hype ensues and magnifies as people rush to replicate the study/results.\n\n\n\nJuly 29\n\n📑 Publication: First-principles study on the electronic structure of \\(Pb_{10−x}Cu_x(PO_4)_6O (x=0, 1)\\)\n\n\n\nJuly 31\n\n📑 Publication: Synthesis of possible room temperature superconductor \\(LK-99:Pb_9Cu(PO_4)_6O\\)\n🚫 Replication Failure: Semiconducting transport in \\(Pb_{10-x}Cu_x(PO_4)_6O\\) sintered from \\(Pb_2SO_5\\) and \\(Cu_3P\\)\n\n\n\nAugust 4\n\n💡 Theory: A theoretical explanation for LK-99 is released by Sinead Griffin out of Berkeley.\n📑 Publication: Origin of correlated isolated flat bands in copper-substituted lead phosphate apatite.\n\n\n\nAugust 6\n\n📝 Claim: Group claims LK-99 is a ferromagnet (NOT a superconductor).\n📑 Publication: Ferromagnetic half levitation of LK-99-like synthetic samples\n\n\nAsides\nAuthor of the original paper, Hyun-Tak Kim, from 2018\nWhy does BCS theory fail to explain superconductivity at high temperatures?"
  },
  {
    "objectID": "library/natural-sciences/maths/physics.html",
    "href": "library/natural-sciences/maths/physics.html",
    "title": "Maths x Physics",
    "section": "",
    "text": "My Encounters - as a Physicist - with Mathematics\n\n\n\nDonaldson theory is a branch of mathematics that is concerned with the topology of four-dimensional manifolds. It is named after Simon Donaldson, a British mathematician who made significant contributions to the field in the 1980s.\nThe central problem in Donaldson theory is to understand the topology of four-dimensional manifolds using differential geometry and algebraic topology. Specifically, the theory focuses on the study of vector bundles and connections on these manifolds, and how they can be used to classify different types of four-dimensional manifolds.\nOne of the key results in Donaldson theory is Donaldson’s theorem, which states that the intersection form of a smooth, closed, simply-connected four-dimensional manifold can be recovered from its Seiberg-Witten invariants. The Seiberg-Witten invariants are a set of numbers that can be associated with a four-dimensional manifold and its spin-c structure. They were introduced by Edward Witten and Nathan Seiberg in the mid-1990s and have proven to be a powerful tool in the study of four-dimensional manifolds.\nDonaldson theory has applications in a variety of fields, including physics, where it has been used to study the topology of spacetime in string theory and other areas of theoretical physics. It has also had significant impact in pure mathematics, inspiring further research in the fields of algebraic geometry, topology, and differential geometry.\n\n\n\n\nLie Algebras in Particle Physics\n\nLie Algebras in particle physics are mathematical structures that help to describe and classify physical systems, particularly those involving symmetries and transformations. In essence, a Lie algebra is a vector space equipped with a certain kind of product, called the Lie bracket, that captures the essential information about continuous transformations and symmetries. When applied to particle physics, Lie algebras offer a robust framework for understanding the fundamental particles and forces that govern the universe.\nThe concept of Lie algebras originated in the late 19th century with the work of Norwegian mathematician Sophus Lie. Originally developed to study continuous transformation groups, the scope of Lie algebras has expanded to diverse areas of mathematics and physics. Their application in particle physics became increasingly significant during the 20th century, especially after the development of quantum mechanics and quantum field theory. The SU(3) Lie algebra, for example, was crucial in predicting the existence of particles like the omega-minus baryon before it was experimentally discovered.\nLie algebras offer a theoretical structure that is essential for formulating the Standard Model of particle physics, which describes electromagnetic, weak, and strong forces. Because Lie algebras are tightly connected to symmetry principles, they enable physicists to simplify complex systems and make predictions about particle interactions.\nApplications\n\nParticle Classification: Used for the classification of elementary particles into families and generations, assisting in the prediction of undiscovered particles.\nSymmetry Breaking: Helps in understanding the mechanism by which symmetry breaking occurs, a phenomenon critical to our understanding of the universe.\nField Theories: Employed in various quantum field theories to solve or approximate solutions for complex equations of motion.\nUnification Theories: Lie algebras and their corresponding Lie groups have been essential in attempts to develop Grand Unified Theories (GUTs) and even theories of everything.\n\nRelevant Subtopics\n\nBasic Definitions and Principles: Introduction to Lie groups, Lie algebras, and the relationship between them.\nRepresentation Theory: How Lie algebras can be represented as matrices, and why these representations are useful in particle physics.\nSU(N) Algebras: Special Unitary Groups of degree (N) and their importance in particle physics.\nSymmetry and Conservation Laws: Discussion on how Lie algebras relate to symmetries in physical systems and the corresponding conservation laws.\nApplication to the Standard Model: Utilizing Lie algebras to describe the particles and interactions within the Standard Model.\nAdvanced Topics: Covering roots, weights, Dynkin diagrams, and their role in particle physics."
  },
  {
    "objectID": "library/natural-sciences/physics/relativity/index.html#black-holes",
    "href": "library/natural-sciences/physics/relativity/index.html#black-holes",
    "title": "Relativity",
    "section": "Black Holes",
    "text": "Black Holes\n\nBlack Holes Evade Heat Death\nEffective Action for the Hawking Process\nSupermassive Black Hole Binary\nProbing Supermassive Black Hole Merges and Stalling with Pulsar Timing Arrays\nAbell 1201: detection of an ultramassive black hole in a strong gravitational lens\nMath Proof Draws New Boundaries Around Black Hole Formation\n\nQuanta article\n\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\nGeneralized Black Hole Entropy is von Neumann Entropy\n\n\nEquation for a Rotating Black Hole: A Discussion\n\\[\n\\begin{aligned}\nd s^2= & -\\left(1-\\frac{2 m r}{r^2+a^2 \\cos ^2 \\theta}\\right)\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)^2 \\\\\n& +2\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)\\left(d r-a \\sin ^2 \\theta d \\tilde{\\phi}\\right) \\\\\n& +\\left(r^2+a^2 \\cos ^2 \\theta\\right)\\left(d \\theta^2+\\sin ^2 \\theta d \\tilde{\\phi}^2\\right)\n\\end{aligned}\n\\]\nThread\n\nThis metric equation is valid under the assumption that light propagates at any location around the BH with constant speed. Thus then spacetime gets extremly curved. But if we assume that spacetime remains flat, then we have to rewrite this as what is the local light propagation velocity tensor. Under that assumption this velocity will become equal to the EH surface for a location at the EH. Because still remains valid that nothing can exceed the local speed of light, this means that all matter will come at rest at the EH with every particle wave function frozen on that surface. Nothing ever traverses the EH. All accumulates on it. The BH grows by accumulating frozen matter at its EH surface.\nExactly. In other words, if you take the reference frame of light, you’ll see that the EH is pushed to oo, and all matter will be contained between the photon horizon (r=3M) and the EH (r=2M). (Is our universe rotating?)\nYou can’t take the reference frame of light. In every reference frame the light speed is the same, so “in the reference frame of light” makes no sense because there time is stopped. The EH can’t be seen on oo because for an observer between PS and EH there are a finite number of oscillations of his time reference from PS to EH. The assumption that the universe could rotate leads to a complication of all physical laws. We would get that there then has to be a rotation axis of the universe and that all rules are different with relation to that axis so that speed along the rotation direction can exceed c with any multiple without problems of inertia. This is similar to the Hubble expansion with the difference of an absolute rotation axis. That is why I reject both assumptions. It makes no sense to assume that space rotates. We rotate inside space. It also makes no sense to assume that space expands. We shrink inside space. The big one, space, is invariant, flat, not rotating, not translating, not curving. The small, what is inside space, rotates, translates, changes size. The only property of space that has a variation is that the propagation speed of light depends on the mass/energy density distribution in space.\nIsn’t it easier for Hawking radiation to escape if black holes have hair? So it’s not perfectly curved there. How does this equation differ from the superfluid quantum gravity spinning vortice(s) model of black holes?\n@bgreene marveled about the beauty of the equation. He didn’t gave a judgement about its validity. I gave an explanation on what assumptions are needed to allow this metric equation to be applicable. You come with the concept of a radiating BH. That only asks wether a particle pair of matter and antimatter could split such that one falks into, and one escapes the BH. But since the propagation speed of light at the EH is equal to the EH nothing moves there. So a hairy EH would assume that this propagation speed distribution is not smooth. This then should lead to particle wave functions to start from “stand still” and move outward. Such phenomen would need a different metric equation, but would not alter the beauty of the equation that @bgreene mentioned."
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html",
    "href": "library/natural-sciences/computing/classical/index.html",
    "title": "Classical",
    "section": "",
    "text": "CPUs are designed for serialized execution: fault tolerant, low latency. A CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores."
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html#classical-computing",
    "href": "library/natural-sciences/computing/classical/index.html#classical-computing",
    "title": "Computer Hardware",
    "section": "",
    "text": "CPUs are designed for serialized execution: fault tolerant, low latency\nA CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\nTODO: more content coming soon\n\n\n\nGraphics Processing Units are designed for parallel procesing: high throughout, less control logic.\nApple’s GPU cores are split into 16 execution units, where each of these has 8 algorithmic logic units (ALUs). When NVIDIA says they have “8960 CUDA Cores” this is referring to ALUs. ALUs are the fundamental operating units.\nCUDA is a software framework by NVIDIA to simplify parallelization.\n\n\nSupercut Presentation, July 2023\nThe HGX H100 H100 has 35,000 components and 8 Hopper GPUs. It weighs 60 pounds, and costs $200,000. The compute tray is the first computer with a transformer engine in it.\nThere’s 2 fundamental trends: CPU scaling has ended, and AI has begun (accelerated computing). the tipping point, NVIDIA GPU utilization is high.\nComparison: $10mm\n\n960 CPUs, consumes 11GWh, 1x LLM\n48 GPUs, consumes 3.2 GWh, 44x LLM (performance)\n\n\n\n\n\nRISC (Reduced Instruction Set Computer) is a design philosophy for CPUs, emphasizing a small and simple set of instructions that execute in a single clock cycle. RISC-V, on the other hand, is a specific, open-standard instruction set architecture (ISA) based on the RISC principles.\nWhile RISC and RISC-V are primarily associated with CPUs, the concepts and ISAs can be applied elsewhere. In fact, with the advent of more versatile computing platforms and the demand for specialized hardware accelerators, the lines between CPUs, GPUs, and other processing units can sometimes blur.\nGPUs and RISC: GPUs (Graphics Processing Units) have a different historical design lineage than CPUs. While CPUs are designed for general-purpose tasks and can handle a wide variety of operations in sequence, GPUs are designed for parallelism, optimized for executing the same operation on a large number of data elements simultaneously. This design is especially suitable for graphics rendering tasks, where, for instance, the same shading operation might be applied to millions of pixels.\nThat said, modern GPUs have evolved and can handle more general-purpose tasks. This field, known as GPGPU (General-Purpose computing on Graphics Processing Units), has grown in prominence, especially with applications in scientific computing, machine learning, etc.\nThe instruction set architectures for GPUs are typically proprietary to the manufacturer: - NVIDIA GPUs use an architecture known as CUDA (Compute Unified Device Architecture). - AMD GPUs use architectures like GCN (Graphics Core Next) or RDNA.\nWhile these architectures might share some high-level concepts with RISC — like the importance of efficiency and streamlined operations — they’re not RISC architectures in the traditional sense.\nRISC-V and GPUs: RISC-V, given its open nature, is seeing exploration beyond traditional CPUs. There are projects and discussions around using RISC-V principles in GPU design or other specialized hardware accelerators. However, as of my last training data in September 2021, RISC-V’s primary traction is in the CPU space, from microcontrollers to more powerful processors.\nIn conclusion, while RISC and RISC-V are primarily associated with CPUs, the principles and architectures are versatile. The GPU world has its architectures optimized for its specific tasks, but the lines between these domains are evolving, and there’s potential for overlap in the future.\n\n\n\nDesigning a virtual machine (VM) specifically optimized for GPUs and AI operations is not just a sensible idea, but it’s also a direction in which some sectors of the tech industry are heading. Let’s explore why this is a compelling notion and what features or characteristics such a VM might possess.\n\n\n\n\nSpecialized Operations: AI operations, especially deep learning, involve a lot of matrix multiplications and tensor operations. Traditional VMs are not optimized for these.\nMassive Parallelism: GPUs are inherently parallel and can handle thousands of threads simultaneously. A VM designed with this in mind would cater to this strength.\nMemory Management: Deep learning models, especially larger ones, can consume significant amounts of memory. Effective and efficient memory management tailored for these operations can greatly boost performance.\nInteroperability: AI frameworks and libraries are vast and varied (TensorFlow, PyTorch, ONNX, etc.). A VM optimized for AI could provide native support or efficient bridges for these frameworks.\n\n\n\n\n\nTensor Operations: First-class support for tensor operations would be a fundamental feature. This means native operations for matrix multiplications, convolutions, etc., optimized for the VM.\nDynamic Scheduling: Given the parallel nature of GPUs, the VM should be capable of dynamically scheduling tasks based on GPU workloads, ensuring maximum hardware utilization.\nMemory Hierarchies: GPUs have various memory types (global, shared, local, constant). The VM should manage these efficiently, allocating memory based on access patterns and tensor sizes.\nCustom Instruction Sets: The VM’s bytecode or intermediate representation might have custom instructions tailored for common AI patterns and operations.\nJust-In-Time (JIT) Compilation: To squeeze out maximum performance, the VM could utilize JIT compilation, translating bytecode to GPU instructions on the fly, with optimizations based on the actual data and model being processed.\nHardware Acceleration: Besides standard GPU operations, there could be support for AI-specific hardware accelerators or ASICs (like Google’s TPUs).\nNative Libraries: Integrated support for popular deep learning libraries or primitives, ensuring optimized performance without redundant operations.\nSafety and Security: With AI models being deployed in critical applications, features to ensure model integrity, data privacy, and secure execution would be essential.\nPortability: One of the core benefits of a VM is portability. The VM should ensure that AI models run consistently across various GPU architectures and versions.\nInteroperability Bridges: Efficient connectors or bridges to interact with popular AI frameworks, ensuring smooth deployment without significant model rewrites.\nDebugging and Profiling: Built-in tools for performance profiling, debugging, and visualization, catering specifically to AI operations.\n\nIn essence, the idea of a virtual machine optimized for GPUs and AI operations seeks to bridge the gap between high-level AI frameworks and the raw power of GPU hardware. While creating such a VM is a non-trivial task and demands deep integration between software and hardware, the potential benefits in terms of performance, security, and portability make it a compelling direction for the future of AI infrastructure.\nAs of my last update in September 2021, there isn’t a mainstream “virtual machine” tailored explicitly for GPUs in the same way that the Java Virtual Machine (JVM) or the Ethereum Virtual Machine (EVM) are for their respective domains. However, there are platforms and runtime environments optimized for GPU operations, especially in the context of AI/ML.\nSome of these platforms and their unique features include:\n\nCUDA (Compute Unified Device Architecture):\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nProvides a parallel computing platform and API model.\nIncorporates the CUDA Instruction Set Architecture (ISA) and the parallel compute engine in NVIDIA GPUs.\nSupports various high-level programming languages like C, C++, and Fortran.\n\nUse Cases: General GPU-accelerated computing, scientific simulations, deep learning training & inference.\n\nTensorRT:\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nHigh-performance deep learning inference optimizer and runtime.\nReduces the model size for faster inferencing.\nProvides INT8 and FP16 optimizations for production deployments.\n\nUse Cases: Optimizing and deploying deep learning models for production environments, especially on NVIDIA GPUs.\n\nROCm (Radeon Open Compute):\n\nDeveloper & Manufacturer: AMD\nUnique Features:\n\nOpen-source platform for GPU-enabled HPC (High Performance Computing) computing.\nSupports a range of machine learning frameworks like TensorFlow and PyTorch.\n\nUse Cases: GPU-accelerated computing on AMD GPUs, scientific simulations, AI/ML training & inference.\n\nDirectML:\n\nDeveloper: Microsoft\nUnique Features:\n\nPart of the DirectX family, providing a low-level API for ML.\nHardware-accelerated and works with any DirectX 12-compatible GPU.\n\nUse Cases: GPU-accelerated ML inference in Windows applications.\n\n\nThese platforms are more akin to runtime environments than traditional “virtual machines.” Still, they are optimized for GPU operations, and they play a role similar to VMs by providing a bridge between high-level code and low-level hardware instructions.\nMain Benefits of GPU-optimized Platforms: 1. Performance: Accelerate computations that can be parallelized, dramatically reducing the time required for tasks like training deep learning models. 2. Efficiency: Better utilization of available GPU resources, ensuring that the hardware’s full capabilities are harnessed. 3. Portability: In some cases (like CUDA to some extent), the platform provides an abstraction over the hardware, allowing code to run on different GPU architectures (within limits and considering vendor lock-ins). 4. Integration with Popular Tools: Many of these platforms offer integrations with popular ML frameworks, making it easier to transition from research to production.\nHowever, it’s essential to understand that while these platforms provide the tools and runtime for GPU-optimized operations, they don’t function as “virtual machines” in the traditional sense of emulating a complete computing environment. They are closer to specialized compilers and runtime environments."
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html#hardware",
    "href": "library/natural-sciences/computing/classical/index.html#hardware",
    "title": "Classical Computing",
    "section": "",
    "text": "TODO: more content coming soon"
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html#cpus-1",
    "href": "library/natural-sciences/computing/classical/index.html#cpus-1",
    "title": "Classical Computing",
    "section": "CPUs",
    "text": "CPUs\nCPUs are designed for serialized execution: fault tolerant, low latency. A CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores.\n\nRISC Architecture\nRISC (Reduced Instruction Set Computer) is a design philosophy for CPUs, emphasizing a small and simple set of instructions that execute in a single clock cycle. RISC-V, on the other hand, is a specific, open-standard instruction set architecture (ISA) based on the RISC principles.\nWhile RISC and RISC-V are primarily associated with CPUs, the concepts and ISAs can be applied elsewhere. In fact, with the advent of more versatile computing platforms and the demand for specialized hardware accelerators, the lines between CPUs, GPUs, and other processing units can sometimes blur.\nGPUs and RISC: GPUs (Graphics Processing Units) have a different historical design lineage than CPUs. While CPUs are designed for general-purpose tasks and can handle a wide variety of operations in sequence, GPUs are designed for parallelism, optimized for executing the same operation on a large number of data elements simultaneously. This design is especially suitable for graphics rendering tasks, where, for instance, the same shading operation might be applied to millions of pixels.\nThat said, modern GPUs have evolved and can handle more general-purpose tasks. This field, known as GPGPU (General-Purpose computing on Graphics Processing Units), has grown in prominence, especially with applications in scientific computing, machine learning, etc.\nThe instruction set architectures for GPUs are typically proprietary to the manufacturer: - NVIDIA GPUs use an architecture known as CUDA (Compute Unified Device Architecture). - AMD GPUs use architectures like GCN (Graphics Core Next) or RDNA.\nWhile these architectures might share some high-level concepts with RISC — like the importance of efficiency and streamlined operations — they’re not RISC architectures in the traditional sense.\nRISC-V and GPUs: RISC-V, given its open nature, is seeing exploration beyond traditional CPUs. There are projects and discussions around using RISC-V principles in GPU design or other specialized hardware accelerators. However, as of my last training data in September 2021, RISC-V’s primary traction is in the CPU space, from microcontrollers to more powerful processors.\nIn conclusion, while RISC and RISC-V are primarily associated with CPUs, the principles and architectures are versatile. The GPU world has its architectures optimized for its specific tasks, but the lines between these domains are evolving, and there’s potential for overlap in the future.\n\n\nDesigning a VM for GPUs\nDesigning a virtual machine (VM) specifically optimized for GPUs and AI operations is not just a sensible idea, but it’s also a direction in which some sectors of the tech industry are heading. Let’s explore why this is a compelling notion and what features or characteristics such a VM might possess.\n\n\nRationale:\n\nSpecialized Operations: AI operations, especially deep learning, involve a lot of matrix multiplications and tensor operations. Traditional VMs are not optimized for these.\nMassive Parallelism: GPUs are inherently parallel and can handle thousands of threads simultaneously. A VM designed with this in mind would cater to this strength.\nMemory Management: Deep learning models, especially larger ones, can consume significant amounts of memory. Effective and efficient memory management tailored for these operations can greatly boost performance.\nInteroperability: AI frameworks and libraries are vast and varied (TensorFlow, PyTorch, ONNX, etc.). A VM optimized for AI could provide native support or efficient bridges for these frameworks.\n\n\n\nFeatures/Characteristics:\n\nTensor Operations: First-class support for tensor operations would be a fundamental feature. This means native operations for matrix multiplications, convolutions, etc., optimized for the VM.\nDynamic Scheduling: Given the parallel nature of GPUs, the VM should be capable of dynamically scheduling tasks based on GPU workloads, ensuring maximum hardware utilization.\nMemory Hierarchies: GPUs have various memory types (global, shared, local, constant). The VM should manage these efficiently, allocating memory based on access patterns and tensor sizes.\nCustom Instruction Sets: The VM’s bytecode or intermediate representation might have custom instructions tailored for common AI patterns and operations.\nJust-In-Time (JIT) Compilation: To squeeze out maximum performance, the VM could utilize JIT compilation, translating bytecode to GPU instructions on the fly, with optimizations based on the actual data and model being processed.\nHardware Acceleration: Besides standard GPU operations, there could be support for AI-specific hardware accelerators or ASICs (like Google’s TPUs).\nNative Libraries: Integrated support for popular deep learning libraries or primitives, ensuring optimized performance without redundant operations.\nSafety and Security: With AI models being deployed in critical applications, features to ensure model integrity, data privacy, and secure execution would be essential.\nPortability: One of the core benefits of a VM is portability. The VM should ensure that AI models run consistently across various GPU architectures and versions.\nInteroperability Bridges: Efficient connectors or bridges to interact with popular AI frameworks, ensuring smooth deployment without significant model rewrites.\nDebugging and Profiling: Built-in tools for performance profiling, debugging, and visualization, catering specifically to AI operations.\n\nIn essence, the idea of a virtual machine optimized for GPUs and AI operations seeks to bridge the gap between high-level AI frameworks and the raw power of GPU hardware. While creating such a VM is a non-trivial task and demands deep integration between software and hardware, the potential benefits in terms of performance, security, and portability make it a compelling direction for the future of AI infrastructure.\nAs of my last update in September 2021, there isn’t a mainstream “virtual machine” tailored explicitly for GPUs in the same way that the Java Virtual Machine (JVM) or the Ethereum Virtual Machine (EVM) are for their respective domains. However, there are platforms and runtime environments optimized for GPU operations, especially in the context of AI/ML.\nSome of these platforms and their unique features include:\n\nCUDA (Compute Unified Device Architecture):\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nProvides a parallel computing platform and API model.\nIncorporates the CUDA Instruction Set Architecture (ISA) and the parallel compute engine in NVIDIA GPUs.\nSupports various high-level programming languages like C, C++, and Fortran.\n\nUse Cases: General GPU-accelerated computing, scientific simulations, deep learning training & inference.\n\nTensorRT:\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nHigh-performance deep learning inference optimizer and runtime.\nReduces the model size for faster inferencing.\nProvides INT8 and FP16 optimizations for production deployments.\n\nUse Cases: Optimizing and deploying deep learning models for production environments, especially on NVIDIA GPUs.\n\nROCm (Radeon Open Compute):\n\nDeveloper & Manufacturer: AMD\nUnique Features:\n\nOpen-source platform for GPU-enabled HPC (High Performance Computing) computing.\nSupports a range of machine learning frameworks like TensorFlow and PyTorch.\n\nUse Cases: GPU-accelerated computing on AMD GPUs, scientific simulations, AI/ML training & inference.\n\nDirectML:\n\nDeveloper: Microsoft\nUnique Features:\n\nPart of the DirectX family, providing a low-level API for ML.\nHardware-accelerated and works with any DirectX 12-compatible GPU.\n\nUse Cases: GPU-accelerated ML inference in Windows applications.\n\n\nThese platforms are more akin to runtime environments than traditional “virtual machines.” Still, they are optimized for GPU operations, and they play a role similar to VMs by providing a bridge between high-level code and low-level hardware instructions.\nMain Benefits of GPU-optimized Platforms: 1. Performance: Accelerate computations that can be parallelized, dramatically reducing the time required for tasks like training deep learning models. 2. Efficiency: Better utilization of available GPU resources, ensuring that the hardware’s full capabilities are harnessed. 3. Portability: In some cases (like CUDA to some extent), the platform provides an abstraction over the hardware, allowing code to run on different GPU architectures (within limits and considering vendor lock-ins). 4. Integration with Popular Tools: Many of these platforms offer integrations with popular ML frameworks, making it easier to transition from research to production.\nHowever, it’s essential to understand that while these platforms provide the tools and runtime for GPU-optimized operations, they don’t function as “virtual machines” in the traditional sense of emulating a complete computing environment. They are closer to specialized compilers and runtime environments."
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html#cpus",
    "href": "library/natural-sciences/computing/classical/index.html#cpus",
    "title": "Classical",
    "section": "",
    "text": "CPUs are designed for serialized execution: fault tolerant, low latency. A CPU has a large control unit, a few ALUs, and usually only 8 to 16 cores. A GPU, on the other hand, can feature 11,000 cores."
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html#gpus",
    "href": "library/natural-sciences/computing/classical/index.html#gpus",
    "title": "Classical",
    "section": "GPUs",
    "text": "GPUs\nGraphics Processing Units are designed for parallel procesing: high throughout, less control logic.\nApple’s GPU cores are split into 16 execution units, where each of these has 8 algorithmic logic units (ALUs). When NVIDIA says they have “8960 CUDA Cores” this is referring to ALUs. ALUs are the fundamental operating units.\nCUDA is a software framework by NVIDIA to simplify parallelization.\n\nNVIDIA \nSupercut Presentation, July 2023\nThe HGX H100 H100 has 35,000 components and 8 Hopper GPUs. It weighs 60 pounds, and costs $200,000. The compute tray is the first computer with a transformer engine in it.\nThere’s 2 fundamental trends: CPU scaling has ended, and AI has begun (accelerated computing). the tipping point, NVIDIA GPU utilization is high.\nComparison: $10mm\n\n960 CPUs, consumes 11GWh, 1x LLM\n48 GPUs, consumes 3.2 GWh, 44x LLM (performance)"
  },
  {
    "objectID": "library/natural-sciences/computing/classical/index.html#risc-architecture",
    "href": "library/natural-sciences/computing/classical/index.html#risc-architecture",
    "title": "Classical",
    "section": "RISC Architecture",
    "text": "RISC Architecture\nRISC (Reduced Instruction Set Computer) is a design philosophy for CPUs, emphasizing a small and simple set of instructions that execute in a single clock cycle. RISC-V, on the other hand, is a specific, open-standard instruction set architecture (ISA) based on the RISC principles.\nWhile RISC and RISC-V are primarily associated with CPUs, the concepts and ISAs can be applied elsewhere. In fact, with the advent of more versatile computing platforms and the demand for specialized hardware accelerators, the lines between CPUs, GPUs, and other processing units can sometimes blur.\nGPUs and RISC\nGPUs (Graphics Processing Units) have a different historical design lineage than CPUs. While CPUs are designed for general-purpose tasks and can handle a wide variety of operations in sequence, GPUs are designed for parallelism, optimized for executing the same operation on a large number of data elements simultaneously. This design is especially suitable for graphics rendering tasks, where, for instance, the same shading operation might be applied to millions of pixels.\nThat said, modern GPUs have evolved and can handle more general-purpose tasks. This field, known as GPGPU (General-Purpose computing on Graphics Processing Units), has grown in prominence, especially with applications in scientific computing, machine learning, etc.\nThe instruction set architectures for GPUs are typically proprietary to the manufacturer: - NVIDIA GPUs use an architecture known as CUDA (Compute Unified Device Architecture). - AMD GPUs use architectures like GCN (Graphics Core Next) or RDNA.\nWhile these architectures might share some high-level concepts with RISC — like the importance of efficiency and streamlined operations — they’re not RISC architectures in the traditional sense.\nRISC-V and GPUs\nRISC-V, given its open nature, is seeing exploration beyond traditional CPUs. There are projects and discussions around using RISC-V principles in GPU design or other specialized hardware accelerators. However, as of my last training data in September 2021, RISC-V’s primary traction is in the CPU space, from microcontrollers to more powerful processors.\nIn conclusion, while RISC and RISC-V are primarily associated with CPUs, the principles and architectures are versatile. The GPU world has its architectures optimized for its specific tasks, but the lines between these domains are evolving, and there’s potential for overlap in the future.\n\nDesigning a VM for GPUs\nDesigning a virtual machine (VM) specifically optimized for GPUs and AI operations is not just a sensible idea, but it’s also a direction in which some sectors of the tech industry are heading. Let’s explore why this is a compelling notion and what features or characteristics such a VM might possess.\n\n\nRationale:\n\nSpecialized Operations: AI operations, especially deep learning, involve a lot of matrix multiplications and tensor operations. Traditional VMs are not optimized for these.\nMassive Parallelism: GPUs are inherently parallel and can handle thousands of threads simultaneously. A VM designed with this in mind would cater to this strength.\nMemory Management: Deep learning models, especially larger ones, can consume significant amounts of memory. Effective and efficient memory management tailored for these operations can greatly boost performance.\nInteroperability: AI frameworks and libraries are vast and varied (TensorFlow, PyTorch, ONNX, etc.). A VM optimized for AI could provide native support or efficient bridges for these frameworks.\n\n\n\nFeatures/Characteristics:\n\nTensor Operations: First-class support for tensor operations would be a fundamental feature. This means native operations for matrix multiplications, convolutions, etc., optimized for the VM.\nDynamic Scheduling: Given the parallel nature of GPUs, the VM should be capable of dynamically scheduling tasks based on GPU workloads, ensuring maximum hardware utilization.\nMemory Hierarchies: GPUs have various memory types (global, shared, local, constant). The VM should manage these efficiently, allocating memory based on access patterns and tensor sizes.\nCustom Instruction Sets: The VM’s bytecode or intermediate representation might have custom instructions tailored for common AI patterns and operations.\nJust-In-Time (JIT) Compilation: To squeeze out maximum performance, the VM could utilize JIT compilation, translating bytecode to GPU instructions on the fly, with optimizations based on the actual data and model being processed.\nHardware Acceleration: Besides standard GPU operations, there could be support for AI-specific hardware accelerators or ASICs (like Google’s TPUs).\nNative Libraries: Integrated support for popular deep learning libraries or primitives, ensuring optimized performance without redundant operations.\nSafety and Security: With AI models being deployed in critical applications, features to ensure model integrity, data privacy, and secure execution would be essential.\nPortability: One of the core benefits of a VM is portability. The VM should ensure that AI models run consistently across various GPU architectures and versions.\nInteroperability Bridges: Efficient connectors or bridges to interact with popular AI frameworks, ensuring smooth deployment without significant model rewrites.\nDebugging and Profiling: Built-in tools for performance profiling, debugging, and visualization, catering specifically to AI operations.\n\nIn essence, the idea of a virtual machine optimized for GPUs and AI operations seeks to bridge the gap between high-level AI frameworks and the raw power of GPU hardware. While creating such a VM is a non-trivial task and demands deep integration between software and hardware, the potential benefits in terms of performance, security, and portability make it a compelling direction for the future of AI infrastructure.\nAs of my last update in September 2021, there isn’t a mainstream “virtual machine” tailored explicitly for GPUs in the same way that the Java Virtual Machine (JVM) or the Ethereum Virtual Machine (EVM) are for their respective domains. However, there are platforms and runtime environments optimized for GPU operations, especially in the context of AI/ML.\nSome of these platforms and their unique features include:\n\nCUDA (Compute Unified Device Architecture):\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nProvides a parallel computing platform and API model.\nIncorporates the CUDA Instruction Set Architecture (ISA) and the parallel compute engine in NVIDIA GPUs.\nSupports various high-level programming languages like C, C++, and Fortran.\n\nUse Cases: General GPU-accelerated computing, scientific simulations, deep learning training & inference.\n\nTensorRT:\n\nDeveloper & Manufacturer: NVIDIA\nUnique Features:\n\nHigh-performance deep learning inference optimizer and runtime.\nReduces the model size for faster inferencing.\nProvides INT8 and FP16 optimizations for production deployments.\n\nUse Cases: Optimizing and deploying deep learning models for production environments, especially on NVIDIA GPUs.\n\nROCm (Radeon Open Compute):\n\nDeveloper & Manufacturer: AMD\nUnique Features:\n\nOpen-source platform for GPU-enabled HPC (High Performance Computing) computing.\nSupports a range of machine learning frameworks like TensorFlow and PyTorch.\n\nUse Cases: GPU-accelerated computing on AMD GPUs, scientific simulations, AI/ML training & inference.\n\nDirectML:\n\nDeveloper: Microsoft\nUnique Features:\n\nPart of the DirectX family, providing a low-level API for ML.\nHardware-accelerated and works with any DirectX 12-compatible GPU.\n\nUse Cases: GPU-accelerated ML inference in Windows applications.\n\n\nThese platforms are more akin to runtime environments than traditional “virtual machines.” Still, they are optimized for GPU operations, and they play a role similar to VMs by providing a bridge between high-level code and low-level hardware instructions.\nMain Benefits of GPU-optimized Platforms\n\nPerformance: Accelerate computations that can be parallelized, dramatically reducing the time required for tasks like training deep learning models.\nEfficiency: Better utilization of available GPU resources, ensuring that the hardware’s full capabilities are harnessed.\nPortability: In some cases (like CUDA to some extent), the platform provides an abstraction over the hardware, allowing code to run on different GPU architectures (within limits and considering vendor lock-ins).\nIntegration with Popular Tools: Many of these platforms offer integrations with popular ML frameworks, making it easier to transition from research to production.\n\nHowever, it’s essential to understand that while these platforms provide the tools and runtime for GPU-optimized operations, they don’t function as “virtual machines” in the traditional sense of emulating a complete computing environment. They are closer to specialized compilers and runtime environments."
  },
  {
    "objectID": "library/natural-sciences/physics/field-theory/index.html#resources",
    "href": "library/natural-sciences/physics/field-theory/index.html#resources",
    "title": "Field Theory",
    "section": "",
    "text": "Brief History of Guage Field Physics\nThe Unreasonable Effectiveness of Quantum Field Theory\nIntroduction to Genralized Global Symmetries in QFT and Particle Physics\nLectures on Field Theory and the Standard Model: A Symmetry-Oriented Approach\nScattering Amplitudes in Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nEPFL Lectures on General Relativity as a Quantum Field Theory\n\n\n\nIn physics and mathematics, a gauge group is a group of transformations that preserves the fundamental properties of a physical or mathematical system. Gauge groups are important in both classical and quantum field theories, as well as in the study of differential geometry and topology.\nIn the context of physics, gauge groups are used to describe the symmetries of a physical system. For example, in electromagnetism, the gauge group is the group of local phase transformations that leave the electromagnetic potential and field strength unchanged. Similarly, in the theory of the strong force, the gauge group is the group of local color transformations that leave the quark-gluon field strength unchanged.\nIn mathematics, gauge groups arise in the study of connections on vector bundles over a manifold. The gauge group is the group of transformations of the connection that leave the curvature of the connection invariant. These groups play an important role in the study of the topology and geometry of manifolds, and have applications in areas such as mathematical physics, algebraic geometry, and topology.\nOne of the key features of gauge groups is that the physical or mathematical properties of a system are invariant under gauge transformations. This means that different gauge choices can be made for the same physical or mathematical system, without affecting its essential properties. This property is known as gauge invariance and is a fundamental concept in many areas of physics and mathematics.\n\n\n\nThe Yang-Mills theory is a quantum field theory that describes the behavior of particles known as gauge bosons, which mediate the strong nuclear force. The theory is based on the idea of local gauge symmetry, which means that the fundamental equations of the theory are invariant under certain transformations of the fields that describe the particles.\nThe Yang-Mills equations describe the behavior of the gauge bosons, which are particles that transmit the strong force between quarks. The equations involve a set of mathematical terms that describe the interactions between the gauge bosons and the quarks.\nThe Yang-Mills equations are based on a set of mathematical objects known as gauge fields, which describe the behavior of the gauge bosons. The gauge fields are represented by a set of matrices, which are used to calculate the interactions between the gauge bosons and the quarks.\nThe equations are formulated using the mathematical concept of a gauge group, which describes the possible transformations that can be made to the gauge fields. In the case of the strong force, the gauge group is called SU(3), which stands for special unitary group of degree 3.\nThe Yang-Mills equations involve two terms: the kinetic term and the interaction term. The kinetic term describes the free motion of the gauge bosons, while the interaction term describes the interactions between the gauge bosons and the quarks.\nThe kinetic term involves the gauge field strength tensor, which is a mathematical object that describes the strength of the gauge field at each point in spacetime. The interaction term involves the coupling constant, which is a parameter that describes the strength of the interaction between the gauge bosons and the quarks.\nThe Yang-Mills equations are highly non-linear and require advanced mathematical techniques to solve. They are also closely related to the concept of gauge invariance, which means that the equations are invariant under certain transformations of the gauge fields.\nOverall, the Yang-Mills theory provides a mathematical framework for describing the behavior of the strong nuclear force, which is one of the four fundamental forces of nature. The theory has been extensively tested and is an important component of the Standard Model of particle physics, which describes the behavior of all known elementary particles and their interactions."
  },
  {
    "objectID": "library/natural-sciences/physics/astrophysics/index.html",
    "href": "library/natural-sciences/physics/astrophysics/index.html",
    "title": "Astrophysics",
    "section": "",
    "text": "The Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry\nEinstein, Barcelona, Symmetry & Cosmology: The Birth of an Equation for the Universe\nSeeing the Gravitational Wave Universe\nNASA Selects 5 Missions for 2024 Total Solar Eclipse\nJames Webb Images\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nHolography of the Photon Ring\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics\nDiscovery of Gamma Rays from the Quiescent Sun with HAWC\n10 galaxies that existed just 830 million years after the Big Bang The seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster.\n\n\n\n\nInteracting Dark Matter - Phenomenology and Implications for Cosmology\nNew shape of parity-violating graviton non-Gaussianity | Explainer"
  },
  {
    "objectID": "library/natural-sciences/physics/astrophysics/index.html#cosmology",
    "href": "library/natural-sciences/physics/astrophysics/index.html#cosmology",
    "title": "Astrophysics",
    "section": "",
    "text": "The Pseudo-Conformal Universe: Scale Invariance from Spontaneous Breaking of Conformal Symmetry\nEinstein, Barcelona, Symmetry & Cosmology: The Birth of an Equation for the Universe\nSeeing the Gravitational Wave Universe\nNASA Selects 5 Missions for 2024 Total Solar Eclipse\nJames Webb Images\nPlanck 2018 Results, Cosmological Parameters\nWebb Telescope finds surprising evidence of well-formed early galaxies\nHolography of the Photon Ring\nSun blasts out highest-energy radiation ever recorded, raising questions for solar physics\nDiscovery of Gamma Rays from the Quiescent Sun with HAWC\n10 galaxies that existed just 830 million years after the Big Bang The seven galaxies highlighted in this image from the NASA/ESA/CSA Telescope have been confirmed to be at a distance that astronomers refer to as redshift 7.9, which correlates to 650 million years after the big bang. This makes them the earliest galaxies yet to be spectroscopically confirmed as part of a developing cluster.\n\n\n\n\nInteracting Dark Matter - Phenomenology and Implications for Cosmology\nNew shape of parity-violating graviton non-Gaussianity | Explainer"
  },
  {
    "objectID": "library/natural-sciences/maths/physics.html#general",
    "href": "library/natural-sciences/maths/physics.html#general",
    "title": "Maths x Physics",
    "section": "",
    "text": "My Encounters - as a Physicist - with Mathematics\n\n\n\nDonaldson theory is a branch of mathematics that is concerned with the topology of four-dimensional manifolds. It is named after Simon Donaldson, a British mathematician who made significant contributions to the field in the 1980s.\nThe central problem in Donaldson theory is to understand the topology of four-dimensional manifolds using differential geometry and algebraic topology. Specifically, the theory focuses on the study of vector bundles and connections on these manifolds, and how they can be used to classify different types of four-dimensional manifolds.\nOne of the key results in Donaldson theory is Donaldson’s theorem, which states that the intersection form of a smooth, closed, simply-connected four-dimensional manifold can be recovered from its Seiberg-Witten invariants. The Seiberg-Witten invariants are a set of numbers that can be associated with a four-dimensional manifold and its spin-c structure. They were introduced by Edward Witten and Nathan Seiberg in the mid-1990s and have proven to be a powerful tool in the study of four-dimensional manifolds.\nDonaldson theory has applications in a variety of fields, including physics, where it has been used to study the topology of spacetime in string theory and other areas of theoretical physics. It has also had significant impact in pure mathematics, inspiring further research in the fields of algebraic geometry, topology, and differential geometry.\n\n\n\n\nLie Algebras in Particle Physics\n\nLie Algebras in particle physics are mathematical structures that help to describe and classify physical systems, particularly those involving symmetries and transformations. In essence, a Lie algebra is a vector space equipped with a certain kind of product, called the Lie bracket, that captures the essential information about continuous transformations and symmetries. When applied to particle physics, Lie algebras offer a robust framework for understanding the fundamental particles and forces that govern the universe.\nThe concept of Lie algebras originated in the late 19th century with the work of Norwegian mathematician Sophus Lie. Originally developed to study continuous transformation groups, the scope of Lie algebras has expanded to diverse areas of mathematics and physics. Their application in particle physics became increasingly significant during the 20th century, especially after the development of quantum mechanics and quantum field theory. The SU(3) Lie algebra, for example, was crucial in predicting the existence of particles like the omega-minus baryon before it was experimentally discovered.\nLie algebras offer a theoretical structure that is essential for formulating the Standard Model of particle physics, which describes electromagnetic, weak, and strong forces. Because Lie algebras are tightly connected to symmetry principles, they enable physicists to simplify complex systems and make predictions about particle interactions.\nApplications\n\nParticle Classification: Used for the classification of elementary particles into families and generations, assisting in the prediction of undiscovered particles.\nSymmetry Breaking: Helps in understanding the mechanism by which symmetry breaking occurs, a phenomenon critical to our understanding of the universe.\nField Theories: Employed in various quantum field theories to solve or approximate solutions for complex equations of motion.\nUnification Theories: Lie algebras and their corresponding Lie groups have been essential in attempts to develop Grand Unified Theories (GUTs) and even theories of everything.\n\nRelevant Subtopics\n\nBasic Definitions and Principles: Introduction to Lie groups, Lie algebras, and the relationship between them.\nRepresentation Theory: How Lie algebras can be represented as matrices, and why these representations are useful in particle physics.\nSU(N) Algebras: Special Unitary Groups of degree (N) and their importance in particle physics.\nSymmetry and Conservation Laws: Discussion on how Lie algebras relate to symmetries in physical systems and the corresponding conservation laws.\nApplication to the Standard Model: Utilizing Lie algebras to describe the particles and interactions within the Standard Model.\nAdvanced Topics: Covering roots, weights, Dynkin diagrams, and their role in particle physics."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#astrophysics",
    "href": "library/natural-sciences/physics/index.html#astrophysics",
    "title": "Physics",
    "section": "Astrophysics",
    "text": "Astrophysics\nAstrophysics is a branch of astronomy that applies the principles of physics and mathematics to understand the fundamental workings of the universe. It aims to explain the behavior and characteristics of astronomical objects, from stars and planets to galaxies and the entire universe itself.\n\nPrimary Subdomains\n\nCosmology - The study of the origin, structure, and eventual fate of the universe.\nStellar Astrophysics - Focuses on the physical properties and life cycles of stars.\nGalactic and Extragalactic Astronomy - Study of galaxies and structures beyond our galaxy.\nPlanetary Science - Study of planets, both within our solar system and beyond (exoplanets).\nHigh-Energy Astrophysics - Investigates phenomena that occur at extremely high energies, such as black holes, neutron stars, and gamma-ray bursts.\nAstrobiology - The study of the origin, evolution, and possibility of life elsewhere in the universe.\nObservational Astrophysics - Focuses on the data collection and interpretation, often via telescopes and other instruments.\nTheoretical Astrophysics - Concerned with developing theoretical models to describe astrophysical objects and phenomena.\n\n\n\nFields of Application\n\nAerospace Engineering - The understanding of celestial mechanics is crucial for space missions.\nClimate Studies - Understanding the Sun’s impact on Earth’s climate.\nComputer Science - Data from astrophysical observations often require sophisticated algorithms for interpretation.\nPublic Policy & Education - Findings in astrophysics often inform science policy and are popular subjects for educational outreach.\n\n\n\nAdditional Notes\n\nAstrophysics is highly interdisciplinary, often overlapping with particle physics, general relativity, and quantum mechanics to explain phenomena like dark matter, dark energy, and black holes.\nDue to the advancement in technology, there’s been a significant increase in the discovery rate of exoplanets, leading to more sub-specializations within the field.\nA number of Nobel Prizes have been awarded for astrophysical research, highlighting its importance and impact on our understanding of the universe.\n\nThis category serves as an essential foundation for understanding the complexities of the universe, helping to answer fundamental questions related to our existence and the nature of reality itself."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#materials-physics",
    "href": "library/natural-sciences/physics/index.html#materials-physics",
    "title": "Physics",
    "section": "Materials Physics",
    "text": "Materials Physics\nMaterials Physics is a subfield of condensed matter physics that focuses on the study of materials and their properties at the microscopic or atomic level. This branch of physics aims to understand how the individual components (atoms, molecules, etc.) of a material contribute to its macroscopic properties like strength, electrical conductivity, and thermal properties. Materials physics seeks not just to understand existing materials but also to predict and create new materials with desired properties.\n\nPrimary Subdomains\n\nElectronic Properties of Solids: Study of electrical, magnetic, and optical properties of solid materials.\nMechanical Properties: Exploration of strength, elasticity, and other mechanical properties of materials.\nMagnetic Materials: Study of ferromagnetism, antiferromagnetism, and various other kinds of magnetic ordering.\nPolymer Physics: Understanding the physical properties of polymers.\nNano-materials: Study of materials at the nanometer scale, often involving nano-particles, nano-composites, and nano-porous materials.\nBio-materials: Study of materials that interact with biological systems.\nSuperconductivity: Understanding materials that exhibit zero electrical resistance.\nPhotonic and Optoelectronic Materials: Materials designed to manipulate and utilize light (photons).\nSemiconductors: Materials that have a conductivity between conductors and insulators.\n\n\n\nFields of Application\n\nAerospace: Creation of materials that can withstand extreme conditions.\nElectronics: Development of more efficient semiconductors, conductors, and insulators.\nEnergy: Materials for better energy storage like batteries and supercapacitors.\nMedicine: Development of bio-compatible materials.\nTelecommunications: Optoelectronic materials for better data transmission.\nEnvironmental Science: Materials for pollution control and environmental remediation.\n\n\n\nAdditional Notes\nMaterials physics often overlaps with materials science, chemistry, and engineering in interdisciplinary research and applications. Advances in this field often rely on cutting-edge techniques in computational physics, quantum mechanics, and statistical mechanics."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#electromagnetism-1",
    "href": "library/natural-sciences/physics/index.html#electromagnetism-1",
    "title": "Relativity",
    "section": "Electromagnetism",
    "text": "Electromagnetism"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#relativity-1",
    "href": "library/natural-sciences/physics/index.html#relativity-1",
    "title": "Relativity",
    "section": "Relativity",
    "text": "Relativity\n\nResources\n\nLecture Notes on Holographic Renomalization\nAdS/CFT correspondence and Geometry (Hamilton-Jacobi approach to holographic renormalization)\nEPFL Lectures on General Relativity as a Quantum Field Theory\nGeneral Relativity as a Perturbative Quantum Field Theory\nEffective Field Physics (EFT) Methods of General Relativity\nHarmonic Springs and Gravity\nThe Role of Gravitation in Physics\n\n\n\nEinstein Field Equation\n\npaper\n\nThe Einstein field equation is a fundamental equation in general relativity that relates the geometry of spacetime to the distribution of matter and energy. The equation is given by:\n\\[R_{\\mu\\nu} - \\frac{1}{2}R g_{\\mu\\nu} + \\Lambda g_{\\mu\\nu} = \\frac{8\\pi G}{c^4} T_{\\mu\\nu}\\]\nwhere \\(R_{\\mu\\nu}\\) is the Ricci curvature tensor, \\(R\\) is the scalar curvature, \\(g_{\\mu\\nu}\\) is the metric tensor, \\(\\Lambda\\) is the cosmological constant, \\(G\\) is the gravitational constant, \\(c\\) is the speed of light, and \\(T_{\\mu\\nu}\\) is the stress-energy tensor.\nThe Ricci curvature tensor \\(R_{\\mu\\nu}\\) is a measure of the curvature of spacetime, and is related to the distribution of matter and energy through the stress-energy tensor \\(T_{\\mu\\nu}\\). The scalar curvature \\(R\\) is a measure of the overall curvature of spacetime, and is related to the Ricci curvature tensor through the Einstein field equation.\nThe metric tensor \\(g_{\\mu\\nu}\\) is a mathematical object that describes the geometry of spacetime. It specifies the distances between nearby points in spacetime and is used to calculate the curvature of spacetime. The cosmological constant \\(\\Lambda\\) is a parameter that was introduced by Einstein to allow for a static universe, but it is now thought to describe the energy density of the vacuum.\nThe stress-energy tensor \\(T_{\\mu\\nu}\\) describes the distribution of matter and energy in spacetime. It includes contributions from matter, radiation, and other forms of energy. The equation states that the curvature of spacetime is related to the distribution of matter and energy through the stress-energy tensor.\nIn summary, the Einstein field equation is a fundamental equation in general relativity that relates the geometry of spacetime to the distribution of matter and energy. It is a mathematical expression of the idea that matter and energy warp spacetime, and that the curvature of spacetime determines the motion of matter and energy.\n\n\nMinkowski Metric\nIn physics, the Minkowski metric (also known as the Minkowski spacetime or the Minkowski metric tensor) is a mathematical tool used to describe spacetime in special relativity. It is named after the German mathematician Hermann Minkowski, who developed the concept of spacetime as a four-dimensional manifold with a metric in the early 20th century.\nThe Minkowski metric describes the geometry of spacetime in special relativity. It is a mathematical object that assigns a distance or interval between two events in spacetime. In the Minkowski metric, the interval between two events is defined by:\n\\[ds^2 = -c^2 dt^2 + dx^2 + dy^2 + dz^2\\]\nwhere \\(ds\\) is the spacetime interval between two events, \\(c\\) is the speed of light, \\(dt\\) is the time interval between the two events, and \\(dx\\), \\(dy\\), and \\(dz\\) are the three spatial intervals between the two events. The minus sign in front of the \\(c^2 dt^2\\) term ensures that the interval is negative for timelike separations, which represent events that can be causally connected, and positive for spacelike separations, which represent events that cannot be causally connected. The Minkowski metric has a signature of (-, +, +, +), which means that the time interval has the opposite sign compared to the spatial intervals.\nThe Minkowski metric is a special case of the more general metric tensor used in general relativity. In general relativity, the metric tensor is a function of the curvature of spacetime caused by matter and energy, and it is used to describe the gravitational field. However, in special relativity, where there is no gravitational field, the metric tensor is simply the Minkowski metric, and it describes the flat spacetime of special relativity."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#black-holes",
    "href": "library/natural-sciences/physics/index.html#black-holes",
    "title": "Relativity",
    "section": "Black Holes",
    "text": "Black Holes\n\nBlack Holes Evade Heat Death\nEffective Action for the Hawking Process\nSupermassive Black Hole Binary\nProbing Supermassive Black Hole Merges and Stalling with Pulsar Timing Arrays\nAbell 1201: detection of an ultramassive black hole in a strong gravitational lens\nMath Proof Draws New Boundaries Around Black Hole Formation\n\nQuanta article\n\nA Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets\n\n\nEquation for a Rotating Black Hole: A Discussion\n\\[\n\\begin{aligned}\nd s^2= & -\\left(1-\\frac{2 m r}{r^2+a^2 \\cos ^2 \\theta}\\right)\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)^2 \\\\\n& +2\\left(d v-a \\sin ^2 \\theta d \\tilde{\\phi}\\right)\\left(d r-a \\sin ^2 \\theta d \\tilde{\\phi}\\right) \\\\\n& +\\left(r^2+a^2 \\cos ^2 \\theta\\right)\\left(d \\theta^2+\\sin ^2 \\theta d \\tilde{\\phi}^2\\right)\n\\end{aligned}\n\\]\nThread\n\nThis metric equation is valid under the assumption that light propagates at any location around the BH with constant speed. Thus then spacetime gets extremly curved. But if we assume that spacetime remains flat, then we have to rewrite this as what is the local light propagation velocity tensor. Under that assumption this velocity will become equal to the EH surface for a location at the EH. Because still remains valid that nothing can exceed the local speed of light, this means that all matter will come at rest at the EH with every particle wave function frozen on that surface. Nothing ever traverses the EH. All accumulates on it. The BH grows by accumulating frozen matter at its EH surface.\nExactly. In other words, if you take the reference frame of light, you’ll see that the EH is pushed to oo, and all matter will be contained between the photon horizon (r=3M) and the EH (r=2M). (Is our universe rotating?)\nYou can’t take the reference frame of light. In every reference frame the light speed is the same, so “in the reference frame of light” makes no sense because there time is stopped. The EH can’t be seen on oo because for an observer between PS and EH there are a finite number of oscillations of his time reference from PS to EH. The assumption that the universe could rotate leads to a complication of all physical laws. We would get that there then has to be a rotation axis of the universe and that all rules are different with relation to that axis so that speed along the rotation direction can exceed c with any multiple without problems of inertia. This is similar to the Hubble expansion with the difference of an absolute rotation axis. That is why I reject both assumptions. It makes no sense to assume that space rotates. We rotate inside space. It also makes no sense to assume that space expands. We shrink inside space. The big one, space, is invariant, flat, not rotating, not translating, not curving. The small, what is inside space, rotates, translates, changes size. The only property of space that has a variation is that the propagation speed of light depends on the mass/energy density distribution in space.\nIsn’t it easier for Hawking radiation to escape if black holes have hair? So it’s not perfectly curved there. How does this equation differ from the superfluid quantum gravity spinning vortice(s) model of black holes?\n@bgreene marveled about the beauty of the equation. He didn’t gave a judgement about its validity. I gave an explanation on what assumptions are needed to allow this metric equation to be applicable. You come with the concept of a radiating BH. That only asks wether a particle pair of matter and antimatter could split such that one falks into, and one escapes the BH. But since the propagation speed of light at the EH is equal to the EH nothing moves there. So a hairy EH would assume that this propagation speed distribution is not smooth. This then should lead to particle wave functions to start from “stand still” and move outward. Such phenomen would need a different metric equation, but would not alter the beauty of the equation that @bgreene mentioned."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#particle-physics-1",
    "href": "library/natural-sciences/physics/index.html#particle-physics-1",
    "title": "Relativity",
    "section": "Particle Physics",
    "text": "Particle Physics"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#unification",
    "href": "library/natural-sciences/physics/index.html#unification",
    "title": "Physics",
    "section": "Unification",
    "text": "Unification\nThe quest for a Theory of Everything (ToE) in physics is an endeavor to unify all fundamental forces and fields under a single, coherent theoretical framework. The primary goal is to reconcile quantum mechanics, which describes the forces of electromagnetism, weak nuclear force, and strong nuclear force, with general relativity, which describes gravity. Unification theories aim to provide a more elegant and simplified explanation for the complexities of the universe.\n\nPrimary Subdomains:\n\nGrand Unified Theories (GUTs) - These theories attempt to unify the electromagnetic, weak, and strong forces.\nQuantum Gravity - Theoretical frameworks like Loop Quantum Gravity and String Theory fall under this category, aiming to reconcile quantum mechanics with general relativity.\nSupersymmetry - A proposed extension of the standard space-time symmetries to unify fermions and bosons.\nHigher-Dimensional Theories - Such as Kaluza-Klein theory, which posits extra spatial dimensions to unify forces.\nPreon Theories - These hypothesize that quarks and leptons are made of more fundamental particles.\nCosmological Implications - Including models that address the Big Bang, inflation, and the fate of the universe within the framework of unification theories.\n\n\n\nFields of Application:\n\nHigh Energy Physics - Particle accelerators and colliders often test predictions made by unification theories.\nCosmology - The origins and large-scale structure of the universe could be better understood through a ToE.\nQuantum Computing - Understanding the unified forces could potentially unlock new computational paradigms.\nAstrophysics - Phenomena like black holes and neutron stars are better understood in the context of a unified theory.\n\n\n\nAdditional Notes:\n\nNo single unification theory has been universally accepted or proven yet, although String Theory is often cited as a leading candidate.\nExperimental verification remains a challenge due to the extreme conditions required to test these theories, often beyond current technological capabilities.\nPhilosophical implications also abound, particularly questions around determinism, free will, and the nature of reality itself.\n\nThis category sits at the intersection of several fundamental areas in physics and represents the cutting edge of our understanding of the physical universe."
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#unidentified-aerial-phenomena",
    "href": "library/natural-sciences/physics/index.html#unidentified-aerial-phenomena",
    "title": "Physics",
    "section": "Unidentified Aerial Phenomena",
    "text": "Unidentified Aerial Phenomena"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#field-theory-1",
    "href": "library/natural-sciences/physics/index.html#field-theory-1",
    "title": "Relativity",
    "section": "Field Theory",
    "text": "Field Theory"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#random",
    "href": "library/natural-sciences/physics/index.html#random",
    "title": "Physics",
    "section": "Random",
    "text": "Random\n\nTASI 2023: Aspects of Symmetry\nThe 8 Fallacies of Assembly Theory\nPhysics of the Analytic S-Matrix\nWorld from Eyes, Reconstruct 3D Scene from Someone’s Eyeball\nEd Witten Interview\nUnitarity"
  },
  {
    "objectID": "library/natural-sciences/physics/index.html#grand-unification",
    "href": "library/natural-sciences/physics/index.html#grand-unification",
    "title": "Physics",
    "section": "Grand Unification",
    "text": "Grand Unification\nThe quest for a Theory of Everything (ToE) in physics is an endeavor to unify all fundamental forces and fields under a single, coherent theoretical framework. The primary goal is to reconcile quantum mechanics, which describes the forces of electromagnetism, weak nuclear force, and strong nuclear force, with general relativity, which describes gravity. Unification theories aim to provide a more elegant and simplified explanation for the complexities of the universe.\n\nPrimary Subdomains\n\nGrand Unified Theories (GUTs) - These theories attempt to unify the electromagnetic, weak, and strong forces.\nQuantum Gravity - Theoretical frameworks like Loop Quantum Gravity and String Theory fall under this category, aiming to reconcile quantum mechanics with general relativity.\nSupersymmetry - A proposed extension of the standard space-time symmetries to unify fermions and bosons.\nHigher-Dimensional Theories - Such as Kaluza-Klein theory, which posits extra spatial dimensions to unify forces.\nPreon Theories - These hypothesize that quarks and leptons are made of more fundamental particles.\nCosmological Implications - Including models that address the Big Bang, inflation, and the fate of the universe within the framework of unification theories.\n\n\n\nFields of Application\n\nHigh Energy Physics - Particle accelerators and colliders often test predictions made by unification theories.\nCosmology - The origins and large-scale structure of the universe could be better understood through a ToE.\nQuantum Computing - Understanding the unified forces could potentially unlock new computational paradigms.\nAstrophysics - Phenomena like black holes and neutron stars are better understood in the context of a unified theory.\n\n\n\nAdditional Notes\n\nNo single unification theory has been universally accepted or proven yet, although String Theory is often cited as a leading candidate.\nExperimental verification remains a challenge due to the extreme conditions required to test these theories, often beyond current technological capabilities.\nPhilosophical implications also abound, particularly questions around determinism, free will, and the nature of reality itself.\n\nThis category sits at the intersection of several fundamental areas in physics and represents the cutting edge of our understanding of the physical universe."
  },
  {
    "objectID": "library/natural-sciences/ai/history-of-ai/index.html",
    "href": "library/natural-sciences/ai/history-of-ai/index.html",
    "title": "History of AI",
    "section": "",
    "text": "Timeline of AI\nHistory of Artificial Neural Networks\nDeep Learning History\n\n\n\nFrank Rosenblatt invented the perceptron, an algorithm for pattern recognition, which is essentially a single-layer neural network.\n\n\n\nShortly after, he went on to explore deeper, multilayer perceptrons. His MLPs had a non-learning first layer with randomized weights and an adaptive output layer. Although this was not yet deep learning, because only the last layer learned.\n\n\n\nSuccessful learning in deep feedforward network architectures started in 1965 in the Ukraine (back then the USSR) when Alexey Ivakhnenko & Valentin Lapa introduced the first general, working learning algorithms for deep MLPs with arbitrarily many hidden layers (already containing the now popular multiplicative gates). A paper of 1971 already described a deep learning net with 8 layers, trained by their highly cited method which was still popular in the new millennium, especially in Eastern Europe, where much of Machine Learning was born.\n\n\n\nIvakhnenko and Lapa (1965, see above) trained their deep networks layer by layer. In 1967, however, Shun-Ichi Amari suggested to train MLPs with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent, a method proposed in 1951 by Robbins & Monro.\nAmari’s implementation (with his student Saito) learned internal representations in a five layer MLP with two modifiable layers, which was trained to classify non-linearily separable pattern classes.\n\n\n\nKunihiko Fukushima introduced rectified linear units (ReLUs) for NNs (1969). They are now widely used in CNNs and other NNs.\n\n\n\nSeppo Linnainmaa was the first to publish what’s now known as backpropagation, the famous algorithm for credit assignment in networks of differentiable nodes, also known as “reverse mode of automatic differentiation.” It is now the foundation of widely used NN software packages such as PyTorch and Google’s Tensorflow.\n\n\n\nAmari published a paper on Amari-Hopfield networks, which resemble what’s now known as Recurrent Neural Networks (RNNs).\n\n\n\nComputer Vision was revolutionized in the 2010s by a particular feedforward NN called the convolutional NN (CNN). The basic CNN architecture with alternating convolutional and downsampling layers is due to Kunihiko Fukushima, 1979. He called it Neocognitron.\n\n\n\n\nThe Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project.\nThe UK began the £350 million Alvey project.\nDARPA founded the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n\n\n\nPhysicist John Hopfield was able to prove that a form of neural network (now called a “Hopfield net”) could learn and process information in a completely new way. This built on the Amari-Hopfield network from Amari’s 1972 publication\n\n\n\n\nGeoffrey Hinton “godfather of AI” invented the idea of multilayered neural networks, with nodes and weights. Node takes inputs and weights of inputs, outputs a signal if sum &gt; 0. - 1985 | A Learning Algorithm for Boltzmann Machines - 1986 | Learning representations by back-propagating errors\n\n\n\nDavid E. Rumelhart demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs. At least for supervised learning, backpropagation is generally more efficient than Amari’s above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier\nFeng-hsiung Hsu begins development on Chess-playing expert system called ChipTest. In 1988 it was moved to IBM and renamed Deep Thought, and then renamed again in 1989 to Deep Blue.\n\n\n\nGenerative Adversarial Networks (GANs) are first published in 1990 in Munich under the moniker Artificial Curiosity. Two dueling NNs (a probabilistic generator and a predictor) are trying to maximize each other’s loss in a minimax game. The generator (called the controller) generates probabilistic outputs (using stochastic units like in the much later StyleGANs). The predictor (called the world model) sees the outputs of the controller and predicts environmental reactions to them. Using gradient descent, the predictor NN minimizes its error, while the generator NN tries to make outputs that maximize this error: one net’s loss is the other net’s gain\n\n\n\nJiirgen Schmidhuber published a paper describing an alternative to RNNs: A feedforward NN slowly learns by gradient descent to program the changes of the fast weights of another NN. Such Fast Weight Programmers (FWPs) can learn to memorize past data, too. In 1991, one of them computed its fast weight changes through additive outer products of self-invented activation patterns (now often called keys and values for self-attention). The very similar Transformers combine this with projections and softmax and are now widely used in natural language processing. For long input sequences, their efficiency was improved through Transformers with linearized self-attention whose core is formally equivalent to the 1991 Fast Weight Programmers.\n\n\n\nSepp Hochreiter and Jurgen Schmidhuber published Long Short-Term Memory, the most cited NN paper of the 20th century. A later milestone was the “vanilla LSTM architecture” with forget gate — the LSTM variant of 1999-2000 that everybody is using today, e.g., in Google’s Tensorflow. Alex was lead author of our first successful application of LSTM to speech (2004). 2005 saw the first publication of LSTM with full backpropagation through time and of bi-directional LSTM (now widely used).\nAlso in 1997, Deep Blue beats Gary Kasparov in chess.\n\n\n\nImageNet is created, a large visual database envisioned by Fei-Fei Li from Stanford University, who realized that the best machine learning algorithms wouldn’t work well if the data didn’t reflect the real world. For many, ImageNet was the catalyst for the AI boom of the 21st century.\n\n\n\nX (formerly Google X) is an American semi-secret research and development facility and organization founded by Google in January 2010. X has its headquarters about a mile and a half from Alphabet’s corporate headquarters, the Googleplex, in Mountain View, California\nDeepMind was founded in the UK by Demis Hassabis, Shane Legg and Mustafa Suleyman in September 2010.\n\n\n\nThe Google Brain project began in 2011 as a part-time research collaboration between Google fellow Jeff Dean, Google Researcher Greg Corrado, and Stanford University professor Andrew Ng. Google Brain started as a Google X project and became so successful that it was graduated back to Google: Astro Teller has said that Google Brain paid for the entire cost of Google X.\n\n\n\nGeoffrey Hinton tests artificial deep neural network on a widely used image recogniztion test, called ImageNet. AlexNet was the program, scored 75% success, way better than competitors. This generates a ton of hype, and sparks more funding/research in AI, particularly image recognition.\n\n\n\nIn 2013, Geoffrey Hinton was acqui-hired by Google.\n\n\n\nThe attention mechanism is introduced, which would became the foundation for the Transformer.\n\n\n\nIn December 2015, Sam Altman, Greg Brockman, Reid Hoffman, Jessica Livingston, Peter Thiel, Elon Musk, Amazon Web Services (AWS), Infosys, and YC Research announced the formation of OpenAI and pledged over $1 billion to the venture.\nDecember 11, 2015 announcement by Greg Brockman and Ilya Sutskever.\n\n\n\n\nAlphaGo becomes supreme at Go\nGoogle Brain neural network learns secure encryption\n\nDecember 2016, OpenAI released “Universe”, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites, and other applications. Intended to be the reinforcement learning version of ImageNet.\n\n\n\nThe Google Brain team publishes a paper titled Attention is All You Need, introducing the Transformer - which is now an essential ingredient in many cutting edge models, particularly LLMs.\nThe key innovation is the idea of self-attention, a mechanism that allows the model to selectively choose which parts of the input to pay attention to rather than using the entire input equally.\nTransformers address RNN limitations by replacing recurrance with self attention. This weighs the importance of different parts of the input without having to maintain internal state. Much easier to parallize, and eliminates vanishing & exploding gradient problem.\nAlso 2017, Tesla poaches deep learning expert Andrej Karpathy from OpenAI to be its new head of Autopilot Vision.\n\n\n\n\nOpenAI Charter is published, which is later cited upon holding back powerful models like GPT-2.\nElon leaves OpenAI In early 2018, Musk told Sam Altman, another OpenAI founder, that he believed the venture had fallen fatally behind Google, people familiar with the matter said. Musk proposed a possible solution: He would take control of OpenAI and run it himself.\n\nAltman and OpenAI’s other founders rejected Musk’s proposal. Musk, in turn, walked away from the company — and reneged on a massive planned donation. The fallout from that conflict, culminating in the announcement of Musk’s departure on Feb 20, 2018, would shape the industry that’s changing the world, and the company at the heart of it.\nFebruary 20, 2018 announcement that Elon is departing. In the same month, OpenAI switched cloud providers from Amazon to Google, signing an agreement to spend at least $63 million with the tech giant over the next two years.\n\n\n\n\nOpenAI shifts from nonprofit to ‘capped-profit’ to attract capital.\n\nJuly 2019, Microsoft invests $1 billion in OpenAI to develop AI technologies on Microsoft Azure.\n\n\n\nOctober 2020, GPT-3 is released.\n\n\n\nOpenAI debtus DALL-E, text-to-image.\nDecember 2022, ChatGPT\n\n\n\nJanuary 2023, Microsoft buys 49% of OpenAI at $29 billion valuation.\nMarch 14, 2023: GPT-4.\nMay 2023, Governance of superintelligence blog published\nJuly 24, 2023: Attention is off by One"
  },
  {
    "objectID": "library/natural-sciences/ai/history-of-ai/index.html#resources",
    "href": "library/natural-sciences/ai/history-of-ai/index.html#resources",
    "title": "History of AI",
    "section": "",
    "text": "Timeline of AI\nHistory of Artificial Neural Networks\nDeep Learning History\n\n\n\nFrank Rosenblatt invented the perceptron, an algorithm for pattern recognition, which is essentially a single-layer neural network.\n\n\n\nShortly after, he went on to explore deeper, multilayer perceptrons. His MLPs had a non-learning first layer with randomized weights and an adaptive output layer. Although this was not yet deep learning, because only the last layer learned.\n\n\n\nSuccessful learning in deep feedforward network architectures started in 1965 in the Ukraine (back then the USSR) when Alexey Ivakhnenko & Valentin Lapa introduced the first general, working learning algorithms for deep MLPs with arbitrarily many hidden layers (already containing the now popular multiplicative gates). A paper of 1971 already described a deep learning net with 8 layers, trained by their highly cited method which was still popular in the new millennium, especially in Eastern Europe, where much of Machine Learning was born.\n\n\n\nIvakhnenko and Lapa (1965, see above) trained their deep networks layer by layer. In 1967, however, Shun-Ichi Amari suggested to train MLPs with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent, a method proposed in 1951 by Robbins & Monro.\nAmari’s implementation (with his student Saito) learned internal representations in a five layer MLP with two modifiable layers, which was trained to classify non-linearily separable pattern classes.\n\n\n\nKunihiko Fukushima introduced rectified linear units (ReLUs) for NNs (1969). They are now widely used in CNNs and other NNs.\n\n\n\nSeppo Linnainmaa was the first to publish what’s now known as backpropagation, the famous algorithm for credit assignment in networks of differentiable nodes, also known as “reverse mode of automatic differentiation.” It is now the foundation of widely used NN software packages such as PyTorch and Google’s Tensorflow.\n\n\n\nAmari published a paper on Amari-Hopfield networks, which resemble what’s now known as Recurrent Neural Networks (RNNs).\n\n\n\nComputer Vision was revolutionized in the 2010s by a particular feedforward NN called the convolutional NN (CNN). The basic CNN architecture with alternating convolutional and downsampling layers is due to Kunihiko Fukushima, 1979. He called it Neocognitron.\n\n\n\n\nThe Japanese Ministry of International Trade and Industry set aside $850 million for the Fifth generation computer project.\nThe UK began the £350 million Alvey project.\nDARPA founded the Strategic Computing Initiative and tripling its investment in AI between 1984 and 1988.\n\n\n\n\n\nPhysicist John Hopfield was able to prove that a form of neural network (now called a “Hopfield net”) could learn and process information in a completely new way. This built on the Amari-Hopfield network from Amari’s 1972 publication\n\n\n\n\nGeoffrey Hinton “godfather of AI” invented the idea of multilayered neural networks, with nodes and weights. Node takes inputs and weights of inputs, outputs a signal if sum &gt; 0. - 1985 | A Learning Algorithm for Boltzmann Machines - 1986 | Learning representations by back-propagating errors\n\n\n\nDavid E. Rumelhart demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs. At least for supervised learning, backpropagation is generally more efficient than Amari’s above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier\nFeng-hsiung Hsu begins development on Chess-playing expert system called ChipTest. In 1988 it was moved to IBM and renamed Deep Thought, and then renamed again in 1989 to Deep Blue.\n\n\n\nGenerative Adversarial Networks (GANs) are first published in 1990 in Munich under the moniker Artificial Curiosity. Two dueling NNs (a probabilistic generator and a predictor) are trying to maximize each other’s loss in a minimax game. The generator (called the controller) generates probabilistic outputs (using stochastic units like in the much later StyleGANs). The predictor (called the world model) sees the outputs of the controller and predicts environmental reactions to them. Using gradient descent, the predictor NN minimizes its error, while the generator NN tries to make outputs that maximize this error: one net’s loss is the other net’s gain\n\n\n\nJiirgen Schmidhuber published a paper describing an alternative to RNNs: A feedforward NN slowly learns by gradient descent to program the changes of the fast weights of another NN. Such Fast Weight Programmers (FWPs) can learn to memorize past data, too. In 1991, one of them computed its fast weight changes through additive outer products of self-invented activation patterns (now often called keys and values for self-attention). The very similar Transformers combine this with projections and softmax and are now widely used in natural language processing. For long input sequences, their efficiency was improved through Transformers with linearized self-attention whose core is formally equivalent to the 1991 Fast Weight Programmers.\n\n\n\nSepp Hochreiter and Jurgen Schmidhuber published Long Short-Term Memory, the most cited NN paper of the 20th century. A later milestone was the “vanilla LSTM architecture” with forget gate — the LSTM variant of 1999-2000 that everybody is using today, e.g., in Google’s Tensorflow. Alex was lead author of our first successful application of LSTM to speech (2004). 2005 saw the first publication of LSTM with full backpropagation through time and of bi-directional LSTM (now widely used).\nAlso in 1997, Deep Blue beats Gary Kasparov in chess.\n\n\n\nImageNet is created, a large visual database envisioned by Fei-Fei Li from Stanford University, who realized that the best machine learning algorithms wouldn’t work well if the data didn’t reflect the real world. For many, ImageNet was the catalyst for the AI boom of the 21st century.\n\n\n\nX (formerly Google X) is an American semi-secret research and development facility and organization founded by Google in January 2010. X has its headquarters about a mile and a half from Alphabet’s corporate headquarters, the Googleplex, in Mountain View, California\nDeepMind was founded in the UK by Demis Hassabis, Shane Legg and Mustafa Suleyman in September 2010.\n\n\n\nThe Google Brain project began in 2011 as a part-time research collaboration between Google fellow Jeff Dean, Google Researcher Greg Corrado, and Stanford University professor Andrew Ng. Google Brain started as a Google X project and became so successful that it was graduated back to Google: Astro Teller has said that Google Brain paid for the entire cost of Google X.\n\n\n\nGeoffrey Hinton tests artificial deep neural network on a widely used image recogniztion test, called ImageNet. AlexNet was the program, scored 75% success, way better than competitors. This generates a ton of hype, and sparks more funding/research in AI, particularly image recognition.\n\n\n\nIn 2013, Geoffrey Hinton was acqui-hired by Google.\n\n\n\nThe attention mechanism is introduced, which would became the foundation for the Transformer.\n\n\n\nIn December 2015, Sam Altman, Greg Brockman, Reid Hoffman, Jessica Livingston, Peter Thiel, Elon Musk, Amazon Web Services (AWS), Infosys, and YC Research announced the formation of OpenAI and pledged over $1 billion to the venture.\nDecember 11, 2015 announcement by Greg Brockman and Ilya Sutskever.\n\n\n\n\nAlphaGo becomes supreme at Go\nGoogle Brain neural network learns secure encryption\n\nDecember 2016, OpenAI released “Universe”, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites, and other applications. Intended to be the reinforcement learning version of ImageNet.\n\n\n\nThe Google Brain team publishes a paper titled Attention is All You Need, introducing the Transformer - which is now an essential ingredient in many cutting edge models, particularly LLMs.\nThe key innovation is the idea of self-attention, a mechanism that allows the model to selectively choose which parts of the input to pay attention to rather than using the entire input equally.\nTransformers address RNN limitations by replacing recurrance with self attention. This weighs the importance of different parts of the input without having to maintain internal state. Much easier to parallize, and eliminates vanishing & exploding gradient problem.\nAlso 2017, Tesla poaches deep learning expert Andrej Karpathy from OpenAI to be its new head of Autopilot Vision.\n\n\n\n\nOpenAI Charter is published, which is later cited upon holding back powerful models like GPT-2.\nElon leaves OpenAI In early 2018, Musk told Sam Altman, another OpenAI founder, that he believed the venture had fallen fatally behind Google, people familiar with the matter said. Musk proposed a possible solution: He would take control of OpenAI and run it himself.\n\nAltman and OpenAI’s other founders rejected Musk’s proposal. Musk, in turn, walked away from the company — and reneged on a massive planned donation. The fallout from that conflict, culminating in the announcement of Musk’s departure on Feb 20, 2018, would shape the industry that’s changing the world, and the company at the heart of it.\nFebruary 20, 2018 announcement that Elon is departing. In the same month, OpenAI switched cloud providers from Amazon to Google, signing an agreement to spend at least $63 million with the tech giant over the next two years.\n\n\n\n\nOpenAI shifts from nonprofit to ‘capped-profit’ to attract capital.\n\nJuly 2019, Microsoft invests $1 billion in OpenAI to develop AI technologies on Microsoft Azure.\n\n\n\nOctober 2020, GPT-3 is released.\n\n\n\nOpenAI debtus DALL-E, text-to-image.\nDecember 2022, ChatGPT\n\n\n\nJanuary 2023, Microsoft buys 49% of OpenAI at $29 billion valuation.\nMarch 14, 2023: GPT-4.\nMay 2023, Governance of superintelligence blog published\nJuly 24, 2023: Attention is off by One"
  },
  {
    "objectID": "library/natural-sciences/ai/history-of-ai/index.html#the-start-of-the-race",
    "href": "library/natural-sciences/ai/history-of-ai/index.html#the-start-of-the-race",
    "title": "History of AI",
    "section": "The Start of the Race",
    "text": "The Start of the Race\n\n2014: Attention, the Start of the Race\nThe attention mechanism is introduced, which would became the foundation for the Transformer.\n\n\n2015: OpenAI\nIn December 2015, Sam Altman, Greg Brockman, Reid Hoffman, Jessica Livingston, Peter Thiel, Elon Musk, Amazon Web Services (AWS), Infosys, and YC Research announced the formation of OpenAI and pledged over $1 billion to the venture.\nDecember 11, 2015 announcement by Greg Brockman and Ilya Sutskever.\n\n\n2016\n\nAlphaGo becomes supreme at Go\nGoogle Brain neural network learns secure encryption\n\nDecember 2016, OpenAI released “Universe”, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites, and other applications. Intended to be the reinforcement learning version of ImageNet.\n\n\n2017: Attention is All You Need\nThe Google Brain team publishes a paper titled Attention is All You Need, introducing the Transformer - which is now an essential ingredient in many cutting edge models, particularly LLMs.\nThe key innovation is the idea of self-attention, a mechanism that allows the model to selectively choose which parts of the input to pay attention to rather than using the entire input equally.\nTransformers address RNN limitations by replacing recurrance with self attention. This weighs the importance of different parts of the input without having to maintain internal state. Much easier to parallize, and eliminates vanishing & exploding gradient problem.\nAlso 2017, Tesla poaches deep learning expert Andrej Karpathy from OpenAI to be its new head of Autopilot Vision.\n\n\n2018\n\nOpenAI Charter is published, which is later cited upon holding back powerful models like GPT-2.\nElon leaves OpenAI In early 2018, Musk told Sam Altman, another OpenAI founder, that he believed the venture had fallen fatally behind Google, people familiar with the matter said. Musk proposed a possible solution: He would take control of OpenAI and run it himself.\n\nAltman and OpenAI’s other founders rejected Musk’s proposal. Musk, in turn, walked away from the company — and reneged on a massive planned donation. The fallout from that conflict, culminating in the announcement of Musk’s departure on Feb 20, 2018, would shape the industry that’s changing the world, and the company at the heart of it.\nFebruary 20, 2018 announcement that Elon is departing. In the same month, OpenAI switched cloud providers from Amazon to Google, signing an agreement to spend at least $63 million with the tech giant over the next two years.\n\n\n2019\n\nOpenAI shifts from nonprofit to ‘capped-profit’ to attract capital.\n\nJuly 2019, Microsoft invests $1 billion in OpenAI to develop AI technologies on Microsoft Azure.\n\n\n2020\nOctober 2020, GPT-3 is released.\n\n\nCont’d\nOpenAI debtus DALL-E, text-to-image.\nDecember 2022, ChatGPT\n\n\n2023\nJanuary 2023, Microsoft buys 49% of OpenAI at $29 billion valuation.\nMarch 14, 2023: GPT-4.\nMay 2023, Governance of superintelligence blog published\nJuly 24, 2023: Attention is off by One"
  },
  {
    "objectID": "library/natural-sciences/physics/materials/index.html",
    "href": "library/natural-sciences/physics/materials/index.html",
    "title": "Materials Physics",
    "section": "",
    "text": "Riddle Solved: Roman concrete\n\npaper\n\nA Novel Mineral-like Copper Phosphate Chloride with a Disordered Guest Structure: Crystal Chemistry and Magnetic Properties\n“Mix coconut oil and gasoline and pour it on asphalt on a hot day to disintegrate a roadbed”\nGasoline dissolves asphalt\nAmerican Elements"
  },
  {
    "objectID": "library/natural-sciences/physics/materials/index.html#resources",
    "href": "library/natural-sciences/physics/materials/index.html#resources",
    "title": "Materials Physics",
    "section": "",
    "text": "Riddle Solved: Roman concrete\n\npaper\n\nA Novel Mineral-like Copper Phosphate Chloride with a Disordered Guest Structure: Crystal Chemistry and Magnetic Properties\n“Mix coconut oil and gasoline and pour it on asphalt on a hot day to disintegrate a roadbed”\nGasoline dissolves asphalt\nAmerican Elements"
  },
  {
    "objectID": "library/natural-sciences/physics/materials/index.html#lead-copper-phosphate-compound",
    "href": "library/natural-sciences/physics/materials/index.html#lead-copper-phosphate-compound",
    "title": "Materials Physics",
    "section": "Lead Copper Phosphate Compound",
    "text": "Lead Copper Phosphate Compound\n\\[\n\\mathrm{Pb}_{10-x} \\mathrm{Cu}_x\\left(\\mathrm{PO}_4\\right)_6 \\mathrm{O}\n\\]\nThe chemical formula you’ve given is for a lead copper phosphate mineral that’s part of a larger solid solution series. Solid solution series occur when two or more different elements can substitute for each other in a mineral’s structure to a significant degree. Here, the variable x represents a range of compositions that can exist within this series.\nThe formula indicates that for every 6 units of phosphate (PO4) and one oxygen (O), there are 10-x lead (Pb) atoms and x copper (Cu) atoms. The “x” in the formula implies that the copper content can vary, essentially representing a range of similar minerals with varying amounts of copper and lead. As the copper content increases (x increases), the lead content decreases correspondingly.\nPlease note that this is a general explanation and the specifics of the mineral can vary greatly depending on its formation conditions and geological setting.\nIf you want to understand this equation thoroughly, you would need to delve into crystal chemistry and solid state physics.\nCrystal Chemistry: The substitution of Pb by Cu is possible due to similarities in their ionic radii and charge. Minerals form in specific crystalline structures and the substitution of one atom for another depends on these factors.\nSolid State Physics: The physical properties of this mineral series, such as its electrical conductivity or magnetic properties, would vary based on the exact ratio of Pb to Cu. Understanding these properties requires knowledge of solid state physics."
  },
  {
    "objectID": "library/natural-sciences/physics/materials/index.html#pre-war-steel",
    "href": "library/natural-sciences/physics/materials/index.html#pre-war-steel",
    "title": "Materials Physics",
    "section": "Pre-War Steel",
    "text": "Pre-War Steel\nRadioactivity in Steel Production After Nuclear Bombs\n\nSummary\nThe phrase “pre-war steel” is often used in relation to low-background steel, which is steel produced prior to the detonation of the first atomic bombs in the mid-1940s. It’s not that the steel produced before these explosions is stronger or of better quality, but it’s that the steel manufactured after the start of the atomic age is slightly radioactive.\nIn 1945, when the first atomic bombs were detonated during World War II, they released various radionuclides, including Carbon-14 and other radioactive isotopes, into the atmosphere. These isotopes circled the globe and were incorporated into many things, including the iron ore used to produce steel. As a result, steel produced after 1945 can exhibit slight radioactivity.\nThis can be an issue in certain sensitive applications where even the tiniest amount of background radiation can interfere with equipment operation or measurements, like Geiger counters, certain medical equipment, and scientific devices used in physics and geology. For these uses, pre-war or low-background steel, typically salvaged from pre-1945 ships and buildings, is often sought.\n\n\nResearch\n\nLow-Background Steel Wiki\nReadiation Damage Wiki\nRadiation Effects in Steel\nInvestigation of Natural Radioactivity and Dose Assessment over Steel Making Region\nEffects of Irradiation on Mechanical Properties\nIs neutron radiation exposure always detrimental to metals (steels)?\nEffects of Radiation Damage"
  },
  {
    "objectID": "library/natural-sciences/computing/quantum/index.html",
    "href": "library/natural-sciences/computing/quantum/index.html",
    "title": "Quantum",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization\nSimulating Quantum Computers Using OpenCL\nUpgrading qsim, Google Quantum AI’s Open Source Quantum Simulator\nClosed Timelike Curves Make Quantum and Classical Computing Equivalent\nRunning Quantum Software on a Classical Computer\nVariational Quantum Thermalization and the Future of Quantum Thermodynamics\nEvidence for the utility of quantum computing before fault tolerance\nQuantum Computation and Quantum Information\n\n\n\n\nWhat is the logical gate speed of a photonic quantum computer?\n\nSummary\nThe blog post, written by Terry Rudolph from PsiQuantum & Imperial College London, discusses the logical gate speed of a photonic quantum computer. The author argues that photonic quantum computers can perform computations orders of magnitude faster than superconducting qubit machines, even if every physical timescale of the photonic machine was slower. This is due to the unique properties of photonics, such as the ability to store/delay photons in long lengths of optical fiber with very low error rates, and the potential for active-volume architectures that can perform non-trivial computational gates more efficiently.\nNotes\n1. Photonic Quantum Computers: Photonic quantum computers use light (photons) to carry out quantum computations. They have the potential to perform computations faster than superconducting qubit machines due to their unique properties.\n2. Logical Gate Speed: The logical gate speed of a quantum computer is determined by the rate at which it can perform quantum logic gates. In photonic quantum computers, this is influenced by the rate of entangled photon production and the speed of optical switches.\n3. Interleaving: Photonic quantum computers can use a technique called interleaving, where many resource states are produced by a single resource state generator. This is possible due to the ability to store/delay photons in long lengths of optical fiber with very low error rates.\n4. Active-Volume Architectures: Active-volume architectures in photonic quantum computers can eliminate the majority of resource consumption expended on idling qubits by performing non-trivial computational gates. This is possible due to the ability to perform a limited number of non-nearest neighbor fusions between photons.\n5. Resource State Generation: The speed and scale of resource state generation is a critical factor in determining the logical gate speed of a photonic quantum computer. High repetition rates have been achieved in the production of single photons via a probabilistic parametric process.\n6. Future of Quantum Computing: The author believes that the long-term future of quantum computing is ultimately photonic due to the potential for high-speed resource state generation and the unique properties of photonics.\n7. Applications: The author provides an example of breaking elliptic curve cryptosystems on a quantum computer using Shor’s algorithm. He shows that a photonic quantum computer with an active-volume architecture can perform the computation significantly faster than a superconducting qubit machine.\n8. Conclusion: The author concludes that the logical gate speed of a photonic quantum computer is not solely determined by the physical timescales of the machine. Instead, it is influenced by the unique properties of photonics and the efficient parallelization achieved through long-range connections in the photonic active-volume device."
  },
  {
    "objectID": "library/natural-sciences/computing/quantum/index.html#resources",
    "href": "library/natural-sciences/computing/quantum/index.html#resources",
    "title": "Quantum",
    "section": "",
    "text": "Quantum Hamiltonian-Based Models & the Variational Quantum Thermalizer Algorithm\nLimitations of optimization algorithms on noisy quantum devices\nVariational Quantum Thermalization\nSimulating Quantum Computers Using OpenCL\nUpgrading qsim, Google Quantum AI’s Open Source Quantum Simulator\nClosed Timelike Curves Make Quantum and Classical Computing Equivalent\nRunning Quantum Software on a Classical Computer\nVariational Quantum Thermalization and the Future of Quantum Thermodynamics\nEvidence for the utility of quantum computing before fault tolerance\nQuantum Computation and Quantum Information\n\n\n\n\nWhat is the logical gate speed of a photonic quantum computer?\n\nSummary\nThe blog post, written by Terry Rudolph from PsiQuantum & Imperial College London, discusses the logical gate speed of a photonic quantum computer. The author argues that photonic quantum computers can perform computations orders of magnitude faster than superconducting qubit machines, even if every physical timescale of the photonic machine was slower. This is due to the unique properties of photonics, such as the ability to store/delay photons in long lengths of optical fiber with very low error rates, and the potential for active-volume architectures that can perform non-trivial computational gates more efficiently.\nNotes\n1. Photonic Quantum Computers: Photonic quantum computers use light (photons) to carry out quantum computations. They have the potential to perform computations faster than superconducting qubit machines due to their unique properties.\n2. Logical Gate Speed: The logical gate speed of a quantum computer is determined by the rate at which it can perform quantum logic gates. In photonic quantum computers, this is influenced by the rate of entangled photon production and the speed of optical switches.\n3. Interleaving: Photonic quantum computers can use a technique called interleaving, where many resource states are produced by a single resource state generator. This is possible due to the ability to store/delay photons in long lengths of optical fiber with very low error rates.\n4. Active-Volume Architectures: Active-volume architectures in photonic quantum computers can eliminate the majority of resource consumption expended on idling qubits by performing non-trivial computational gates. This is possible due to the ability to perform a limited number of non-nearest neighbor fusions between photons.\n5. Resource State Generation: The speed and scale of resource state generation is a critical factor in determining the logical gate speed of a photonic quantum computer. High repetition rates have been achieved in the production of single photons via a probabilistic parametric process.\n6. Future of Quantum Computing: The author believes that the long-term future of quantum computing is ultimately photonic due to the potential for high-speed resource state generation and the unique properties of photonics.\n7. Applications: The author provides an example of breaking elliptic curve cryptosystems on a quantum computer using Shor’s algorithm. He shows that a photonic quantum computer with an active-volume architecture can perform the computation significantly faster than a superconducting qubit machine.\n8. Conclusion: The author concludes that the logical gate speed of a photonic quantum computer is not solely determined by the physical timescales of the machine. Instead, it is influenced by the unique properties of photonics and the efficient parallelization achieved through long-range connections in the photonic active-volume device."
  },
  {
    "objectID": "library/natural-sciences/ai/tools.html#coding",
    "href": "library/natural-sciences/ai/tools.html#coding",
    "title": "AI Tools",
    "section": "Coding",
    "text": "Coding\n\nMentat: Integrated Coding Assistant"
  },
  {
    "objectID": "library/natural-sciences/ai/index.html#research",
    "href": "library/natural-sciences/ai/index.html#research",
    "title": "Artificial Intelligence",
    "section": "Research",
    "text": "Research\n\nGeneral ML & Algorithms\n\nBroken Neural Scaling Laws\nGrokking: Generalization Beyond Overfitting on Small Algorithmic Datasets\nDeepmind: Discovering novel algorithms with AlphaTensor\nPrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning\n\n\n\nNLP and LLMs\n\nRetrieval-Enhanced Large Language Models\nTraining Compute-Optimal Large Language Models\nParsel: A Unified Natural Language Framework for Algorithmic Reasoning\nLarge Language Models can Self-Improve\nEmergent Abilities of Large Language Models\nSelf-Instruct: Aligning Language Model with Self Generated Instructions\nGalactica: A Large Language Model for Science\nOPT-IML: An instruction-tuned LLM for open-use\nLLM Refinement Process, reduce mistakes\n\n\n\nDiffusion Models\n\nHigh Resolution Image Synthesis with Latent Diffusion Models\nDenoising Diffusion Probabilistic Models\nDenoising Diffusion Implicit Models\nPseudo Numerical Methods for Diffusion Models on Manifolds\nFast Sampling of Diffusion Models with Exponential Integrator\nDiffusion Language Models\n\n\n\nMultimodal Models\n\nMultimodal Neurons in Artificial Neural Networks\nMeta: CICERO\nOpenAI: Learning to play Minecraft with video pre-training (VPT)\nMultimodal Deep Learning\n\n\n\nApplications & Miscellaneous\n\nDeepmind: Accelerating fusion science through learned plasma control\nDreambooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation\nDeep Learning and Computational Physics (Lecture Notes)\nWolfram Alpha x ChatGPT\n\n\n\nData & Bias\n\nAdjusting Biased Samples\nData Distillation\n\n\n\nText &lt;&gt; Image\n\nAn Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion\nDALL-E: Zero-Shot Text-to-Image Generation\nMake-A-Video: Text-to-Video Generation without Text-Video Data\nBLIP-2: Image to Text\n\n\n\nVoice and Audio\n\nVALL-E: Generate voice snippets with only a few seconds of input audio\nWhisper: OpenAI Speech Recognition\n\n\n\nBiology\n\nMolecular recordings by directed CRISPR spacer acquisition\nReasons to be Grateful for Biotechnology\n\n\n\nOther Topics\n\nChatGPT Political Biases\n3D Image Inpainting\nDetecting Watermarks on GPT\nDeep Learning Tuning Playbook"
  },
  {
    "objectID": "library/natural-sciences/ai/index.html#philosophy",
    "href": "library/natural-sciences/ai/index.html#philosophy",
    "title": "Artificial Intelligence",
    "section": "",
    "text": "Asymptotically Unambitious Artificial General Intelligence\nWe Still Don’t Understand the Models We’ve Built\n\n“Glitch Token”"
  },
  {
    "objectID": "library/natural-sciences/ai/index.html#topics",
    "href": "library/natural-sciences/ai/index.html#topics",
    "title": "Artificial Intelligence",
    "section": "Topics",
    "text": "Topics\n\nAttention: A Huge Leap\nIn 2014, an Attention mechanism was introduced by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. This became the foundation for the Transformer. - Neural Machine Translation by Jointly Learning to Align and Translate - ffective Approaches to Attention-based Neural Machine Translation\nThe attention mechanism allows the model to assign different weights or importance to different parts of the input sequence when making predictions or generating output. Instead of relying solely on fixed-length vector representations or encoding the entire input sequence into a fixed-length representation, the attention mechanism enables the model to dynamically attend to relevant parts of the input at each step of the computation.\nIn a typical attention mechanism, there are three main components:\n\nQuery: A query represents the current step or position in the output generation process. It is used to compare against different parts of the input sequence to determine their relevance.\nKey: The keys are representations of the different parts of the input sequence. These keys are compared to the query to measure their similarity or relevance.\nValue: The values are additional information associated with the input sequence parts. They provide the context or content that the model focuses on.\n\nThe attention mechanism computes a similarity score between the query and each key, which determines the relevance or attention assigned to the corresponding value. These similarity scores are typically computed using dot products, additive or multiplicative operations, or neural networks.\nThe resulting attention weights are used to weight the values associated with the input sequence parts. This weighted information is then combined or aggregated to provide a context-aware representation for the current step, allowing the model to focus more on relevant parts of the input.\nBy incorporating attention mechanisms into deep learning models, they can effectively capture dependencies between different elements of the input sequence, improve performance on sequential tasks, and handle long-range dependencies more effectively than traditional fixed-length representations.\n\n\nThe Transformer “Attention is All You Need”\nPaper published by a team at Google Brain. - Attention is All You Need\nThe Transformer architecture is built on the idea of self-attention or scaled dot-product attention, which can be seen as an extension of the attention mechanism. In traditional sequence-to-sequence models, such as recurrent neural networks (RNNs), sequential information is processed step by step, which can be computationally expensive and hinder parallelization.\nThe key innovation of the Transformer is that it replaces recurrent layers with self-attention layers. Self-attention allows the model to compute the relationships between all positions in the input sequence simultaneously. This means that each position can attend to any other position, capturing global dependencies in the sequence. By doing so, the Transformer can process inputs in parallel and handle long-range dependencies more effectively.\nThe Transformer architecture consists of two main components: the encoder and the decoder. The encoder takes an input sequence and generates a sequence of contextualized representations, while the decoder takes the encoder’s output and generates the final output sequence.\nWithin the encoder and decoder, the Transformer uses multi-head self-attention mechanisms. Instead of a single self-attention mechanism, multiple attention heads are employed to capture different types of information and attend to different parts of the input sequence simultaneously. This allows the model to focus on different aspects of the input and learn more diverse and expressive representations.\nThe Transformer also introduces positional encoding, which provides information about the position of each element in the input sequence. Since self-attention lacks the notion of position, positional encoding enables the model to incorporate sequential information into its computations.\nThe dominance of the Transformer architecture in modern AI can be attributed to several factors:\n\nParallelization: The self-attention mechanism in the Transformer enables parallel processing of inputs, making it highly efficient for training on modern hardware, such as graphics processing units (GPUs) or tensor processing units (TPUs).\nLong-range dependencies: The self-attention mechanism allows the Transformer to capture dependencies between distant positions in the input sequence, making it more effective in modeling long-range relationships compared to traditional recurrent architectures.\nExpressiveness: By employing multiple attention heads and capturing different types of information, the Transformer can learn more expressive and rich representations of the input data.\nTransferability: The Transformer has shown strong performance across a wide range of NLP tasks, such as machine translation, language understanding, text generation, and more. Its effectiveness and versatility have made it a popular choice and a basis for many state-of-the-art models.\n\nOverall, the Transformer’s ability to model global dependencies, parallelize computations, and learn expressive representations has contributed to its dominance in modern AI, particularly in the field of natural language processing.\n\n\nBackpropogation\nBackpropogation is an algorithm for training neural-networks, used to update its weights to minimize the ‘loss’\n\nNetwork makes a prediction on a batch of input data\nLoss is calculated between predicted and actual output\nGradient of the loss with respect to the weights are calculated using the chain rule of differentiation\nThe gradients are used to update the weights in the opposite direction of the gradient, reducing the loss\nRepeat the process until the loss reaches a satisfactory level or a maximum number of iterations\n\n\n\nThe Evolution of Context Windows\n\nIntroduction\nThe context window—the maximum sequence length that a model can process in a single pass—is a hot topic in the field of large language models. It serves as a critical constraint for tasks that require understanding or generating longer sequences of text. From OpenAI’s ambitious goal of one million tokens to Magic’s announcement of a 5M token model, and Anthropic’s 100K context window model, we’re witnessing a context-length party. But why stop there? This article explores novel techniques and architectures that aim to stretch or even potentially eliminate these limitations.\n\n\nTL;DR\n\nContext window length limitations have been a bottleneck in the performance of large language models.\nVarious tricks like SuperHOT, and architectures like RWKV and Hyena, are breaking these limitations.\nEach approach comes with its trade-offs, but the direction is clear: larger context windows are inevitable.\n\n\n\nThe SuperHOT Method\nAbout two weeks ago, an innovative trick called SuperHOT surfaced on 4-chan. The user claimed that dividing the model’s positional encoding by 4 could trick the model into working with lengths 4 times longer than its original setting. The trick gained enough traction to be cited in academic papers. Following this, an anonymous Reddit user improved upon the idea, using non-linear interpolation to further enhance the performance of these “stretched” models. However, such tricks are not without drawbacks; performance dips and hyperparameter tuning are among the issues.\n\n\nInfinite Context with RWKV\nRWKV, known as the largest LSTM network in the world, is unique in its ability to theoretically offer an infinite context length. It ranks among the five best models in the Vicuna table and is one of the most used models on Huggingface. It’s not just good—it’s also cheap to run, operating at a lower computational cost than its Transformer counterparts.\n\n\nGPT-4: A Tangent on Architecture\nThe latest in the line of OpenAI’s GPT models, GPT-4 is a behemoth with eight different transformers and 220 billion parameters. Its architecture has sparked theories and speculation, some even suggesting that the model can dynamically change while running. It remains a remarkable but expensive framework, leading us to consider alternative architectures that can handle longer sequences more efficiently.\n\n\nGoodbye Transformers, Hello Hyena\nEnter Hyena, a convolution-based architecture that recently outperformed a larger Transformer model. It promises monstrous sequence lengths, faster computation, and possibly even higher accuracy. Hyena’s secret sauce is its ability to learn a map from position encoding to filter values, enabling more context-aware processing without the computational intensity of Transformers.\n\nThe Core Trick in Hyena\nHyena generates filters based on positional encoding. These filters are then applied in a Toeplitz matrix, which mimics the function of a convolution operation. This unique architecture allows Hyena to be as “data-controlled” as possible, similar to how attention layers work in Transformers but at a fraction of the computational cost.\n\n\n\nConclusion\nFrom tweaking positional encodings in the SuperHOT method to adopting entirely different architectures like RWKV and Hyena, the pursuit of longer context windows in large language models is more alive than ever. As we move forward, we can expect even more groundbreaking innovations that push the boundaries, opening new possibilities for applications that require understanding vast swaths of data in a single glance.\n\nFurther Reading\n\nGLam: Mixture of Experts\nSwitch Transformer\nRouted Language Models\nBranch-Train-Merge\nScaling Laws of Expert Networks\nCombining Knowledge Domains in MoE Nets\nHyena Paper\nHyena Blogs"
  },
  {
    "objectID": "library/natural-sciences/ai/index.html#the-evolution-of-context-windows-in-large-language-models",
    "href": "library/natural-sciences/ai/index.html#the-evolution-of-context-windows-in-large-language-models",
    "title": "Artificial Intelligence",
    "section": "The Evolution of Context Windows in Large Language Models",
    "text": "The Evolution of Context Windows in Large Language Models\n\nIntroduction\nThe context window—the maximum sequence length that a model can process in a single pass—is a hot topic in the field of large language models. It serves as a critical constraint for tasks that require understanding or generating longer sequences of text. From OpenAI’s ambitious goal of one million tokens to Magic’s announcement of a 5M token model, and Anthropic’s 100K context window model, we’re witnessing a context-length party. But why stop there? This article explores novel techniques and architectures that aim to stretch or even potentially eliminate these limitations.\n\n\nTL;DR\n\nContext window length limitations have been a bottleneck in the performance of large language models.\nVarious tricks like SuperHOT, and architectures like RWKV and Hyena, are breaking these limitations.\nEach approach comes with its trade-offs, but the direction is clear: larger context windows are inevitable.\n\n\n\nThe SuperHOT Method\nAbout two weeks ago, an innovative trick called SuperHOT surfaced on 4-chan. The user claimed that dividing the model’s positional encoding by 4 could trick the model into working with lengths 4 times longer than its original setting. The trick gained enough traction to be cited in academic papers. Following this, an anonymous Reddit user improved upon the idea, using non-linear interpolation to further enhance the performance of these “stretched” models. However, such tricks are not without drawbacks; performance dips and hyperparameter tuning are among the issues.\n\n\nInfinite Context with RWKV\nRWKV, known as the largest LSTM network in the world, is unique in its ability to theoretically offer an infinite context length. It ranks among the five best models in the Vicuna table and is one of the most used models on Huggingface. It’s not just good—it’s also cheap to run, operating at a lower computational cost than its Transformer counterparts.\n\n\nGPT-4: A Tangent on Architecture\nThe latest in the line of OpenAI’s GPT models, GPT-4 is a behemoth with eight different transformers and 220 billion parameters. Its architecture has sparked theories and speculation, some even suggesting that the model can dynamically change while running. It remains a remarkable but expensive framework, leading us to consider alternative architectures that can handle longer sequences more efficiently.\n\n\nGoodbye Transformers, Hello Hyena\nEnter Hyena, a convolution-based architecture that recently outperformed a larger Transformer model. It promises monstrous sequence lengths, faster computation, and possibly even higher accuracy. Hyena’s secret sauce is its ability to learn a map from position encoding to filter values, enabling more context-aware processing without the computational intensity of Transformers.\n\nThe Core Trick in Hyena\nHyena generates filters based on positional encoding. These filters are then applied in a Toeplitz matrix, which mimics the function of a convolution operation. This unique architecture allows Hyena to be as “data-controlled” as possible, similar to how attention layers work in Transformers but at a fraction of the computational cost.\n\n\n\nConclusion\nFrom tweaking positional encodings in the SuperHOT method to adopting entirely different architectures like RWKV and Hyena, the pursuit of longer context windows in large language models is more alive than ever. As we move forward, we can expect even more groundbreaking innovations that push the boundaries, opening new possibilities for applications that require understanding vast swaths of data in a single glance.\n\nFurther Reading\n\nGLam: Mixture of Experts\nSwitch Transformer\nRouted Language Models\nBranch-Train-Merge\nScaling Laws of Expert Networks\nCombining Knowledge Domains in MoE Nets\nHyena Paper\nHyena Blogs"
  },
  {
    "objectID": "writes/posts/welcome-example/index.html",
    "href": "writes/posts/welcome-example/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/consensus.html#consensus",
    "href": "library/natural-sciences/crypto/blockchains/consensus.html#consensus",
    "title": "bmac",
    "section": "",
    "text": "All things Byzantine Fault Tolerant: Research and implementations of consensus mechanisms.\n\n\n\nTendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical\n\n\n\n\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\n\n\n\n\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#early-contributions",
    "href": "library/natural-sciences/crypto/blockchains/index.html#early-contributions",
    "title": "Blockchains",
    "section": "",
    "text": "David Chaum, 1983 Electronic Cash\nDavid Chaum, 1985 Security without Identification\nDr. Douglas Jackson and Barry K. Downey, 1996 E-Gold\nWei Dai, 1998 b-money\nNick Szabo, 1998 Bit Gold"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#layer-1-whitepapers",
    "href": "library/natural-sciences/crypto/blockchains/index.html#layer-1-whitepapers",
    "title": "Blockchains",
    "section": "Layer 1 Whitepapers",
    "text": "Layer 1 Whitepapers\n\nBitcoin\nEthereum: A Next-Generation Smart Contract and Decentralized Application Platform\nEthereum: A Secure Decentralized Generalized Transaction Ledger\nZerocash: Decentralized Anonymous Payments from Bitcoin\nCosmos: Internet of Blockchains\nSolana: A new Architecture for a High Performance Blockchain\nCardano\nAlgorand: Scaling Byzantine Agreements for Cryptocurrencies\nAvalanche Platform\nThe Spacemesh Protocol"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#consensus",
    "href": "library/natural-sciences/crypto/blockchains/index.html#consensus",
    "title": "Blockchains",
    "section": "Consensus",
    "text": "Consensus\nAll things Byzantine Fault Tolerant: Research and implementations of consensus mechanisms.\n\nWhitepapers\n\nTendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical\n\n\n\nResearch\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\n\n\n\nAttacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchains/index.html#events",
    "href": "library/natural-sciences/crypto/blockchains/index.html#events",
    "title": "Blockchains",
    "section": "Events",
    "text": "Events\nMay 12, 2023: Ethereum Consensus Issues\n\ntweet one\ntweet two"
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/ygg.html",
    "href": "library/natural-sciences/crypto/rekt/ygg.html",
    "title": "YGG REKT",
    "section": "",
    "text": "August 7\n9:04 am YGG in top 3 volume, followed by shitcoins with negative funding (heavy shorts)\nHsaka’s Take | tweet\nAug 6, 7:04am YGG “looking spicy” says Nik’s quant\nReported at 9:52am Binance increased the funding rate settlement frequency from 8 hours to 2 hours\nReminder that 2018 scam pumps were even crazier\n\nso much commentary and ‘hate’ on the YGG situation when people don’t remember the summer of 2022 where we had 10x pumps in 1 minute on shitcoins. oh sweet children you haven’t experienced the true depths of market manipulation yet"
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/mango.html",
    "href": "library/natural-sciences/crypto/rekt/mango.html",
    "title": "Mango Markets REKT",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/mango.html#overview",
    "href": "library/natural-sciences/crypto/rekt/mango.html#overview",
    "title": "Mango Markets REKT",
    "section": "",
    "text": "On October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network."
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/mango.html#how-it-worked",
    "href": "library/natural-sciences/crypto/rekt/mango.html#how-it-worked",
    "title": "Mango Markets REKT",
    "section": "How it worked",
    "text": "How it worked\nAttacker had two accounts, let’s call them account A and account B.\n\nAttacker funds account A with $5 million of USDC, to be used as collateral for on-chain positions.\nAttacker then offered out (sold short) ~483 million MNGO tokens, trading at $0.038 at the time.\nAttacker then funds account B with $5 million USDC, and purchases those ~438 million MNGO at $0.0382\nAttacker then purchases MNGO on the Spot market, artificially increasing its price. The price of mango reached $0.91 (a 24x increase).\nAt this new inflated price, account B was in the money for ~ $423 million. He used this account value to take out a loan of $116 million consisting of several tokens.\nAfter the attack, the MNGO/USD spot market then traded down to $0.02, which put account A in the money. However, Mango protocol was effectively drained of all liquidity, so account A could not be paid out."
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/mango.html#summary",
    "href": "library/natural-sciences/crypto/rekt/mango.html#summary",
    "title": "Mango Markets REKT",
    "section": "Summary",
    "text": "Summary\nMango Markets were designed to give loans at a certain collateralization ratio (e.g. 400%), but they used the spot market as an oracle for “fair price” of the token. Thus, tokens with low liquidity could be easily manipulated such that the protocol believes “fair price” is multiples above what anyone would purchase the token at in free markets."
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/mango.html#future-mitigation",
    "href": "library/natural-sciences/crypto/rekt/mango.html#future-mitigation",
    "title": "Mango Markets REKT",
    "section": "Future Mitigation",
    "text": "Future Mitigation\nMitigating this type of attack is as simple as fixing the Oracle mechanism. For example, one could use a 24hr rolling average price to determine “fair value” for lending, which would make the market manipulator’s attack much more difficult (must pump price for 24 hour rather than a few seconds)."
  },
  {
    "objectID": "library/natural-sciences/crypto/rekt/mango.html#credits-commentary",
    "href": "library/natural-sciences/crypto/rekt/mango.html#credits-commentary",
    "title": "Mango Markets REKT",
    "section": "Credits & Commentary",
    "text": "Credits & Commentary\n\nNotice of Exploit by Otter Security\nEarly Analysis of What Happened\nSam Bankman Freid on How to Protect from this Attack\nAttacker Admitting his Involvement"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/hyperliquid.html",
    "href": "library/natural-sciences/crypto/apps/hyperliquid.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/hyperliquid.html#current-widely-accepted-funding-rate-formula",
    "href": "library/natural-sciences/crypto/apps/hyperliquid.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/natural-sciences/crypto/apps/hyperliquid.html#potentially-new-funding-rate-formula",
    "href": "library/natural-sciences/crypto/apps/hyperliquid.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#general-1",
    "href": "library/natural-sciences/maths/index.html#general-1",
    "title": "Maths x Physics",
    "section": "General",
    "text": "General\n\nMy Encounters - as a Physicist - with Mathematics\n\n\nDonaldson Theory\nDonaldson theory is a branch of mathematics that is concerned with the topology of four-dimensional manifolds. It is named after Simon Donaldson, a British mathematician who made significant contributions to the field in the 1980s.\nThe central problem in Donaldson theory is to understand the topology of four-dimensional manifolds using differential geometry and algebraic topology. Specifically, the theory focuses on the study of vector bundles and connections on these manifolds, and how they can be used to classify different types of four-dimensional manifolds.\nOne of the key results in Donaldson theory is Donaldson’s theorem, which states that the intersection form of a smooth, closed, simply-connected four-dimensional manifold can be recovered from its Seiberg-Witten invariants. The Seiberg-Witten invariants are a set of numbers that can be associated with a four-dimensional manifold and its spin-c structure. They were introduced by Edward Witten and Nathan Seiberg in the mid-1990s and have proven to be a powerful tool in the study of four-dimensional manifolds.\nDonaldson theory has applications in a variety of fields, including physics, where it has been used to study the topology of spacetime in string theory and other areas of theoretical physics. It has also had significant impact in pure mathematics, inspiring further research in the fields of algebraic geometry, topology, and differential geometry.\n\n\nLie Algebras in Particle Physics\n\nLie Algebras in Particle Physics\n\nLie Algebras in particle physics are mathematical structures that help to describe and classify physical systems, particularly those involving symmetries and transformations. In essence, a Lie algebra is a vector space equipped with a certain kind of product, called the Lie bracket, that captures the essential information about continuous transformations and symmetries. When applied to particle physics, Lie algebras offer a robust framework for understanding the fundamental particles and forces that govern the universe.\nThe concept of Lie algebras originated in the late 19th century with the work of Norwegian mathematician Sophus Lie. Originally developed to study continuous transformation groups, the scope of Lie algebras has expanded to diverse areas of mathematics and physics. Their application in particle physics became increasingly significant during the 20th century, especially after the development of quantum mechanics and quantum field theory. The SU(3) Lie algebra, for example, was crucial in predicting the existence of particles like the omega-minus baryon before it was experimentally discovered.\nLie algebras offer a theoretical structure that is essential for formulating the Standard Model of particle physics, which describes electromagnetic, weak, and strong forces. Because Lie algebras are tightly connected to symmetry principles, they enable physicists to simplify complex systems and make predictions about particle interactions.\nApplications\n\nParticle Classification: Used for the classification of elementary particles into families and generations, assisting in the prediction of undiscovered particles.\nSymmetry Breaking: Helps in understanding the mechanism by which symmetry breaking occurs, a phenomenon critical to our understanding of the universe.\nField Theories: Employed in various quantum field theories to solve or approximate solutions for complex equations of motion.\nUnification Theories: Lie algebras and their corresponding Lie groups have been essential in attempts to develop Grand Unified Theories (GUTs) and even theories of everything.\n\nRelevant Subtopics\n\nBasic Definitions and Principles: Introduction to Lie groups, Lie algebras, and the relationship between them.\nRepresentation Theory: How Lie algebras can be represented as matrices, and why these representations are useful in particle physics.\nSU(N) Algebras: Special Unitary Groups of degree (N) and their importance in particle physics.\nSymmetry and Conservation Laws: Discussion on how Lie algebras relate to symmetries in physical systems and the corresponding conservation laws.\nApplication to the Standard Model: Utilizing Lie algebras to describe the particles and interactions within the Standard Model.\nAdvanced Topics: Covering roots, weights, Dynkin diagrams, and their role in particle physics."
  },
  {
    "objectID": "library/natural-sciences/maths/index.html#mathematical-physics",
    "href": "library/natural-sciences/maths/index.html#mathematical-physics",
    "title": "Maths",
    "section": "Mathematical Physics",
    "text": "Mathematical Physics\n\nMy Encounters - as a Physicist - with Mathematics\n\n\nDonaldson Theory\nDonaldson theory is a branch of mathematics that is concerned with the topology of four-dimensional manifolds. It is named after Simon Donaldson, a British mathematician who made significant contributions to the field in the 1980s.\nThe central problem in Donaldson theory is to understand the topology of four-dimensional manifolds using differential geometry and algebraic topology. Specifically, the theory focuses on the study of vector bundles and connections on these manifolds, and how they can be used to classify different types of four-dimensional manifolds.\nOne of the key results in Donaldson theory is Donaldson’s theorem, which states that the intersection form of a smooth, closed, simply-connected four-dimensional manifold can be recovered from its Seiberg-Witten invariants. The Seiberg-Witten invariants are a set of numbers that can be associated with a four-dimensional manifold and its spin-c structure. They were introduced by Edward Witten and Nathan Seiberg in the mid-1990s and have proven to be a powerful tool in the study of four-dimensional manifolds.\nDonaldson theory has applications in a variety of fields, including physics, where it has been used to study the topology of spacetime in string theory and other areas of theoretical physics. It has also had significant impact in pure mathematics, inspiring further research in the fields of algebraic geometry, topology, and differential geometry.\n\n\nLie Algebras in Particle Physics\n\nLie Algebras in Particle Physics\n\nLie Algebras in particle physics are mathematical structures that help to describe and classify physical systems, particularly those involving symmetries and transformations. In essence, a Lie algebra is a vector space equipped with a certain kind of product, called the Lie bracket, that captures the essential information about continuous transformations and symmetries. When applied to particle physics, Lie algebras offer a robust framework for understanding the fundamental particles and forces that govern the universe.\nThe concept of Lie algebras originated in the late 19th century with the work of Norwegian mathematician Sophus Lie. Originally developed to study continuous transformation groups, the scope of Lie algebras has expanded to diverse areas of mathematics and physics. Their application in particle physics became increasingly significant during the 20th century, especially after the development of quantum mechanics and quantum field theory. The SU(3) Lie algebra, for example, was crucial in predicting the existence of particles like the omega-minus baryon before it was experimentally discovered.\nLie algebras offer a theoretical structure that is essential for formulating the Standard Model of particle physics, which describes electromagnetic, weak, and strong forces. Because Lie algebras are tightly connected to symmetry principles, they enable physicists to simplify complex systems and make predictions about particle interactions.\nApplications\n\nParticle Classification: Used for the classification of elementary particles into families and generations, assisting in the prediction of undiscovered particles.\nSymmetry Breaking: Helps in understanding the mechanism by which symmetry breaking occurs, a phenomenon critical to our understanding of the universe.\nField Theories: Employed in various quantum field theories to solve or approximate solutions for complex equations of motion.\nUnification Theories: Lie algebras and their corresponding Lie groups have been essential in attempts to develop Grand Unified Theories (GUTs) and even theories of everything.\n\nRelevant Subtopics\n\nBasic Definitions and Principles: Introduction to Lie groups, Lie algebras, and the relationship between them.\nRepresentation Theory: How Lie algebras can be represented as matrices, and why these representations are useful in particle physics.\nSU(N) Algebras: Special Unitary Groups of degree (N) and their importance in particle physics.\nSymmetry and Conservation Laws: Discussion on how Lie algebras relate to symmetries in physical systems and the corresponding conservation laws.\nApplication to the Standard Model: Utilizing Lie algebras to describe the particles and interactions within the Standard Model.\nAdvanced Topics: Covering roots, weights, Dynkin diagrams, and their role in particle physics."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html",
    "title": "Ethereum",
    "section": "",
    "text": "Ethereum Research Forum\nEth R&D Discord\nFlashbots Collective Forum\nEthereum Youtube: Community calls and such"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#consensus",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#consensus",
    "title": "Ethereum",
    "section": "Consensus",
    "text": "Consensus\n\nEthereum Consensus Spec\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\n\nelopio’s annotations\n\nBeacon Chain Casper Mini-Spec\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\nEthereum Inactivity Leak\n\n\nConsensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#consensus-attacks",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#consensus-attacks",
    "title": "Ethereum",
    "section": "Consensus Attacks",
    "text": "Consensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#proposer-builder-separation",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#proposer-builder-separation",
    "title": "Ethereum",
    "section": "Proposer Builder Separation",
    "text": "Proposer Builder Separation\n\nMEV-Boost Plan\nProposer Boost Considerations by Caspar Schwarz-Schilling (RIG/EF)\nMEV-Boost in a Nutshell\nEthereum Builder API Specs\nMEV-Boost Relay API Specification V1\nPBS Censorship Resistance\nState of research: increasing censorship resistance of transactions under PBS\nPBS Censorship-Resistance Alternatives\nCurrent crList Proposal\nProposer/block builder separation-friendly fee market designs by Vitalik Buterin (EF)\nTwo-slot proposer/builder separation by Vitalik Buterin (EF)\nState of research: increasing censorship resistance of transactions under proposer/builder separation (PBS) by Vitalik Buterin (EF)\nPBS Censorship-Resistance Alternatives by Francesco D’Amato (EF)"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#sharding",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#sharding",
    "title": "Ethereum",
    "section": "Sharding",
    "text": "Sharding\n\nDanksharding\nPolynya on Danksharding\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding\n\n\nGeneral\n\nEthereum Inactivity Leak\nIntent Based Architectures and Their Risks\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses\nAccount Abstraction Using Alt Mempool\nEIP-1153: Transient Storage\nTime to Bribe: Measuring Block Construction Markets\n2FA ZK Rollups using SGX\nClient Bootnode Concerns\nCollecting Signatures for Faster Finality\nProof of Solvency\nState of Testnets\nEth Withdrawals FAQ\n100 Days After the Merge\nWithdrawals after Shanghai\nExecution Layer Meeting\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\nEthereum Data Structures\nEth2Book: A lot of Good Info on Ethereum\nOfficial Merge Announcement\nERC-4337: What’s in an Account?"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#general",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#general",
    "title": "Ethereum",
    "section": "General",
    "text": "General\n\nEth2Book: A lot of Good Info on Ethereum\nIntent Based Architectures and Their Risks\nClient Bootnode Concerns\nCollecting Signatures for Faster Finality\nProof of Solvency\nState of Testnets\nVitalik: the roads not taken\nEndgame by Vitalik Buterin (EF)\nUpdated Ethereum Roadmap by Vitalik Buterin (EF)\nTime to Bribe: Measuring Block Construction Markets\nRetroactive Proposer Rewards by Caspar Schwarz-Schilling (RIG/EF)\nSingle Secret Leader Election Boneh et al. (2020)\nCurrent CrList Proposal by Francesco D’Amato\nThe Hitchhiker’s Guide to Ethereum - very good technical introduction\nMergeMock"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#eips",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#eips",
    "title": "Ethereum",
    "section": "EIPs",
    "text": "EIPs\n\n3675\nProof of Stake\n\nEIP-3675: Upgrade consensus to Proof-of-Stake\nEth Withdrawals FAQ\n100 Days After the Merge\nWithdrawals after Shanghai\nOfficial Merge Announcement\nExploring Inequality in Proof of Stake by Barnabe Monnot (RIG/EF)\nWhat Happens After Finality in eth2 by Raul Jordan (Prysmatic)\nUnderstanding Eth2 Slashing Preventative Measures\n\n\n\n4844\nProto-Danksharding\n\nEIP-4844: Shard Blob Transactions\nDanksharding\nPolynya on Danksharding\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding\nProto-Danksharding FAQ by Vitalik Buterin (EF)\n“Dude, what’s the Danksharding situation?” Workshop by Dankrad Feist & Vitalik Buterin (EF)\n\n\n\n2938/4337\nAccount Abstraction\n\nEIP-2938: Account Abstraction\nERC-4337: Account Abstraction Using Alt Mempool\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses\nWhat’s in an Account?\n\n\n\nOther\n\nEIP-1153: Transient Storage"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/solana/index.html",
    "href": "library/natural-sciences/crypto/blockchain/solana/index.html",
    "title": "Solana",
    "section": "",
    "text": "How will Solana Improve its Stability?"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/solana/index.html#the-tech",
    "href": "library/natural-sciences/crypto/blockchain/solana/index.html#the-tech",
    "title": "Solana",
    "section": "",
    "text": "How will Solana Improve its Stability?"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/solana/index.html#partnerships",
    "href": "library/natural-sciences/crypto/blockchain/solana/index.html#partnerships",
    "title": "Solana",
    "section": "Partnerships",
    "text": "Partnerships\n\nVisa expands stablecoin settlement capabilities with Circle’s USDC utilizing the Solana blockchain.\nVia: A deep dive on Solana, a high performance blockchain network\n\n\nFee Markets\n\nPriority Fees Github Issue\nDune Query: % of Sol Txs with Fee above base\n\n\n\nThe Solana Validator\n\nFiredancer: A New Client by Jump\nValidator Economics on Solana"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/solana/index.html#mango-rekt",
    "href": "library/natural-sciences/crypto/blockchain/solana/index.html#mango-rekt",
    "title": "Solana",
    "section": "Mango Rekt",
    "text": "Mango Rekt\n\nOverview\nOn October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network.\n\n\nHow it worked\nAttacker had two accounts, let’s call them account A and account B.\n\nAttacker funds account A with $5 million of USDC, to be used as collateral for on-chain positions.\nAttacker then offered out (sold short) ~483 million MNGO tokens, trading at $0.038 at the time.\nAttacker then funds account B with $5 million USDC, and purchases those ~438 million MNGO at $0.0382\nAttacker then purchases MNGO on the Spot market, artificially increasing its price. The price of mango reached $0.91 (a 24x increase).\nAt this new inflated price, account B was in the money for ~ $423 million. He used this account value to take out a loan of $116 million consisting of several tokens.\nAfter the attack, the MNGO/USD spot market then traded down to $0.02, which put account A in the money. However, Mango protocol was effectively drained of all liquidity, so account A could not be paid out.\n\n\n\nSummary\nMango Markets were designed to give loans at a certain collateralization ratio (e.g. 400%), but they used the spot market as an oracle for “fair price” of the token. Thus, tokens with low liquidity could be easily manipulated such that the protocol believes “fair price” is multiples above what anyone would purchase the token at in free markets.\n\n\nFuture Mitigation\nMitigating this type of attack is as simple as fixing the Oracle mechanism. For example, one could use a 24hr rolling average price to determine “fair value” for lending, which would make the market manipulator’s attack much more difficult (must pump price for 24 hour rather than a few seconds).\n\n\nFurther Reads\n\nNotice of Exploit by Otter Security\nEarly Analysis of What Happened\nSam Bankman Freid on How to Protect from this Attack\nAttacker Admitting his Involvement"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/rekt/index.html",
    "href": "library/natural-sciences/crypto/blockchain/rekt/index.html",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2\n\n\n\n\nSlope Finance Wallet Exploit: Otter Security"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/rekt/index.html#resources",
    "href": "library/natural-sciences/crypto/blockchain/rekt/index.html#resources",
    "title": "Rekt",
    "section": "",
    "text": "Rekt Leaderboard\nChainalysis 2022 Crypto Crime Report\nTimeline of breahces, frauds and scams\n\n\n\nSharedStake sgETH contract has been exploited for 102 ETH and sgETH has been infiniminted\n\nFortunately the contract was only a month or two old and didn’t have much TVL.\n\nHacker Address 1 Hacker Address 2\n\n\n\n\nSlope Finance Wallet Exploit: Otter Security"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/rekt/index.html#mango-rekt",
    "href": "library/natural-sciences/crypto/blockchain/rekt/index.html#mango-rekt",
    "title": "Rekt",
    "section": "Mango Rekt",
    "text": "Mango Rekt\n\nOverview\nOn October 11th, 2022, Avraham Eisenberg and co conducted a “highly profitable trade”, exploiting a poor liquidation implementation on Mango Markets, a DeFi application on the Solana network.\n\n\nHow it worked\nAttacker had two accounts, let’s call them account A and account B.\n\nAttacker funds account A with $5 million of USDC, to be used as collateral for on-chain positions.\nAttacker then offered out (sold short) ~483 million MNGO tokens, trading at $0.038 at the time.\nAttacker then funds account B with $5 million USDC, and purchases those ~438 million MNGO at $0.0382\nAttacker then purchases MNGO on the Spot market, artificially increasing its price. The price of mango reached $0.91 (a 24x increase).\nAt this new inflated price, account B was in the money for ~ $423 million. He used this account value to take out a loan of $116 million consisting of several tokens.\nAfter the attack, the MNGO/USD spot market then traded down to $0.02, which put account A in the money. However, Mango protocol was effectively drained of all liquidity, so account A could not be paid out.\n\n\n\nSummary\nMango Markets were designed to give loans at a certain collateralization ratio (e.g. 400%), but they used the spot market as an oracle for “fair price” of the token. Thus, tokens with low liquidity could be easily manipulated such that the protocol believes “fair price” is multiples above what anyone would purchase the token at in free markets.\n\n\nFuture Mitigation\nMitigating this type of attack is as simple as fixing the Oracle mechanism. For example, one could use a 24hr rolling average price to determine “fair value” for lending, which would make the market manipulator’s attack much more difficult (must pump price for 24 hour rather than a few seconds).\n\n\nFurther Reads\n\nNotice of Exploit by Otter Security\nEarly Analysis of What Happened\nSam Bankman Freid on How to Protect from this Attack\nAttacker Admitting his Involvement\n\nVyper Compiler Bug\nTakes down Curve, JPEG’d, and others\n\nOtterSec Postmortem Timeline"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/rekt/stake.html",
    "href": "library/natural-sciences/crypto/blockchain/rekt/stake.html",
    "title": "Stake",
    "section": "",
    "text": "Timeline\nFirst and second transactions\nPeckshield Alert | tweet\nFlow of Funds Diagram | tweet\nStake statement\n\n\nOverview\nETH, BSC, and Polygon affected"
  },
  {
    "objectID": "library/natural-sciences/software/index.html",
    "href": "library/natural-sciences/software/index.html",
    "title": "Software",
    "section": "",
    "text": "From the Transistor to the Web Browser: Understanding the Modern Computer Stack from First Principles\nInformation (Technology), Market Performance, and Welfare in the South Indian Fisheries Sector\n\nTLDR: Three different regions of Kerala encountered phone adotpion at different times. Each region saw adoption go from 0% to 60% within ~10 weeks. The effects on the fishing market were crystal clear and significant. Fish price volatility dropped by magnitudes, displaying the enablement of information transfer."
  },
  {
    "objectID": "library/natural-sciences/software/index.html#high-level-reads",
    "href": "library/natural-sciences/software/index.html#high-level-reads",
    "title": "Software",
    "section": "",
    "text": "From the Transistor to the Web Browser: Understanding the Modern Computer Stack from First Principles\nInformation (Technology), Market Performance, and Welfare in the South Indian Fisheries Sector\n\nTLDR: Three different regions of Kerala encountered phone adotpion at different times. Each region saw adoption go from 0% to 60% within ~10 weeks. The effects on the fishing market were crystal clear and significant. Fish price volatility dropped by magnitudes, displaying the enablement of information transfer."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/mev/index.html",
    "href": "library/natural-sciences/crypto/blockchain/mev/index.html",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay\nMempool Dumpster\nMev Boost (Docker image)\nFlashbots relay\nGo Boost Utils\nBoost Geth Builder\nMev-rs\nMergeMock"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/mev/index.html#dashboards-tools",
    "href": "library/natural-sciences/crypto/blockchain/mev/index.html#dashboards-tools",
    "title": "Overview",
    "section": "",
    "text": "ZeroMEV Explorer\nEigenPhi: Arbitrage Dashboard\nMEV Boost\nManifold Freelay\nMempool Dumpster\nMev Boost (Docker image)\nFlashbots relay\nGo Boost Utils\nBoost Geth Builder\nMev-rs\nMergeMock"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/mev/index.html#research",
    "href": "library/natural-sciences/crypto/blockchain/mev/index.html#research",
    "title": "Overview",
    "section": "Research",
    "text": "Research\n\nEarly Research\n\nEnter the Hydra\nThe Cost of Decentralization in 0x and EtherDelta\nFlash Boys 2.0\nOrder-Fairness for Byzantine Consensus\nThemis: Fast, Strong Order-Fairness in Byzantine Consensus\nMEV… Wat Do?\nEthereum is a Dark Forest\nFlashbots: Frontrunning the MEV Crisis\n\n\n\nGeneral\n\nFlashbots Research Repository\nSomeone’s MEV Mega-resource\nStudying Flash Loan Attacks\nMEV by Galaxy Digital, Pt 2\nModular MEV Write-up\nPerformant routing and latency benchmarking for Ethereum RPC and Relay Service Providers\nMEV in Fixed Price Auctions\nMEV Boost Capella Upgrades\nFrontier Research\nAutomated Market Making and Arbitrage Profits in the Presence of Fees\nMEV Capturing AMM\nTime to Bribe: Measuring Block Construction Markets\nA Framework for Building Searchers\nHow to Fix Ethereum’s MEV Problem\nMEV in ETH2 - An Early Exploration\nMEV in eth2 (associated repo) by Alex Obadia & Taarush Vemulapalli (Flashbots)\nImproving PoS Economic Security via MEV Redistribution\nTowards a Theory of MEV I\nCommitee-driven MEV smoothing by Francesco D’Amato (EF)\nLatency Arms Race\nFBAs (frequent batch auctions) are a nerd snipe\nMEV Driven Centralization in Ethereum: Part 1\n\n\n\nMEV-Boost / Proposer-Builder Separation\n\nProposer Boost Considerations\nMEV-Boost Plan\nEthereum Builder API Specs\nMEV-Boost Relay API Specification V1\nRunning MEV-Relay at Scale\nmev.day talks\n\nMEV on ETH2: MEV-boost, PBS, Danksharding… How do the pieces fit together? - Vitalik Buterin (EF) (YouTube, 30min)\nTackling MEV with cryptography - Justin Drake (EF) (YouTube, 19min)\n\nProposer/block builder separation-friendly fee market designs (@vbuterin)\nMEV-Boost: Merge ready Flashbots Architecture (@thegostep)\n\n\n\nVideos & Talks\n\nMEV Day\n\nVideo Recap\n\nEncode x Wintermute: MEV with Robert Miller\nStanford MEV Workshop Recording\nMEVconomics Playlist | youtube\nStanford Blockchain Conference (SBC’23)\nRecordings: Day 1 | Day 2 | Day 3\nMEV Workshop at SBC’23 | Recording\nFlashbots Incentives for Geographical Diversity at EthStaker Amsterdam by Leo Arias & Alex Obadia (Flashbots)\nMEV & Cryptography by Justin Drake (EF)\nFlashbots MEV Roast #15: PBS on Ethereum Roadmap\nMEV after EIP-1559 and the Merge at EthCC 4 by Alex Obadia & Alejo Salles (Flashots)\nThe MEV in Nethermind in eth2 at EthCC 4 by Tomasz Stańczak & Marcello Bardus (Flashbots/Nethermind)\nMEV on eth2 at ETHGlobal Scaling Ethereum Roast by Alex Obadia (Flashbots)\nMEV after The Merge with Nethermind and Flashbots at ETHGlobal Scaling Ethereum conference by Alex Obadia & Tomasz Stańczak (Flashbots/Nethermind)\n\n\n\nProtocols, and Implementation Resources\n\nmev-rs\nUniswap V3 Book\nRunning MEV-Relay at Scale\nJaredFromSubway.eth’s Access Lists"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/apps/hyperliquid.html",
    "href": "library/natural-sciences/crypto/blockchain/apps/hyperliquid.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/apps/hyperliquid.html#current-widely-accepted-funding-rate-formula",
    "href": "library/natural-sciences/crypto/blockchain/apps/hyperliquid.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/apps/hyperliquid.html#potentially-new-funding-rate-formula",
    "href": "library/natural-sciences/crypto/blockchain/apps/hyperliquid.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html",
    "title": "Bitcoin",
    "section": "",
    "text": "Bitcoin: A Peer to Peer Electronic Cash System\nBitcoin Lightning Network\nSegregated Witness Benefits\nVulnerability | tweet"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#transaction-versions",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#transaction-versions",
    "title": "Bitcoin",
    "section": "Transaction Versions",
    "text": "Transaction Versions\nBitcoin has 4 transaction versions. A transaction, in each version, consists of an input and output. A transaction corresponds to a txid, which is a hash of the transaction.\n\nLegacy\n\nInput: - UTxO (Unspent Tx) consists of a txid and output #. - Script signature, proves I have the private key of the address that owns the UTXO.\nOutput: - Amount (satoshis) - public spending script. 2 Main types - P2PKH (Pay to Public Key Hash) = 25 bytes: specific to a single public key. - P2SH (Pay to Script Hash) = 23 bytes: Allows for multisigs.\n\nSegwit (Segregated Witness)\n\nInput: - UTxO: same as legacy - Signed script signature: same as legacy\nOutput: - Amount (satoshis): same as legacy - &lt;version&gt; &lt;witness program&gt;: When a legacy blockchain looks at this, it looks like anyone can spend this. A valid transaction, but it appears to not have a public key. But the soft fork enforces that the public key is spent through a “witness”. So when you want to spend it, you prove you know what your witness is. When you spend a received tx, you append a witness. A miner will verify a witness before it is mined, but the txid doesnt include the witness. This increases available space in the blockchain. This enables a practical lightning network There are tricks where you can have more than one signature valid for a spending script, and have 2 diff txids. This was one of the attacks against Mt Gox to take money out. - P2WSH = 32 bytes: - P2WPKH = 22 bytes:\nThere are 2 Segwit versions. About 50% of transactions are version 0 Segwit, the other are the old versions. Segwit was introduced in a soft fork.\nVersion 1 is Taproot.\n\nTaproot\n\nThe main feature is a new signature algorithm, not on the elliptic curve. It is Schnorr. It is a signature scheme that is more efficient, and has some privacy benefits. It is a soft fork. - P2TR (Pay to Taproot) (Bech32m) = 32 bytes:\n“tweak: with MAST. This allows you to hash scripts to get a root hash, and aggregate this with a master pubkey to get a new pubkey. This allows you to to prove the tx is valid without revealing the master pubkey."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#ordinals",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#ordinals",
    "title": "Bitcoin",
    "section": "Ordinals",
    "text": "Ordinals\nHow to Split Ordinals Mixed in a Single UTXO - article\nSplitting Bitcoin from Inscriptions on Ordinals Wallet - article"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#tech-stuff",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#tech-stuff",
    "title": "Bitcoin",
    "section": "Tech Stuff",
    "text": "Tech Stuff\n# create ordinal wallet\nord wallet create\n\n# receive sats\nord wallet receive\n\n# create inscription\nord wallet inscribe --fee-rate 22 &lt;FILE&gt;\n\nIssues\nTransport error upon inscription attempt here\nInscriptions taking too long here\nIndexing not working here\nHow much does an inscription cost? - calculator"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#guides",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#guides",
    "title": "Bitcoin",
    "section": "Guides",
    "text": "Guides\n\nHow to create\nHow to buy\nMinting Ordinals"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#btc-naming-service",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#btc-naming-service",
    "title": "Bitcoin",
    "section": "BTC Naming Service",
    "text": "BTC Naming Service\nCasey Rodarmor’s Thoughts: 26:00 min mark - here\n\nLook up top level domain (com)\nFind the output its in, and get address of the output\nGet authenticated encrypted channel with the person that owns that\nAsk “who has ‘myname.com’?” and they send you signed message of the pubkey, and then you get IP address. But no good names exist yet.\n\n\nThings I’ve Learned on the Ordinals Journey\nBitcoin has several address formats.\n\nLegacy Addresses\nScript Addresses\nSegwit Addresses\nTaproot Addresses\n\nOrdinals uses Taproot Addresses, which result from a recent upgrade aimed to introduce more reobust security, privacy, and scalability."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#other-stuff",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#other-stuff",
    "title": "Bitcoin",
    "section": "Other Stuff",
    "text": "Other Stuff\nWhat is it?\n\nanswered here\n\nResources\n\nHandbook\nGithub\nBIP\nMainnet Explorer\nTestnet (Signet) Explorer\nGuide\nNo Code Mint Platform\n\nCool Info\nOn August 21st, 2012, Charlie Lee posted a proposal to add proof-of-stake to Bitcoin to the Bitcoin Talk forum. This wasn’t an asset scheme, but did use the ordinal algorithm, and was implemented but never deployed.\nOn October 8th, 2012, jl2012 posted a scheme to the the same forum which uses decimal notation and has all the important properties of ordinals. The scheme was discussed but never implemented.\nGud Video\n\nyoutube\ninterview\n\nMultimint - video"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#mint-an-nft",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#mint-an-nft",
    "title": "Bitcoin",
    "section": "Mint an NFT",
    "text": "Mint an NFT\n# inscribe\nord wallet inscribe --fee-rate 20 ABSOLUTE_FILE_PATH"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#test",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#test",
    "title": "Bitcoin",
    "section": "TEST",
    "text": "TEST\nI inscribed an image of Logan Tobias onto the Bitcoin blockchain.\n$ ord wallet inscribe --fee-rate 20 /home/ubuntu/server-share/logan_resized.jpeg \n{\n  \"commit\": \"93f5630a6f6eb49235fb25878df06563f509ff5d5d89da6a4092af5d68eb4afd\",\n  \"inscription\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8i0\",\n  \"reveal\": \"2a7ff69382e71a01ac12884d974b3c1606d07624e3592f5c32068d1bfd8588a8\",\n  \"fees\": 282600\n}\nSat: 465805240538644\n\nOrdinal Project\nThis is a short guide on how to mint multiple ordinals quickly.\n\nCreate a Sparrow wallet to generate multiple UTXOs.\nCalculate cost per ordinal.\n\n\ncalculator\nmempool Add 600 (dust limit) + 10,000 (ordinal fee) to sats amount\n\nWe have: 132,000 sats per ordinal + 600 + 10,000 = 142,600 sats per ordinal"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html",
    "href": "library/natural-sciences/crypto/blockchain/index.html",
    "title": "Blockchains",
    "section": "",
    "text": "The Soveriegn Individual\nManifesto for a Democratic Civilization\nV for Vendetta"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#early-contributions",
    "href": "library/natural-sciences/crypto/blockchain/index.html#early-contributions",
    "title": "Blockchains",
    "section": "",
    "text": "1983, David Chaum: Electronic Cash\n1985, David Chaum: Security without Identification\n1996, Dr. Douglas Jackson and Barry K. Downey: E-Gold\n1998, Wei Dai: b-money\n1998, Nick Szabo: Bit Gold"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#layer-1-whitepapers",
    "href": "library/natural-sciences/crypto/blockchain/index.html#layer-1-whitepapers",
    "title": "Blockchains",
    "section": "Layer 1 Whitepapers",
    "text": "Layer 1 Whitepapers\n\nBitcoin: A Peer-to-Peer Electronic Cash System\nZerocash: Decentralized Anonymous Payments from Bitcoin\nEthereum: A Next-Generation Smart Contract and Decentralized Application Platform\nEthereum: A Secure Decentralized Generalized Transaction Ledger\nCosmos: Internet of Blockchains\nSolana: A new Architecture for a High Performance Blockchain\nCardano\nAlgorand: Scaling Byzantine Agreements for Cryptocurrencies\nAvalanche Platform\nThe Spacemesh Protocol\nTON: The Open Network"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#consensus",
    "href": "library/natural-sciences/crypto/blockchain/index.html#consensus",
    "title": "Blockchains",
    "section": "Consensus",
    "text": "Consensus\nAll things Byzantine Fault Tolerant: Research and implementations of consensus mechanisms.\n\nByzantine Fault Tolerance\n\nPractical Byzantine Fault Tolerance\n\n\n\nWhitepapers\n\nTendermint: Consensus without Mining\nDFINITY Consensus System\nRipple Protocol Consensus Algorithm\nAvalanche Consensus\nNarwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus\nCosmos without Tendermint\nThe Honey Badger of BFT Protocols\nHashgraph Protocol: Efficient ABFT\nByzantine Ordered Consensus without Byzantine Oligarchy\nBEAT: Asynchronous BFT Made Practical\nTON: Catchain Consensus\nAnother advantage of free choice (Extended Abstract): Completely asynchronous agreement protocols\n\n\n\nResearch\n\nLong Range Attacks on PoS\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\nBeacon Chain Casper Mini-Spec\nMitigating Balancing Attacks on LMD GHOST\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\n\n\n\nAttacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks\n\n\n\nEvents\nMay 12, 2023: Ethereum Consensus Issues\n\ntweet one\ntweet two"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#events",
    "href": "library/natural-sciences/crypto/blockchain/index.html#events",
    "title": "Blockchains",
    "section": "Events",
    "text": "Events\nMay 12, 2023: Ethereum Consensus Issues\n\ntweet one\ntweet two"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#recent-general",
    "href": "library/natural-sciences/crypto/blockchain/index.html#recent-general",
    "title": "Blockchains",
    "section": "Recent, General",
    "text": "Recent, General\n\nDBA: Proof of Governance\nBlockchain Privacy and Rgulatory Compliance: Towards a Practical Equilibrium"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#privacy",
    "href": "library/natural-sciences/crypto/blockchain/index.html#privacy",
    "title": "Blockchains",
    "section": "Privacy",
    "text": "Privacy"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Resources\n\nNeat Resource\nComplete List of Commands\n\n\n\nShort Version\n# download software\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n# extract contents\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\n# install extracted contents to local bin\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*\n# check version\nbitcoind --version\n# start the software\nbitcoind -daemon -txindex\n# check status\nbitcoin-cli -getinfo\n# check block count\nbitcoin-cli getblockcount\n# stop the software\nbitcoin-cli stop\n\n\n\nStep 1: Download Bitcoin Core\nAs of today (Feb 11, 2023), the latest version of Bitcoin Core is 24.0.1. You can find the download links here\n\nCopy the link address of the version you need - I am running Linux Ubuntu so I will use the x86_64-linux-gnu.tar.gz\n\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n\nExtract the contents\n\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\nThis downloads the contents into /usr/local/ directory\n\n\nStep 2: Install Bitcoin from Downloaded Contents\nRun this command (idk the details who cares)\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*\n\n\nStep 3: Run Bitcoin Core\nbitcoind -daemon\nYou can check the progress of syncing with bitcoin-cli -getinfo\nThis should produce something that looks like this\nubuntu@REDACTED:~$ bitcoin-cli -getinfo\nChain: main\nBlocks: 235213\nHeaders: 775994\nVerification progress: ▒░░░░░░░░░░░░░░░░░░░░ 2.1719%\nDifficulty: 10076292.88341872\n\nNetwork: in 0, out 10, total 10\nVersion: 240001\nTime offset (s): -1\nProxies: n/a\nMin tx relay fee rate (BTC/kvB): 0.00001000\nCompare “blocks” with the latest block on the chain.\n\n\nDone\nAll in all, it took me 34 minutes to figure this out."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#resources",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#resources",
    "title": "Running Bitcoin Core",
    "section": "",
    "text": "Neat Resource\nComplete List of Commands"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#short-version",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#short-version",
    "title": "Running Bitcoin Core",
    "section": "Short Version",
    "text": "Short Version\n# download software\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n# extract contents\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\n# install extracted contents to local bin\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*\n# check version\nbitcoind --version\n# start the software\nbitcoind -daemon -txindex\n# check status\nbitcoin-cli -getinfo\n# check block count\nbitcoin-cli getblockcount\n# stop the software\nbitcoin-cli stop"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#step-1-download-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 1: Download Bitcoin Core",
    "text": "Step 1: Download Bitcoin Core\nAs of today (Feb 11, 2023), the latest version of Bitcoin Core is 24.0.1. You can find the download links here\n\nCopy the link address of the version you need - I am running Linux Ubuntu so I will use the x86_64-linux-gnu.tar.gz\n\nwget https://bitcoincore.org/bin/bitcoin-core-24.0.1/\n\nExtract the contents\n\nsudo tar -C /usr/local -xzf bitcoin-24.0.1-x86_64-linux-gnu.tar.gz\nThis downloads the contents into /usr/local/ directory"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#step-2-install-bitcoin-from-downloaded-contents",
    "title": "Running Bitcoin Core",
    "section": "Step 2: Install Bitcoin from Downloaded Contents",
    "text": "Step 2: Install Bitcoin from Downloaded Contents\nRun this command (idk the details who cares)\nsudo install -m 0755 -o root -g root -t /usr/local/bin /usr/local/bitcoin-24.0.1/bin/*"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#step-3-run-bitcoin-core",
    "title": "Running Bitcoin Core",
    "section": "Step 3: Run Bitcoin Core",
    "text": "Step 3: Run Bitcoin Core\nbitcoind -daemon\nYou can check the progress of syncing with bitcoin-cli -getinfo\nThis should produce something that looks like this\nubuntu@REDACTED:~$ bitcoin-cli -getinfo\nChain: main\nBlocks: 235213\nHeaders: 775994\nVerification progress: ▒░░░░░░░░░░░░░░░░░░░░ 2.1719%\nDifficulty: 10076292.88341872\n\nNetwork: in 0, out 10, total 10\nVersion: 240001\nTime offset (s): -1\nProxies: n/a\nMin tx relay fee rate (BTC/kvB): 0.00001000\nCompare “blocks” with the latest block on the chain."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#done",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/btc-core.html#done",
    "title": "Running Bitcoin Core",
    "section": "Done",
    "text": "Done\nAll in all, it took me 34 minutes to figure this out."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/rekt/ygg.html",
    "href": "library/natural-sciences/crypto/blockchain/rekt/ygg.html",
    "title": "YGG REKT",
    "section": "",
    "text": "August 7\n9:04 am YGG in top 3 volume, followed by shitcoins with negative funding (heavy shorts)\nHsaka’s Take | tweet\nAug 6, 7:04am YGG “looking spicy” says Nik’s quant\nReported at 9:52am Binance increased the funding rate settlement frequency from 8 hours to 2 hours\nReminder that 2018 scam pumps were even crazier\n\nso much commentary and ‘hate’ on the YGG situation when people don’t remember the summer of 2022 where we had 10x pumps in 1 minute on shitcoins. oh sweet children you haven’t experienced the true depths of market manipulation yet"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/apps/ethena/ethena.html",
    "href": "library/natural-sciences/crypto/blockchain/apps/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "Some thoughts on @ethena_labs and the attempt towards a stablecoin, $USDe, independent of the traditional banking system. https://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\nQuick Overview of the Basic Mechanism\n\n1 $USDe is backed by a $1 delta neutral ETH position. - Long $1 of stETH spot - Short $1 of ETH perpetual futures swap contracts (on a centralized exchange, with the spot stETH as cross-collateral).\nFor a more substantial overview, check out @cryptohayes (Ethena advisor) “Dust on Crust” https://blog.bitmex.com/dust-on-crust/\n\nA note the scale of this endeavor (relevant later).\n\nEthena is pursuing a trillion dollar TAM.\n\nStablecoin circulating supply sits comfortably above $100 billion (throughout the bear market).\nTether printed over $1 billion in profit last quarter.\nThe CBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n\nOn the surface, there’s two obvious/primary risks to the mechanism.\n\nCounterparty (exchange) Risk\nBasis (funding rate) Risk\n\n\nHow, and to what extent, is Ethena mitigating these?\n\nAddressing Counterparty Risk\n\nWhether its an external hack (Mt Gox) or insider theft (FTX) - CEX risk is certainly non-negligible. What’s the risk-adjusted rate at which you would park 8+ figures on Binance, or Deribit? This is a serious question that crypto firms (HFT shops, VC firms) decide internally…\nIn other words, if Binance were a public company, where would their credit default swaps trade?\nCounter to what @cryptohayes initially described in his early writings, Ethena must avoid custodying the assets at the exchanges. Instead, park the assets with a secure third party (Fireblocks, Ledger, Copper), form agreements with the exchanges to accept this (likely some form of ZK-Proof of stETH asset balance) as collateral, and simply settle funding payments on the derivatives intermittently.\nThis doesn’t exactly eliminate all counterparty risk (can expand on this in the future), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\n\nAddressing Basis Risk\n\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\nFounder @leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n\nI will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\n\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n\nHowever, I subscribe to two principles which may complicate this assumption.\n\nThe Observer Effect: The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\n\nConsidering the scale of the stablecoin market, it’s naive to neglect the reflexivity of the relationship between Ethena’s operations/supply and the aggregate ETH perp funding rate.\nThe in-sample backtest shown in the previous tweet simulates yield on $5b circulating $USDe supply. What’s not mentioned, however, is that $USDe would have represented roughly half of aggregate ETH open interest… the backtest is inherently flawed.\n\n\n\n\nAlthough it’s important to point out weakness of the backtest, this doesn’t necessarily suggest a point of failure for $USDe.\n\nThe design is fundamentally different from the UST-esque algostables, which were always necessarily destined to collapse. In fact, if Ethena’s mint & redemption process is both free and (near) instant, the $USDe mechanism can be inherently self-correcting.\nLet’s imagine the $USDe supply was $5b today, Ethena would represent nearly half of the $10b ETH perp open interest, and the funding rate would likely be negative (exact threshold for % of OI Ethena can be comfortable with is unclear, but 50% is probably unhealthy).\nWith transparent metrics on curculating supply, assets, liabilities, and distribution (what % of the shorts are on BitMex vs Bybit vs …), the market can observe collateral fluctuations, and react rationally. Users swap out of $USDe on Curve, which is purchased by market makers/arbitrageurs who then redeem with Ethena. This lifts the short pressure until the funding rate (or net yield, including stETH) is positive again.\n\nThere is certainly much more to be discussed.\n\n\nWhat can be done to further mitigate exchange risk, even if it’s only relevant to the short derivative leg?\nWhere will the “natural funding rate” converge with this mechanism implemented at scale?\nWhat role does the insurance fund play, and how shall it be sized/scaled optimally?\nCan the “internet bond” effectively offer an inversely correlated yield to bonds (think crypto OI/perp funding in bullish, low-rate environment vs high-rate)?\n\nBut I’ll end the thread here for now.\nThe @ethena_labs team is legit, and it’s clear they are continuing to diligence the relevant considerations. A bankless stablecoin is a pivotal instrument for the cryptoeconomy, and I look forward to further public engagement as this develops. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/apps/ethena/ethena.html#tweet-thread",
    "href": "library/natural-sciences/crypto/blockchain/apps/ethena/ethena.html#tweet-thread",
    "title": "Ethena Labs",
    "section": "",
    "text": "Some thoughts on @ethena_labs and the attempt towards a stablecoin, $USDe, independent of the traditional banking system. https://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\nQuick Overview of the Basic Mechanism\n\n1 $USDe is backed by a $1 delta neutral ETH position. - Long $1 of stETH spot - Short $1 of ETH perpetual futures swap contracts (on a centralized exchange, with the spot stETH as cross-collateral).\nFor a more substantial overview, check out @cryptohayes (Ethena advisor) “Dust on Crust” https://blog.bitmex.com/dust-on-crust/\n\nA note the scale of this endeavor (relevant later).\n\nEthena is pursuing a trillion dollar TAM.\n\nStablecoin circulating supply sits comfortably above $100 billion (throughout the bear market).\nTether printed over $1 billion in profit last quarter.\nThe CBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n\nOn the surface, there’s two obvious/primary risks to the mechanism.\n\nCounterparty (exchange) Risk\nBasis (funding rate) Risk\n\n\nHow, and to what extent, is Ethena mitigating these?\n\nAddressing Counterparty Risk\n\nWhether its an external hack (Mt Gox) or insider theft (FTX) - CEX risk is certainly non-negligible. What’s the risk-adjusted rate at which you would park 8+ figures on Binance, or Deribit? This is a serious question that crypto firms (HFT shops, VC firms) decide internally…\nIn other words, if Binance were a public company, where would their credit default swaps trade?\nCounter to what @cryptohayes initially described in his early writings, Ethena must avoid custodying the assets at the exchanges. Instead, park the assets with a secure third party (Fireblocks, Ledger, Copper), form agreements with the exchanges to accept this (likely some form of ZK-Proof of stETH asset balance) as collateral, and simply settle funding payments on the derivatives intermittently.\nThis doesn’t exactly eliminate all counterparty risk (can expand on this in the future), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\n\nAddressing Basis Risk\n\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\nFounder @leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n\nI will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\n\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n\nHowever, I subscribe to two principles which may complicate this assumption.\n\nThe Observer Effect: The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\n\nConsidering the scale of the stablecoin market, it’s naive to neglect the reflexivity of the relationship between Ethena’s operations/supply and the aggregate ETH perp funding rate.\nThe in-sample backtest shown in the previous tweet simulates yield on $5b circulating $USDe supply. What’s not mentioned, however, is that $USDe would have represented roughly half of aggregate ETH open interest… the backtest is inherently flawed.\n\n\n\n\nAlthough it’s important to point out weakness of the backtest, this doesn’t necessarily suggest a point of failure for $USDe.\n\nThe design is fundamentally different from the UST-esque algostables, which were always necessarily destined to collapse. In fact, if Ethena’s mint & redemption process is both free and (near) instant, the $USDe mechanism can be inherently self-correcting.\nLet’s imagine the $USDe supply was $5b today, Ethena would represent nearly half of the $10b ETH perp open interest, and the funding rate would likely be negative (exact threshold for % of OI Ethena can be comfortable with is unclear, but 50% is probably unhealthy).\nWith transparent metrics on curculating supply, assets, liabilities, and distribution (what % of the shorts are on BitMex vs Bybit vs …), the market can observe collateral fluctuations, and react rationally. Users swap out of $USDe on Curve, which is purchased by market makers/arbitrageurs who then redeem with Ethena. This lifts the short pressure until the funding rate (or net yield, including stETH) is positive again.\n\nThere is certainly much more to be discussed.\n\n\nWhat can be done to further mitigate exchange risk, even if it’s only relevant to the short derivative leg?\nWhere will the “natural funding rate” converge with this mechanism implemented at scale?\nWhat role does the insurance fund play, and how shall it be sized/scaled optimally?\nCan the “internet bond” effectively offer an inversely correlated yield to bonds (think crypto OI/perp funding in bullish, low-rate environment vs high-rate)?\n\nBut I’ll end the thread here for now.\nThe @ethena_labs team is legit, and it’s clear they are continuing to diligence the relevant considerations. A bankless stablecoin is a pivotal instrument for the cryptoeconomy, and I look forward to further public engagement as this develops. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/apps/ethena/ethena.html#thread-draft-old",
    "href": "library/natural-sciences/crypto/blockchain/apps/ethena/ethena.html#thread-draft-old",
    "title": "Ethena Labs",
    "section": "Thread Draft OLD",
    "text": "Thread Draft OLD\n\nSome thoughts on @ethena_labs and $USDe, an attempt towards a stablecoin which is independent of the traditional banking system.\n\nhttps://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\n2/ First, a quick mid-bell summary of USDe mechanism\n\nAlice deposits $1 worth of some asset (USDC, WBTC, doesn’t matter)\nEthena swaps this for $1 worth of stETH, which is then used as cross-collateral for a $1 notional ETH perp short on some CEX\nEthena mints 1 $USDe to Alice, backed by the delta-neutral $1 position\n\nFor a more substantial overview, check out @cryptohayes “Dust on Crust” (which Ethena cites as inspiration)\nhttps://blog.bitmex.com/dust-on-crust/\n3/ Let me note the scale of this endeavor (relevant later).\n\nStablecoin circulating supply sits comfortably above $100 billion throughout the bear market.\nTether printed over $1 billion in profit last quarter.\nCBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\nEthena is pursuing is a trillion dollar TAM.\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n4/ Okay, so there’s two obvious/primary risks to the $USDe mechanism\n\nCounterparty (CEX) Risk\nBasis Risk\n\nHow is Ethena addressing these?\n5/ Addressing Counterparty Risk\nWhether its an external hack (Mt Gox) or insider theft (FTX) doesn’t matter - CEX risk is real. How much would you have to get paid to park your funds at Binance? 30%? 80%? This is a real question that CEX HFT shops and crypto VCs decide internally - the consensus is almost certainly above $USDe’s expected yield.\nThe only proper mitigation I see is to avoid custodying assets at the exchanges. Park the stETH in Fireblocks, Ledger, etc. and make special agreements with Binance, Bybit, Bitmex, etc. to accept this (likely some form of ZK-Proof of stETH asset claim) as collateral, and simply settle funding payments intermittently.\nThis doesn’t exactly eliminate all counterparty risk (still an operational nightmare/panic if Binance goes FTX mode), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\nTODO: Mention the black swan force exit short perps too (the BitMex event)? - Ethena redemption should have scaled down exposure in the hours and minutes prior to this event (funding will necessarily have been negative before the trigger) - Ethena is hedged across multiple CEXes (historically this happens on one exchange at a time) - Ethena insurance fund as final backstop\n6/ Addressing Basis Risk\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\n@leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n7/ I will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n8/ However, I subscribe to two schools of thought which may challenge this assumption.\n\nQuantum Mechanics (the observer effect): The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\nKeeping in mind the scale of the stablecoin market, it’s naive to neglect the reflexivity bwteen Ethena’s operations and the ETH perp funding rate. The backtested yield in the previous tweet is under the assumption of $5b circulating $USDe supply - I predict this in-sample backtesting wil. This implies a $5b short OI, which is sustantial considering aggregate OI seen historically.\nThe image below shows Binance alone, but including Bybit, Bitmex, Derbit, and OKEx, total OI on ETH perpetual swaps is ~$TODO. Ethena would represent TODO% of ETH perp OI across all major exchanges.\n\n\n\nFix Up - not final\n9/ The question becomes: In the scenario wherein $USDe is widely adopted, what is the “natural funding rate” of ETH perps? Here’s a thesis:\nThe introduction of ETH staking, and liquid staking derivatives, effectively increased the baseline ETH lending rate (ETH’s LIBOR/SOFR) by the network’s staking yield. Why would anyone lend ETH at 80bps, when they can deposit for an LSD and earn 5% (where they can also then lend the LSD for 80bps)?\nThe “natural funding rate” baseline (not including the upwards skew cause by net bullish payment for leverage, which will remain a factor) on ETH perps will no longer necessarily == risk-free rate, as traditionally assumed for non-interest accruing assets (BTC, Gold, etc.). Instead, it will begin to additionally reflect the yield of ETH staking (risk-free rate - expected stETH yield). {{\n\n\n\n}}\n10/ Explain the logic - how other traders will arb funding rate considering availability of stETH as collateral. Why would this suggest a negative bias ~= eth yield.\nFin/ The team behind Ethena is legit. To their credit, it seems they are continuing to diligence this concern. This is a pivotal mechanism for the crypto economy, and I look forward to the exploration that is to come. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20\nTODO: Mention the black swan force exit short perps too (the BitMex event)? - Ethena redemption should have scaled down exposure in the hours and minutes prior to this event (funding will necessarily have been negative before the trigger) - Ethena is hedged across multiple CEXes (historically this happens on one exchange at a time) - Ethena insurance fund as final backstop"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/mev/amm/index.html",
    "href": "library/natural-sciences/crypto/blockchain/mev/amm/index.html",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/mev/amm/index.html#papers-research",
    "href": "library/natural-sciences/crypto/blockchain/mev/amm/index.html#papers-research",
    "title": "MEV on AMMs",
    "section": "",
    "text": "Automated Market Making and Arbitrage Profits in the Presence of Fees\nJaredFromSubway.eth’s Access Lists | etherscan"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/mev/amm/index.html#strategies",
    "href": "library/natural-sciences/crypto/blockchain/mev/amm/index.html#strategies",
    "title": "MEV on AMMs",
    "section": "Strategies",
    "text": "Strategies\n\nIncoming Swap\n\nSandwiching\n\nIncoming buy, deliver bundle {mybuy, buy, mysell}\nIncoming sell (requires inventory), deliver bundle {mysell, sell, mybuy} (JaredFromSubway’s claim to fame and riches)\n\n\n\nJIT Liquidity\nIncoming transaction, frontrun it with a large liquidity position at the optimal tick bounds\n\n\nJIT + Sandwich Combo\nThis is the optimal strategy assuming negligible gas fees\n\nIncoming buy: frontrun buy, add LP, victim buy, remove LP, backrun sell\nIncoming sell: opposite\n\nResources on it: tweet 1\nExample bot executing this etherscan\nList of examples in prod tweet\n\n\n\nIncoming Liquidity Provision Position\n\nLP Addition\nIncoming LP Addition, deliver bundle {mybuy, lpAdd, mysell} - since liquidity is greater during sell, face less slippage - net sell price &gt; net buy price\n\n\nLP Removal\nIncoming LP Removal, deliver bundle {mysell, lpRemove, mybuy} - since liquidity is greater during buy, face less slippage. End up with more tokens than you started with. - net sell price &lt; net buy price"
  },
  {
    "objectID": "library/natural-sciences/finance/index.html#finance-reads",
    "href": "library/natural-sciences/finance/index.html#finance-reads",
    "title": "Finance",
    "section": "",
    "text": "The Intelligent Investor\nFlash Boys\nLiars Poker\nBeat the Dealer\nAlchemy of Finance\nWhen Genius Failed\nExotic Options and Hybrids\n\nVol. models, correlation, forward starting options, barriers, ATRs, etc.\n\nThe Smartest Guys in the Room\nReminiscences of a Stock Operator\nMore Money than God"
  },
  {
    "objectID": "library/natural-sciences/finance/index.html#good-reads",
    "href": "library/natural-sciences/finance/index.html#good-reads",
    "title": "Finance",
    "section": "",
    "text": "The Intelligent Investor\nFlash Boys: History of HFT, frontrunning, etc\nLiars Poker: Solomon Brothers and the real start of bond trading\nBeat the Dealer\nAlchemy of Finance: Soros’ Reflexivity theory of markets\nWhen Genius Failed: The rise and fall of Long Term Capital Management\nExotic Options and Hybrids: Vol. models, correlation, barriers, ATRs, etc.\nThe Smartest Guys in the Room: The massive fraud of Enron\nReminiscences of a Stock Operator: An absolute classic on stock trading\nMore Money than God: On the hedge fund industry\nThe Changing World Order: Ray Dalio’s macro book\nThe Black Swan\nBeat the Market: Highly coveted book by some iconic quants\nThe Art of Currency Trading: A Professional’s Guide to the Foreign Exchange Market\nThe Disciplined Trader\nTrader Vic II: Principles of Professional Speculation\nLearn to Trade Momentum Stocks\nThe Bond and Money Markets\nTrading in the Zone\nBollinger on Bollinger Bands\nAdventures of a Currency Trader\nAce the Trading Systems Developer Interview (C++ Edition)\nProfessional Automated Trading: Theory and Practice\nTrading Systems Performance Unleashed: Mastering Latency and Efficiency in High-Frequency Trading"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html",
    "href": "library/natural-sciences/crypto/cryptography/index.html",
    "title": "Cryptography",
    "section": "",
    "text": "Applied Cryptography\nNSA: tor Stinks\nComplete Knowledge: Preventing Encumbrance of Cryptographic Secrets"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#zero-knowledge",
    "href": "library/natural-sciences/crypto/cryptography/index.html#zero-knowledge",
    "title": "Cryptography",
    "section": "Zero Knowledge",
    "text": "Zero Knowledge\n\nExample: The 3-Color Graph Coloring Problem\nA Zero-Knowledge Proof (ZKP) allows a prover to demonstrate knowledge of some secret without revealing the secret itself. Let’s illustrate this using a graph coloring problem.\n\nProblem Statement\nImagine Alice has a graph \\((G = (V, E))\\), where \\((V)\\) is the set of vertices and \\((E)\\) is the set of edges. Alice claims she can 3-color the graph so that no adjacent vertices share the same color. Bob wants to verify this claim without learning the actual coloring.\n\n\nThe ZKP Protocol\n\nCommitment: Alice chooses a random permutation of her 3-coloring and commits to it, sending a cryptographic hash of each vertex’s color to Bob.\nChallenge: Bob randomly selects an edge \\(((u, v) \\in E)\\)\nResponse: Alice reveals the colors of vertices \\((u)\\) and \\((v)\\).\nVerification: Bob checks if the revealed colors are different and match the hash commitments.\n\nThrough repeated iterations, Bob becomes increasingly confident that Alice has a valid 3-coloring, but gains no knowledge about the coloring itself.\n\n\nMath Syntax\n\nGraph: \\((G = (V, E))\\)\nColors: \\((\\{ \\text{Red}, \\text{Green}, \\text{Blue} \\})\\)\nRandom Permutation: \\((\\pi)\\)\nHash Commitment for vertex \\((v): ( H(\\pi(\\text{color}(v))) )\\)\n\nThis example shows that ZKPs can provide robust verification without sacrificing the secrecy of the information involved.\n\n\nConclusion\nGraph three coloring is NP-complete. Thus, any protocol that can prove a solution to this problem can be used to prove any statement in the class NP.\nThree critical properties a ZKP must satisfy:\n\nCompleteness: If the Prover is honest, then she will eventually convince the Verifier.\nSoundness: The Prover can only convince the Verifier if the statement is true.\nZero-knowledge(ness): The Verifier learns no information beyond the fact that the statement is true.\n\n\n\n\nReads\nEducational Resources\n\nZKP Illustrated Primer Part 1\nZKP Illustrated Primer Part 2\nZkIntro\n\nResource Compilations\n\nZero Knowledge A-Z\nHickup’s ZK Journey\nZK “Canon” by A16z\nZKP.Science\n\nVideo Resources\n\nRiscZero Study Club\nIntroduction to Zero Knowledge: Video Tutorial\n\nFoundational Papers\n\nNew Directions in Cryptography, 1976\nPublic-coin zero-knowledge arguments with (almost) minimal time and space overheads, 2020\nA method for obtaining digital signatures and public-key cryptosystems\nProofs, Arguments, and Zero-Knowledge\n\nTechnical Deep Dives\n\nOverview of Verifiable Computing\nInteractive Proofs\nMeasuring SNARK Performance\nWhy and How ZK-SNARK Works\nSuccint Non-Interactive Zero Knowledge for a von Neumann Architecture\nPLONK Explainer by Vitalik\nPLONK ePrint\nStreaming Zero-Knowledge Proofs\nWhy and How ZK-SNARK Works\nFast Amortized KZG Proofs\nZK Development Playground\nBeginner Intro to Coding ZK Proofs\n\n\n\nPractical Applications\n\nApplied ZK\nCrypto Regulations, Privacy and Beyond\nZK Benchmarks\n\n\n\nProjects\nAxiom: Building a zk coprocessor for Ethereum\n\nTwitter\nWebsite\nDemo\nDocs\n\nRiscZero: Making generalizable computer architecture for ZK\n\nwebsite\ndocs\ngithub\n\nBlockchain product: Bonsai - docs - starter template\nZK Proof of Exploit\n\ntwitter"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#fully-homomorphic-encryption",
    "href": "library/natural-sciences/crypto/cryptography/index.html#fully-homomorphic-encryption",
    "title": "Cryptography",
    "section": "Fully Homomorphic Encryption",
    "text": "Fully Homomorphic Encryption\n\nReads\n\nFirst Ever Fully Homomorphic Encryption Scheme\nVitalik on FHE\n\nOriginal FHE innovation with bootstrapping (inefficient)\n\n2009, Fully homomorphic encryption using ideal lattices\n2010, Computing arbitrary functions of encrypted data\n\nEfficiency Improvements\n\n2019, TFHE: Fast Fully Homomorphic Encryption Over the Torus\n2021, Programmable Bootstrapping Enables Efficient Homomorphic Inference of Deep Neural Networks\n2023, TFHE Public-Key Encryption Revisited\n\nbased on a variant of Learning With Errors (LEW) problem, first introduced by Regev On lattices, learning with errors, random linear codes, and cryptography\n\n\n\n\nProjects\nZama\n\nwebsite\ndocumentation\ngithub\nZama Concrete: documentation\n\n\n\nfhEVM\n\nfhEVM\nTFHE.sol\nFhenix Blockchain\n\nRelated\n\nPractical and Efficient FHE-based MPC\nNoah’s Ark: Efficient Threshold-FHE Using Noise Flooding\n\n\nNotes\nThere is a global FHE key under which all inputs and private state are encrypted. This allows easy mixing of encrypted data across users and smart contracts. Private decryption key is a secret shared across the validators.\nProviding an encrypted input\nTo provide an encrypted input to a transaction or view function, users must submit two values. 1) encrypted input using the global public FHE key. 2) The associated valid zero-knolwedge proof of plaintext knowledge. These components form a ceritifed cyphertext.\nSolidity Library: TFHE\nOffers four types: euint8, euint16, euint32, ebool.\n\n\n\nKZG Commitments\n\n(Original Paper) Constant-Size Commitments to Polynomials and Their Applications\nDankrad Feist, KZG Polynomial Commitments\n\n\n\nBLS\nBoneh-Lynn-Shacham Signature Scheme\n\nBLS Introduction\nBLS Signature Scheme\nPragmatic signature aggregation with BLS\nBLS Signature for Busy People"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#tools",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#tools",
    "title": "Bitcoin",
    "section": "Tools",
    "text": "Tools\n\nExplorer"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#bitcoin-transaction-versions",
    "href": "library/natural-sciences/crypto/blockchain/bitcoin/index.html#bitcoin-transaction-versions",
    "title": "Bitcoin",
    "section": "Bitcoin Transaction Versions",
    "text": "Bitcoin Transaction Versions\nBitcoin transactions have undergone various upgrades to improve scalability, security, and functionality. This document aims to elucidate the differences among different Bitcoin transaction versions, focusing on cryptographic aspects such as address formats and transaction input/output (tx I/O) variations.\n\nLegacy\nLegacy Transactions Support both Legacy addresses (P2PKH) and Script addresses (P2SH)\nLegacy Address Format (P2PKH)\n\nBase58Check encoded\nStarts with 1\n\nCryptographic Aspects\n\nPublic Key Hash (PKH) derived from SHA256 and RIPEMD160\nScriptSig (Unlocking Script): PUSH [Sig] PUSH [PubKey]\nScriptPubKey (Locking Script): OP_DUP OP_HASH160 [PKH] OP_EQUALVERIFY OP_CHECKSIG\n\nScript Address Format (P2SH)\n\nBase58Check encoded\nStarts with 3\n\nCryptographic Aspects\n\nScript Hash (SH) derived from SHA256 and RIPEMD160\nScriptSig: PUSH [Redeem Script]\nScriptPubKey: OP_HASH160 [SH] OP_EQUAL\n\nInput:\n\nUTxO (Unspent Transaction Output): Identified by a txid and an output number.\nScript Signature: Proves possession of the private key for the address owning the UTxO.\n\nOutput:\n\nAmount: In satoshis.\nPublic Spending Script: Two primary types.\n\nP2PKH (Pay to Public Key Hash): 25 bytes, specific to a single public key.\nP2SH (Pay to Script Hash): 23 bytes, allows for multisignature transactions.\n\n\nResources\n\nLegacy Addresses\nScript Addresses\n\n\n\nSegwit (Segregated Witness)\nAddress Format (P2WPKH, P2WSH)\n\nBech32 encoded\nStarts with bc1\n\nCryptographic Aspects\n\nWitness Program derived from SHA256\nScriptSig (Unlocking Script): Absent, replaced by witness data\nScriptPubKey (Locking Script): 0 [20-byte PKH or 32-byte script hash]\n\nInput:\n\nUTxO (Unspent Transaction Output): Identified by a txid and an output number.\nScript Signature: Replaced by witness data, validated separately.\n\nOutput:\n\nAmount: In satoshis.\nWitness Program: Two primary types.\n\nP2WPKH (Pay to Witness Public Key Hash): 22 bytes, simple single-signature transactions.\nP2WSH (Pay to Witness Script Hash): 32 bytes, multisignature or complex scripts.\n\n\nAdditional Context\n\nSoft Fork Introduction: Increases blockchain space efficiency.\nPractical Implications: Enables a practical Lightning Network.\nTxid Malleability: Fixes some attacks related to transaction ID malleability.\nVersions: 50% of transactions use version 0; the remainder are legacy.\n\nResources\n\nSegwit Addresses\n\n\n\nTaproot\nAddress Format (P2TR)\n\nBech32m encoded\nStarts with bc1p\n\nCryptographic Aspects\n\nUtilizes Schnorr signatures\nScriptSig (Unlocking Script): Absent, replaced by witness and control block\nScriptPubKey (Locking Script): 1 [32-byte public key]\n\nInput:\n\nUTxO (Unspent Transaction Output): Identified by a txid and an output number.\nScript Signature: Replaced by Schnorr signature and optional control block for spending conditions.\n\nOutput:\n\nAmount: In satoshis.\nPublic Spending Script:\n\nP2TR (Pay to Taproot): 32 bytes, allows flexible conditions with Schnorr and MAST.\n\n\nAdditional Context\n\nMAST: Merkle Abstract Syntax Trees allow hashing scripts to produce a root hash, enabling proof of transaction validity without revealing the master public key.\n\nResources\n\nTaproot Addresses\n\n\n\nSummary\n\n\n\n\n\n\n\n\n\n\nVersion\nAddress Encoding\nKey/Script Hashing\nScriptSig\nScriptPubKey\n\n\n\n\nP2PKH\nBase58Check\nSHA256/RIPEMD160\nPUSH [Sig] PUSH [PubKey]\nOP_DUP OP_HASH160 [PKH] ...\n\n\nP2SH\nBase58Check\nSHA256/RIPEMD160\nPUSH [Redeem Script]\nOP_HASH160 [SH] OP_EQUAL\n\n\nP2WPKH\nBech32\nSHA256/RIPEMD160\nEmpty\nOP_0 [WPKH]\n\n\nP2TR\nBech32m\nSchnorr\nEmpty\nOP_1 [TOK]\n\n\n\nTrade-offs\nUnderstanding the cryptographic nuances among different Bitcoin transaction versions reveals trade-offs in three main domains: complexity, scalability, and security.\nComplexity\n\nP2PKH: Simple but less flexible. Good for basic transactions but limited in complex conditions.\nP2SH: More complex due to the redeem script but offers multi-sig capabilities.\nP2WPKH: Simplified transaction size but requires new address format, which might not be supported everywhere.\nP2TR: Most complex, leveraging Schnorr signatures and Merkle trees. Allows scriptless scripts and aggregated signatures.\n\nScalability\n\nP2PKH: Larger transaction sizes result in higher fees.\nP2SH: Can be size-efficient for complex conditions, but generally heavier than P2PKH.\nP2WPKH: SegWit improves scalability by separating the witness, thereby reducing transaction size.\nP2TR: Potentially most scalable, allowing complex conditions without bloating the blockchain.\n\nSecurity\n\nP2PKH: Reliable but lacks native multi-sig and other advanced features.\nP2SH: Enables multi-sig but could be susceptible to hash collision attacks.\nP2WPKH: Inherent SegWit benefits such as eliminating third-party malleability.\nP2TR: Provides the highest security, including script privacy and aggregated signatures.\n\nThe intricacies in cryptographic mechanisms across versions are not just academic curiosities; they have practical implications in choosing the right transaction type for specific use-cases. Thus, this understanding is pivotal for both academic and applied research."
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#learning-resources",
    "href": "library/natural-sciences/crypto/cryptography/index.html#learning-resources",
    "title": "Cryptography",
    "section": "",
    "text": "Applied Cryptography\n\n\n\n\nPolynomial Commitment Schemes Multiproofs using Random Evaluation\n\n\n\n\n\nNSA: tor Stinks\n\n\n\n\n\nPublic-Key Quantum Money from Collision-Resistant Hash Functions\n\n\n\n\n\nShucking Attacks\nBreaking Elliptic Curve - How to compute a 256-bit elliptic curve private key with only 50 million Toffoli gates"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#resources",
    "href": "library/natural-sciences/crypto/cryptography/index.html#resources",
    "title": "Cryptography",
    "section": "",
    "text": "Applied Cryptography\nNSA: tor Stinks\nComplete Knowledge: Preventing Encumbrance of Cryptographic Secrets"
  },
  {
    "objectID": "library/natural-sciences/software/index.html#firmware",
    "href": "library/natural-sciences/software/index.html#firmware",
    "title": "Software",
    "section": "Firmware",
    "text": "Firmware\n\nReverse Engineering Qualcomm Baseband Scripts"
  },
  {
    "objectID": "library/natural-sciences/software/cybersec/index.html",
    "href": "library/natural-sciences/software/cybersec/index.html",
    "title": "Cybersecurity",
    "section": "",
    "text": "hackertest.net"
  },
  {
    "objectID": "library/natural-sciences/software/cybersec/index.html#learning",
    "href": "library/natural-sciences/software/cybersec/index.html#learning",
    "title": "Cybersecurity",
    "section": "",
    "text": "hackertest.net"
  },
  {
    "objectID": "library/natural-sciences/software/cybersec/index.html#tools",
    "href": "library/natural-sciences/software/cybersec/index.html#tools",
    "title": "Cybersecurity",
    "section": "Tools",
    "text": "Tools\n\nSubdomain finder (e.g. ___.example.com)\n\nin use\n\nScout2: AWS Security Tool\n\nPrivacy Protect - github - website - original article\nSim Swap Protectins - Efani"
  },
  {
    "objectID": "library/natural-sciences/software/cybersec/index.html#articles",
    "href": "library/natural-sciences/software/cybersec/index.html#articles",
    "title": "Cybersecurity",
    "section": "Articles",
    "text": "Articles\nEthClipper: A Clipboard Meddling Attack on Hardware Wallets with Address Verification Evasion - paper\nOnly Safe Way to Store Crypto - article\nTempest: Spying on information systems through leaking emanations - wiki"
  },
  {
    "objectID": "library/natural-sciences/software/languages/python/index.html",
    "href": "library/natural-sciences/software/languages/python/index.html",
    "title": "Python",
    "section": "",
    "text": "Generate LaTex with Python - tweet - github - colab\nFastAPI: Making Web APIs - docs\nTyper: Making Python CLI Apps - docs\nReact for Python Now Exists - github"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#proof-of-stake",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#proof-of-stake",
    "title": "Ethereum",
    "section": "Proof of Stake",
    "text": "Proof of Stake\n\n100 Days After the Merge\nWithdrawals after Shanghai\nOfficial Merge Announcement\nExploring Inequality in Proof of Stake by Barnabe Monnot (RIG/EF)\nWhat Happens After Finality in eth2 by Raul Jordan (Prysmatic)\nRocketpool Post-Merge research\n(Un-)Timeliness in PoS Ethereum by Caspar Schwarz-Schilling (RIG/EF)"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#bls",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#bls",
    "title": "Ethereum",
    "section": "BLS",
    "text": "BLS\n\nBLS Introduction\nBLS Signature Scheme\nPragmatic signature aggregation with BLS\nBLS Signature for Busy People\nSSZ\n\n[https://www.simpleserialize.com/](https://www.simpleseria\n\n\n\nEIPs\nEIP-3675: Proof of Stake\n\nEIP-3675: Upgrade consensus to Proof-of-Stake\nEth Withdrawals FAQ\n100 Days After the Merge\nWithdrawals after Shanghai\nOfficial Merge Announcement\nExploring Inequality in Proof of Stake by Barnabe Monnot (RIG/EF)\nWhat Happens After Finality in eth2 by Raul Jordan (Prysmatic)\nUnderstanding Eth2 Slashing Preventative Measures\n\nEIP-4844: Proto-Danksharding\n\nEIP-4844: Shard Blob Transactions\nDanksharding\nPolynya on Danksharding\nNightshade: Near Protocol Sharding Design\nThe Tie: Danksharding\nProto-Danksharding FAQ by Vitalik Buterin (EF)\n“Dude, what’s the Danksharding situation?” Workshop by Dankrad Feist & Vitalik Buterin (EF)\n\n\n\n2938/4337\nAccount Abstraction\n\nEIP-2938: Account Abstraction\nERC-4337: Account Abstraction Using Alt Mempool\nAccount Abstraction in a Multichain Landscape - Part 1: Addresses\nWhat’s in an Account?\n\n\n\nOther\n\nEIP-1153: Transient Storage"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#ethos",
    "href": "library/natural-sciences/crypto/blockchain/index.html#ethos",
    "title": "Blockchains",
    "section": "",
    "text": "The Soveriegn Individual\nManifesto for a Democratic Civilization\nV for Vendetta"
  },
  {
    "objectID": "library/natural-sciences/crypto/legal/index.html",
    "href": "library/natural-sciences/crypto/legal/index.html",
    "title": "Legal",
    "section": "",
    "text": "SEC Comissioner Hester M. Peirce, on the Kraken Suit\nSEC Charges Terraform (Luna) with Fraud\nFBI Confirms Lazarus Group Cyber Actors Responsible for Harmony’s Horizon Bridge Currency Theft\nU.S. Attorney Damian Williams announces the first-ever criminal case involving an attack on a smart contract operated by a decentralized cryptocurrency exchange.\nTornado Cash and Blockchain Privacy: A Primer for Economists and Policymakers"
  },
  {
    "objectID": "library/natural-sciences/software/languages/bash/index.html",
    "href": "library/natural-sciences/software/languages/bash/index.html",
    "title": "bash",
    "section": "",
    "text": "##########################\n### ALIAS \nnano ~/.zshrc\nalias sshgeth='ssh &lt;USER&gt;@&lt;IP_ADDRESS&gt;'\nsource ~/.zshrc\n\n##########################\n### Directory Mainpuations\n\n# create directory\nmkdir\n# copy directory and contents\ncp -r\n# move directory and contents\nmv -r\n# remove directory and contents\nrm -r\n# remove directory contents without prompt\nrm -rf /path/to/directory/*\n# example: copies all files in directory to another directory and uses variable date for name\ncp -r logs/futures datastore/futures_$(date +%Y%m%d_%H:%M)\nrm -rf logs/futures/*\n\n##########################\n### File Manipulation\n# create file\ntouch filename.txt\n# edit file\nnano filename.txt\n\n##########################\n### Screens\n\n# list all screens\nscreen -ls\n# create new screen\nscreen -S screen_name\n# detach from screen\nctrl+a d\n# reattach to screen\nscreen -r screen_name\n# check if you are on a screen\necho $STY\n\n##########################\n### Jobs\n\n# list all jobs\njobs\n# kill job\nkill %job_number\n# bring job to foreground\nfg %job_number\n# bring job to background\nbg %job_number\n# bring current job to background\nctrl+z\n\n##########################\n### Disk Space\n\n# check disk space\ndf -h\n# check disk space of directory\ndu -sh /path/to/directory\n# check disk space of directory and subdirectories\ndu -sh /path/to/directory/*\n\n##########################\n### No Sleep\n\n# keep computer awake for 1 hr\ncaffeinate -t 3600 &\n# keep awake until command finishes\ncaffeinate -i long_running_script.sh"
  },
  {
    "objectID": "library/natural-sciences/software/languages/bash/index.html#bash-cheatsheet",
    "href": "library/natural-sciences/software/languages/bash/index.html#bash-cheatsheet",
    "title": "bash",
    "section": "",
    "text": "##########################\n### ALIAS \nnano ~/.zshrc\nalias sshgeth='ssh &lt;USER&gt;@&lt;IP_ADDRESS&gt;'\nsource ~/.zshrc\n\n##########################\n### Directory Mainpuations\n\n# create directory\nmkdir\n# copy directory and contents\ncp -r\n# move directory and contents\nmv -r\n# remove directory and contents\nrm -r\n# remove directory contents without prompt\nrm -rf /path/to/directory/*\n# example: copies all files in directory to another directory and uses variable date for name\ncp -r logs/futures datastore/futures_$(date +%Y%m%d_%H:%M)\nrm -rf logs/futures/*\n\n##########################\n### File Manipulation\n# create file\ntouch filename.txt\n# edit file\nnano filename.txt\n\n##########################\n### Screens\n\n# list all screens\nscreen -ls\n# create new screen\nscreen -S screen_name\n# detach from screen\nctrl+a d\n# reattach to screen\nscreen -r screen_name\n# check if you are on a screen\necho $STY\n\n##########################\n### Jobs\n\n# list all jobs\njobs\n# kill job\nkill %job_number\n# bring job to foreground\nfg %job_number\n# bring job to background\nbg %job_number\n# bring current job to background\nctrl+z\n\n##########################\n### Disk Space\n\n# check disk space\ndf -h\n# check disk space of directory\ndu -sh /path/to/directory\n# check disk space of directory and subdirectories\ndu -sh /path/to/directory/*\n\n##########################\n### No Sleep\n\n# keep computer awake for 1 hr\ncaffeinate -t 3600 &\n# keep awake until command finishes\ncaffeinate -i long_running_script.sh"
  },
  {
    "objectID": "library/life-sciences/health/viruses/index.html",
    "href": "library/life-sciences/health/viruses/index.html",
    "title": "Viruses",
    "section": "",
    "text": "COVID-19\n\n\nFebruary\n\nZhou Yusen filed a patent for a Covid-19 vaccine on February 24, 2020.\n\nMarch\n\nTheProximal Origin of SARS-CoV-2\n\n“Our analyses clearly show that SARS-CoV-2 is not a laboratory construct or a purposefully manipulated virus.”\n\n\nMay\n\nZhou Yusen died in mysterious circumstances in May 2020, aged 54. Zhou worked for the People’s Liberation Army and was collaborating with Wuhan scientists at the time of the outbreak. US investigators are said to have been told ‘Zhou fell from the roof of the Institute’, although this has not been confirmed.\n\n\n\n\nJanuary\n\nWerriam Webster changed the definition of Vaccine\n\nJan 11, 2021\nJan 26, 2021\n\n\nDecember\n\nCanadian Covid Care Alliance: The Pfizer Inoculations for COVID-19, More Harm than Good\n\n\n\n\nFebruary\n\nLawrence Sellin: The Laboratory Origin of COVID-19\n\nOctober\n\nSenate Committee on Health Education, Labor and Pensions: An Analysis of the Origins of the COVID-19 Pandemic\n\n\n\n\nJanuary\n\nAHA Circulation Journal: Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\nWe discovered that individuals who developed postvaccine myocarditis uniquely exhibit elevated levels of free spike protein in circulation, unbound by anti-spike antibodies, which appear to correlate with cardiac troponin T levels and innate immune activation with cytokine release\n\n\nFebruary\nBivalent Covid-19 Vaccines — A Cautionary Tale\nMay\nU.S. Senate Report: A Political Chronology of the SARS-CoV-2 Outbreak\n\nVaccine could not have been developed in claimed timeframe, must have began Nov ’19 or earlier\n\nJune\nDr. Peter Hotez’s Funding Linked to Controversial Chinese Military Scientists at Wuhan Lab\n\nFunded by Dr. Fauci and Dr. Hotez’s R01AI098775 grant, Dr. Shibo Jiang and Dr. Lanying Du collaborated with scientists from the People’s Liberation Army and the Wuhan Institute of Virology.\n\nJuly\n\nInvestigating the Proximal Origin of a Cover-Up\n\nAugust\n\nNational Review: The Covid Cover-Up\n\n\n\n\n\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\nAustralia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis\nDr. Robert Malone Twitter Ban Details\nCovid Care Alliance: More Harm Than Good\n\nVideo\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\nProtection of mRNA vaccines against hospitalized COVID-19\nPharma Rackateering\nIsrael Ministry of Health released Pfizer Agreement\n\nThey first claimed they “couldn’t find it”\n\nArticle\nDocument\nAdministrative Appeal\n\n\nNew Zealand 2022 Data\nMethodist Hospital threatened their doctors\n\n“You cannot report adverse reactions to these vaccines”\n\nMore dishonest statements about boosters by the FDA’s Marks and Califf\nRisk of Myocarditis in Boys 18-39\nVaccine on Birthing\n\nArticle 1\nArticle 2 / Correction\n\nHow Britons are dying in their tens of thousands\n\nbut no one knows why: From May to December last year, there were 32,441 excess deaths in England and Wales, excluding deaths from Covid\n\n\n\n\n\nA necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\n\n\n\n\n\n\n\nInterview with German MEP, Christine Anderson\n\nGovernments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”"
  },
  {
    "objectID": "library/life-sciences/health/viruses/index.html#sars-cov-2",
    "href": "library/life-sciences/health/viruses/index.html#sars-cov-2",
    "title": "Viruses",
    "section": "",
    "text": "COVID-19\n\n\nFebruary\n\nZhou Yusen filed a patent for a Covid-19 vaccine on February 24, 2020.\n\nMarch\n\nTheProximal Origin of SARS-CoV-2\n\n“Our analyses clearly show that SARS-CoV-2 is not a laboratory construct or a purposefully manipulated virus.”\n\n\nMay\n\nZhou Yusen died in mysterious circumstances in May 2020, aged 54. Zhou worked for the People’s Liberation Army and was collaborating with Wuhan scientists at the time of the outbreak. US investigators are said to have been told ‘Zhou fell from the roof of the Institute’, although this has not been confirmed.\n\n\n\n\nJanuary\n\nWerriam Webster changed the definition of Vaccine\n\nJan 11, 2021\nJan 26, 2021\n\n\nDecember\n\nCanadian Covid Care Alliance: The Pfizer Inoculations for COVID-19, More Harm than Good\n\n\n\n\nFebruary\n\nLawrence Sellin: The Laboratory Origin of COVID-19\n\nOctober\n\nSenate Committee on Health Education, Labor and Pensions: An Analysis of the Origins of the COVID-19 Pandemic\n\n\n\n\nJanuary\n\nAHA Circulation Journal: Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\nWe discovered that individuals who developed postvaccine myocarditis uniquely exhibit elevated levels of free spike protein in circulation, unbound by anti-spike antibodies, which appear to correlate with cardiac troponin T levels and innate immune activation with cytokine release\n\n\nFebruary\nBivalent Covid-19 Vaccines — A Cautionary Tale\nMay\nU.S. Senate Report: A Political Chronology of the SARS-CoV-2 Outbreak\n\nVaccine could not have been developed in claimed timeframe, must have began Nov ’19 or earlier\n\nJune\nDr. Peter Hotez’s Funding Linked to Controversial Chinese Military Scientists at Wuhan Lab\n\nFunded by Dr. Fauci and Dr. Hotez’s R01AI098775 grant, Dr. Shibo Jiang and Dr. Lanying Du collaborated with scientists from the People’s Liberation Army and the Wuhan Institute of Virology.\n\nJuly\n\nInvestigating the Proximal Origin of a Cover-Up\n\nAugust\n\nNational Review: The Covid Cover-Up\n\n\n\n\n\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\nAustralia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis\nDr. Robert Malone Twitter Ban Details\nCovid Care Alliance: More Harm Than Good\n\nVideo\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\nProtection of mRNA vaccines against hospitalized COVID-19\nPharma Rackateering\nIsrael Ministry of Health released Pfizer Agreement\n\nThey first claimed they “couldn’t find it”\n\nArticle\nDocument\nAdministrative Appeal\n\n\nNew Zealand 2022 Data\nMethodist Hospital threatened their doctors\n\n“You cannot report adverse reactions to these vaccines”\n\nMore dishonest statements about boosters by the FDA’s Marks and Califf\nRisk of Myocarditis in Boys 18-39\nVaccine on Birthing\n\nArticle 1\nArticle 2 / Correction\n\nHow Britons are dying in their tens of thousands\n\nbut no one knows why: From May to December last year, there were 32,441 excess deaths in England and Wales, excluding deaths from Covid\n\n\n\n\n\nA necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\n\n\n\n\n\n\n\nInterview with German MEP, Christine Anderson\n\nGovernments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”"
  },
  {
    "objectID": "library/life-sciences/health/viruses/index.html#mrna-vaccine",
    "href": "library/life-sciences/health/viruses/index.html#mrna-vaccine",
    "title": "Viruses",
    "section": "mRNA Vaccine",
    "text": "mRNA Vaccine\n\nThe mRNA platform is brilliant. But it has a giant gaping flaw in it, which is; Any cell of yours that produces a foreign protein, will be targetted by your immune system and destroyed. You will create an autoimmune disorder. When it works. How do you keep it out of your heart. Not by coding it in a lipid nanoparticle. So, they had no way to deliver it safely to market. So then they had a pandemic, the emergency allowed them to do it. This technology, in my opinion, was at least 3 decades out from being usefully and safely deployed at all, if at all. They did not want to wait, this crisis gave them the opportunity not to wait. And now, they will blame the spike protein, we picked the wrong protein. When in actual fact there are 2 problems, the spike protein and the platform itself. - Brett Weinstein\n\n\nMyocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSerum Vax Spike\n\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”"
  },
  {
    "objectID": "library/life-sciences/health/viruses/index.html#the-effect-of-mandatory-masks-on-autism-in-children",
    "href": "library/life-sciences/health/viruses/index.html#the-effect-of-mandatory-masks-on-autism-in-children",
    "title": "Viruses",
    "section": "The Effect of Mandatory Masks on Autism in Children",
    "text": "The Effect of Mandatory Masks on Autism in Children\n\nBut hopefully, this [mask mandate in schools] will be a temporary thing, temporary enough that it [masks] doesn’t have any lasting negative impact on them [children]. - Anthony Fauci, August 9 2021\n\n\nRecognition of Faces: An Approach to the Study of Autism\n\nTwo age groups of normal, autistic and subnormal children were tested for their ability to recognize the faces of peers from isolated facial features and inverted photographs. The normal and subnormal subjects found the upper regions of the face most helpful for identification, whereas the younger autistic children found the lower features more helpful. The older autistic children showed no specific reliance on any one area, but were found to have error scores as low as those of the younger autistic children on the recognition of lower parts and error scores as low as the; controls on recognizing upper portions. The results are discussed and are found to favour a hypothesis in which the autistic child’s familiarity with the mouth and/or eye areas is related to a cognitive deficit which affects the processing of both verbal and non-verbal interpersonal communication.\n\nAmerican Academy of Pediatrics Poster, Highlighting the Importance of Facial Expressions for Children\n\nThey later were swallowed by the narrative, and made a public statement that in-school masks does not affect children (hypocritical)\n\nVisual Impairment: Its Effect on Cognitive Development and Behavior\nInfants Deploy Selective Attention to the Mouth of a Talking Face when Learning Speech\n\nThe mechanisms underlying the acquisition of speech-production ability in human infancy are not well understood. We tracked 4–12-mo-old English-learning infants’ and adults’ eye gaze while they watched and listened to a female reciting a monologue either in their native (English) or nonnative (Spanish) language. We found that infants shifted their attention from the eyes to the mouth between 4 and 8 mo of age regardless of language and then began a shift back to the eyes at 12 mo in response to native but not nonnative speech. We posit that the first shift enables infants to gain access to redundant audiovisual speech cues that enable them to learn their native speech forms and that the second shift reflects growing native-language expertise that frees them to shift attention to the eyes to gain access to social cues. On this account, 12-mo-old infants do not shift attention to the eyes when exposed to nonnative speech because increasing native-language expertise and perceptual narrowing make it more difficult to process nonnative speech and require them to continue to access redundant audiovisual cues. Overall, the current findings demonstrate that the development of speech production capacity relies on changes in selective audiovisual attention and that this depends critically on early experience.\n\nUnderstanding the Impact of Face Masks on the Processing of Facial Identity, Emotion, Age, and Gender\n\nThis is not even about children in particular, but illustrates how it may be detremential to young people in a learning phase\nAbstract Result: The results revealed that masks hindered the perception of virtually all tested facial dimensions (i.e., emotion, gender, age, and identity), interfering with normal speed and accuracy of categorization. We also found that the unwarranted effects of masks were not due to holistic processes, because the Face Inversion Effect (FIE) was generally not larger with unmasked compared with masked faces. Moreover, we found that the impact of masks is not automatic and that under some contexts observers can control at least part of their detrimental effects.\n\nFace masks reduce emotion-recognition accuracy and perceived closeness\n\nAgain, this was on adults, because you wouldn’t be able to publish your findings in 2021 if you exposed what it does to children\n\n\nIMPORTANT\n\nEmotion comprehension between 3 and 11 years: Developmental periods and hierarchical organization\nDarwin’s Contributions of our Understanding of Emotional Expressions\nInfants deploy selective attention to the mouth of a talking face when learning speech\nPotential Impact of the COVID-19 Pandemic on Communication and Language Skills in Children\nEffect of face mask and noise on word recognition by children and adults\n\nThis PDF was taken off the web! I am linking it through Wayback machine\n\nThe puzzle of Autism in the time of COVID-19 pandemic: “Light it up Blue”\n\n“… Barriers to essential services such as speech and occupational therapies, combined with loss of routine and predictability has widened the gap between needs and provided care. Parents, teachers and health care should aim to work collectively for a broadened approach that is child/parent centered to compensate for most of disrupted vital support and services”"
  },
  {
    "objectID": "library/life-sciences/health/cognition/index.html#neurons-outside-the-brain",
    "href": "library/life-sciences/health/cognition/index.html#neurons-outside-the-brain",
    "title": "Cognition",
    "section": "Neurons Outside the Brain",
    "text": "Neurons Outside the Brain\n\nThe Intestine (Gut)\nThe intestine had a network of neurons called the enteric nervous system (ENS) which coordinates diverse functions in the intestine.\n\nCell maps reveal diversity of neurons in gut\nThe Human and Mouse Enteric Nervous System at Single-Cell Resolution\n\n\n\n\n\n\nThe Heart\nThe human heart has been found to have its own “little brain” - a network of neurons known as the instrinsic cardiac nervous system. It plays a key role in regulating cardiac activity.\n\n3D single cell scale anatomical map of sex-dependent variability of the rat intrinsic cardiac nervous system\nResearchers Map and Explore the Heart’s “Little Brain”"
  },
  {
    "objectID": "library/life-sciences/medicine/index.html",
    "href": "library/life-sciences/medicine/index.html",
    "title": "Medicine",
    "section": "",
    "text": "Vaccines\nThis is not to be anti-vaccine, this is to avoid dogma in the pursuit of truth.\nStanley Plotkin: “The Godfather of Vaccines” Under Oath - tweet\n2020 Pilot Survey Data Comparison: Vaccinated vs Unvaccinated - paper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html",
    "title": "Hyperbolic",
    "section": "",
    "text": "The Internet has made the world more connected than ever. With years of efforts, companies have developed software stacks for cloud services that power the user-end products. Ironically, together with the backing hardware resources, they are mostly limited to the corporation boundaries, forming dispersed islands that effectively isolate the Internet. This business structure, while being profitable for decades, gradually shows the signs of problems, with the increasing demand for more data control and privacy by the users, more flexible and reusable services by the developers, and more opportunities of providing hardware resources for computation by the investors.\nThe so-called “Web 3” [6] initiative, driven by blockchains and exemplified by Ethereum, aims to host the computation of all services on a decentralized platform, backed by a chain (ledger), replicated by all validators. Nevertheless, encoding each single step of the computation as a transaction and interpreting all transactions on the chain is fundamentally impractical to realize existing services from the traditional cloud computing, as they vary in terms of performance demand, trust model and fault tolerance. As a result, various “Layer-2” solutions, bridges, and oracles have been proposed and built to move things off-chain again. However, the absence of a more foundational, expressive, and fault-tolerant computational paradigm has once again turned these solutions into pre-blockchain isolated islands.\nWe introduce Hyperbolic, a high-performance microservices platform driven by a new chain-less abstraction for decentralized computing, fabricated together with an Internet-scale mesh network. It unifies diverse services and applications, fostering a connected, interoperable, and composable digital computing world.\nHyperbolic’s relay network enables permissionless participation and self-healing resilience. Nodes in the network forward data to others in a peer-to-peer manner while receiving rewards as incentives for their work. Utilizing a smart routing protocol, the network autonomously recovers from failures, ensuring uninterrupted end-to-end connectivity during disruptions. This design cultivates a healthy ecosystem that promotes active participation and serves as a resilient and efficient alternative to traditional corporate-wide networks.\nOn top of the network fabric, Hyperbolic facilitates the development and deployment of a wide spectrum of composable Decentralized Services (D-Services) that follow a new Invoke-Return-Combine (IRC) paradigm. These D-Services are hosted by a dynamic subset of nodes, making trade-offs between performance and fault tolerance according to the nature of the individual service. D-Services follow a classic client-server model with server-side fault tolerance. Each client talks to multiple gateway servers to access the service with redundancy, but also conducts client-side computation to locally work out the output given multiple servers’ responses. This unique two-level design of D-Services and relay network reduces unnecessary resource consumption (e.g. bandwidth, CPU, storage), to horizontally scale much better than a purely P2P solution. To help developers build their D-Services, Hyperbolic will offer useful, basic D-Services as node modules, such as Content Delivery Network (D-CDN), video streaming (D-Streaming), Publish-Subscribe patterns (D-PubSub), and blockchain ledger (D-Ledger) out of the box. Developers who are building different products can utilize these microservices, offered by Hyperbolic nodes, to compose larger services for their applications, which again follow the same IRC pattern. As a result, they can contribute/lease their useful D-Services to others, fostering an ecosystem of reusable modules.\nHyperbolic’s versatile platform advocates numerous applications across multiple domains, such as social networks, document collaboration apps, AI training/inference infrastructures, AI data collection and cleaning tools, Multi-Party Computation, and even blockchains. Its flexibility makes it an ideal choice for both small startups and well-established organizations, promoting innovation and collaboration in a loosely organized, inclusive manner with customizability. We also develop Hyllo, our first-party messaging app that functions as a noncustodial, open-standard messaging app bound to cryptographic identities. More importantly, Hyllo serves as a portal to Hyperbolic, allowing end users to directly interact with applications based on D-Services seamlessly. It is the browser of our Hyperbolic web services."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#vision-mission",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#vision-mission",
    "title": "Hyperbolic",
    "section": "",
    "text": "The Internet has made the world more connected than ever. With years of efforts, companies have developed software stacks for cloud services that power the user-end products. Ironically, together with the backing hardware resources, they are mostly limited to the corporation boundaries, forming dispersed islands that effectively isolate the Internet. This business structure, while being profitable for decades, gradually shows the signs of problems, with the increasing demand for more data control and privacy by the users, more flexible and reusable services by the developers, and more opportunities of providing hardware resources for computation by the investors.\nThe so-called “Web 3” [6] initiative, driven by blockchains and exemplified by Ethereum, aims to host the computation of all services on a decentralized platform, backed by a chain (ledger), replicated by all validators. Nevertheless, encoding each single step of the computation as a transaction and interpreting all transactions on the chain is fundamentally impractical to realize existing services from the traditional cloud computing, as they vary in terms of performance demand, trust model and fault tolerance. As a result, various “Layer-2” solutions, bridges, and oracles have been proposed and built to move things off-chain again. However, the absence of a more foundational, expressive, and fault-tolerant computational paradigm has once again turned these solutions into pre-blockchain isolated islands.\nWe introduce Hyperbolic, a high-performance microservices platform driven by a new chain-less abstraction for decentralized computing, fabricated together with an Internet-scale mesh network. It unifies diverse services and applications, fostering a connected, interoperable, and composable digital computing world.\nHyperbolic’s relay network enables permissionless participation and self-healing resilience. Nodes in the network forward data to others in a peer-to-peer manner while receiving rewards as incentives for their work. Utilizing a smart routing protocol, the network autonomously recovers from failures, ensuring uninterrupted end-to-end connectivity during disruptions. This design cultivates a healthy ecosystem that promotes active participation and serves as a resilient and efficient alternative to traditional corporate-wide networks.\nOn top of the network fabric, Hyperbolic facilitates the development and deployment of a wide spectrum of composable Decentralized Services (D-Services) that follow a new Invoke-Return-Combine (IRC) paradigm. These D-Services are hosted by a dynamic subset of nodes, making trade-offs between performance and fault tolerance according to the nature of the individual service. D-Services follow a classic client-server model with server-side fault tolerance. Each client talks to multiple gateway servers to access the service with redundancy, but also conducts client-side computation to locally work out the output given multiple servers’ responses. This unique two-level design of D-Services and relay network reduces unnecessary resource consumption (e.g. bandwidth, CPU, storage), to horizontally scale much better than a purely P2P solution. To help developers build their D-Services, Hyperbolic will offer useful, basic D-Services as node modules, such as Content Delivery Network (D-CDN), video streaming (D-Streaming), Publish-Subscribe patterns (D-PubSub), and blockchain ledger (D-Ledger) out of the box. Developers who are building different products can utilize these microservices, offered by Hyperbolic nodes, to compose larger services for their applications, which again follow the same IRC pattern. As a result, they can contribute/lease their useful D-Services to others, fostering an ecosystem of reusable modules.\nHyperbolic’s versatile platform advocates numerous applications across multiple domains, such as social networks, document collaboration apps, AI training/inference infrastructures, AI data collection and cleaning tools, Multi-Party Computation, and even blockchains. Its flexibility makes it an ideal choice for both small startups and well-established organizations, promoting innovation and collaboration in a loosely organized, inclusive manner with customizability. We also develop Hyllo, our first-party messaging app that functions as a noncustodial, open-standard messaging app bound to cryptographic identities. More importantly, Hyllo serves as a portal to Hyperbolic, allowing end users to directly interact with applications based on D-Services seamlessly. It is the browser of our Hyperbolic web services."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#hyperbolic-the-microservices-platform",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#hyperbolic-the-microservices-platform",
    "title": "Hyperbolic",
    "section": "2 Hyperbolic: the microservices platform",
    "text": "2 Hyperbolic: the microservices platform\nAfter years of research and development experience in areas including Cloud-computing, AI, Fintech, and Blockchains, we have come to realize a fact that many may have overlooked: the current philosophy of distributed computing infrastructure has reached its limits in terms of flexibility, versatility, security, and privacy (left of Figure 1). On the other hand, the alleged Cloud-computing (“Web z”) killer, blockchains, while solving the trust issue of decentralization, have taken a more rudimentary infrastructure design than Cloud-computing (middle of Figure 1). Since Ethereum, projects and developers have been painstakingly trying to directly squeeze the computational logic onto the chain as much as possible. Ironically, the chain, being overloaded with application traces as transactions, struggle to even enable traditional applications from the less celebrated Web z world with promised additional security guarantees, leaving the main usable applications mostly DeFi/NFT to the general public. Admit it or not, the relatively small market is far from fulfilling the futuristic picture of “Web 3”.\nMost of us, do acknowledge the deficiency of having a single blockchain and may advocate to move things “off chain” again or resort to Layer-2 solutions, further complicated by bridges and oracles needed to let the chains talk to each other, and to the real world. However, by taking a step back and rethink, the crux of the problem is never about debating over on-chain vs. off-chain solutions, but having a well-established, disciplined paradigm that organizes many decentralized computation activities that do not need to frequently consult the ledger. As an analogy, Ethereum contributed a lot to the blockchain world because it has successfully established a paradigm, or a computational model, that led developers to think in the way of “smart contracts”, their states, methods and interactions. Currently, the Web 3 world has adopted blockchain as the de-facto model for decentralized computation, but today we would like to question whether that is the only way. We propose a new model, Hyperbolic, that is more fundamental, inclusive, and opens up a lot of new possibilities. In this new view, however, blockchain consensus, like Paxos [10]/Raft [14] as to Web z, becomes a useful service with strong consistency and ordering guarantee, which could fit straight into our ecosystem. Thus, Hyperbolic is not an L2 or ad-hoc/centralized off-chain trick, but a brand new journey of fulfilling the original dream of Web 3. Blockchains are still handy, but only as participating services of our ecosystem. Unlike those “Layer o” initiatives, Hyperbolic is not chain-centric, and is not powered by a chain."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#hyperbolic-the-microservices-platform-1",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#hyperbolic-the-microservices-platform-1",
    "title": "Hyperbolic",
    "section": "2 Hyperbolic: the microservices platform",
    "text": "2 Hyperbolic: the microservices platform\n\nBolic: Self-Healing Network Fabric\nDistributed computing, decentralized or not, always happens by exchanging data in-between the participating entities (nodes). For a decentralized system, we need to have a simple, robust, and efficient infrastructure for network communication. In Hyperbolic, we first build Bolic, an Internet-scale subsystem that delivers arbitrary binary data from one crypto entity to another with minimal overhead. Unlike many other network/P2P libraries, Bolic is designed with modularity from the ground up and comes with careful thoughts in abstractions. As experienced distributed systems builders, we apply our best practice to the low-level library to make sure the code is lightweight but future-proof. We also realize that the important abstraction in an easy-to-use, Internet-scale network infrastructure includes the disaggregation of the following three aspects:\n\nThe notion of data transmission from one end to another, it should be as simple as Apple’s “Airdrop”: you tag (and encrypt) the message with the recipient (crypto-id) and then “drop” it to Bolic, and the rest of the process is hidden from the user.\nThe actual transport to transmit data in a logical hop, which could be backed by TCP/UDP/WebSocket/WebRTC/SMS/Emails, etc. Or even by the action of scanning a QR code. The transport does not know the data because it is end-to-end encrypted.\nThe routing mechanism to balance the resource cost, reliability, and performance to get the data delivered to the recipient end, offering different tradeoffs and plans.\n\nIn short, our Bolic subsystem resembles building another “Internet” (the “Web” of Web 3), on top of the existing, prevailing data transmission methods, such as the current Internet, but there could also be other data carriers (or virtualized carriers such as Tor-style privacy channels). We hope to retain code minimalism to establish a data transmission and routing network with high capacity and low latency to set the ground for our Hyperbolic decentralized services.\n\n\nBest of Both Worlds: P2P vs. Client-Server\nIt is a prevailing thought that a decentralized system should be based on peer-to-peer (P2P) communication for all stages of services, in contrast to the traditional client-server model where clients (e.g., mobile/web apps) send requests and pull data from the hosting servers. No doubt, client-server is more seen in centralized systems where servers have unequally more control and authoritative interpretation of users’ data and computation, however, this model still has advantages over a pure P2P network because the server canasymmetrically and simultaneously serve multiple (hundred-thousands of) clients at a much lower cost in bandwidth and power.\nImagine the implementation of a “super” group chat, where a chat room accommodates a lot of (say, 100K) users. In this extreme case, with P2P approach, each message will need to be gossiped throughout the network to reach all recipients, resulting in high duplication of load to the system (which is the common problem in the existing design of “decentralized” messaging platforms), whereas if they all talk to the same server, the server only needs to send a message once to every other user, without blindly engaging more nodes in the network. Of course, the latter case has a single point of failure as the server could deliberately omit the message for some or all of the recipients, or it could simply refuse to render the service.\nP2P and client-server approaches are like two extremes where one offers more redundancy and open-membership (“decentralization”) at the expense of preventing a scalable, complex service, while the other one offers more efficient and accurate resource utilization but susceptible to failures and limits participation. This inspired us towards the Hyperbolic service model that chooses a middle ground to get benefits from both.\nBack at the group chat example, in a network of 100K users, if we choose to run 100 chat servers who also join the P2P network, then we let each of 100K users, instead of directly sending to the network or to a single server, talking to 60 of these servers at a time, then we will only have 100 peers in the P2P network relaying messages to each other. In the meanwhile, we still retain very reasonable resilience to failure as each client talks to 60 servers at a time. Moreover, since any two clients will be guaranteed to have (60-100=20) servers in common so these servers can directly pass on messages between them without even going through the P2P network. This simple idea also resembles the concept of quorum intersections in consensus protocols that power Proof-of-Stake blockchains, but sending end-to-end encrypted messages in a virtual chat group is a much easier problem than consensus. As a comparison, a typical decentralized solution would have blindly gone for an on-chain solution which works but creates unnecessary overhead.\nFrom this example, we demonstrated how to shrink down the cost of gossiping among 100K nodes down by 1000 times to 100 nodes while still maintaining very decent fault tolerance for an open-hosting environment where service providers can be malicious or faulty. On the other hand, this allows the platform to have computation and network capability close to traditional cloud computing, but more loosely organized and open. We envision that a good paradigm (model) should be this simple but generally applicable. Fortunately, this idea of balancing performance and fault tolerance can generalize to other services, like Pub-Sub where multiple clients subscribe to some topics and get notified.\nFigure 1: Traditional cloud-computing limits the reusability of both hardware resources and software stack (private services) at the company boundary and has a single point of trust. Existing blockchains alone are not enough to realize the “Web 3” dream because the chain has limited capability of encoding general computation, and lacks a disciplined way for “off-chain” operations with guarantees. Hyperbolic envisions the future of computing could be done by some carefully designed primitive that is chain-less, while incorporating chains as part of the ecosystems. We are shifting from chain-centric to service-centric.\n\n\nD-Services\nMore formally, in our Hyperbolic network, we have all connected participants called nodes. Most of the nodes will have their relay ability enabled, running Bolic that forwards encrypted data in the network (Section 4 describes fee model and algorithm for routing to ensure they do the work). In addition to the role of a relay, a node can opt in one or multiple D-Services by running the server part of the logic for the D-Service, as shown by circles filled with different solid background colors in Figure 2. For a D-Service named “S”, let us denote these nodes by (N_{s}) Whereas each client (i) (could also be a node in Hyperbolic, or just some third-party application) connects to a service-prescribed subset of servers (Q_{si}N_{s}). D-Service paradigm defines a client-server style of microservice with additional fault tolerance customizable by the designer of the service. The service is rendered via RPC-style invocations of methods offered by the service, whose responses get aggregated and deduplicated locally at each client. The entire Invoke-Return-Combine round trip is as follow:\ninvoke Each client (iN_{c}), to initiate an RPC call for the service, it signs and directly sends a message (S.(i,,,)) to all nodes in (Q_{si}). Where () is per-invocation identifier to distinguish the calls and gets incremented each time, which helps the server to bookkeep the service state for the client. In the figure, for example, a client with the “blue” D-Service client part (a triangle) will send the same signed invocation to all nodes (represented in hexagons) that have the corresponding server part (small circles), by following the direct connections in blue lines.\nreturn Each server (u), upon receiving the RPC call message, it validates the message and returns its response by signing and sending\n[S.(i,,,!! ,u,_{u})]\nback to (i), following the blue lines backwards in the figure.\ncombine Each client (i), upon the receiving at least a threshold (constant (T_{si}|Q_{si}|) predefined by the service for each client) of responses from servers:\n[R_{i}={{u}:S.(i,, ,] [!!,u,] [{u}),uQ_{si}}]\n, where (|R_{i}|T_{si}), it computes the final output locally by a service-prescribed client part of D-Service logic: ({i}=S.(R{i})). The D-Service designer needs to make sure as long as the number of collected responses (|R_{i}|) is not less than the threshold (T_{si}), the combined output is a deterministic value that is consistent regardless of the number of responses (|R_{i}|).\nThe aforementioned group chat example can use (T_{si}=51,iN_{c}) threshold for all clients, and run (|N_{s}|=100) servers. The predefined subset for each client is any set (Q_{si}) such that (|Q_{si}|=60). This guarantees if at least (51-100=2) out of 20 servers to which any two clients connect render the service, the message could be passed over directly. Even if there is no non-faulty server in common between any two clients, the clients can still rely on each one of the 60 servers to transmit the message through the Bolic P2P network.\nSimple yet expressive, D-Service paradigm offers the flexibility to engage “quorum-style” fault tolerance as in Proof-of-Stake consensus protocols, and also naturally fits the idea of “aggregation-style” of cryptography like threshold signatures. But like our group chat example, one does not always have to use additional cryptography to implement such result aggregation. For chat and Pub-Sub, the message itself could be verified to see if that’s from the desirable sender. With the same framework, one can describe the run of a quorum-based consensus, or even a centralized service. Here are some examples of D-Service.\nblockchain consensus, version A For blockchains, validators are running the server part of the Consensus D-Service, whereas clients could be user agents (wallet apps or developers). The (3f+1) validators talk to each other through the Bolic P2P network whereas the vast majority of clients can use (|Q_{si}|=f+1) validators (servers). (|N_{s}|) could be at the level of thousands of nodes whereas (|N_{c}|) could be millions and hundreds of millions. This is not just to fit the existing blockchain into our D-Service ecosystem, but actually adds more disciplined security guarantees for users: nowadays, users usually connect to some trusted source (chain API providers like Infura or user-oriented block explorers) to submit transitions and retrieve account balance/state. Ironically, although blockchain guarantees the safety for all participating validators as they work out their own local, replicated state based on consensus, this is never the case for end users. Of course, one user can manually check whether a transaction has gone through by browsing multiple explorers and some exchanges do so for deposit, it is not part of the existing blockchain infrastructure, making the users actually trust the centralized service provider, causing frauds or front-running issues. Our D-Service addresses this issue systematically.\nblockchain consensus, version B An alternative way to host a blockchain as a D-Service is to run validators both as severs and clients in our D-Service model. In this case, no traffic is poured into the P2P network and the D-Service implementor manages thevotes in the protocol in the form of D-Service messages exchanged among the validators. Then (N_{i}=N_{c}), and (|Q_{si}|=|N_{s}|=3f+1), whereas (T_{si}=2f+1). The (S).Combine(()) function is defined to verify the votes and aggregate them into a quorum certificate (used in many state-of-the-art blockchain consensus mechanisms [25, 19, 20, 11]). This solution can easily turn existing blockchains into D-Services and join Hyperbolic ecosystem, without having the network traffic of the blockchain heavily load our Bolic network.\nVrf beaconVerifiable-Random-Function beacons can be smoothly described as a D-Service as well, imagine we have a typical setup of (N_{s}=3f+1) nodes, then threshold (T_{si}) will just be the threshold value for VRF (say, (2f+1)), whereas (S).Combine(()) function will be the VRF math combination of the given output shares from beacon nodes.\nContent delivery network (aka. decentralized storage)In Hyperbolic, we need some decentralized storage solution that helps preserve any blobs of data used by other D-Services or users. We name our official implementation of such service (D)-CDN, as it could be viewed as a more generalized and decentralized version of the traditional Content Delivery Network (CDN). Such D-Service will store end-to-end encrypted chunks of user data and offer data availability in presence of D-Service server failure. The combine function for the client end is easy to implement as one just needs to verify the hash of the stored data and take any copy that checks out. A robust, efficient D-CDN not only benefits existing decentralized applications, but also makes it possible to render services like Netflix, Youtube, in a crowd-sourced manner.\nLive streaming and gamingOur D-Service design enables the decentralization of those computation tasks requiring more real-time responses, which would have been impossible for a chain-centric platform. For a Twitch-like streaming service, there are usually much more audiences than the hosts, whose performance footprint is exactly captured by our D-Service design: (N_{c}) could be much greater than (N_{s}). In this case, streaming packets can have fault tolerance and a client-end application only need one authentic copy of the packet from the video host. Together with our Hyperbolic tokenomics, we believe it not only makes live streaming more secure without sacrificing resources, but also possibly faster, as hosts (or relay nodes) are incentiized to help move forward data across Bolic P2P network. In a way, Bolic by itself is like a “VPN accelerator”.\naround cycles for new hardware and software as they are controlled by a single entity (e.g. Amazon AWS, Google Cloud, Microsoft Azure, etc.). On the other hand, many players in the market would like to invest in hardware assets and lease the computational capability to companies, developers, and users. There has been abundant research in exploring distributed training of relatively large models. We believe for those latency-insensitive cases, it is feasible and beneficial to train models in a distributed manner, opening up more opportunities for business and research. To tailor the pre-trained model to certain applications, fine-tuning a model on domain-specific data will make the model a specialist in certain tasks (e.g., customized LLM for answering legal questions). Effective fine-tuning depends on high-quality data to yield good results, hence it demands domain expertise, especially for data labeling and cleaning. Once the model is well-trained and fine-tuned, applications with large models like ChatGPT also need inference and service hosting. These tasks (data curation, model training, fine-tuning, and inference) do have different hardware and software requirements, and our vision is to also encapsulate them into D-Services and improve the interoperability of different stages in an AI training-to-product pipeline.\n\n\nInvoke-Return-Combine Composability\nWith D-Service’s Invoke-Return-Combine (IRC) primitive, one can build more complex service solutions by repeatedly applying it for each major step required in the pipeline of computation logic. The internal logic of a D-Service’s server part may also contain the client part of another D-Service, and thus may invoke one or more times of the other service. As an interesting coincidence, we find this primitive resembling map-reduce primitive [4] in Machine-Learning systems where each component/operator implements the same interface and data can flow through the entire system by making each step. However, although systems like Spark [26] has notions like Resilient-Data-Set (RDD), RDD is in the realm of a beneign and domain-specific setup where the “resilience” is about\nFigure 4: Different clients may choose to use different D-Services as part of their computation flows.\nFigure 3: Clients utilize multiple D-Services one after another for the application. The output from one IRC primitive could be used as the input for the next IRC.\nrecovering data loss, as the intermediate results in ML/AI computation can always be numerically recomputed at the expense of some extra time, whereas the authenticity or correctness is less of a concern. Our resilience, however, is Byzantine fault tolerance, and not ad-hoc to ML tasks. Unlike map-reduce, IRC process uses multiple parallel servers for their independent outputs of the same task, and then “reduces” the outputs at each client for some customizable resilience to servers’ misbehavior. The IRC primitive also resembles Ethereum’s smart contracts in that different IRC implementations have interoperability, but it does not need on-chain transactions, degrades into a centralized service easily, giving much more freedom and possibilities to the infrastructure developers. On the contrary, a chain server could be wrapped into a D-Service to participate in this playground.\nStaged compositionFor client app developers, the computation may invoke the invocations of multiple different D-Services. Depicted in Figure 3, each client can first participate in (S_{1}), followed by (S_{2},S_{3}), forming a staged flow of decentralized computation. The composed flow of computation offers the flexiblity that has never existed before: different stages possibly hosted by different parties, together with the difference in the nature of the task, can choose different levels of redundancy that balances the resilience and performance. Thus, the IRC primitive allows “heterogenous” fault tolerance, which is not provided by chain-centric platforms.\nMixing compositionOn the other hand, clients’ staged flows could differ. Like shown in Figure 4, another composability is to let D-Service like (S_{1}) usable in different flows. For clients 1-3, they go through (S_{1}) and (S_{2}), whereas clients 4-6 diverges to (S_{3}). As an example, our aforementioned D-DCN service could be such (S_{1}) that is used in all kinds of other D-Services.\nrecursive compositionSo far, only clients can compose one or more D-Services for their application-level purposes. The servers in a D-Service can also serve as the “client” role for some other D-Services, enabling recursive engagement of D-Services. Figure 5 demonstrates such an idea, and it is possible to apply the other two composition strategies along with this one.\n\n\nThe Renaissance of End-to-End Argument\nOur D-Service design retains the scalability of traditional cloud-computing. Unlike blockchain platforms, one can use client-server model for computation, where clients largely outnumber the servers and easily scale horizontally. The composable D-Services make the server side also horizontally scalable. IRC-style is different, however, from a normal centralized setup in that it offloads more computational logic to the clients (“Combine” primitive and how clients interact with multiple different D-Services). Thus, compared to cloud-computing, Hyperbolic advocates a “client-centric” philosophy in that the D-Services only solve some crucial data synchronization and computation without knowing too much about the rest of the client’s demand to finish up its own computation. For example, a group chat D-Service server may never know the actual contents of the messages sent to the group, thanks to end-to-end encryption.\nThis self-serviced, end-to-end pattern was deemed as the major merits of Web 3. Interestingly, in systems research literature, this is not new. An end-to-end argument [18] was made back in the 8os, suggesting something that is still very true for building an in\nFigure 5. Like Ethereum’s smart contracts, D-Services can (recursively) invoke others, thus the developers can try to build up more complex D-Services by “gluing” together basic ones.\nfrastructure: the middleware/servers usually cannot precisely see or predict the application-level needs, but engineers can be tempted to put in more functionalities into the system for the “potential use”. As a result, the system becomes bloated with functionalities that are not quite useful by the “ends” (applications). Thus, each layer in the entire software stack has to repeatedly implement something similar, with better knowledge of the application as it gets closer to the end. In contrast, an end-to-end argument says the services should be kept simple and not make too many assumptions for the additional features, leaving the flexibility to the ends.\nAs a further step in our Hyperbolic initiative, we would like to explore the feasibility of distributed computing by a client-centric paradigm. In the past decades, researchers have come up with a successful State Machine Replication (SMR) model that offers consistent view of computation with fault tolerance, serving as the backbone for both cloud-computing and blockchains. However, this model is platform-centric. While it has the benefits of keeping users’ states in one coherent “state machine” that is replicated and interpreted by multiple servers, it creates bottlenecks in performance and scalability. In the meanwhile, we realize that many useful applications may not need server-maintained states. Some off-chain services such as Ethereum state channels, allow users to directly negotiate and/or securely sign a transaction before it is finalized on chain. The recent trend in Ethereum “rollups” is another example.\nWe envision a Message-carried State Machine (MSM), that keeps track of the computation state in a more “stateless” fashion. In this paradigm, clients keep track of their own local state, whereas they update their state by exchanging state-transitioning messages. As a basic example, multi-signature signing can be done in this way because there is no need to have a database (e.g., smart contracts) to keep track of the intermediate signing state. One just needs to exchange the signature shares between the signers and aggregate their own local state with the help of cryptography. Moreover, the local state may also be carried in the state transition message so that the recipients work out their local states by “chaining” the verified transitions, as shown in Figure 6. MSM model is more general as a blockchain could be viewed as an MSM where clients are the validators, and the consensus mechanism is used to resolve the possible state bifurcation shown in the figure. However, MSM offers more flexibility as some computation, such as signature aggregation used in VRF, does not have state bifurcation as any (2f+1) shares will always generate the same output."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#hyllo-the-browser-for-next-gen-internet-services",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#hyllo-the-browser-for-next-gen-internet-services",
    "title": "Hyperbolic",
    "section": "3 Hyllo: the browser for next-gen internet services",
    "text": "3 Hyllo: the browser for next-gen internet services\n\nMore than a Natural Way of Interaction\nAs the first application, we would like to launch something that could both be friendly to end users and serve as the portal to our Hyperbolic platform, connecting the D-Service/application developers directly to the users via a unified entry point. We believe the best way is via a text-messaging app. But unlike any existing messaging apps in the market, Hyllo is built with a different philosophy. First, it utilizes Bolic P2P network to directly send encrypted messages in a decentralized manner. For group chats, it makes use of the aforementioned Pub-Sub D-Services to enable scalable group size. Live-streaming D-Services also equip Hyllo with additional social capabilities, potentially fulfilling what “Social-Fi” dreamed of but never managed to achieve. Because Hyllo app is also a node in the network, the user can even opt in the Bolic network to help relay traffic, or join as a lightweight D-Service server, to earn a reward for the useful computation it renders. This opens up\nFigure 6: Client-centric, Message-carried State Machines can be locally maintained by putting together the state transition messages.\nendless opportunities for crowd-sourced computation and socialization with security and resilience.\n\n\nIn the Era of New AI\nThe recent development in Large Language Model (LLM) such as ChatGPT [15], Llama a [23], has started a revolution of how humans interact with computers, i.e., the automation tools. Although there has been a heated debate regarding whether the model could be viewed as Artificial General Intelligence (AGI), we believe at the minimum, the successful new models can serve as a “programming language” that takes the form of natural languages. This is revolutionary because most of the non-programmer crowd have limited knowledge or capability in harnessing the computational power of machines for their own tasks and business. On the other hand, builders and hackers also would like to be liberated from the burden of writing boilerplate code, but instead, spend more time and energy in creating and testing new algorithms and products. Thus, LLMs offer a very promising boost in productivity for all. We will soon see “chat bots” that also serve as our personal assistants in that we “program” the logic for task handling, business activities, etc. to the bots by speaking to them directly, whereas they work on the repeated tasks at an unseen efficiency based on our strategy. In Hyllo, we plan to offer a native, secure way for such Human-AI interaction, and explore the future of AI-AI interaction: imagine both sides of a business negotiation could first use bots to lay out some common ground of understanding to save time. The existing apps such as Telegram and Discord do offer an integration with the new AI, but still through a rudimentary approach. We hope to offer a more native experience in Hyllo for prompt-engineering and the human interaction with the AI-generated content."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#incentivization-algorithms",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#incentivization-algorithms",
    "title": "Hyperbolic",
    "section": "4 Incentivization algorithms",
    "text": "4 Incentivization algorithms\nIn order to encourage active participation of Bolic network and advocate availability of D-Services, we design a Proof-of-Relay scheme for Bolic network, and a Proof-of-Storage scheme (see Appendix A) for the D-CDN service. As developers can design and implement new D-Services, similar to smart contracts in Ethereum’s ecosystem, the proof schemes for different D-Services may vary. We hope our D-CDN proof scheme will serve as an example for other developers to design the scheme suitable for their own D-Services.\nIn Proof-of-Relay, due to the high volume of messages within the Bolic network, requiring nodes to generate a proof for each message and then redeem for reward is impractical. To minimize the performance overhead, we randomly select nodes as a verifiable starting point to conduct a “verifiable random walk” for connectivity in each epoch. By running the challenge epochs indefinitely, it provides network-wide coverage, thereby incentivizes the network to stay healthy without stuttering the transmission. We describe the algorithm in details in the remainder of this section.\n\nSetup and Requirements\nThe Proof-of-Relay scheme is built upon several existing systems and protocols:\n\nblockchain[13, 2, 17]: a customized ledger that tracks epoch-related events and keeps a record of rewards.\nVerifiable Random Function (VRF)[12]: a protocol allowing multiple parties to collaboratively generate a verifiable random output, whose value is determined by the majority of the participants.\nrandomness beacon[1]: a service that regularly produces pseudo-random seeds for the VRF. A simple implementation could be using block hashes.\nElliptic-Curve Diffie-Hellman (ECDH): a key exchange protocol that allows two parties, each having an elliptic-curve public-private key pair, to establish a shared secret over an insecure channel. It is a variant of the Diffie-Hellman protocol using elliptic-curve cryptography.\n\nWe would like a design with the following constraints to make it practical:\nno responseThere should be no response messages to challenge messages. This simplifies our overall design and offers more robustness in an Internet-scale deployment.\nno real-world clockWe shall not rely on the concept of real-world time or a timestamp system to coordinate steps within each epoch. It helps prevent potential synchronization issues and precludes unnecessary wait time.\nagnostic to network topologyThe design should not assume there is a pre-defined or static network topology. Namely, the underlying relay path should not matter to the proof scheme. This gives flexibility to the routing algorithm employed by Bolic.\n\n\nDefinitions\nepochA predefined time cycle for the random walk of challenge messages and reward distribution. It can be a range of block heights from the blockchain.\nbernoulli distributionThe discrete probability distribution of a random variable which takes the value 1 with probability (p) and the value 0 with probability (q=1-p). (p) is predetermined in the Proof-of-Relay scheme.\nReputation scoreA numerical score that represents the reliability and performance of a node within the network. Nodes are initialized with some default score, and then their scores are adjusted over time based on their behaivor during the epoches.\n\n\nProof-of-Relay Scheme\nAs shown in Figure 7, the procedure for our Proof-of-Relay scheme contains the following steps:\n\nPrior to each epoch, the randomness beacon emits a random value (x). Consider an arbitrary Node (C_{0}). This node then calculates the Verifiable Random Function (VRF) output (y_{A}) and its corresponding proof ({A}). These values are derived from input (x) and (C{0})’s private key (sk_{A}), that is, (y_{A},{A}(x,sk{A})). Node (C_{0}) then seeds a sampler with its own (y_{A}) (optionally salted with some public information such as the crypto address of the node, as it adds more unpredictability). This sampler, with a Bernoulli distribution, generates a pseudo-random value to determine if (C_{0}) should act as a challenger in this epoch. If selected, a challenge message (m_{A}) of random size and the node (C_{1}) to be challenged are chosen by the same sampler with uniform distribution, in the range of size limit of the message and the range of all participating nodes other than (C_{0}).\nNode (C_{0}) encrypts (m_{A}) using an ECDH scheme involving its own private key and node (C_{1})’s public key. The encrypted message is then transmitted to (C_{1}) through the relay network. This may involve zero to many intermediate relay nodes in the network who do not know (m_{A}) is a challenge message.\nUpon receiving the encrypted challenge message, node (C_{1}) decrypts it. Recognizing it as a challenge, (C_{1}) commits the message along with a proof to the blockchain.\nNode (C_{1}) then computes its own VRF output (y_{B}) and associated proof ({B}) which is derived from the challenge message and its private key (sk{B}). Using (y_{B}), it generates a new challenge message (m_{B}) and identifies the next node (C_{2}) to challenge. Node (C_{1}) repeats the process in step 2, sending the new challenge message (m_{B}) to (C_{2}).\nNode (C_{2}), upon receipt of the encrypted challenge message from (C_{1}), repeats steps 3 and 4. The random walk continues until either a node realizes the epoch has ended (no reward to continue) or a Time-To-Live (TTL) hard limit is reached.\nAfter the epoch ends, a verifiable path of challenges (C_{0},C_{1},C_{2},) is established. The nodes on this path and their peers are awarded points for their reputation score as described in Section 4.4. Additionally, after each epoch, each node’s reputation score is decreased by a constant. Thus, if a node fails to participate in the random walk, its reputation will decay over time. Only nodes with the reputation above a certain threshold are eligible for receiving relay rewards.\n\n\n\nReputation Scoring\nAfter the epoch ends, there are paths of challenges which originate from nodes who are selected as starting points based on the Bernoulli distribution. Consider one path of challenges ({C_{0},C_{1},,C_{k}}), and we denote its length as (k) (some nodes may appear more than once). The (i)-th node (C_{i}) in this path, along with its peers, will collectively receive a total of (R(i,k)={j=0}{k-i}1/2{j}) reputation points, i.e., (C{i}), will receive reputation points calculated based on the remaining length of the path after that node. Nodes at the start of long paths are rewarded more than later nodes, but the reward for any node is still bounded because of the exponentially diminishing tail rewards.\nLet’s assume (C) is a node in the path of challenges and (C) has (m) peers. To incentivize nodes to maintain a well-connected network, we incorporate a node’s degree (number of directly connected peers) into the reward distribution. Let (N) be the desired minimum degree for which nodes should aim. The reputation reward (R) is divided between node (C) and its peers using the following formulas:\n[(C) =R] [=\n\\[\\begin{cases}\\frac{R}{2},&m\\leq N\\\\ R\\times\\frac{N}{N},&m&gt;N\\end{cases}\\]\n] [() =] [=\n\\[\\begin{cases}\\frac{R}{2m},&m\\leq N\\\\ \\frac{R}{N+m},&m&gt;N\\end{cases}\\]\n]\nIn order to preserve fairness and integrity during challenges, security measures are established to deter any node from prematurely broadcasting the challenge message to its peers or other colluding nodes. If a node makes an early claim regarding the identity of a challenge message before the epoch ends, both the node and its collider will have their rewards revoked. As an incentive for honesty in the challenge, the node that reports such a violation will be awarded some rewards. To avoid an overload of such claims, each node is permitted to submit only a limited number of claims per epoch.\nOverall, our scheme has the following desirable properties:\nindistinguishable probing To prevent the intermediate nodes from only relaying the challenge messages, challenge messages deliberately vary in their size, and are encrypted to be indistinguishable from normal messages. This forces every node to treat and relay every messages seriously for their best interest.\nuniform distribution of challenge messages Due to the unpredictable delivery time and continuing steps of the random walk, challenge messages are heard in the network throughout the entire epoch, so nodes cannot guess a specific time period when they could strategically omit the messages and only care for the period when there are more challenge messages.\nMinimizing beacon asynchrony The time span of each epoch is significantly larger than the delay of the randomness beacon. This minimizes the discrepancy between the times at which different nodes receive the random beacon, ensuring a fair start for all.\nfavor low latency The length of the path of challenges provides an indirect measure of network connection speeds. Within a fixed epoch, a longer challenge path indicates a shorter average time per challenge hop. Our reputation scoring design takes that into account, which incentivizes nodes to upload their proof of relay as swiftly as possible, thereby fostering network efficiency.\nfavor stable connections Setting up connections with new nodes takes time and can potentially affect a node’s ability to quickly relay challenge messages. Thus, nodes are discouraged from frequently changing their connections.\nfavor high-quality peers The reputation scoring system motivates nodes to maintain a balanced number of high-quality peer connections. If a node (C) has significantly more peers than the desired degree (N), its share of the reputation reward (R) decreases. This drives nodes to prune low-quality peers and retain only those reliable with good network traffic.\nadvocate relay diligence The confidentiality of the message source prevents nodes from knowing if they are directly connected with the challenge sender. As a result, all nodes are encouraged to diligently relay challenge messages, and unknowingly assist a peer, as oppose to keeping all messeages from the peer to itself.\nThe properties above provide a robust and fair framework for nodes to participate in and benefit from the Proof-of-Relay system."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#rewards-and-payments",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#rewards-and-payments",
    "title": "Hyperbolic",
    "section": "5 Rewards and payments",
    "text": "5 Rewards and payments\nIn Hyperbolic, we use a dual reward structure consists of both Relay Rewards and D-Service Rewards. Namely, a node first earns Relay Rewards by forwarding data as a Bolic node. Additionally, it can also earn D-Service Rewards by rendering D-Services to clients. Rewards could be in the form of Hyperbolic’s native token. Also, D-Service designers can choose to use their service-related tokens or fiat money for billing, with a customized fee model tailored to the specific service.\nRelay rewards are designed to encourage early adoption and participation in the network. They will initially be significant to offset the operational costs of running a node, thus ensuring node operators exceed their break-even point during the network’s inception phase. Over time, as the network matures, we anticipate these rewards may gradually decrease. Relay rewards will serve as the primary source of rewards in the initial years, with D-Services income taking over\nFigure 7: Schematic Diagram Illustrating the Proof-of-Relay Protocol.\nas they have more demand from the applications, and also need Bolic network hosted by the same nodes.\nD-Service rewards serve as an incentive for nodes to provide D-Services. The mechanism is simple: users compensate nodes for their services, thereby incentivizing nodes to perform more work. To ensure transparency and fairness, D-Service rewards can be disbursed to the node operators only after the successful completion of tasks or prorated for segmented periods. This approach not only safeguards the interests of the users, but also ensures that nodes are adequately rewarded for their contributions by some controllable loss from users’ dishonest behavior.\nFrom a payment perspective, users are free to utilize the Bolic relay network without incurring any charges. However, the payment mechanisms for each D-Service will differ and be independently established by their respective developers. This ensures that each D-Service can adopt a payment model that best aligns with its unique functionality, making a competitive and healthy marketplace for all."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#other-related-systems",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#other-related-systems",
    "title": "Hyperbolic",
    "section": "6 other related systems",
    "text": "6 other related systems\nIn this section, we discuss related systems and projects, their features and inherent limitations, and as a comparison, why Hyperbolic is fundamentally different.\n\nHistorical P2P File-Sharing and IPFS\nGnutella was a pioneering P2P network protocol established in 2000. As the first decentralized peer-to-peer network of its kind, it set the stage for subsequent networks to adopt a similar model. Gnutella enables users to share files through a decentralized search mechanism.\nBitTorrent is a popular P2P file-sharing platform that enables users to distribute large files efficiently. Many users use it to share multimedia files (movies), often with legal issues. eMule, started in 2002, offers a very similar service to BitTorrent. It uses its own algorithm and zlib for compression.\nInterPlanetary File System (IPFS) is also for P2P storage and sharing. It is written in more modern, Go language and unlike the above file-sharing clients, focuses on the functionality as a “middle-ware” to other Internet-scale projects. It is plug-and-play for storage hosting machines and offers a directory-like hierarchy for file storage. It was later on incentivized by tokens like Fleccoin to encourage the availability of the stored data.\nHowever, all of the above P2P storage platforms emphasize on the possibility of storing data in a decentralized manner, so the architecture is ad-hoc to the only task. Usually the latency is less predictable and the implementation is either dated or just enough to support file-sharing. While storing data is important, there is no actual computation or interaction with the stored data on these platforms, limiting their evolution.\nIn contrast, the backbone of Hyperbolic is a modern P2P network, Bolic, designed to be a messaging platform and generalized for different purposes. Using this backbone, we build our D-Service framework which is not necessary in a P2P model at all stages. This allows a wide spectrum of services, including (e.g., D-CDN) but not limited to file-sharing.\n\n\nTor\nTor, also known as The Onion Router, is an anonymous communication network that enables users to browse the Internet and access services without revealing their identity or location. Tor achieves this by obfuscating traffic through a series of relays, encrypting at each step to maintain user privacy. While Tor provides a valuable tool for preserving anonymity, its focus on privacy comes at the expense of performance. It also uses the traditional web model. Hyperbolic, on the other hand, offers a new D-Service platform that can potentially accommodate Tor-style routing as an optional feature.\n\n\nContent Delivery Networks\nContent Delivery networks (CDNs) are large-scale distributed systems designed to serve static contents to end users with different geographical locations. Traditional CDNs are typically centralized and operated by companies. Thus, the implementations of CDNs vary and are usually private to the operators. They are also specialized in use so that streaming services like Netflix have their own video CDN servers, whereas many websites use Cloudflare [3] to cache web pages. In Hyperbolic, we build a general-purpose D-CDN that resembles a distributed key-value store with hashes as keys. Any machines in the network can opt in as a D-CDN server to store and replicate the encrypted data.\n\n\nBlockchains\nBlockchains, such as Bitcoin [13], Ethereum [2], and Avalanche [17], emerged as prominent P2P networked systems providing decentralized finance and/or applications in the form of smart contracts. While they demonstrate the possibilities of decentralized computing, they are built around a chain (or a collection of chains) that directly captures the computational steps of the hosted (virtual) services, which is less suitable for more general computational demands that traditional cloud-computing can satisfy. By finding the new abstraction that is lower-level than a chain-based consensus, Hyperbolic encapsulates the existing chains as ordering services, while exposing a chain-less framework that allows more services with composability and fault tolerance.\n\n\nWaku and XMPP\nWaku [22] is a decentralized messaging protocol designed for privacy, scalability, and friendliness to IoT devices. Waku’s messaging adopts a gossip-based routing algorithm, leading to excessive redundant messages flooding the network in both one-to-one and one-to-many communication scenarios. In contrast, the smart routing protocol of the Bolic network ensures the messages are routed to the recipient(s) with low cost whereas group messages could be handled by D-Services. XMPP is building a network to enable secure messaging between blockchain accounts, but it uses Waku under the hood to relay messages. While Waku and XMTP focus only on messaging, Hyperbolic expands the scope of decentralized systems to cater to a more comprehensive set of services and applications.\n\n\nNym\nNym [5], a Tor-like network, prioritizes user privacy with its Proof-of-Mixing design. All participants in Nym generate measurement messages in a pseudo-random manner and a full path to relay the message through the network using a VRF and a sampler. They then employ the Sphinx packet format to encrypt data and relay it along a pre-determined path through the routing network. However, this approach relies on deterministic relay paths. In contrast, our Proof-of-Relay does not make such an assumption and thus allows the Bolic network to have more flexibility in terms of the routing algorithm.\n\n\nHelium\nHelium [7] aims to establish a decentralized wireless network of hotspots for users. They proposed a Proof-of-Coverage scheme to verify that miners are providing wireless network coverage. Additionally, there is a Proof-of-Serialization scheme, achieving cryptographic time consensus among decentralized clients. Yet, similar to Nym, Helium uses deterministic paths for transmitting challenges. Moreover, due to the complexity of achieving synchronized timestamps, they transitioned from using Proof-of-Serialization to simply employing centralized oracles as the reference point for timestamps. Bolic’s Proof-of-Relay scheme does not have these issues and provides a feasible solution that also considers relay speed."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#references",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#references",
    "title": "Hyperbolic",
    "section": "References",
    "text": "References\n\n[1] Joseph Bonneau and Valeria Nikolaenko. Public randomness and randomness beacons. https://al6zcrypto.com/posts/article/public-randomness-and-randomness-beacons/, 2022.\n[2] Vitalik Buterin. Ethereum: a next-generation smart contract and decentralized application platform. https://ethereum.org/en/whitepaper/, 2014.\nthe web performance & security company. https://www.cloudflare.com/.\n[4] Jeffrey Dean and Sanjay Ghemawat. MapReduce: Simplified data processing on large clusters. In Eric A. Brewer and Peter Chen, editors, 6th Symposium on Operating System Design and Implementation (OSDI 2004), San Francisco, California, USA, December 6-8, 2004, pages 137-150. USENIX Association, 2004.\n[5] Claudia Diaz, Harry Halpin, and Aggelos Kiayias. The Nym network: the next generation of privacy infrastructure (2021). https://nymtech.net/nym-whitepaper.pdf, 2021.\n[6] Mark Fenwick and Paulius Jurcsy. The contested meaning of Web3 and why it matters for (IP) lawyers. Available at SSRN 4017790, 2022.\n[7] Amir Haleem, Andrew Allen, Andrew Thompson, Marc Nijdam, and Rahul Garg. Helium: A decentralized wireless network. Helium Systems Inc., Tech. Rep[Online]. Available: http://whitepaper.helium. com, 2018.\n[8] Aniket Kate, Gregory M Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials and their applications. In Advances in Cryptology-ASIACRYPT 2010: 16th International Conference on the Theory and Application of Cryptology and Information Security, Singapore, December 5-9, 2010. Proceedings 16, pages 177-194. Springer, 2010.\n[9] Protocol Labs. Filecoin: a decentralized storage network. https://filecoin.io/filecoin.pdf, 2017.\n[10] Leslie Lamport. The part-time parliament. ACM Trans. Comput. Syst., 16(2):133-169, 1998.\n[11] Dahlia Malkhi, Chrysoula Stathakopoulou, and Maofan Yin. Build it super simple: Introducing single broadcast consensus on a DAG. https://blog.chain.link/bbca-chain-single-broadcast-consensus-on-a-dag/, 2023.\n[12] Silvio Micali, Michael Rabin, and Salil Vadhan. Verifiable random functions. In 40th annual symposium on foundations of computer science (cat. No. 99CB37039), pages 120-130. IEEE, 1999.\n[13] Satoshi Nakamoto. Bitcoin: a peer-to-peer electronic cash system. https://bitcoin.org/bitcoin.pdf, 2008.\n[14] Diego Ongaro and John K. Ousterhout. In search of an understandable consensus algorithm. In Garth Gibson and Nickolai Zeldovich, editors, 2014 USENIX Annual Technical Conference, USENIX ATC ’14, Philadelphia, PA, USA, June 19-20, 2014, pages 305-319. USENIX Association, 2014.\n[15] OpenAI. ChatGPT. https://openai.com/blog/chatgpt, 2023.\n[16] Henning Pagnia, Felix C Gartner, et al. On the impossibility of fair exchange without a trusted third party. Technical report, Citeseer, 1999.\n[17] Team Rocket, Maofan Yin, Kevin Sekniqi, Robbert van Renesse, and Emin Gun Sirer. Scalable and probabilistic leaderless BFT consensus through metastability. CoRR, abs/1906.08936, 2019.\n[18] Jerome H. Saltzer, David P. Reed, and David D. Clark. End-to-end arguments in system design. ACM Trans. Comput. Syst., 2(4):277-288, 1984.\n[19] Alexander Spiegelman, Neil Giridharan, Alberto Sonnino, and Lefteris Kokoris-Kogias. Bullshark: DAG BFT protocols made practical. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, CCS 2022, Los Angeles, CA, USA, November 7-11, 2022, pages 2705-2718. ACM, 2022.\n[20] Chrysoula Stathakopoulou, Michael Wei, Maofan Yin, Hongbo Zhang, and Dahlia Malkhi. BBCA-LEDGER: high throughput consensus meets low latency. CoRR, abs/2306.14757, 2023.\n[21] Storj Labs, Inc. Storj: a decentralized cloud storage network framework. https://www.storj.io/storjv3.pdf, 2018.\n[22] Oskar Thoren, Sanaz Taheri-Boshrooyeh, and Hanno Cornelius. Waku: a family of modular P2P protocols for secure & censorship-resistant communication. In 2022 IEEE 42nd International Conference on Distributed Computing Systems Workshops (ICDCSW), pages 86-87. IEEE, 2022.\n[23] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajiwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\n[24] Sam Williams, Viktor Diordiiev, Lev Berman, and Ivan Uemilianin. Arweave: a protocol for economically sustainable information permanence. https://yellow-paper.arweave.dev/, 2019.\nAugust 2, 2019_, pages 347-356. ACM, 2019.\n[26] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauly, Michael J. Franklin, Scott Shenker, and Ion Stoica. Resilient distributed datasets: A fault-tolerant abstraction for ir-memory cluster computing. In Steven D. Gribble and Dina Katabi, editors, Proceedings of the gth USENIX Symposium on Networked Systems Design and Implementation, NSDI 2012, San Jose, CA, USA, April 25-27, 2012, pages 15-28. USENIX Association, 2012."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#appendix-a-appendix-proof-of-storage",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic-whitepaper.html#appendix-a-appendix-proof-of-storage",
    "title": "Hyperbolic",
    "section": "Appendix A Appendix: Proof-of-Storage",
    "text": "Appendix A Appendix: Proof-of-Storage\nIn our Decentralized Content Delivery Network (D-CDN) service, Proof of Storage plays a pivotal role in establishing trust and ensuring data availability. The crux of this process is to allow any network participant, who may not have prior knowledge or a copy of the data, to verify whether a certain storage node is faithfully storing a specific piece of data. This process is done in such a way that the verifying party does not need to download the entire data to confirm its integrity. Instead, the node storing the data provides a cryptographic proof that can be verified efficiently. By integrating Proof of Storage, our D-CDN service ensures the reliability and availability of data while minimizing network and computational overheads. This section provides a detailed explanation of our Proof of Storage protocol and its importance to our D-CDN service.\n\nMotivations\nDecentralized storage networks incorporate a variety of proof systems to ensure data integrity and availability.\nArweaveave [24], for instance, relies on a Proof-of-Work algorithm where nodes utilize computational resources to solve complex hash problems tied to files in storage, utilizing the full data content of a randomly chosen prior block to validate transactions and create new blocks in the blockchain. The requirement to generate a hash below a certain difficulty level using a nonce can, however, be computationally intensive and result in unnecessary resource usage.\nFilecoin [9], on the other hand, employs computationally demanding procedures, such as sealing and encoding, to generate proofs of storage, which guarantees that a node has securely created and stored a unique copy of some piece of data. Nevertheless, this technique necessitates high-end hardware due to its dependence on computationally intensive operations to produce sealed sectors. Consequently, nodes with constrained computational resources might be excluded from participating in the network.\nStorj [21], meanwhile, adopts Reed-Solomon encodingto generate extra data segments, enabling the reconstruction of lost or corrupted data. Alongside, the Berlekamp-Welch error correction algorithm is used to identify and correct erroneous responses. However, Storj’s verification process requires multiple data shares from different storage providers. This condition could lead to inefficiencies and dependency on the responsiveness of other nodes for data integrity confirmation.\nTherefore, the need for a more efficient and accessible system for Proof-of-Storage is evident. In response, we propose a novel design for our D-CDN service, aiming to overcome these limitations. Our design only requires a proof from only the storage provider to verify the data integrity, thus eliminating the need to depend on other nodes’ responses. Furthermore, by using KZG polynomial commitment scheme [8] instead of Merkle trees, the proof size is reduced to a constant and verifying the proof only require a constant number of operations. As a result, our approach is less resource-intensive, opening participation to a wider range of nodes.\n\n\nDefintions\n\nReed-Solomon codes: Error-correction codes that process data blocks as finite-field symbols and are able to detect and correct combinations of errors and erasures. Each code is defined by three parameters: the alphabet size (q), block length (n), and message length (k), with (k&lt;nq). Every codeword in the set corresponds to function values from a polynomial of degree less than (k).\nElliptic curves These curves, defined over a field (K), represent points in (K^{2}). They are specifically categorized by the plane algebraic curve equation (y{2}=x{3}+ax+b), where (a) and (b) are coefficients in (K) and the field’s characteristic differs from (2) and (3).\n**Bilinear Pairing*\nA bilinear pairing is a mapping defined between two additive groups (G_{1},G_{2}) and a multiplicative group (G_{T}), all of prime order (p). Here, (g_{1}G_{1}) and (g_{2}G_{2}) are generators of (G_{1}) and (G_{2}) respectively. The pairing is represented as (e:G_{1}G_{2}G_{T}) and has the following properties:\nBilinearity: For all (a,bZ), (e(ag_{1},bg_{2})=e(g_{1},bg_{2})^{ab})\nNon-degeneracy: (e(g_{1},g_{2}))\n\n\n\nProof-of-Storage Scheme\nLet (G_{1}) and (G_{2}) be two elliptic curves with a bilinear pairing (e:G_{1}G_{2}G_{T}). Let (g_{1}) and (g_{2}) be generators of (G_{1}) and (G_{2}). We will use a very useful shorthand notation\n[[x]{1}=xg{1}G_{1}[x]{2}=xg{2}G_{2}]\nfor any (xZ). Here we let (G_{1}) be the elliptic curve (1) which is a pairing-friendly elliptic curve.\n\nTursted Setup The initialization of this protocol requires a one-time trusted setup. Once this is established, the protocol can repeatedly engage in committing to and revealing different polynomials. Assume we have a trusted setup, so that for a secret (s), the elements ([s^{i}]{1}) and ([s^{i}]{2}) are publicly available for all (i=0,,n-1). Now, it’s a fundamental aspect of elliptic curve cryptography that from the provided group elements in the trusted setup, it’s computationally infeasible to extract the actual value of (s). Despite (s) being a member of (F_{p}), the prover is unable to determine its specific value. Instead, the prover is limited to performing certain operations with the given elements. For a given polynomial (p(X)={i=0}{n}p_{i}X{i}), the prover is able to compute [[p(s)]{1}=[_{i=0}{n}p_{i}s{i}]{1}={i=0}^{n}p_{i}[s^{i}]{1}] This process enables the prover to compute the evaluation of the polynomial at the undisclosed point (s) within the group (G{1}), while maintaining the obscurity of (s)’s exact value.\nEncoding A user sends a file to a storage provider for storage. A file is represented by an ordered collection of one or more segments. Segments have a fixed maximum size for erasure encoding (in our case, it’s Reed-Solomon Encoding). Each segment is treated as a vector of k elements in the finite field F, i.e. (x=(x_{1},,x_{k})F^{k}). By using Polynomial Interpolation, the storage provider calculates the unique polynomial (p_{x}) of degree less than k such that [p_{x}(i)=x_{i}i{1,,k}] Once it has been generated, it is evaluated at the other points (k+1,,n).\nCommitment The storage provider commits to Reed-Solomon encoding polynomial (p_{x}) by calculating (C=[p_{x}(s)]_{1}). This is called KZG commitment scheme or just Kate polynomial commitment scheme. It is called a commitment, because having sent the commitment value (an elliptic curve point) to the public, the prover cannot change the polynomial they are working with. They will only be able to provide valid proofs for one polynomial, and if they are trying to cheat, they will either fail to produce a proof or the proof will be rejected by the verifier.\nVerification Every time when a user or other entities asks for verification at a random point z, the storage providers give the evaluation of (p_{x}(z)=y). Besides, he calculates (q(X)=) and the proof (=[q(s)]{1}). He then send (y) and () to the verifier. The user can easily verify it by checking the following equation [(,[s-z]{2})=(C-[y]_{1},H).] If it holds, then the verifier accepts the proof.\n\n\n\nFile Retrieval\nRetrieving a file from the Distributed Content Delivery Network (D-CDN) is a process that necessitates a well-coordinated interaction between storage providers and the user. The concept of ‘fair exchange’ is vital in this scenario. The impossibility results on fair exchange [16] establish that it is unfeasible for two parties to perform an exchange without involving trusted entities. The retrieval process consists of these significant steps:\n\nBandwidth Calculation and Contract Signing: Before initiating the retrieval process, storage providers estimate and communicate the total bandwidth and payment required for the file retrieval. Subsequently, the user selects a storage provider and signs a smart contract with them. The required amount is then escrowed by the smart contract.\nFile Segmentation: Due to the impossibility results on fair exchange without trusted parties, extensive files are fragmented into smaller, manageable segments. This step ensures fair transactions during the retrieval process.\nSegments Retrieval: Segments are retrieved sequentially by the user. Every retrieved segment is verified by the user to ensure its integrity and authenticity. After successful retrieval and verification of a segment, the user signs a message confirming the receipt of the segment and sends it to the storage provider. Upon receiving the confirmation message, the storage provider transmits the next segment to the user.\nRetrieval Interruption: In case the client stop paying, or the storage provider discontinues data transmission, either party has the right to halt the exchange. Subsequently, the storage provider uploads the confirmation messages of the transmitted segment to the smart contract. The smart contract then allocates the payment for the data confirmed by the user to the storage provider, and the remaining amount is refunded to the user. If needed, the user can sign another contract with a different storage provider to retrieve the remaining data.\n\nThrough these steps, the file retrieval process provides a balance of fairness and efficiency, offering users a reliable method to retrieve their files from the D-CDN."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperliquid.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperliquid.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperliquid.html#current-widely-accepted-funding-rate-formula",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperliquid.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperliquid.html#potentially-new-funding-rate-formula",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperliquid.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/ethena/ethena.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/ethena/ethena.html",
    "title": "Ethena Labs",
    "section": "",
    "text": "Some thoughts on @ethena_labs and the attempt towards a stablecoin, $USDe, independent of the traditional banking system. https://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\nQuick Overview of the Basic Mechanism\n\n1 $USDe is backed by a $1 delta neutral ETH position. - Long $1 of stETH spot - Short $1 of ETH perpetual futures swap contracts (on a centralized exchange, with the spot stETH as cross-collateral).\nFor a more substantial overview, check out @cryptohayes (Ethena advisor) “Dust on Crust” https://blog.bitmex.com/dust-on-crust/\n\nA note the scale of this endeavor (relevant later).\n\nEthena is pursuing a trillion dollar TAM.\n\nStablecoin circulating supply sits comfortably above $100 billion (throughout the bear market).\nTether printed over $1 billion in profit last quarter.\nThe CBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n\nOn the surface, there’s two obvious/primary risks to the mechanism.\n\nCounterparty (exchange) Risk\nBasis (funding rate) Risk\n\n\nHow, and to what extent, is Ethena mitigating these?\n\nAddressing Counterparty Risk\n\nWhether its an external hack (Mt Gox) or insider theft (FTX) - CEX risk is certainly non-negligible. What’s the risk-adjusted rate at which you would park 8+ figures on Binance, or Deribit? This is a serious question that crypto firms (HFT shops, VC firms) decide internally…\nIn other words, if Binance were a public company, where would their credit default swaps trade?\nCounter to what @cryptohayes initially described in his early writings, Ethena must avoid custodying the assets at the exchanges. Instead, park the assets with a secure third party (Fireblocks, Ledger, Copper), form agreements with the exchanges to accept this (likely some form of ZK-Proof of stETH asset balance) as collateral, and simply settle funding payments on the derivatives intermittently.\nThis doesn’t exactly eliminate all counterparty risk (can expand on this in the future), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\n\nAddressing Basis Risk\n\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\nFounder @leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n\nI will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\n\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n\nHowever, I subscribe to two principles which may complicate this assumption.\n\nThe Observer Effect: The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\n\nConsidering the scale of the stablecoin market, it’s naive to neglect the reflexivity of the relationship between Ethena’s operations/supply and the aggregate ETH perp funding rate.\nThe in-sample backtest shown in the previous tweet simulates yield on $5b circulating $USDe supply. What’s not mentioned, however, is that $USDe would have represented roughly half of aggregate ETH open interest… the backtest is inherently flawed.\n\n\n\n\nAlthough it’s important to point out weakness of the backtest, this doesn’t necessarily suggest a point of failure for $USDe.\n\nThe design is fundamentally different from the UST-esque algostables, which were always necessarily destined to collapse. In fact, if Ethena’s mint & redemption process is both free and (near) instant, the $USDe mechanism can be inherently self-correcting.\nLet’s imagine the $USDe supply was $5b today, Ethena would represent nearly half of the $10b ETH perp open interest, and the funding rate would likely be negative (exact threshold for % of OI Ethena can be comfortable with is unclear, but 50% is probably unhealthy).\nWith transparent metrics on curculating supply, assets, liabilities, and distribution (what % of the shorts are on BitMex vs Bybit vs …), the market can observe collateral fluctuations, and react rationally. Users swap out of $USDe on Curve, which is purchased by market makers/arbitrageurs who then redeem with Ethena. This lifts the short pressure until the funding rate (or net yield, including stETH) is positive again.\n\nThere is certainly much more to be discussed.\n\n\nWhat can be done to further mitigate exchange risk, even if it’s only relevant to the short derivative leg?\nWhere will the “natural funding rate” converge with this mechanism implemented at scale?\nWhat role does the insurance fund play, and how shall it be sized/scaled optimally?\nCan the “internet bond” effectively offer an inversely correlated yield to bonds (think crypto OI/perp funding in bullish, low-rate environment vs high-rate)?\n\nBut I’ll end the thread here for now.\nThe @ethena_labs team is legit, and it’s clear they are continuing to diligence the relevant considerations. A bankless stablecoin is a pivotal instrument for the cryptoeconomy, and I look forward to further public engagement as this develops. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/ethena/ethena.html#tweet-thread",
    "href": "library/natural-sciences/crypto/blockchain/projects/ethena/ethena.html#tweet-thread",
    "title": "Ethena Labs",
    "section": "",
    "text": "Some thoughts on @ethena_labs and the attempt towards a stablecoin, $USDe, independent of the traditional banking system. https://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\nQuick Overview of the Basic Mechanism\n\n1 $USDe is backed by a $1 delta neutral ETH position. - Long $1 of stETH spot - Short $1 of ETH perpetual futures swap contracts (on a centralized exchange, with the spot stETH as cross-collateral).\nFor a more substantial overview, check out @cryptohayes (Ethena advisor) “Dust on Crust” https://blog.bitmex.com/dust-on-crust/\n\nA note the scale of this endeavor (relevant later).\n\nEthena is pursuing a trillion dollar TAM.\n\nStablecoin circulating supply sits comfortably above $100 billion (throughout the bear market).\nTether printed over $1 billion in profit last quarter.\nThe CBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n\nOn the surface, there’s two obvious/primary risks to the mechanism.\n\nCounterparty (exchange) Risk\nBasis (funding rate) Risk\n\n\nHow, and to what extent, is Ethena mitigating these?\n\nAddressing Counterparty Risk\n\nWhether its an external hack (Mt Gox) or insider theft (FTX) - CEX risk is certainly non-negligible. What’s the risk-adjusted rate at which you would park 8+ figures on Binance, or Deribit? This is a serious question that crypto firms (HFT shops, VC firms) decide internally…\nIn other words, if Binance were a public company, where would their credit default swaps trade?\nCounter to what @cryptohayes initially described in his early writings, Ethena must avoid custodying the assets at the exchanges. Instead, park the assets with a secure third party (Fireblocks, Ledger, Copper), form agreements with the exchanges to accept this (likely some form of ZK-Proof of stETH asset balance) as collateral, and simply settle funding payments on the derivatives intermittently.\nThis doesn’t exactly eliminate all counterparty risk (can expand on this in the future), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\n\nAddressing Basis Risk\n\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\nFounder @leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n\nI will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\n\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n\nHowever, I subscribe to two principles which may complicate this assumption.\n\nThe Observer Effect: The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\n\nConsidering the scale of the stablecoin market, it’s naive to neglect the reflexivity of the relationship between Ethena’s operations/supply and the aggregate ETH perp funding rate.\nThe in-sample backtest shown in the previous tweet simulates yield on $5b circulating $USDe supply. What’s not mentioned, however, is that $USDe would have represented roughly half of aggregate ETH open interest… the backtest is inherently flawed.\n\n\n\n\nAlthough it’s important to point out weakness of the backtest, this doesn’t necessarily suggest a point of failure for $USDe.\n\nThe design is fundamentally different from the UST-esque algostables, which were always necessarily destined to collapse. In fact, if Ethena’s mint & redemption process is both free and (near) instant, the $USDe mechanism can be inherently self-correcting.\nLet’s imagine the $USDe supply was $5b today, Ethena would represent nearly half of the $10b ETH perp open interest, and the funding rate would likely be negative (exact threshold for % of OI Ethena can be comfortable with is unclear, but 50% is probably unhealthy).\nWith transparent metrics on curculating supply, assets, liabilities, and distribution (what % of the shorts are on BitMex vs Bybit vs …), the market can observe collateral fluctuations, and react rationally. Users swap out of $USDe on Curve, which is purchased by market makers/arbitrageurs who then redeem with Ethena. This lifts the short pressure until the funding rate (or net yield, including stETH) is positive again.\n\nThere is certainly much more to be discussed.\n\n\nWhat can be done to further mitigate exchange risk, even if it’s only relevant to the short derivative leg?\nWhere will the “natural funding rate” converge with this mechanism implemented at scale?\nWhat role does the insurance fund play, and how shall it be sized/scaled optimally?\nCan the “internet bond” effectively offer an inversely correlated yield to bonds (think crypto OI/perp funding in bullish, low-rate environment vs high-rate)?\n\nBut I’ll end the thread here for now.\nThe @ethena_labs team is legit, and it’s clear they are continuing to diligence the relevant considerations. A bankless stablecoin is a pivotal instrument for the cryptoeconomy, and I look forward to further public engagement as this develops. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/ethena/ethena.html#thread-draft-old",
    "href": "library/natural-sciences/crypto/blockchain/projects/ethena/ethena.html#thread-draft-old",
    "title": "Ethena Labs",
    "section": "Thread Draft OLD",
    "text": "Thread Draft OLD\n\nSome thoughts on @ethena_labs and $USDe, an attempt towards a stablecoin which is independent of the traditional banking system.\n\nhttps://mirror.xyz/0xF99d0E4E3435cc9C9868D1C6274DfaB3e2721341/2gfr0qaFvZ8UxPaBvPPAZgwdcbssR_cyg5svqj1YGrY\n2/ First, a quick mid-bell summary of USDe mechanism\n\nAlice deposits $1 worth of some asset (USDC, WBTC, doesn’t matter)\nEthena swaps this for $1 worth of stETH, which is then used as cross-collateral for a $1 notional ETH perp short on some CEX\nEthena mints 1 $USDe to Alice, backed by the delta-neutral $1 position\n\nFor a more substantial overview, check out @cryptohayes “Dust on Crust” (which Ethena cites as inspiration)\nhttps://blog.bitmex.com/dust-on-crust/\n3/ Let me note the scale of this endeavor (relevant later).\n\nStablecoin circulating supply sits comfortably above $100 billion throughout the bear market.\nTether printed over $1 billion in profit last quarter.\nCBDCs are coming, from China to the WEF (both of which want censorship permissions).\n\nEthena is pursuing is a trillion dollar TAM.\n“If you don’t believe me or don’t get it, I don’t have time to try to convince you, sorry.” INSERT VIDEO\n4/ Okay, so there’s two obvious/primary risks to the $USDe mechanism\n\nCounterparty (CEX) Risk\nBasis Risk\n\nHow is Ethena addressing these?\n5/ Addressing Counterparty Risk\nWhether its an external hack (Mt Gox) or insider theft (FTX) doesn’t matter - CEX risk is real. How much would you have to get paid to park your funds at Binance? 30%? 80%? This is a real question that CEX HFT shops and crypto VCs decide internally - the consensus is almost certainly above $USDe’s expected yield.\nThe only proper mitigation I see is to avoid custodying assets at the exchanges. Park the stETH in Fireblocks, Ledger, etc. and make special agreements with Binance, Bybit, Bitmex, etc. to accept this (likely some form of ZK-Proof of stETH asset claim) as collateral, and simply settle funding payments intermittently.\nThis doesn’t exactly eliminate all counterparty risk (still an operational nightmare/panic if Binance goes FTX mode), but it ensures assets are safu. I’m not sure this is actually Ethena’s plan, but it appears to be the only sufficient solution (assuming CEXs agree to the setup).\nTODO: Mention the black swan force exit short perps too (the BitMex event)? - Ethena redemption should have scaled down exposure in the hours and minutes prior to this event (funding will necessarily have been negative before the trigger) - Ethena is hedged across multiple CEXes (historically this happens on one exchange at a time) - Ethena insurance fund as final backstop\n6/ Addressing Basis Risk\nThe question/issue is what happens when (not if) the perp-spot spread flips, and the delta-neutral position begins to bleed (rather than accrue) funding payments.\n@leptokurtic gives the TLDR mitigation/assumptions here\nhttps://twitter.com/leptokurtic_/status/1682781081068769280?s=20\n7/ I will focus on one of Ethena’s core assumptions, specifically that the “natural funding rate” is positive. Imo, this is where an interesting discussion lies.\nTo be clear, this assumption is not baseless - it is both supported by historical ETH perp data, and is generally true across (almost) all derivative markets.\n\n\n\n8/ However, I subscribe to two schools of thought which may challenge this assumption.\n\nQuantum Mechanics (the observer effect): The act of observing or measuring a system necessarily disturbs or changes the system.\nSoros’s Reflexivity of Markets: Market participants’ imperfect understanding of the world influences their actions, and those actions, in turn, influence the world in ways that can confirm or contradict their initial beliefs.\n\nKeeping in mind the scale of the stablecoin market, it’s naive to neglect the reflexivity bwteen Ethena’s operations and the ETH perp funding rate. The backtested yield in the previous tweet is under the assumption of $5b circulating $USDe supply - I predict this in-sample backtesting wil. This implies a $5b short OI, which is sustantial considering aggregate OI seen historically.\nThe image below shows Binance alone, but including Bybit, Bitmex, Derbit, and OKEx, total OI on ETH perpetual swaps is ~$TODO. Ethena would represent TODO% of ETH perp OI across all major exchanges.\n\n\n\nFix Up - not final\n9/ The question becomes: In the scenario wherein $USDe is widely adopted, what is the “natural funding rate” of ETH perps? Here’s a thesis:\nThe introduction of ETH staking, and liquid staking derivatives, effectively increased the baseline ETH lending rate (ETH’s LIBOR/SOFR) by the network’s staking yield. Why would anyone lend ETH at 80bps, when they can deposit for an LSD and earn 5% (where they can also then lend the LSD for 80bps)?\nThe “natural funding rate” baseline (not including the upwards skew cause by net bullish payment for leverage, which will remain a factor) on ETH perps will no longer necessarily == risk-free rate, as traditionally assumed for non-interest accruing assets (BTC, Gold, etc.). Instead, it will begin to additionally reflect the yield of ETH staking (risk-free rate - expected stETH yield). {{\n\n\n\n}}\n10/ Explain the logic - how other traders will arb funding rate considering availability of stETH as collateral. Why would this suggest a negative bias ~= eth yield.\nFin/ The team behind Ethena is legit. To their credit, it seems they are continuing to diligence this concern. This is a pivotal mechanism for the crypto economy, and I look forward to the exploration that is to come. https://twitter.com/leptokurtic_/status/1682781205811589120?s=20\nTODO: Mention the black swan force exit short perps too (the BitMex event)? - Ethena redemption should have scaled down exposure in the hours and minutes prior to this event (funding will necessarily have been negative before the trigger) - Ethena is hedged across multiple CEXes (historically this happens on one exchange at a time) - Ethena insurance fund as final backstop"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins.html",
    "href": "library/life-sciences/health/nutrition/vitamins.html",
    "title": "Vitamins",
    "section": "",
    "text": "For standard amounts of A, K, E, Iron, Zinc, etc"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins.html#my-opinionated-stack",
    "href": "library/life-sciences/health/nutrition/vitamins.html#my-opinionated-stack",
    "title": "Vitamins",
    "section": "",
    "text": "For standard amounts of A, K, E, Iron, Zinc, etc"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins.html#vitamin-a",
    "href": "library/life-sciences/health/nutrition/vitamins.html#vitamin-a",
    "title": "Vitamins",
    "section": "Vitamin A",
    "text": "Vitamin A"
  },
  {
    "objectID": "library/life-sciences/biology/proteins/index.html",
    "href": "library/life-sciences/biology/proteins/index.html",
    "title": "bmac",
    "section": "",
    "text": "‘A Pandora’s box’: map of protein-structure families delights scientists"
  },
  {
    "objectID": "library/life-sciences/biology/proteins/index.html#proteins",
    "href": "library/life-sciences/biology/proteins/index.html#proteins",
    "title": "bmac",
    "section": "",
    "text": "‘A Pandora’s box’: map of protein-structure families delights scientists"
  },
  {
    "objectID": "library/natural-sciences/finance/series65/index.html",
    "href": "library/natural-sciences/finance/series65/index.html",
    "title": "Series 65",
    "section": "",
    "text": "Under the Uniform Securities Act, an investment adviser does not need to register in a state if the adviser has no place of business in the state and only has clients in the state that are certain entities such as broker-dealers, other investment advisers, federal covered advisers, banks, insurance companies, and employee benefit plans with assets no less than $1,000,000. Such an adviser may also have up to five clients not among these entities without registering.\nA broker-dealer who has no place of business in a state is allowed to have institutional clients in the state without having to register in that state. Institutional clients include other broker-dealers, banks, pension trusts, and other financial institutions.\nIn general, advisers managing an investment portfolio should be compensated as a percentage of assets under management over a specified time period. However, an adviser is allowed to charge certain “sophisticated” investors an advisory fee based on portfolio performance vs. an index. Among these investors are people or businesses with over $1,000,000 in assets under management, and registered investment companies, such as mutual funds.\nThe formula for the Capital Asset Pricing Model (CAPM) is given by the following: $ Return on Stock = Risk Free Rate + Beta of Stock x (Return on Market - Risk Free Rate) $\nSeveral arrangements can lead to an adviser being deemed to have custody of an account, including having signatory power over a client’s checking account, serving as a trustee of a client’s trust fund, and obtaining advisory fees by directly billing client custodians without effective oversight by the client or an independent party.\nThe Securities Exchange Act of 1934 allows the SEC to require corporations to file financial information on a regular basis. The SEC currently requires an annual report, known as a 10-K, to be filed within 60 to 90 days of the end of each company’s fiscal year. The SEC also requires quarterly reports, known as 10-Q’s, to be filed within 40 to 45 days of the end of each fiscal quarter (three-month period)."
  },
  {
    "objectID": "library/natural-sciences/finance/series65/index.html#notes",
    "href": "library/natural-sciences/finance/series65/index.html#notes",
    "title": "Series 65",
    "section": "",
    "text": "Under the Uniform Securities Act, an investment adviser does not need to register in a state if the adviser has no place of business in the state and only has clients in the state that are certain entities such as broker-dealers, other investment advisers, federal covered advisers, banks, insurance companies, and employee benefit plans with assets no less than $1,000,000. Such an adviser may also have up to five clients not among these entities without registering.\nA broker-dealer who has no place of business in a state is allowed to have institutional clients in the state without having to register in that state. Institutional clients include other broker-dealers, banks, pension trusts, and other financial institutions.\nIn general, advisers managing an investment portfolio should be compensated as a percentage of assets under management over a specified time period. However, an adviser is allowed to charge certain “sophisticated” investors an advisory fee based on portfolio performance vs. an index. Among these investors are people or businesses with over $1,000,000 in assets under management, and registered investment companies, such as mutual funds.\nThe formula for the Capital Asset Pricing Model (CAPM) is given by the following: $ Return on Stock = Risk Free Rate + Beta of Stock x (Return on Market - Risk Free Rate) $\nSeveral arrangements can lead to an adviser being deemed to have custody of an account, including having signatory power over a client’s checking account, serving as a trustee of a client’s trust fund, and obtaining advisory fees by directly billing client custodians without effective oversight by the client or an independent party.\nThe Securities Exchange Act of 1934 allows the SEC to require corporations to file financial information on a regular basis. The SEC currently requires an annual report, known as a 10-K, to be filed within 60 to 90 days of the end of each company’s fiscal year. The SEC also requires quarterly reports, known as 10-Q’s, to be filed within 40 to 45 days of the end of each fiscal quarter (three-month period)."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#dank-sharding",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#dank-sharding",
    "title": "Ethereum",
    "section": "(Dank) Sharding",
    "text": "(Dank) Sharding"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#applied-web3-cryptography-resources",
    "href": "library/natural-sciences/crypto/blockchain/index.html#applied-web3-cryptography-resources",
    "title": "Blockchains",
    "section": "Applied Web3 Cryptography Resources",
    "text": "Applied Web3 Cryptography Resources\n\nrareskills blog"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/index.html#early-papers",
    "href": "library/natural-sciences/crypto/blockchain/index.html#early-papers",
    "title": "Blockchains",
    "section": "Early Papers",
    "text": "Early Papers\n\n1983, David Chaum: Electronic Cash\n1985, David Chaum: Security without Identification\n1996, Dr. Douglas Jackson and Barry K. Downey: E-Gold\n1998, Wei Dai: b-money\n1998, Nick Szabo: Bit Gold"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperliquid/index.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperliquid/index.html",
    "title": "Hyperliquid",
    "section": "",
    "text": "The DEX runs on the Hyperliquid L1"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperliquid/index.html#current-widely-accepted-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "Current (widely accepted) Funding Rate Formula:",
    "text": "Current (widely accepted) Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P, r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperliquid/index.html#potentially-new-funding-rate-formula",
    "title": "Hyperliquid",
    "section": "(Potentially) New Funding Rate Formula:",
    "text": "(Potentially) New Funding Rate Formula:\n\\[F = P + \\text{clamp}(r - P - , r_c, r_c)\\] where - F = Funding Rate - P = Average Premium Index - r = interest rate - r_c = clamp rate (e.g. 0.03%, the max/min funding rate as decided by exchange)\nOne important distinction is that Hyperliquid uses a constant 6000 USD notional value when computing the impact bid and ask prices for the premium.\nInsurance Fund\n\nPortion of trading fees (once turned on) will go here.\nEntirely automated in L1 logic (not discretionary insurance spending)\nIn rare event no one liquidates position (my early question), fund will take over and slowly deleverage it.\n\n“Note that auto-deleveraging has never happened on Hyperliquid to date. However, it is an important final safeguard on the solvency of the platform. There is a strict invariant that under all operation, a user who has no open positions will not socialize any losses of the platform.” - Yea, unless the insurance fund gets rinsed lol.\nMarket Making\n\nIf you’re interested in market making, reach out via Telegram @HyperliquidX We should show interest\n\nVaults\nAnyone can make their account a “vault” which is essentially a copy-trade program. Creator earns additional 10% (makes sense) - I like this, introduces a good social element that was missing from GMX and CEX’s\nHistorical Data\n\nIs available as compressed csv files link"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#good-papers",
    "href": "library/natural-sciences/crypto/cryptography/index.html#good-papers",
    "title": "Cryptography",
    "section": "Good Papers",
    "text": "Good Papers\n\n1976 | New Directions in Cryptography\n1978 | A Method for Obtaining Digital Signatures and Public-Key Cryptosystems\n1978 | Secure Communication Over Insecure Channels\n1980 | Protocols for Public Key Cryptosystems\n1985 | the Knowledge Complexity of Interactive Proof Systems\n1988 | Non-interactive zero-knowledge and its applications\n1988 | Use of Elliptic Curves in Cryptography\n1989 | The Knowledge Complexity of Interactive Proof Systems\n1991 | Proofs that Yield Nothing But Their Validity or All Languages in NP Have Zero-Knowledge Proof Systems\n2000 | Frontiers in Zero Knowledge\n2000 | Computationally Sound Proofs\n2011 | From Extractable Collision Resistance to Succinct Non-Interactive Arguments of Knowledge, and Back Again\n2012 | Efficient Zero-Knowledge Argument for Correctness of a Shuffle\n2015 | Verifying Computations Without Reexecuting Them\n2018 | Scalable, transparent, and post-quantum secure computational integrity\n2019 | Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture\n2020 | Public-Coin Zero-Knowledge Arguments with (almost) Minimal Time and Space Overheads\n2023 | Proofs, Arguments, and Zero Knowledge\n\n\nCryptographic Primitives\n\nDigital Signatures\nAsymmetric (Public/Private Key) Cryptography\nPolynomial Commitment Schemes Multiproofs using Random Evaluation\nPederson Commitments Non-Interactive and Information-Theoretic Secure Verifiable Secret Sharing\n\nZCash and Monero use these to shield transaction amounts\n\n\n\n\nQuantum Cryptography\n\nPublic-Key Quantum Money from Collision-Resistant Hash Functions\n\n\n\nCryptanalysis\n\nShucking Attacks\nBreaking Elliptic Curve - How to compute a 256-bit elliptic curve private key with only 50 million Toffoli gates"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#proofs",
    "href": "library/natural-sciences/crypto/cryptography/index.html#proofs",
    "title": "Cryptography",
    "section": "Proofs",
    "text": "Proofs\nA cryptographic proof must be complete and sound.\nAlice wants to prove knowledge of something (she holds a secret key, for example) to Bob\n\nCompleteness: If Alice performs the protocol honestly, will Bob be satisfied at the end of it?\nSoundness: If Alice successfully convinces Bob, then she must know the secret key."
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#the-schnorr-identification-protocol",
    "href": "library/natural-sciences/crypto/cryptography/index.html#the-schnorr-identification-protocol",
    "title": "Cryptography",
    "section": "The Schnorr Identification Protocol",
    "text": "The Schnorr Identification Protocol\nThe Schnorr protocol, invented by Claus-Peter Schnorr in the 1980s, was concerned with identification.\nImagine that Alice has published her public key to the world, and later on wants to prove that she knows the secret key corresponding to that public key. This is the exact problem that we encounter in real-world protocols such as public-key SSH, so it turns out to be well-motivated.\nSchnorr began with the assumption that the public key would be of a very specific format.\nSpecifically, let \\(p\\) be some prime number, and let \\(g\\) be a generator of a cyclic group of prime-order \\(q\\). To generate a keypair, Alice would first pick a random integer \\(a\\) between 1 and \\(q\\), and then compute the keypair as:\n\\[PK_A = g^a \\: mod \\: p, \\; SK_A = a\\]\nLater on, she wants to prove knowledge of her secret key, she conducts the following interaction with Bob.\n\nAlice: Pick a random \\(k\\) in range \\(1, \\, ... \\, , \\, q\\) and send Bob \\(h = g^k \\: mod \\: p\\)\nBob: Pick a random \\(c\\) in range \\(1, \\, ... \\, , \\, q\\) and send Alice \\(c\\)\nAlice: Send Bob \\(s = ac + k \\: mod \\: q\\)\nBob: Check that \\(g^s = PK^c_A \\dot h \\: mode \\: p\\)\n\n\nIs this complete?\nYes, just by looking at the math and performing substitution.\n\\[\n\\begin{aligned}\ng^s & \\equiv P K_A^c \\cdot h & & \\bmod p \\\\\ng^{a c+k} & \\equiv\\left(g^a\\right)^c \\cdot g^k & & \\bmod p \\\\\ng^{a c+k} & \\equiv g^{a c+k} & & \\bmod p\n\\end{aligned}\n\\]\n\n\nIs it sound?\nWe demonstrate soundness with a special algorithm called a knowledge extractor. A knowledge extractor (or just ‘Extractor’ for short) is a special type of Verifier that interacts with a Prover, and — if the Prover succeeds in completing the proof — the Extractor should be able to extract the Prover’s original secret.\nTo prove soundness for a proof of knowledge, we must show that an Extractor exists for every possible Prover.\nThe extractor for the Schnorr protocol is very simple: After step 3 is complete, rewind the interaction back to step 2. This tricks Alice into performing step 3 with two different \\(c\\) values (\\(c1\\) and \\(c2\\)) using the same \\(k\\).\nThe extractor can then solve the following equation to recover Alice’s secret:\n\\[\n\\begin{array}{rr}\n\\left(s_1-s_2\\right) /(c 1-c 2) & \\bmod q \\\\\n=\\left(a c_1+k\\right)-\\left(a c_2+k\\right) /(c 1-c 2) & \\bmod q \\\\\n=a(c 1-c 2) /(c 1-c 2) & \\bmod q \\\\\n& =a\n\\end{array}\n\\]\n\n\nIs it zero-knowledge?\nWe can prove zero-knowledgeness by describing a Simulator that can interact with any possible Verifier and produce a ‘simulated’ transcript of the proof, even if the Simulator doesn’t know the secret it’s proving it knows.\nThe Schnorr protocol does not have such a Simulator. to make the proof work, we need to make an assumption:\nthe Verifier needs to be “honest”, meaning it will pick its challenge “c” using only its random number generator, and will not choose this value based on any input we provide it.\nThe Simulator does the following:\n\nOutput some initial \\(g^{k_1}\\) as the Prover’s first message, and find out what the Verifier chooses.\nRewind the Verifier, and pick a random integer \\(z\\) in the range \\(1, \\, ... \\, , \\, q - 1\\)\nCompute \\(g^{k_2} = g^z \\times g^{a(-c)}\\) and output \\(g^{k_2}\\) as the Prover’s new initial message.\nWhen the verifier challenges on \\(c\\) again, output \\(z\\).\n\nThis proves the protocol must be zero-knowledge against an honest Verifier.\n\n\nMaking it non-interactive\nWhat if Bob is not online?\nTurns out you can use a sufficient hash function to generate the challenge.\n\nProver picks \\(g^k\\) just as in the interactive protocol.\nProver computes the challenge as \\(c = H(g^k \\, || \\, M)\\) where \\(H()\\) is a hash function, and \\(M\\) is an optional and arbitrary message string.\nCompute \\(s = ac + k \\: mod \\: q\\) just as in the interactive protocol.\n\nThis non-interactive proof is not just a proof of knowledge, but it’s also a signature scheme. That is, if you put a message into the (optional) value \\(M\\), you obtain a signature on \\(M\\), which can only be produced by someone who knows the secret key \\(a\\). The resulting protocol is called the Schnorr signature scheme, and it’s the basis of real-world protocols like EdDSA.\n\n\nKZG Commitments\n\n(Original Paper) Constant-Size Commitments to Polynomials and Their Applications\nDankrad Feist, KZG Polynomial Commitments\n\n\n\nBLS\nBoneh-Lynn-Shacham Signature Scheme\n\nBLS Introduction\nBLS Signature Scheme\nPragmatic signature aggregation with BLS\nBLS Signature for Busy People"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/eigenlayer/index.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/eigenlayer/index.html",
    "title": "EigenLayer",
    "section": "",
    "text": "blog / lightpaper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/eigenlayer/index.html#eigenda",
    "href": "library/natural-sciences/crypto/blockchain/projects/eigenlayer/index.html#eigenda",
    "title": "EigenLayer",
    "section": "",
    "text": "blog / lightpaper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html",
    "title": "Hyperbolic",
    "section": "",
    "text": "This is a protocol by Ted Yin, previously @ avax.\nHere is a link to the whitepaper converted to markdown"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#vision-mission",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#vision-mission",
    "title": "Hyperbolic",
    "section": "1: Vision & Mission",
    "text": "1: Vision & Mission\nThe Internet has made the world more connected than ever. With years of efforts, companies have developed software stacks for cloud services that power the user-end products. Ironically, together with the backing hardware resources, they are mostly limited to the corporation boundaries, forming dispersed islands that effectively isolate the Internet. This business structure, while being profitable for decades, gradually shows the signs of problems, with the increasing demand for more data control and privacy by the users, more flexible and reusable services by the developers, and more opportunities of providing hardware resources for computation by the investors.\nThe so-called “Web 3” [6] initiative, driven by blockchains and exemplified by Ethereum, aims to host the computation of all services on a decentralized platform, backed by a chain (ledger), replicated by all validators. Nevertheless, encoding each single step of the computation as a transaction and interpreting all transactions on the chain is fundamentally impractical to realize existing services from the traditional cloud computing, as they vary in terms of performance demand, trust model and fault tolerance. As a result, various “Layer-2” solutions, bridges, and oracles have been proposed and built to move things off-chain again. However, the absence of a more foundational, expressive, and fault-tolerant computational paradigm has once again turned these solutions into pre-blockchain isolated islands.\nWe introduce Hyperbolic, a high-performance microservices platform driven by a new chain-less abstraction for decentralized computing, fabricated together with an Internet-scale mesh network. It unifies diverse services and applications, fostering a connected, interoperable, and composable digital computing world.\nHyperbolic’s relay network enables permissionless participation and self-healing resilience. Nodes in the network forward data to others in a peer-to-peer manner while receiving rewards as incentives for their work. Utilizing a smart routing protocol, the network autonomously recovers from failures, ensuring uninterrupted end-to-end connectivity during disruptions. This design cultivates a healthy ecosystem that promotes active participation and serves as a resilient and efficient alternative to traditional corporate-wide networks.\nOn top of the network fabric, Hyperbolic facilitates the development and deployment of a wide spectrum of composable Decentralized Services (D-Services) that follow a new Invoke-Return-Combine (IRC) paradigm. These D-Services are hosted by a dynamic subset of nodes, making trade-offs between performance and fault tolerance according to the nature of the individual service. D-Services follow a classic client-server model with server-side fault tolerance. Each client talks to multiple gateway servers to access the service with redundancy, but also conducts client-side computation to locally work out the output given multiple servers’ responses. This unique two-level design of D-Services and relay network reduces unnecessary resource consumption (e.g. bandwidth, CPU, storage), to horizontally scale much better than a purely P2P solution. To help developers build their D-Services, Hyperbolic will offer useful, basic D-Services as node modules, such as Content Delivery Network (D-CDN), video streaming (D-Streaming), Publish-Subscribe patterns (D-PubSub), and blockchain ledger (D-Ledger) out of the box. Developers who are building different products can utilize these microservices, offered by Hyperbolic nodes, to compose larger services for their applications, which again follow the same IRC pattern. As a result, they can contribute/lease their useful D-Services to others, fostering an ecosystem of reusable modules.\nHyperbolic’s versatile platform advocates numerous applications across multiple domains, such as social networks, document collaboration apps, AI training/inference infrastructures, AI data collection and cleaning tools, Multi-Party Computation, and even blockchains. Its flexibility makes it an ideal choice for both small startups and well-established organizations, promoting innovation and collaboration in a loosely organized, inclusive manner with customizability. We also develop Hyllo, our first-party messaging app that functions as a noncustodial, open-standard messaging app bound to cryptographic identities. More importantly, Hyllo serves as a portal to Hyperbolic, allowing end users to directly interact with applications based on D-Services seamlessly. It is the browser of our Hyperbolic web services."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#hyperbolic-the-microservices-platform",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#hyperbolic-the-microservices-platform",
    "title": "Hyperbolic",
    "section": "2 Hyperbolic: the microservices platform",
    "text": "2 Hyperbolic: the microservices platform\nAfter years of research and development experience in areas including Cloud-computing, AI, Fintech, and Blockchains, we have come to realize a fact that many may have overlooked: the current philosophy of distributed computing infrastructure has reached its limits in terms of flexibility, versatility, security, and privacy (left of Figure 1). On the other hand, the alleged Cloud-computing (“Web z”) killer, blockchains, while solving the trust issue of decentralization, have taken a more rudimentary infrastructure design than Cloud-computing (middle of Figure 1). Since Ethereum, projects and developers have been painstakingly trying to directly squeeze the computational logic onto the chain as much as possible. Ironically, the chain, being overloaded with application traces as transactions, struggle to even enable traditional applications from the less celebrated Web z world with promised additional security guarantees, leaving the main usable applications mostly DeFi/NFT to the general public. Admit it or not, the relatively small market is far from fulfilling the futuristic picture of “Web 3”.\nMost of us, do acknowledge the deficiency of having a single blockchain and may advocate to move things “off chain” again or resort to Layer-2 solutions, further complicated by bridges and oracles needed to let the chains talk to each other, and to the real world. However, by taking a step back and rethink, the crux of the problem is never about debating over on-chain vs. off-chain solutions, but having a well-established, disciplined paradigm that organizes many decentralized computation activities that do not need to frequently consult the ledger. As an analogy, Ethereum contributed a lot to the blockchain world because it has successfully established a paradigm, or a computational model, that led developers to think in the way of “smart contracts”, their states, methods and interactions. Currently, the Web 3 world has adopted blockchain as the de-facto model for decentralized computation, but today we would like to question whether that is the only way. We propose a new model, Hyperbolic, that is more fundamental, inclusive, and opens up a lot of new possibilities. In this new view, however, blockchain consensus, like Paxos [10]/Raft [14] as to Web z, becomes a useful service with strong consistency and ordering guarantee, which could fit straight into our ecosystem. Thus, Hyperbolic is not an L2 or ad-hoc/centralized off-chain trick, but a brand new journey of fulfilling the original dream of Web 3. Blockchains are still handy, but only as participating services of our ecosystem. Unlike those “Layer o” initiatives, Hyperbolic is not chain-centric, and is not powered by a chain."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#hyperbolic-the-microservices-platform-1",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#hyperbolic-the-microservices-platform-1",
    "title": "Hyperbolic",
    "section": "2 Hyperbolic: the microservices platform",
    "text": "2 Hyperbolic: the microservices platform\n\nBolic: Self-Healing Network Fabric\nDistributed computing, decentralized or not, always happens by exchanging data in-between the participating entities (nodes). For a decentralized system, we need to have a simple, robust, and efficient infrastructure for network communication. In Hyperbolic, we first build Bolic, an Internet-scale subsystem that delivers arbitrary binary data from one crypto entity to another with minimal overhead. Unlike many other network/P2P libraries, Bolic is designed with modularity from the ground up and comes with careful thoughts in abstractions. As experienced distributed systems builders, we apply our best practice to the low-level library to make sure the code is lightweight but future-proof. We also realize that the important abstraction in an easy-to-use, Internet-scale network infrastructure includes the disaggregation of the following three aspects:\n\nThe notion of data transmission from one end to another, it should be as simple as Apple’s “Airdrop”: you tag (and encrypt) the message with the recipient (crypto-id) and then “drop” it to Bolic, and the rest of the process is hidden from the user.\nThe actual transport to transmit data in a logical hop, which could be backed by TCP/UDP/WebSocket/WebRTC/SMS/Emails, etc. Or even by the action of scanning a QR code. The transport does not know the data because it is end-to-end encrypted.\nThe routing mechanism to balance the resource cost, reliability, and performance to get the data delivered to the recipient end, offering different tradeoffs and plans.\n\nIn short, our Bolic subsystem resembles building another “Internet” (the “Web” of Web 3), on top of the existing, prevailing data transmission methods, such as the current Internet, but there could also be other data carriers (or virtualized carriers such as Tor-style privacy channels). We hope to retain code minimalism to establish a data transmission and routing network with high capacity and low latency to set the ground for our Hyperbolic decentralized services.\n\n\nBest of Both Worlds: P2P vs. Client-Server\nIt is a prevailing thought that a decentralized system should be based on peer-to-peer (P2P) communication for all stages of services, in contrast to the traditional client-server model where clients (e.g., mobile/web apps) send requests and pull data from the hosting servers. No doubt, client-server is more seen in centralized systems where servers have unequally more control and authoritative interpretation of users’ data and computation, however, this model still has advantages over a pure P2P network because the server canasymmetrically and simultaneously serve multiple (hundred-thousands of) clients at a much lower cost in bandwidth and power.\nImagine the implementation of a “super” group chat, where a chat room accommodates a lot of (say, 100K) users. In this extreme case, with P2P approach, each message will need to be gossiped throughout the network to reach all recipients, resulting in high duplication of load to the system (which is the common problem in the existing design of “decentralized” messaging platforms), whereas if they all talk to the same server, the server only needs to send a message once to every other user, without blindly engaging more nodes in the network. Of course, the latter case has a single point of failure as the server could deliberately omit the message for some or all of the recipients, or it could simply refuse to render the service.\nP2P and client-server approaches are like two extremes where one offers more redundancy and open-membership (“decentralization”) at the expense of preventing a scalable, complex service, while the other one offers more efficient and accurate resource utilization but susceptible to failures and limits participation. This inspired us towards the Hyperbolic service model that chooses a middle ground to get benefits from both.\nBack at the group chat example, in a network of 100K users, if we choose to run 100 chat servers who also join the P2P network, then we let each of 100K users, instead of directly sending to the network or to a single server, talking to 60 of these servers at a time, then we will only have 100 peers in the P2P network relaying messages to each other. In the meanwhile, we still retain very reasonable resilience to failure as each client talks to 60 servers at a time. Moreover, since any two clients will be guaranteed to have (60-100=20) servers in common so these servers can directly pass on messages between them without even going through the P2P network. This simple idea also resembles the concept of quorum intersections in consensus protocols that power Proof-of-Stake blockchains, but sending end-to-end encrypted messages in a virtual chat group is a much easier problem than consensus. As a comparison, a typical decentralized solution would have blindly gone for an on-chain solution which works but creates unnecessary overhead.\nFrom this example, we demonstrated how to shrink down the cost of gossiping among 100K nodes down by 1000 times to 100 nodes while still maintaining very decent fault tolerance for an open-hosting environment where service providers can be malicious or faulty. On the other hand, this allows the platform to have computation and network capability close to traditional cloud computing, but more loosely organized and open. We envision that a good paradigm (model) should be this simple but generally applicable. Fortunately, this idea of balancing performance and fault tolerance can generalize to other services, like Pub-Sub where multiple clients subscribe to some topics and get notified.\nFigure 1: Traditional cloud-computing limits the reusability of both hardware resources and software stack (private services) at the company boundary and has a single point of trust. Existing blockchains alone are not enough to realize the “Web 3” dream because the chain has limited capability of encoding general computation, and lacks a disciplined way for “off-chain” operations with guarantees. Hyperbolic envisions the future of computing could be done by some carefully designed primitive that is chain-less, while incorporating chains as part of the ecosystems. We are shifting from chain-centric to service-centric.\n\n\nD-Services\nMore formally, in our Hyperbolic network, we have all connected participants called nodes. Most of the nodes will have their relay ability enabled, running Bolic that forwards encrypted data in the network (Section 4 describes fee model and algorithm for routing to ensure they do the work). In addition to the role of a relay, a node can opt in one or multiple D-Services by running the server part of the logic for the D-Service, as shown by circles filled with different solid background colors in Figure 2. For a D-Service named “S”, let us denote these nodes by (N_{s}) Whereas each client (i) (could also be a node in Hyperbolic, or just some third-party application) connects to a service-prescribed subset of servers (Q_{si}N_{s}). D-Service paradigm defines a client-server style of microservice with additional fault tolerance customizable by the designer of the service. The service is rendered via RPC-style invocations of methods offered by the service, whose responses get aggregated and deduplicated locally at each client. The entire Invoke-Return-Combine round trip is as follow:\ninvoke Each client (iN_{c}), to initiate an RPC call for the service, it signs and directly sends a message (S.(i,,,)) to all nodes in (Q_{si}). Where () is per-invocation identifier to distinguish the calls and gets incremented each time, which helps the server to bookkeep the service state for the client. In the figure, for example, a client with the “blue” D-Service client part (a triangle) will send the same signed invocation to all nodes (represented in hexagons) that have the corresponding server part (small circles), by following the direct connections in blue lines.\nreturn Each server (u), upon receiving the RPC call message, it validates the message and returns its response by signing and sending\n[S.(i,,,!! ,u,_{u})]\nback to (i), following the blue lines backwards in the figure.\ncombine Each client (i), upon the receiving at least a threshold (constant (T_{si}|Q_{si}|) predefined by the service for each client) of responses from servers:\n[R_{i}={{u}:S.(i,, ,] [!!,u,] [{u}),uQ_{si}}]\n, where (|R_{i}|T_{si}), it computes the final output locally by a service-prescribed client part of D-Service logic: ({i}=S.(R{i})). The D-Service designer needs to make sure as long as the number of collected responses (|R_{i}|) is not less than the threshold (T_{si}), the combined output is a deterministic value that is consistent regardless of the number of responses (|R_{i}|).\nThe aforementioned group chat example can use (T_{si}=51,iN_{c}) threshold for all clients, and run (|N_{s}|=100) servers. The predefined subset for each client is any set (Q_{si}) such that (|Q_{si}|=60). This guarantees if at least (51-100=2) out of 20 servers to which any two clients connect render the service, the message could be passed over directly. Even if there is no non-faulty server in common between any two clients, the clients can still rely on each one of the 60 servers to transmit the message through the Bolic P2P network.\nSimple yet expressive, D-Service paradigm offers the flexibility to engage “quorum-style” fault tolerance as in Proof-of-Stake consensus protocols, and also naturally fits the idea of “aggregation-style” of cryptography like threshold signatures. But like our group chat example, one does not always have to use additional cryptography to implement such result aggregation. For chat and Pub-Sub, the message itself could be verified to see if that’s from the desirable sender. With the same framework, one can describe the run of a quorum-based consensus, or even a centralized service. Here are some examples of D-Service.\nblockchain consensus, version A For blockchains, validators are running the server part of the Consensus D-Service, whereas clients could be user agents (wallet apps or developers). The (3f+1) validators talk to each other through the Bolic P2P network whereas the vast majority of clients can use (|Q_{si}|=f+1) validators (servers). (|N_{s}|) could be at the level of thousands of nodes whereas (|N_{c}|) could be millions and hundreds of millions. This is not just to fit the existing blockchain into our D-Service ecosystem, but actually adds more disciplined security guarantees for users: nowadays, users usually connect to some trusted source (chain API providers like Infura or user-oriented block explorers) to submit transitions and retrieve account balance/state. Ironically, although blockchain guarantees the safety for all participating validators as they work out their own local, replicated state based on consensus, this is never the case for end users. Of course, one user can manually check whether a transaction has gone through by browsing multiple explorers and some exchanges do so for deposit, it is not part of the existing blockchain infrastructure, making the users actually trust the centralized service provider, causing frauds or front-running issues. Our D-Service addresses this issue systematically.\nblockchain consensus, version B An alternative way to host a blockchain as a D-Service is to run validators both as severs and clients in our D-Service model. In this case, no traffic is poured into the P2P network and the D-Service implementor manages thevotes in the protocol in the form of D-Service messages exchanged among the validators. Then (N_{i}=N_{c}), and (|Q_{si}|=|N_{s}|=3f+1), whereas (T_{si}=2f+1). The (S).Combine(()) function is defined to verify the votes and aggregate them into a quorum certificate (used in many state-of-the-art blockchain consensus mechanisms [25, 19, 20, 11]). This solution can easily turn existing blockchains into D-Services and join Hyperbolic ecosystem, without having the network traffic of the blockchain heavily load our Bolic network.\nVrf beaconVerifiable-Random-Function beacons can be smoothly described as a D-Service as well, imagine we have a typical setup of (N_{s}=3f+1) nodes, then threshold (T_{si}) will just be the threshold value for VRF (say, (2f+1)), whereas (S).Combine(()) function will be the VRF math combination of the given output shares from beacon nodes.\nContent delivery network (aka. decentralized storage)In Hyperbolic, we need some decentralized storage solution that helps preserve any blobs of data used by other D-Services or users. We name our official implementation of such service (D)-CDN, as it could be viewed as a more generalized and decentralized version of the traditional Content Delivery Network (CDN). Such D-Service will store end-to-end encrypted chunks of user data and offer data availability in presence of D-Service server failure. The combine function for the client end is easy to implement as one just needs to verify the hash of the stored data and take any copy that checks out. A robust, efficient D-CDN not only benefits existing decentralized applications, but also makes it possible to render services like Netflix, Youtube, in a crowd-sourced manner.\nLive streaming and gamingOur D-Service design enables the decentralization of those computation tasks requiring more real-time responses, which would have been impossible for a chain-centric platform. For a Twitch-like streaming service, there are usually much more audiences than the hosts, whose performance footprint is exactly captured by our D-Service design: (N_{c}) could be much greater than (N_{s}). In this case, streaming packets can have fault tolerance and a client-end application only need one authentic copy of the packet from the video host. Together with our Hyperbolic tokenomics, we believe it not only makes live streaming more secure without sacrificing resources, but also possibly faster, as hosts (or relay nodes) are incentiized to help move forward data across Bolic P2P network. In a way, Bolic by itself is like a “VPN accelerator”.\naround cycles for new hardware and software as they are controlled by a single entity (e.g. Amazon AWS, Google Cloud, Microsoft Azure, etc.). On the other hand, many players in the market would like to invest in hardware assets and lease the computational capability to companies, developers, and users. There has been abundant research in exploring distributed training of relatively large models. We believe for those latency-insensitive cases, it is feasible and beneficial to train models in a distributed manner, opening up more opportunities for business and research. To tailor the pre-trained model to certain applications, fine-tuning a model on domain-specific data will make the model a specialist in certain tasks (e.g., customized LLM for answering legal questions). Effective fine-tuning depends on high-quality data to yield good results, hence it demands domain expertise, especially for data labeling and cleaning. Once the model is well-trained and fine-tuned, applications with large models like ChatGPT also need inference and service hosting. These tasks (data curation, model training, fine-tuning, and inference) do have different hardware and software requirements, and our vision is to also encapsulate them into D-Services and improve the interoperability of different stages in an AI training-to-product pipeline.\n\n\nInvoke-Return-Combine Composability\nWith D-Service’s Invoke-Return-Combine (IRC) primitive, one can build more complex service solutions by repeatedly applying it for each major step required in the pipeline of computation logic. The internal logic of a D-Service’s server part may also contain the client part of another D-Service, and thus may invoke one or more times of the other service. As an interesting coincidence, we find this primitive resembling map-reduce primitive [4] in Machine-Learning systems where each component/operator implements the same interface and data can flow through the entire system by making each step. However, although systems like Spark [26] has notions like Resilient-Data-Set (RDD), RDD is in the realm of a beneign and domain-specific setup where the “resilience” is about\nFigure 4: Different clients may choose to use different D-Services as part of their computation flows.\nFigure 3: Clients utilize multiple D-Services one after another for the application. The output from one IRC primitive could be used as the input for the next IRC.\nrecovering data loss, as the intermediate results in ML/AI computation can always be numerically recomputed at the expense of some extra time, whereas the authenticity or correctness is less of a concern. Our resilience, however, is Byzantine fault tolerance, and not ad-hoc to ML tasks. Unlike map-reduce, IRC process uses multiple parallel servers for their independent outputs of the same task, and then “reduces” the outputs at each client for some customizable resilience to servers’ misbehavior. The IRC primitive also resembles Ethereum’s smart contracts in that different IRC implementations have interoperability, but it does not need on-chain transactions, degrades into a centralized service easily, giving much more freedom and possibilities to the infrastructure developers. On the contrary, a chain server could be wrapped into a D-Service to participate in this playground.\nStaged compositionFor client app developers, the computation may invoke the invocations of multiple different D-Services. Depicted in Figure 3, each client can first participate in (S_{1}), followed by (S_{2},S_{3}), forming a staged flow of decentralized computation. The composed flow of computation offers the flexiblity that has never existed before: different stages possibly hosted by different parties, together with the difference in the nature of the task, can choose different levels of redundancy that balances the resilience and performance. Thus, the IRC primitive allows “heterogenous” fault tolerance, which is not provided by chain-centric platforms.\nMixing compositionOn the other hand, clients’ staged flows could differ. Like shown in Figure 4, another composability is to let D-Service like (S_{1}) usable in different flows. For clients 1-3, they go through (S_{1}) and (S_{2}), whereas clients 4-6 diverges to (S_{3}). As an example, our aforementioned D-DCN service could be such (S_{1}) that is used in all kinds of other D-Services.\nrecursive compositionSo far, only clients can compose one or more D-Services for their application-level purposes. The servers in a D-Service can also serve as the “client” role for some other D-Services, enabling recursive engagement of D-Services. Figure 5 demonstrates such an idea, and it is possible to apply the other two composition strategies along with this one.\n\n\nThe Renaissance of End-to-End Argument\nOur D-Service design retains the scalability of traditional cloud-computing. Unlike blockchain platforms, one can use client-server model for computation, where clients largely outnumber the servers and easily scale horizontally. The composable D-Services make the server side also horizontally scalable. IRC-style is different, however, from a normal centralized setup in that it offloads more computational logic to the clients (“Combine” primitive and how clients interact with multiple different D-Services). Thus, compared to cloud-computing, Hyperbolic advocates a “client-centric” philosophy in that the D-Services only solve some crucial data synchronization and computation without knowing too much about the rest of the client’s demand to finish up its own computation. For example, a group chat D-Service server may never know the actual contents of the messages sent to the group, thanks to end-to-end encryption.\nThis self-serviced, end-to-end pattern was deemed as the major merits of Web 3. Interestingly, in systems research literature, this is not new. An end-to-end argument [18] was made back in the 8os, suggesting something that is still very true for building an in\nFigure 5. Like Ethereum’s smart contracts, D-Services can (recursively) invoke others, thus the developers can try to build up more complex D-Services by “gluing” together basic ones.\nfrastructure: the middleware/servers usually cannot precisely see or predict the application-level needs, but engineers can be tempted to put in more functionalities into the system for the “potential use”. As a result, the system becomes bloated with functionalities that are not quite useful by the “ends” (applications). Thus, each layer in the entire software stack has to repeatedly implement something similar, with better knowledge of the application as it gets closer to the end. In contrast, an end-to-end argument says the services should be kept simple and not make too many assumptions for the additional features, leaving the flexibility to the ends.\nAs a further step in our Hyperbolic initiative, we would like to explore the feasibility of distributed computing by a client-centric paradigm. In the past decades, researchers have come up with a successful State Machine Replication (SMR) model that offers consistent view of computation with fault tolerance, serving as the backbone for both cloud-computing and blockchains. However, this model is platform-centric. While it has the benefits of keeping users’ states in one coherent “state machine” that is replicated and interpreted by multiple servers, it creates bottlenecks in performance and scalability. In the meanwhile, we realize that many useful applications may not need server-maintained states. Some off-chain services such as Ethereum state channels, allow users to directly negotiate and/or securely sign a transaction before it is finalized on chain. The recent trend in Ethereum “rollups” is another example.\nWe envision a Message-carried State Machine (MSM), that keeps track of the computation state in a more “stateless” fashion. In this paradigm, clients keep track of their own local state, whereas they update their state by exchanging state-transitioning messages. As a basic example, multi-signature signing can be done in this way because there is no need to have a database (e.g., smart contracts) to keep track of the intermediate signing state. One just needs to exchange the signature shares between the signers and aggregate their own local state with the help of cryptography. Moreover, the local state may also be carried in the state transition message so that the recipients work out their local states by “chaining” the verified transitions, as shown in Figure 6. MSM model is more general as a blockchain could be viewed as an MSM where clients are the validators, and the consensus mechanism is used to resolve the possible state bifurcation shown in the figure. However, MSM offers more flexibility as some computation, such as signature aggregation used in VRF, does not have state bifurcation as any (2f+1) shares will always generate the same output."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#hyllo-the-browser-for-next-gen-internet-services",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#hyllo-the-browser-for-next-gen-internet-services",
    "title": "Hyperbolic",
    "section": "3 Hyllo: the browser for next-gen internet services",
    "text": "3 Hyllo: the browser for next-gen internet services\n\nMore than a Natural Way of Interaction\nAs the first application, we would like to launch something that could both be friendly to end users and serve as the portal to our Hyperbolic platform, connecting the D-Service/application developers directly to the users via a unified entry point. We believe the best way is via a text-messaging app. But unlike any existing messaging apps in the market, Hyllo is built with a different philosophy. First, it utilizes Bolic P2P network to directly send encrypted messages in a decentralized manner. For group chats, it makes use of the aforementioned Pub-Sub D-Services to enable scalable group size. Live-streaming D-Services also equip Hyllo with additional social capabilities, potentially fulfilling what “Social-Fi” dreamed of but never managed to achieve. Because Hyllo app is also a node in the network, the user can even opt in the Bolic network to help relay traffic, or join as a lightweight D-Service server, to earn a reward for the useful computation it renders. This opens up\nFigure 6: Client-centric, Message-carried State Machines can be locally maintained by putting together the state transition messages.\nendless opportunities for crowd-sourced computation and socialization with security and resilience.\n\n\nIn the Era of New AI\nThe recent development in Large Language Model (LLM) such as ChatGPT [15], Llama a [23], has started a revolution of how humans interact with computers, i.e., the automation tools. Although there has been a heated debate regarding whether the model could be viewed as Artificial General Intelligence (AGI), we believe at the minimum, the successful new models can serve as a “programming language” that takes the form of natural languages. This is revolutionary because most of the non-programmer crowd have limited knowledge or capability in harnessing the computational power of machines for their own tasks and business. On the other hand, builders and hackers also would like to be liberated from the burden of writing boilerplate code, but instead, spend more time and energy in creating and testing new algorithms and products. Thus, LLMs offer a very promising boost in productivity for all. We will soon see “chat bots” that also serve as our personal assistants in that we “program” the logic for task handling, business activities, etc. to the bots by speaking to them directly, whereas they work on the repeated tasks at an unseen efficiency based on our strategy. In Hyllo, we plan to offer a native, secure way for such Human-AI interaction, and explore the future of AI-AI interaction: imagine both sides of a business negotiation could first use bots to lay out some common ground of understanding to save time. The existing apps such as Telegram and Discord do offer an integration with the new AI, but still through a rudimentary approach. We hope to offer a more native experience in Hyllo for prompt-engineering and the human interaction with the AI-generated content."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#incentivization-algorithms",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#incentivization-algorithms",
    "title": "Hyperbolic",
    "section": "4 Incentivization algorithms",
    "text": "4 Incentivization algorithms\nIn order to encourage active participation of Bolic network and advocate availability of D-Services, we design a Proof-of-Relay scheme for Bolic network, and a Proof-of-Storage scheme (see Appendix A) for the D-CDN service. As developers can design and implement new D-Services, similar to smart contracts in Ethereum’s ecosystem, the proof schemes for different D-Services may vary. We hope our D-CDN proof scheme will serve as an example for other developers to design the scheme suitable for their own D-Services.\nIn Proof-of-Relay, due to the high volume of messages within the Bolic network, requiring nodes to generate a proof for each message and then redeem for reward is impractical. To minimize the performance overhead, we randomly select nodes as a verifiable starting point to conduct a “verifiable random walk” for connectivity in each epoch. By running the challenge epochs indefinitely, it provides network-wide coverage, thereby incentivizes the network to stay healthy without stuttering the transmission. We describe the algorithm in details in the remainder of this section.\n\nSetup and Requirements\nThe Proof-of-Relay scheme is built upon several existing systems and protocols:\n\nblockchain[13, 2, 17]: a customized ledger that tracks epoch-related events and keeps a record of rewards.\nVerifiable Random Function (VRF)[12]: a protocol allowing multiple parties to collaboratively generate a verifiable random output, whose value is determined by the majority of the participants.\nrandomness beacon[1]: a service that regularly produces pseudo-random seeds for the VRF. A simple implementation could be using block hashes.\nElliptic-Curve Diffie-Hellman (ECDH): a key exchange protocol that allows two parties, each having an elliptic-curve public-private key pair, to establish a shared secret over an insecure channel. It is a variant of the Diffie-Hellman protocol using elliptic-curve cryptography.\n\nWe would like a design with the following constraints to make it practical:\nno responseThere should be no response messages to challenge messages. This simplifies our overall design and offers more robustness in an Internet-scale deployment.\nno real-world clockWe shall not rely on the concept of real-world time or a timestamp system to coordinate steps within each epoch. It helps prevent potential synchronization issues and precludes unnecessary wait time.\nagnostic to network topologyThe design should not assume there is a pre-defined or static network topology. Namely, the underlying relay path should not matter to the proof scheme. This gives flexibility to the routing algorithm employed by Bolic.\n\n\nDefinitions\nepochA predefined time cycle for the random walk of challenge messages and reward distribution. It can be a range of block heights from the blockchain.\nbernoulli distributionThe discrete probability distribution of a random variable which takes the value 1 with probability (p) and the value 0 with probability (q=1-p). (p) is predetermined in the Proof-of-Relay scheme.\nReputation scoreA numerical score that represents the reliability and performance of a node within the network. Nodes are initialized with some default score, and then their scores are adjusted over time based on their behaivor during the epoches.\n\n\nProof-of-Relay Scheme\nAs shown in Figure 7, the procedure for our Proof-of-Relay scheme contains the following steps:\n\nPrior to each epoch, the randomness beacon emits a random value (x). Consider an arbitrary Node (C_{0}). This node then calculates the Verifiable Random Function (VRF) output (y_{A}) and its corresponding proof ({A}). These values are derived from input (x) and (C{0})’s private key (sk_{A}), that is, (y_{A},{A}(x,sk{A})). Node (C_{0}) then seeds a sampler with its own (y_{A}) (optionally salted with some public information such as the crypto address of the node, as it adds more unpredictability). This sampler, with a Bernoulli distribution, generates a pseudo-random value to determine if (C_{0}) should act as a challenger in this epoch. If selected, a challenge message (m_{A}) of random size and the node (C_{1}) to be challenged are chosen by the same sampler with uniform distribution, in the range of size limit of the message and the range of all participating nodes other than (C_{0}).\nNode (C_{0}) encrypts (m_{A}) using an ECDH scheme involving its own private key and node (C_{1})’s public key. The encrypted message is then transmitted to (C_{1}) through the relay network. This may involve zero to many intermediate relay nodes in the network who do not know (m_{A}) is a challenge message.\nUpon receiving the encrypted challenge message, node (C_{1}) decrypts it. Recognizing it as a challenge, (C_{1}) commits the message along with a proof to the blockchain.\nNode (C_{1}) then computes its own VRF output (y_{B}) and associated proof ({B}) which is derived from the challenge message and its private key (sk{B}). Using (y_{B}), it generates a new challenge message (m_{B}) and identifies the next node (C_{2}) to challenge. Node (C_{1}) repeats the process in step 2, sending the new challenge message (m_{B}) to (C_{2}).\nNode (C_{2}), upon receipt of the encrypted challenge message from (C_{1}), repeats steps 3 and 4. The random walk continues until either a node realizes the epoch has ended (no reward to continue) or a Time-To-Live (TTL) hard limit is reached.\nAfter the epoch ends, a verifiable path of challenges (C_{0},C_{1},C_{2},) is established. The nodes on this path and their peers are awarded points for their reputation score as described in Section 4.4. Additionally, after each epoch, each node’s reputation score is decreased by a constant. Thus, if a node fails to participate in the random walk, its reputation will decay over time. Only nodes with the reputation above a certain threshold are eligible for receiving relay rewards.\n\n\n\nReputation Scoring\nAfter the epoch ends, there are paths of challenges which originate from nodes who are selected as starting points based on the Bernoulli distribution. Consider one path of challenges ({C_{0},C_{1},,C_{k}}), and we denote its length as (k) (some nodes may appear more than once). The (i)-th node (C_{i}) in this path, along with its peers, will collectively receive a total of (R(i,k)={j=0}{k-i}1/2{j}) reputation points, i.e., (C{i}), will receive reputation points calculated based on the remaining length of the path after that node. Nodes at the start of long paths are rewarded more than later nodes, but the reward for any node is still bounded because of the exponentially diminishing tail rewards.\nLet’s assume (C) is a node in the path of challenges and (C) has (m) peers. To incentivize nodes to maintain a well-connected network, we incorporate a node’s degree (number of directly connected peers) into the reward distribution. Let (N) be the desired minimum degree for which nodes should aim. The reputation reward (R) is divided between node (C) and its peers using the following formulas:\n[(C) =R] [=\n\\[\\begin{cases}\\frac{R}{2},&m\\leq N\\\\ R\\times\\frac{N}{N},&m&gt;N\\end{cases}\\]\n] [() =] [=\n\\[\\begin{cases}\\frac{R}{2m},&m\\leq N\\\\ \\frac{R}{N+m},&m&gt;N\\end{cases}\\]\n]\nIn order to preserve fairness and integrity during challenges, security measures are established to deter any node from prematurely broadcasting the challenge message to its peers or other colluding nodes. If a node makes an early claim regarding the identity of a challenge message before the epoch ends, both the node and its collider will have their rewards revoked. As an incentive for honesty in the challenge, the node that reports such a violation will be awarded some rewards. To avoid an overload of such claims, each node is permitted to submit only a limited number of claims per epoch.\nOverall, our scheme has the following desirable properties:\nindistinguishable probing To prevent the intermediate nodes from only relaying the challenge messages, challenge messages deliberately vary in their size, and are encrypted to be indistinguishable from normal messages. This forces every node to treat and relay every messages seriously for their best interest.\nuniform distribution of challenge messages Due to the unpredictable delivery time and continuing steps of the random walk, challenge messages are heard in the network throughout the entire epoch, so nodes cannot guess a specific time period when they could strategically omit the messages and only care for the period when there are more challenge messages.\nMinimizing beacon asynchrony The time span of each epoch is significantly larger than the delay of the randomness beacon. This minimizes the discrepancy between the times at which different nodes receive the random beacon, ensuring a fair start for all.\nfavor low latency The length of the path of challenges provides an indirect measure of network connection speeds. Within a fixed epoch, a longer challenge path indicates a shorter average time per challenge hop. Our reputation scoring design takes that into account, which incentivizes nodes to upload their proof of relay as swiftly as possible, thereby fostering network efficiency.\nfavor stable connections Setting up connections with new nodes takes time and can potentially affect a node’s ability to quickly relay challenge messages. Thus, nodes are discouraged from frequently changing their connections.\nfavor high-quality peers The reputation scoring system motivates nodes to maintain a balanced number of high-quality peer connections. If a node (C) has significantly more peers than the desired degree (N), its share of the reputation reward (R) decreases. This drives nodes to prune low-quality peers and retain only those reliable with good network traffic.\nadvocate relay diligence The confidentiality of the message source prevents nodes from knowing if they are directly connected with the challenge sender. As a result, all nodes are encouraged to diligently relay challenge messages, and unknowingly assist a peer, as oppose to keeping all messeages from the peer to itself.\nThe properties above provide a robust and fair framework for nodes to participate in and benefit from the Proof-of-Relay system."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#rewards-and-payments",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#rewards-and-payments",
    "title": "Hyperbolic",
    "section": "5 Rewards and payments",
    "text": "5 Rewards and payments\nIn Hyperbolic, we use a dual reward structure consists of both Relay Rewards and D-Service Rewards. Namely, a node first earns Relay Rewards by forwarding data as a Bolic node. Additionally, it can also earn D-Service Rewards by rendering D-Services to clients. Rewards could be in the form of Hyperbolic’s native token. Also, D-Service designers can choose to use their service-related tokens or fiat money for billing, with a customized fee model tailored to the specific service.\nRelay rewards are designed to encourage early adoption and participation in the network. They will initially be significant to offset the operational costs of running a node, thus ensuring node operators exceed their break-even point during the network’s inception phase. Over time, as the network matures, we anticipate these rewards may gradually decrease. Relay rewards will serve as the primary source of rewards in the initial years, with D-Services income taking over\nFigure 7: Schematic Diagram Illustrating the Proof-of-Relay Protocol.\nas they have more demand from the applications, and also need Bolic network hosted by the same nodes.\nD-Service rewards serve as an incentive for nodes to provide D-Services. The mechanism is simple: users compensate nodes for their services, thereby incentivizing nodes to perform more work. To ensure transparency and fairness, D-Service rewards can be disbursed to the node operators only after the successful completion of tasks or prorated for segmented periods. This approach not only safeguards the interests of the users, but also ensures that nodes are adequately rewarded for their contributions by some controllable loss from users’ dishonest behavior.\nFrom a payment perspective, users are free to utilize the Bolic relay network without incurring any charges. However, the payment mechanisms for each D-Service will differ and be independently established by their respective developers. This ensures that each D-Service can adopt a payment model that best aligns with its unique functionality, making a competitive and healthy marketplace for all."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#other-related-systems",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#other-related-systems",
    "title": "Hyperbolic",
    "section": "6 other related systems",
    "text": "6 other related systems\nIn this section, we discuss related systems and projects, their features and inherent limitations, and as a comparison, why Hyperbolic is fundamentally different.\n\nHistorical P2P File-Sharing and IPFS\nGnutella was a pioneering P2P network protocol established in 2000. As the first decentralized peer-to-peer network of its kind, it set the stage for subsequent networks to adopt a similar model. Gnutella enables users to share files through a decentralized search mechanism.\nBitTorrent is a popular P2P file-sharing platform that enables users to distribute large files efficiently. Many users use it to share multimedia files (movies), often with legal issues. eMule, started in 2002, offers a very similar service to BitTorrent. It uses its own algorithm and zlib for compression.\nInterPlanetary File System (IPFS) is also for P2P storage and sharing. It is written in more modern, Go language and unlike the above file-sharing clients, focuses on the functionality as a “middle-ware” to other Internet-scale projects. It is plug-and-play for storage hosting machines and offers a directory-like hierarchy for file storage. It was later on incentivized by tokens like Fleccoin to encourage the availability of the stored data.\nHowever, all of the above P2P storage platforms emphasize on the possibility of storing data in a decentralized manner, so the architecture is ad-hoc to the only task. Usually the latency is less predictable and the implementation is either dated or just enough to support file-sharing. While storing data is important, there is no actual computation or interaction with the stored data on these platforms, limiting their evolution.\nIn contrast, the backbone of Hyperbolic is a modern P2P network, Bolic, designed to be a messaging platform and generalized for different purposes. Using this backbone, we build our D-Service framework which is not necessary in a P2P model at all stages. This allows a wide spectrum of services, including (e.g., D-CDN) but not limited to file-sharing.\n\n\nTor\nTor, also known as The Onion Router, is an anonymous communication network that enables users to browse the Internet and access services without revealing their identity or location. Tor achieves this by obfuscating traffic through a series of relays, encrypting at each step to maintain user privacy. While Tor provides a valuable tool for preserving anonymity, its focus on privacy comes at the expense of performance. It also uses the traditional web model. Hyperbolic, on the other hand, offers a new D-Service platform that can potentially accommodate Tor-style routing as an optional feature.\n\n\nContent Delivery Networks\nContent Delivery networks (CDNs) are large-scale distributed systems designed to serve static contents to end users with different geographical locations. Traditional CDNs are typically centralized and operated by companies. Thus, the implementations of CDNs vary and are usually private to the operators. They are also specialized in use so that streaming services like Netflix have their own video CDN servers, whereas many websites use Cloudflare [3] to cache web pages. In Hyperbolic, we build a general-purpose D-CDN that resembles a distributed key-value store with hashes as keys. Any machines in the network can opt in as a D-CDN server to store and replicate the encrypted data.\n\n\nBlockchains\nBlockchains, such as Bitcoin [13], Ethereum [2], and Avalanche [17], emerged as prominent P2P networked systems providing decentralized finance and/or applications in the form of smart contracts. While they demonstrate the possibilities of decentralized computing, they are built around a chain (or a collection of chains) that directly captures the computational steps of the hosted (virtual) services, which is less suitable for more general computational demands that traditional cloud-computing can satisfy. By finding the new abstraction that is lower-level than a chain-based consensus, Hyperbolic encapsulates the existing chains as ordering services, while exposing a chain-less framework that allows more services with composability and fault tolerance.\n\n\nWaku and XMPP\nWaku [22] is a decentralized messaging protocol designed for privacy, scalability, and friendliness to IoT devices. Waku’s messaging adopts a gossip-based routing algorithm, leading to excessive redundant messages flooding the network in both one-to-one and one-to-many communication scenarios. In contrast, the smart routing protocol of the Bolic network ensures the messages are routed to the recipient(s) with low cost whereas group messages could be handled by D-Services. XMPP is building a network to enable secure messaging between blockchain accounts, but it uses Waku under the hood to relay messages. While Waku and XMTP focus only on messaging, Hyperbolic expands the scope of decentralized systems to cater to a more comprehensive set of services and applications.\n\n\nNym\nNym [5], a Tor-like network, prioritizes user privacy with its Proof-of-Mixing design. All participants in Nym generate measurement messages in a pseudo-random manner and a full path to relay the message through the network using a VRF and a sampler. They then employ the Sphinx packet format to encrypt data and relay it along a pre-determined path through the routing network. However, this approach relies on deterministic relay paths. In contrast, our Proof-of-Relay does not make such an assumption and thus allows the Bolic network to have more flexibility in terms of the routing algorithm.\n\n\nHelium\nHelium [7] aims to establish a decentralized wireless network of hotspots for users. They proposed a Proof-of-Coverage scheme to verify that miners are providing wireless network coverage. Additionally, there is a Proof-of-Serialization scheme, achieving cryptographic time consensus among decentralized clients. Yet, similar to Nym, Helium uses deterministic paths for transmitting challenges. Moreover, due to the complexity of achieving synchronized timestamps, they transitioned from using Proof-of-Serialization to simply employing centralized oracles as the reference point for timestamps. Bolic’s Proof-of-Relay scheme does not have these issues and provides a feasible solution that also considers relay speed."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#references",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#references",
    "title": "Hyperbolic",
    "section": "References",
    "text": "References\n\n[1] Joseph Bonneau and Valeria Nikolaenko. Public randomness and randomness beacons. https://al6zcrypto.com/posts/article/public-randomness-and-randomness-beacons/, 2022.\n[2] Vitalik Buterin. Ethereum: a next-generation smart contract and decentralized application platform. https://ethereum.org/en/whitepaper/, 2014.\nthe web performance & security company. https://www.cloudflare.com/.\n[4] Jeffrey Dean and Sanjay Ghemawat. MapReduce: Simplified data processing on large clusters. In Eric A. Brewer and Peter Chen, editors, 6th Symposium on Operating System Design and Implementation (OSDI 2004), San Francisco, California, USA, December 6-8, 2004, pages 137-150. USENIX Association, 2004.\n[5] Claudia Diaz, Harry Halpin, and Aggelos Kiayias. The Nym network: the next generation of privacy infrastructure (2021). https://nymtech.net/nym-whitepaper.pdf, 2021.\n[6] Mark Fenwick and Paulius Jurcsy. The contested meaning of Web3 and why it matters for (IP) lawyers. Available at SSRN 4017790, 2022.\n[7] Amir Haleem, Andrew Allen, Andrew Thompson, Marc Nijdam, and Rahul Garg. Helium: A decentralized wireless network. Helium Systems Inc., Tech. Rep[Online]. Available: http://whitepaper.helium. com, 2018.\n[8] Aniket Kate, Gregory M Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials and their applications. In Advances in Cryptology-ASIACRYPT 2010: 16th International Conference on the Theory and Application of Cryptology and Information Security, Singapore, December 5-9, 2010. Proceedings 16, pages 177-194. Springer, 2010.\n[9] Protocol Labs. Filecoin: a decentralized storage network. https://filecoin.io/filecoin.pdf, 2017.\n[10] Leslie Lamport. The part-time parliament. ACM Trans. Comput. Syst., 16(2):133-169, 1998.\n[11] Dahlia Malkhi, Chrysoula Stathakopoulou, and Maofan Yin. Build it super simple: Introducing single broadcast consensus on a DAG. https://blog.chain.link/bbca-chain-single-broadcast-consensus-on-a-dag/, 2023.\n[12] Silvio Micali, Michael Rabin, and Salil Vadhan. Verifiable random functions. In 40th annual symposium on foundations of computer science (cat. No. 99CB37039), pages 120-130. IEEE, 1999.\n[13] Satoshi Nakamoto. Bitcoin: a peer-to-peer electronic cash system. https://bitcoin.org/bitcoin.pdf, 2008.\n[14] Diego Ongaro and John K. Ousterhout. In search of an understandable consensus algorithm. In Garth Gibson and Nickolai Zeldovich, editors, 2014 USENIX Annual Technical Conference, USENIX ATC ’14, Philadelphia, PA, USA, June 19-20, 2014, pages 305-319. USENIX Association, 2014.\n[15] OpenAI. ChatGPT. https://openai.com/blog/chatgpt, 2023.\n[16] Henning Pagnia, Felix C Gartner, et al. On the impossibility of fair exchange without a trusted third party. Technical report, Citeseer, 1999.\n[17] Team Rocket, Maofan Yin, Kevin Sekniqi, Robbert van Renesse, and Emin Gun Sirer. Scalable and probabilistic leaderless BFT consensus through metastability. CoRR, abs/1906.08936, 2019.\n[18] Jerome H. Saltzer, David P. Reed, and David D. Clark. End-to-end arguments in system design. ACM Trans. Comput. Syst., 2(4):277-288, 1984.\n[19] Alexander Spiegelman, Neil Giridharan, Alberto Sonnino, and Lefteris Kokoris-Kogias. Bullshark: DAG BFT protocols made practical. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, CCS 2022, Los Angeles, CA, USA, November 7-11, 2022, pages 2705-2718. ACM, 2022.\n[20] Chrysoula Stathakopoulou, Michael Wei, Maofan Yin, Hongbo Zhang, and Dahlia Malkhi. BBCA-LEDGER: high throughput consensus meets low latency. CoRR, abs/2306.14757, 2023.\n[21] Storj Labs, Inc. Storj: a decentralized cloud storage network framework. https://www.storj.io/storjv3.pdf, 2018.\n[22] Oskar Thoren, Sanaz Taheri-Boshrooyeh, and Hanno Cornelius. Waku: a family of modular P2P protocols for secure & censorship-resistant communication. In 2022 IEEE 42nd International Conference on Distributed Computing Systems Workshops (ICDCSW), pages 86-87. IEEE, 2022.\n[23] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajiwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\n[24] Sam Williams, Viktor Diordiiev, Lev Berman, and Ivan Uemilianin. Arweave: a protocol for economically sustainable information permanence. https://yellow-paper.arweave.dev/, 2019.\nAugust 2, 2019_, pages 347-356. ACM, 2019.\n[26] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauly, Michael J. Franklin, Scott Shenker, and Ion Stoica. Resilient distributed datasets: A fault-tolerant abstraction for ir-memory cluster computing. In Steven D. Gribble and Dina Katabi, editors, Proceedings of the gth USENIX Symposium on Networked Systems Design and Implementation, NSDI 2012, San Jose, CA, USA, April 25-27, 2012, pages 15-28. USENIX Association, 2012."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#appendix-a-appendix-proof-of-storage",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#appendix-a-appendix-proof-of-storage",
    "title": "Hyperbolic",
    "section": "Appendix A Appendix: Proof-of-Storage",
    "text": "Appendix A Appendix: Proof-of-Storage\nIn our Decentralized Content Delivery Network (D-CDN) service, Proof of Storage plays a pivotal role in establishing trust and ensuring data availability. The crux of this process is to allow any network participant, who may not have prior knowledge or a copy of the data, to verify whether a certain storage node is faithfully storing a specific piece of data. This process is done in such a way that the verifying party does not need to download the entire data to confirm its integrity. Instead, the node storing the data provides a cryptographic proof that can be verified efficiently. By integrating Proof of Storage, our D-CDN service ensures the reliability and availability of data while minimizing network and computational overheads. This section provides a detailed explanation of our Proof of Storage protocol and its importance to our D-CDN service.\n\nMotivations\nDecentralized storage networks incorporate a variety of proof systems to ensure data integrity and availability.\nArweaveave [24], for instance, relies on a Proof-of-Work algorithm where nodes utilize computational resources to solve complex hash problems tied to files in storage, utilizing the full data content of a randomly chosen prior block to validate transactions and create new blocks in the blockchain. The requirement to generate a hash below a certain difficulty level using a nonce can, however, be computationally intensive and result in unnecessary resource usage.\nFilecoin [9], on the other hand, employs computationally demanding procedures, such as sealing and encoding, to generate proofs of storage, which guarantees that a node has securely created and stored a unique copy of some piece of data. Nevertheless, this technique necessitates high-end hardware due to its dependence on computationally intensive operations to produce sealed sectors. Consequently, nodes with constrained computational resources might be excluded from participating in the network.\nStorj [21], meanwhile, adopts Reed-Solomon encodingto generate extra data segments, enabling the reconstruction of lost or corrupted data. Alongside, the Berlekamp-Welch error correction algorithm is used to identify and correct erroneous responses. However, Storj’s verification process requires multiple data shares from different storage providers. This condition could lead to inefficiencies and dependency on the responsiveness of other nodes for data integrity confirmation.\nTherefore, the need for a more efficient and accessible system for Proof-of-Storage is evident. In response, we propose a novel design for our D-CDN service, aiming to overcome these limitations. Our design only requires a proof from only the storage provider to verify the data integrity, thus eliminating the need to depend on other nodes’ responses. Furthermore, by using KZG polynomial commitment scheme [8] instead of Merkle trees, the proof size is reduced to a constant and verifying the proof only require a constant number of operations. As a result, our approach is less resource-intensive, opening participation to a wider range of nodes.\n\n\nDefintions\n\nReed-Solomon codes: Error-correction codes that process data blocks as finite-field symbols and are able to detect and correct combinations of errors and erasures. Each code is defined by three parameters: the alphabet size (q), block length (n), and message length (k), with (k&lt;nq). Every codeword in the set corresponds to function values from a polynomial of degree less than (k).\nElliptic curves These curves, defined over a field (K), represent points in (K^{2}). They are specifically categorized by the plane algebraic curve equation (y{2}=x{3}+ax+b), where (a) and (b) are coefficients in (K) and the field’s characteristic differs from (2) and (3).\n**Bilinear Pairing*\nA bilinear pairing is a mapping defined between two additive groups (G_{1},G_{2}) and a multiplicative group (G_{T}), all of prime order (p). Here, (g_{1}G_{1}) and (g_{2}G_{2}) are generators of (G_{1}) and (G_{2}) respectively. The pairing is represented as (e:G_{1}G_{2}G_{T}) and has the following properties:\nBilinearity: For all (a,bZ), (e(ag_{1},bg_{2})=e(g_{1},bg_{2})^{ab})\nNon-degeneracy: (e(g_{1},g_{2}))\n\n\n\nProof-of-Storage Scheme\nLet (G_{1}) and (G_{2}) be two elliptic curves with a bilinear pairing (e:G_{1}G_{2}G_{T}). Let (g_{1}) and (g_{2}) be generators of (G_{1}) and (G_{2}). We will use a very useful shorthand notation\n[[x]{1}=xg{1}G_{1}[x]{2}=xg{2}G_{2}]\nfor any (xZ). Here we let (G_{1}) be the elliptic curve (1) which is a pairing-friendly elliptic curve.\n\nTursted Setup The initialization of this protocol requires a one-time trusted setup. Once this is established, the protocol can repeatedly engage in committing to and revealing different polynomials. Assume we have a trusted setup, so that for a secret (s), the elements ([s^{i}]{1}) and ([s^{i}]{2}) are publicly available for all (i=0,,n-1). Now, it’s a fundamental aspect of elliptic curve cryptography that from the provided group elements in the trusted setup, it’s computationally infeasible to extract the actual value of (s). Despite (s) being a member of (F_{p}), the prover is unable to determine its specific value. Instead, the prover is limited to performing certain operations with the given elements. For a given polynomial (p(X)={i=0}{n}p_{i}X{i}), the prover is able to compute [[p(s)]{1}=[_{i=0}{n}p_{i}s{i}]{1}={i=0}^{n}p_{i}[s^{i}]{1}] This process enables the prover to compute the evaluation of the polynomial at the undisclosed point (s) within the group (G{1}), while maintaining the obscurity of (s)’s exact value.\nEncoding A user sends a file to a storage provider for storage. A file is represented by an ordered collection of one or more segments. Segments have a fixed maximum size for erasure encoding (in our case, it’s Reed-Solomon Encoding). Each segment is treated as a vector of k elements in the finite field F, i.e. (x=(x_{1},,x_{k})F^{k}). By using Polynomial Interpolation, the storage provider calculates the unique polynomial (p_{x}) of degree less than k such that [p_{x}(i)=x_{i}i{1,,k}] Once it has been generated, it is evaluated at the other points (k+1,,n).\nCommitment The storage provider commits to Reed-Solomon encoding polynomial (p_{x}) by calculating (C=[p_{x}(s)]_{1}). This is called KZG commitment scheme or just Kate polynomial commitment scheme. It is called a commitment, because having sent the commitment value (an elliptic curve point) to the public, the prover cannot change the polynomial they are working with. They will only be able to provide valid proofs for one polynomial, and if they are trying to cheat, they will either fail to produce a proof or the proof will be rejected by the verifier.\nVerification Every time when a user or other entities asks for verification at a random point z, the storage providers give the evaluation of (p_{x}(z)=y). Besides, he calculates (q(X)=) and the proof (=[q(s)]{1}). He then send (y) and () to the verifier. The user can easily verify it by checking the following equation [(,[s-z]{2})=(C-[y]_{1},H).] If it holds, then the verifier accepts the proof.\n\n\n\nFile Retrieval\nRetrieving a file from the Distributed Content Delivery Network (D-CDN) is a process that necessitates a well-coordinated interaction between storage providers and the user. The concept of ‘fair exchange’ is vital in this scenario. The impossibility results on fair exchange [16] establish that it is unfeasible for two parties to perform an exchange without involving trusted entities. The retrieval process consists of these significant steps:\n\nBandwidth Calculation and Contract Signing: Before initiating the retrieval process, storage providers estimate and communicate the total bandwidth and payment required for the file retrieval. Subsequently, the user selects a storage provider and signs a smart contract with them. The required amount is then escrowed by the smart contract.\nFile Segmentation: Due to the impossibility results on fair exchange without trusted parties, extensive files are fragmented into smaller, manageable segments. This step ensures fair transactions during the retrieval process.\nSegments Retrieval: Segments are retrieved sequentially by the user. Every retrieved segment is verified by the user to ensure its integrity and authenticity. After successful retrieval and verification of a segment, the user signs a message confirming the receipt of the segment and sends it to the storage provider. Upon receiving the confirmation message, the storage provider transmits the next segment to the user.\nRetrieval Interruption: In case the client stop paying, or the storage provider discontinues data transmission, either party has the right to halt the exchange. Subsequently, the storage provider uploads the confirmation messages of the transmitted segment to the smart contract. The smart contract then allocates the payment for the data confirmed by the user to the storage provider, and the remaining amount is refunded to the user. If needed, the user can sign another contract with a different storage provider to retrieve the remaining data.\n\nThrough these steps, the file retrieval process provides a balance of fairness and efficiency, offering users a reliable method to retrieve their files from the D-CDN."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/eth-node.html",
    "href": "library/natural-sciences/crypto/blockchain/dev/eth-node.html",
    "title": "Reth",
    "section": "",
    "text": "Running an Ethereum node post-merge consists of running a client for both the execution layer (EL) and consensus layer (CL).\nExecution Layer Client Options\n\nReth | Book\nGeth | Docs\nNethermind | Docs\nErigon\n\nConsensus Layer Client Options\n\nLighthouse | Book | Blog\nPrysm | Docs\n\nI am going to be running Reth + Lighthouse node on a linux Ubuntu server. The following guide pertains to that specific OS, but the process is closely similar for other operating systems.\nArchitecture:            x86_64\n  CPU op-mode(s):        32-bit, 64-bit\n  Address sizes:         39 bits physical, 48 bits virtual\n  Byte Order:            Little Endian\nCPU(s):                  12\n  On-line CPU(s) list:   0-11\nVendor ID:               GenuineIntel\n  Model name:            Intel(R) Xeon(R) E-2386G CPU @ 3.50GHz\n\n\nDownload the latest version of Reth and extract its contents.\n# download the archive\nwget -c https://github.com/paradigmxyz/reth/releases/download/v0.1.0-alpha.9/reth-v0.1.0-alpha.9-x86_64-unknown-linux-gnu.tar.gz\n\n# extract contents\ntar -xzf reth-v0.1.0-alpha.9-x86_64-unknown-linux-gnu.tar.gz\nDo the same with the latest version of lighthouse.\n# download the archive\nwget -c https://github.com/sigp/lighthouse/releases/download/v4.5.0/lighthouse-v4.5.0-x86_64-unknown-linux-gnu.tar.gz\n\n# extract contents\ntar -xzf lighthouse-v4.5.0-x86_64-unknown-linux-gnu.tar.gz\n\n\n\nTo run processes perpetually, I use screen. screen command in Linux provides the ability to launch and use multiple shell sessions from a single ssh session.\nBrief cheatsheet\n# view existing screens\nscreen -ls\n# make a new screen\nscreen -S rethnode\n\n# leave screen without halting with ctrl-a, d \n\n# connect to existing screen\nscreen -r myscreen\nEach client has many command line options which allow you to customize the configuration. Get an overview of command line options with\nreth node --help\n\nlighthouse --help\nI will be running the following commands\nReth\n# cd into proper directory\nRUST_LOG=info ./reth node --full \\\n--http --http.corsdomain \"*\" --http.api all \\\n--ws --ws.origins \"*\" --ws.api all \nexit screen and create a new one\nLighthouse\n./lighthouse bn \\\n  --execution-endpoint http://localhost:8551 \\\n  --execution-jwt $HOME/.local/share/reth/mainnet/jwt.hex \\\n  --checkpoint-sync-url https://mainnet.checkpoint.sigp.io \\\n  --disable-deposit-contract-sync\nCongratulations. You are now running an Ethereum client. Expect the syncing process to take ~50 hours, after which you may query the Ethereum blockchain (and submit transactions) directly from your node."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#overview",
    "href": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#overview",
    "title": "Reth",
    "section": "",
    "text": "Running an Ethereum node post-merge consists of running a client for both the execution layer (EL) and consensus layer (CL).\nExecution Layer Client Options\n\nReth | Book\nGeth | Docs\nNethermind | Docs\nErigon\n\nConsensus Layer Client Options\n\nLighthouse | Book | Blog\nPrysm | Docs\n\nI am going to be running Reth + Lighthouse node on a linux Ubuntu server. The following guide pertains to that specific OS, but the process is closely similar for other operating systems.\nArchitecture:            x86_64\n  CPU op-mode(s):        32-bit, 64-bit\n  Address sizes:         39 bits physical, 48 bits virtual\n  Byte Order:            Little Endian\nCPU(s):                  12\n  On-line CPU(s) list:   0-11\nVendor ID:               GenuineIntel\n  Model name:            Intel(R) Xeon(R) E-2386G CPU @ 3.50GHz\n\n\nDownload the latest version of Reth and extract its contents.\n# download the archive\nwget -c https://github.com/paradigmxyz/reth/releases/download/v0.1.0-alpha.9/reth-v0.1.0-alpha.9-x86_64-unknown-linux-gnu.tar.gz\n\n# extract contents\ntar -xzf reth-v0.1.0-alpha.9-x86_64-unknown-linux-gnu.tar.gz\nDo the same with the latest version of lighthouse.\n# download the archive\nwget -c https://github.com/sigp/lighthouse/releases/download/v4.5.0/lighthouse-v4.5.0-x86_64-unknown-linux-gnu.tar.gz\n\n# extract contents\ntar -xzf lighthouse-v4.5.0-x86_64-unknown-linux-gnu.tar.gz\n\n\n\nTo run processes perpetually, I use screen. screen command in Linux provides the ability to launch and use multiple shell sessions from a single ssh session.\nBrief cheatsheet\n# view existing screens\nscreen -ls\n# make a new screen\nscreen -S rethnode\n\n# leave screen without halting with ctrl-a, d \n\n# connect to existing screen\nscreen -r myscreen\nEach client has many command line options which allow you to customize the configuration. Get an overview of command line options with\nreth node --help\n\nlighthouse --help\nI will be running the following commands\nReth\n# cd into proper directory\nRUST_LOG=info ./reth node --full \\\n--http --http.corsdomain \"*\" --http.api all \\\n--ws --ws.origins \"*\" --ws.api all \nexit screen and create a new one\nLighthouse\n./lighthouse bn \\\n  --execution-endpoint http://localhost:8551 \\\n  --execution-jwt $HOME/.local/share/reth/mainnet/jwt.hex \\\n  --checkpoint-sync-url https://mainnet.checkpoint.sigp.io \\\n  --disable-deposit-contract-sync\nCongratulations. You are now running an Ethereum client. Expect the syncing process to take ~50 hours, after which you may query the Ethereum blockchain (and submit transactions) directly from your node."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#step-1-installation",
    "href": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#step-1-installation",
    "title": "Reth",
    "section": "Step 1: Installation",
    "text": "Step 1: Installation\nDownload the latest version of Reth and extract its contents.\n# download the archive\nwget -c https://github.com/paradigmxyz/reth/releases/download/v0.1.0-alpha.9/reth-v0.1.0-alpha.9-x86_64-unknown-linux-gnu.tar.gz\n\n# extract contents\ntar -xzf reth-v0.1.0-alpha.9-x86_64-unknown-linux-gnu.tar.gz\nDo the same with the latest version of lighthouse.\n# download the archive\nwget -c https://github.com/sigp/lighthouse/releases/download/v4.5.0/lighthouse-v4.5.0-x86_64-unknown-linux-gnu.tar.gz\n\n# extract contents\ntar -xzf lighthouse-v4.5.0-x86_64-unknown-linux-gnu.tar.gz"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#step-2-run-the-clients",
    "href": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#step-2-run-the-clients",
    "title": "Reth",
    "section": "Step 2: Run the clients",
    "text": "Step 2: Run the clients\nTo run processes perpetually, I use screen. screen command in Linux provides the ability to launch and use multiple shell sessions from a single ssh session.\nBrief cheatsheet\n# view existing screens\nscreen -ls\n# make a new screen\nscreen -S rethnode\n\n# leave screen without halting with ctrl-a, d \n\n# connect to existing screen\nscreen -r myscreen\nEach client has many command line options which allow you to customize the configuration. Get an overview of command line options with\nreth node --help\n\nlighthouse --help\nI will be running the following commands\nReth\n# cd into proper directory\nRUST_LOG=info ./reth node --full \\\n--http --http.corsdomain \"*\" --http.api all \\\n--ws --ws.origins \"*\" --ws.api all \nexit screen and create a new one\nLighthouse\n./lighthouse bn \\\n  --execution-endpoint http://localhost:8551 \\\n  --execution-jwt $HOME/.local/share/reth/mainnet/jwt.hex \\\n  --checkpoint-sync-url https://mainnet.checkpoint.sigp.io \\\n  --disable-deposit-contract-sync\nCongratulations. You are now running an Ethereum client. Expect the syncing process to take ~50 hours, after which you may query the Ethereum blockchain (and submit transactions) directly from your node."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#part-b-external-rpc-serving",
    "href": "library/natural-sciences/crypto/blockchain/dev/eth-node.html#part-b-external-rpc-serving",
    "title": "Reth",
    "section": "Part B: External RPC Serving",
    "text": "Part B: External RPC Serving\nWe will configure an NGINX reverse proxy to serve an ethereum JSON-RPC at a custom domain.\nOut goal is to serve an HTTP endpoint at https://mynode.mywebsite.com/rpc and a WSS endpoint at wss://mynode.mywebsite.com/ws.\n\nStep 1: Install NGINX\nsudo apt-get update\nsudo apt-get install nginx \nNavigate to /etc/nginx/conf.d\nCreate a file called node.conf\nsudo nano node.conf \nAnd paste the following contents\nserver {\n\n  listen 80;\n  listen [::]:80;\n  server_name 01.my.ip.10 mynode.mywebsite.com;\n\n  listen 443 ssl;\n  listen [::]:443 ssl;\n  ssl_certificate /etc/nginx/ssl/mynode.mywebsite.com.crt;\n  ssl_certificate_key /etc/nginx/ssl/mynode.mywebsite.com.key;\n\n  location /ws {\n      proxy_http_version 1.1;\n      proxy_set_header Upgrade $http_upgrade;\n      proxy_set_header Connection \"Upgrade\";\n      proxy_set_header Host $host;\n      proxy_pass   http://127.0.0.1:8546/;\n  }\n\n  location /rpc {\n      proxy_redirect off;\n      proxy_pass    http://127.0.0.1:8545/;\n  }\n}\nNow retrieve an SSL origin certificate from Cloudflare, and paste the .crt and .pem contents at:\n/etc/nginx/ssl/mynode.mywebsite.com.crt and /etc/nginx/ssl/mynode.mywebsite.com.key, respectively.\nMake sure your domain has an A record pointing to “mynode” (or whatever you picked as a subdomain).\nYou should now be able to go to your domain “mynode.mywebsite.com” and see the NGINX welcome page."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/ton.html",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/ton.html",
    "title": "TON",
    "section": "",
    "text": "TON Whitepaper\nwebsite\nTON Virtual Machine Whitepaper\nTON Blockchain Whitepaper\nCatchain Consensus Whitepaper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/ton.html#resources",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/ton.html#resources",
    "title": "TON",
    "section": "",
    "text": "TON Whitepaper\nwebsite\nTON Virtual Machine Whitepaper\nTON Blockchain Whitepaper\nCatchain Consensus Whitepaper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/ton.html#brief-history",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/ton.html#brief-history",
    "title": "TON",
    "section": "Brief History",
    "text": "Brief History\nFounder: Dr. Nikolai Durov"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#computational-complexity-theory",
    "href": "library/natural-sciences/crypto/cryptography/index.html#computational-complexity-theory",
    "title": "Cryptography",
    "section": "Computational Complexity Theory",
    "text": "Computational Complexity Theory\n“NP” is short for “nondeterministic polynomial-time”\n\nNP-Completeness\nA problem is NP-Complete when - It is a decision problem, meaning that for any input to the problem, the output is either “yes” or “no”. - When the answer is “yes”, this can be demonstrated through the existence of a short (polynomial length) solution. - The correctness of each solution can be verified quickly (namely, in polynomial time) and a brute-force search algorithm can find a solution by trying all possible solutions. - The problem can be used to simulate every other problem for which we can verify quickly that a solution is correct. In this sense, NP-complete problems are the hardest of the problems to which solutions can be verified quickly. If we could find solutions of some NP-complete problem quickly, we could quickly find the solutions of every other problem to which a given solution can be easily verified."
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/index.html#concepts",
    "href": "library/natural-sciences/crypto/cryptography/index.html#concepts",
    "title": "Cryptography",
    "section": "Concepts",
    "text": "Concepts\n\nSNARKs\n\nVitalik Intro 1\nVitalik Intro 2\nVitalik Intro 3\n\n\n\nSTARKs\n\nVitalik Intro 1\nVitalik Intro 2\nVitalik Intro 3"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/zk.html",
    "href": "library/natural-sciences/crypto/cryptography/zk.html",
    "title": "ZK",
    "section": "",
    "text": "A Zero-Knowledge Proof (ZKP) allows a prover to demonstrate knowledge of some secret without revealing the secret itself. Let’s illustrate this using a graph coloring problem.\n\n\nImagine Alice has a graph \\((G = (V, E))\\), where \\((V)\\) is the set of vertices and \\((E)\\) is the set of edges. Alice claims she can 3-color the graph so that no adjacent vertices share the same color. Bob wants to verify this claim without learning the actual coloring.\n\n\n\n\nCommitment: Alice chooses a random permutation of her 3-coloring and commits to it, sending a cryptographic hash of each vertex’s color to Bob.\nChallenge: Bob randomly selects an edge \\(((u, v) \\in E)\\)\nResponse: Alice reveals the colors of vertices \\((u)\\) and \\((v)\\).\nVerification: Bob checks if the revealed colors are different and match the hash commitments.\n\nThrough repeated iterations, Bob becomes increasingly confident that Alice has a valid 3-coloring, but gains no knowledge about the coloring itself.\n\n\n\n\nGraph: \\((G = (V, E))\\)\nColors: \\((\\{ \\text{Red}, \\text{Green}, \\text{Blue} \\})\\)\nRandom Permutation: \\((\\pi)\\)\nHash Commitment for vertex \\((v): ( H(\\pi(\\text{color}(v))) )\\)\n\nThis example shows that ZKPs can provide robust verification without sacrificing the secrecy of the information involved.\n\n\n\nGraph three coloring is NP-complete. Thus, any protocol that can prove a solution to this problem can be used to prove any statement in the class NP.\nThree critical properties a ZKP must satisfy:\n\nCompleteness: If the Prover is honest, then she will eventually convince the Verifier.\nSoundness: The Prover can only convince the Verifier if the statement is true.\nZero-knowledge(ness): The Verifier learns no information beyond the fact that the statement is true."
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/zk.html#concepts",
    "href": "library/natural-sciences/crypto/cryptography/zk.html#concepts",
    "title": "ZK",
    "section": "Concepts",
    "text": "Concepts\n\nSNARKs\n\nVitalik Intro 1\nVitalik Intro 2\nVitalik Intro 3\n\n\n\nSTARKs\n\nVitalik Intro 1\nVitalik Intro 2\nVitalik Intro 3"
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/zk.html#reads",
    "href": "library/natural-sciences/crypto/cryptography/zk.html#reads",
    "title": "ZK",
    "section": "Reads",
    "text": "Reads\n\nEducational Resources\n\nZKP Illustrated Primer Part 1\nZKP Illustrated Primer Part 2\nZkIntro\n\n\n\nResource Compilations\n\nZero Knowledge A-Z\nHickup’s ZK Journey\nZK “Canon” by A16z\nZKP.Science\n\n\n\nVideo Resources\n\nRiscZero Study Club\nIntroduction to Zero Knowledge: Video Tutorial\n\n\n\nFoundational Papers\n\nNew Directions in Cryptography, 1976\nPublic-coin zero-knowledge arguments with (almost) minimal time and space overheads, 2020\nA method for obtaining digital signatures and public-key cryptosystems\nProofs, Arguments, and Zero-Knowledge\n\n\n\nTechnical Deep Dives\n\nOverview of Verifiable Computing\nInteractive Proofs\nMeasuring SNARK Performance\nWhy and How ZK-SNARK Works\nSuccint Non-Interactive Zero Knowledge for a von Neumann Architecture\nPLONK Explainer by Vitalik\nPLONK ePrint\nStreaming Zero-Knowledge Proofs\nWhy and How ZK-SNARK Works\nFast Amortized KZG Proofs\nZK Development Playground\nBeginner Intro to Coding ZK Proofs\n\n\n\nPractical Applications\n\nApplied ZK\nCrypto Regulations, Privacy and Beyond\nZK Benchmarks\n\n\n\nProjects\nAxiom: Building a zk coprocessor for Ethereum\n\nTwitter\nWebsite\nDemo\nDocs\n\nRiscZero: Making generalizable computer architecture for ZK\n\nwebsite\ndocs\ngithub\n\nBlockchain product: Bonsai\n\ndocs\nstarter template\n\nZK Proof of Exploit\n\ntwitter"
  },
  {
    "objectID": "library/life-sciences/biology/viruses/index.html",
    "href": "library/life-sciences/biology/viruses/index.html",
    "title": "Viruses",
    "section": "",
    "text": "COVID-19\n\n\nFebruary\n\nZhou Yusen filed a patent for a Covid-19 vaccine on February 24, 2020.\n\nMarch\n\nTheProximal Origin of SARS-CoV-2\n\n“Our analyses clearly show that SARS-CoV-2 is not a laboratory construct or a purposefully manipulated virus.”\n\n\nMay\n\nZhou Yusen died in mysterious circumstances in May 2020, aged 54. Zhou worked for the People’s Liberation Army and was collaborating with Wuhan scientists at the time of the outbreak. US investigators are said to have been told ‘Zhou fell from the roof of the Institute’, although this has not been confirmed.\n\n\n\n\nJanuary\n\nWerriam Webster changed the definition of Vaccine\n\nJan 11, 2021\nJan 26, 2021\n\n\nDecember\n\nCanadian Covid Care Alliance: The Pfizer Inoculations for COVID-19, More Harm than Good\n\n\n\n\nFebruary\n\nLawrence Sellin: The Laboratory Origin of COVID-19\n\nOctober\n\nSenate Committee on Health Education, Labor and Pensions: An Analysis of the Origins of the COVID-19 Pandemic\n\n\n\n\nJanuary\n\nAHA Circulation Journal: Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\n“We discovered that individuals who developed postvaccine myocarditis uniquely exhibit elevated levels of free spike protein in circulation, unbound by anti-spike antibodies, which appear to correlate with cardiac troponin T levels and innate immune activation with cytokine release.””\n\n\nFebruary\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\n\nMay\n\nU.S. Senate Report: A Political Chronology of the SARS-CoV-2 Outbreak\n\nVaccine could not have been developed in claimed timeframe, must have began Nov ’19 or earlier\n\n\nJune\n\nDr. Peter Hotez’s Funding Linked to Controversial Chinese Military Scientists at Wuhan Lab\n\nFunded by Dr. Fauci and Dr. Hotez’s R01AI098775 grant, Dr. Shibo Jiang and Dr. Lanying Du collaborated with scientists from the People’s Liberation Army and the Wuhan Institute of Virology.\n\n\nJuly\n\nInvestigating the Proximal Origin of a Cover-Up\n\nAugust\n\nNational Review: The Covid Cover-Up\n\n\n\n\n\nAustralia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis\nDr. Robert Malone Twitter Ban Details\nCovid Care Alliance: More Harm Than Good\n\nVideo\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\nProtection of mRNA vaccines against hospitalized COVID-19\nPharma Rackateering\nIsrael Ministry of Health released Pfizer Agreement\n\nThey first claimed they “couldn’t find it”\n\nArticle\nDocument\nAdministrative Appeal\n\n\nNew Zealand 2022 Data\nMethodist Hospital threatened their doctors\n\n“You cannot report adverse reactions to these vaccines”\n\nMore dishonest statements about boosters by the FDA’s Marks and Califf\nRisk of Myocarditis in Boys 18-39\nVaccine on Birthing\n\nArticle 1\nArticle 2 / Correction\n\nHow Britons are dying in their tens of thousands\n\nbut no one knows why: From May to December last year, there were 32,441 excess deaths in England and Wales, excluding deaths from Covid\n\nPfizer Caught Funnelling $12 Million to Anderson Cooper To Promote mRNA Jabs to Americans\n\n\n\n\nA necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\n\n\n\n\n\n\n\nInterview with German MEP, Christine Anderson\n\nGovernments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”"
  },
  {
    "objectID": "library/life-sciences/biology/viruses/index.html#sars-cov-2",
    "href": "library/life-sciences/biology/viruses/index.html#sars-cov-2",
    "title": "Viruses",
    "section": "",
    "text": "COVID-19\n\n\nFebruary\n\nZhou Yusen filed a patent for a Covid-19 vaccine on February 24, 2020.\n\nMarch\n\nTheProximal Origin of SARS-CoV-2\n\n“Our analyses clearly show that SARS-CoV-2 is not a laboratory construct or a purposefully manipulated virus.”\n\n\nMay\n\nZhou Yusen died in mysterious circumstances in May 2020, aged 54. Zhou worked for the People’s Liberation Army and was collaborating with Wuhan scientists at the time of the outbreak. US investigators are said to have been told ‘Zhou fell from the roof of the Institute’, although this has not been confirmed.\n\n\n\n\nJanuary\n\nWerriam Webster changed the definition of Vaccine\n\nJan 11, 2021\nJan 26, 2021\n\n\nDecember\n\nCanadian Covid Care Alliance: The Pfizer Inoculations for COVID-19, More Harm than Good\n\n\n\n\nFebruary\n\nLawrence Sellin: The Laboratory Origin of COVID-19\n\nOctober\n\nSenate Committee on Health Education, Labor and Pensions: An Analysis of the Origins of the COVID-19 Pandemic\n\n\n\n\nJanuary\n\nAHA Circulation Journal: Circulating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\n“We discovered that individuals who developed postvaccine myocarditis uniquely exhibit elevated levels of free spike protein in circulation, unbound by anti-spike antibodies, which appear to correlate with cardiac troponin T levels and innate immune activation with cytokine release.””\n\n\nFebruary\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\n\nMay\n\nU.S. Senate Report: A Political Chronology of the SARS-CoV-2 Outbreak\n\nVaccine could not have been developed in claimed timeframe, must have began Nov ’19 or earlier\n\n\nJune\n\nDr. Peter Hotez’s Funding Linked to Controversial Chinese Military Scientists at Wuhan Lab\n\nFunded by Dr. Fauci and Dr. Hotez’s R01AI098775 grant, Dr. Shibo Jiang and Dr. Lanying Du collaborated with scientists from the People’s Liberation Army and the Wuhan Institute of Virology.\n\n\nJuly\n\nInvestigating the Proximal Origin of a Cover-Up\n\nAugust\n\nNational Review: The Covid Cover-Up\n\n\n\n\n\nAustralia Senate Hearing: Pfizer representative admits that they don’t understand the mechanism by which the vaccine causes myocarditis\nDr. Robert Malone Twitter Ban Details\nCovid Care Alliance: More Harm Than Good\n\nVideo\n\nBivalent Covid-19 Vaccines — A Cautionary Tale\nProtection of mRNA vaccines against hospitalized COVID-19\nPharma Rackateering\nIsrael Ministry of Health released Pfizer Agreement\n\nThey first claimed they “couldn’t find it”\n\nArticle\nDocument\nAdministrative Appeal\n\n\nNew Zealand 2022 Data\nMethodist Hospital threatened their doctors\n\n“You cannot report adverse reactions to these vaccines”\n\nMore dishonest statements about boosters by the FDA’s Marks and Califf\nRisk of Myocarditis in Boys 18-39\nVaccine on Birthing\n\nArticle 1\nArticle 2 / Correction\n\nHow Britons are dying in their tens of thousands\n\nbut no one knows why: From May to December last year, there were 32,441 excess deaths in England and Wales, excluding deaths from Covid\n\nPfizer Caught Funnelling $12 Million to Anderson Cooper To Promote mRNA Jabs to Americans\n\n\n\n\nA necessary Narrative for FDA emergency Authorization\nFDA emergency authorization of a vaccine/medicinal treatment, by law, cannot be administered if an existing medication is provably effective in reducing the risks associated with the disease/virus.\n\n\n\n\n\n\n\nInterview with German MEP, Christine Anderson\n\nGovernments around the world used outright psychological warfare—targeted even at children—to terrify their populations into submission with Covid tyranny, in a way that was globally coordinated.\n“In Germany, there was a manual on how to get the people to do what the government wanted them to do to adhere to these restrictions. They outlined [that] even though kids are at no risk of Covid, we have to make them afraid [that] if they catch it, and then they infect their grandparents, they’re responsible for having killed their grandparents.”"
  },
  {
    "objectID": "library/life-sciences/biology/viruses/index.html#mrna-vaccine",
    "href": "library/life-sciences/biology/viruses/index.html#mrna-vaccine",
    "title": "Viruses",
    "section": "mRNA Vaccine",
    "text": "mRNA Vaccine\n\nThe mRNA platform is brilliant. But it has a giant gaping flaw in it, which is; Any cell of yours that produces a foreign protein, will be targetted by your immune system and destroyed. You will create an autoimmune disorder. When it works. How do you keep it out of your heart. Not by coding it in a lipid nanoparticle. So, they had no way to deliver it safely to market. So then they had a pandemic, the emergency allowed them to do it. This technology, in my opinion, was at least 3 decades out from being usefully and safely deployed at all, if at all. They did not want to wait, this crisis gave them the opportunity not to wait. And now, they will blame the spike protein, we picked the wrong protein. When in actual fact there are 2 problems, the spike protein and the platform itself. - Brett Weinstein\n\n\nMyocarditis/Pericarditis\n\nDifferent virus vs vax myocarditis mechanisms isn’t just theory. Here’s why you’re correct in real life.\n\n\nTIMING\n\nVirus myocarditis As Offit said, SARS2 viral myocarditis most often manifests as post-viral myocarditis due to molecular mimicry.\n\nThis means a few to several weeks after covid infection (ie symptoms/viral load were already gone weeks or 1-2 months ago), there is Ab/T crossreactivity (mimicry) to self-antigens in heart cells.\nThis mechanism is most often mild, good prognosis.\nTo clarify, SARS2 viral fulminant myocarditis, which can occur in days to a week after covid infection, is very rare. Initial covid presentation with fulminant myocarditis is so rare and unusual, it’s a case report. Almost all SARS2 viral myocarditis is post-viral and mild.\n\nVax myocarditis Most often occurs days to 1 week after 2nd vax dose. Also occurs after 1st vax dose or booster.\n\nThis timing is atypical of mimicry. Rather, this timing is textbook for a primary or secondary direct immune cell attack on mRNA-transfected heart cells.\nOffit knows all this. He’s obviously pulling a “limited hangout”. Pfizer will copy what Offit says.\nIf politicians were honest, they’d ask if mechanisms are the same (mimicry) for both virus and vax myo, then why are the timing and severity distinctly different for virus vs vax myo?\n\n\nSerum Vax Spike\n\nCirculating Spike Protein Detected in Post–COVID-19 mRNA Vaccine Myocarditis\n\nThere’s a high correlation of vax spike found in serum (blood) of vax myocarditis. Vax controls showed no serum vax spike.\nImportantly, Ab/T immunoprofiling of vax myocarditis patients were indistinguishable from vax controls (ie no unusual autoantibodies or autoreactive T cells (no mimicry signs)).\nThis is more evidence that in vax myo, your immune cells are killing your own heart cells that look virus-infected.\nThere’s more vax myo mechanisms like inflammasome or apoptosis. But you said the main vax myo mechanism perfectly.”"
  },
  {
    "objectID": "library/life-sciences/biology/viruses/index.html#the-effect-of-mandatory-masks-on-autism-in-children",
    "href": "library/life-sciences/biology/viruses/index.html#the-effect-of-mandatory-masks-on-autism-in-children",
    "title": "Viruses",
    "section": "The Effect of Mandatory Masks on Autism in Children",
    "text": "The Effect of Mandatory Masks on Autism in Children\n\nBut hopefully, this [mask mandate in schools] will be a temporary thing, temporary enough that it [masks] doesn’t have any lasting negative impact on them [children]. - Anthony Fauci, August 9 2021\n\n\nRecognition of Faces: An Approach to the Study of Autism\n\nTwo age groups of normal, autistic and subnormal children were tested for their ability to recognize the faces of peers from isolated facial features and inverted photographs. The normal and subnormal subjects found the upper regions of the face most helpful for identification, whereas the younger autistic children found the lower features more helpful. The older autistic children showed no specific reliance on any one area, but were found to have error scores as low as those of the younger autistic children on the recognition of lower parts and error scores as low as the; controls on recognizing upper portions. The results are discussed and are found to favour a hypothesis in which the autistic child’s familiarity with the mouth and/or eye areas is related to a cognitive deficit which affects the processing of both verbal and non-verbal interpersonal communication.\n\nAmerican Academy of Pediatrics Poster, Highlighting the Importance of Facial Expressions for Children\n\nThey later were swallowed by the narrative, and made a public statement that in-school masks does not affect children (hypocritical)\n\nVisual Impairment: Its Effect on Cognitive Development and Behavior\nInfants Deploy Selective Attention to the Mouth of a Talking Face when Learning Speech\n\nThe mechanisms underlying the acquisition of speech-production ability in human infancy are not well understood. We tracked 4–12-mo-old English-learning infants’ and adults’ eye gaze while they watched and listened to a female reciting a monologue either in their native (English) or nonnative (Spanish) language. We found that infants shifted their attention from the eyes to the mouth between 4 and 8 mo of age regardless of language and then began a shift back to the eyes at 12 mo in response to native but not nonnative speech. We posit that the first shift enables infants to gain access to redundant audiovisual speech cues that enable them to learn their native speech forms and that the second shift reflects growing native-language expertise that frees them to shift attention to the eyes to gain access to social cues. On this account, 12-mo-old infants do not shift attention to the eyes when exposed to nonnative speech because increasing native-language expertise and perceptual narrowing make it more difficult to process nonnative speech and require them to continue to access redundant audiovisual cues. Overall, the current findings demonstrate that the development of speech production capacity relies on changes in selective audiovisual attention and that this depends critically on early experience.\n\nUnderstanding the Impact of Face Masks on the Processing of Facial Identity, Emotion, Age, and Gender\n\nThis is not even about children in particular, but illustrates how it may be detremential to young people in a learning phase\nAbstract Result: The results revealed that masks hindered the perception of virtually all tested facial dimensions (i.e., emotion, gender, age, and identity), interfering with normal speed and accuracy of categorization. We also found that the unwarranted effects of masks were not due to holistic processes, because the Face Inversion Effect (FIE) was generally not larger with unmasked compared with masked faces. Moreover, we found that the impact of masks is not automatic and that under some contexts observers can control at least part of their detrimental effects.\n\nFace masks reduce emotion-recognition accuracy and perceived closeness\n\nAgain, this was on adults, because you wouldn’t be able to publish your findings in 2021 if you exposed what it does to children\n\n\nIMPORTANT\n\nEmotion comprehension between 3 and 11 years: Developmental periods and hierarchical organization\nDarwin’s Contributions of our Understanding of Emotional Expressions\nInfants deploy selective attention to the mouth of a talking face when learning speech\nPotential Impact of the COVID-19 Pandemic on Communication and Language Skills in Children\nEffect of face mask and noise on word recognition by children and adults\n\nThis PDF was taken off the web! I am linking it through Wayback machine\n\nThe puzzle of Autism in the time of COVID-19 pandemic: “Light it up Blue”\n\n“… Barriers to essential services such as speech and occupational therapies, combined with loss of routine and predictability has widened the gap between needs and provided care. Parents, teachers and health care should aim to work collectively for a broadened approach that is child/parent centered to compensate for most of disrupted vital support and services”"
  },
  {
    "objectID": "library/life-sciences/health/autism/index.html",
    "href": "library/life-sciences/health/autism/index.html",
    "title": "Autism",
    "section": "",
    "text": "How environmental and genetic factors combine to cause autism: A redox/methylation hypothesis\nMycotoxins in the food chain: human health implications\nPublic Health Impacts of Foodborne Mycotoxins\nMold and Autism\n\n\n\n\nCase Study: Rapid Complete Recovery From An Autism Spectrum Disorder After Treatment of Aspergillus With The Antifungal Drugs Itraconazole And Sporanox\n\nA child with symptoms placing him in the Autism spectruma and with urine biochemical markers consistent with fungal colonization of the gastrointestinal tract was first reated with a antifungal probiotic.\nThe child’s physician (Baker) wished to try a more potent antifungal therapy, itraconazole, in an attempt to reverse the child’s autism since itraconazole is an especially effective agent against Aspergillus species.\nEscalation of the dose of itraconazole resulted in a complete loss of all symptoms of autism over the course of three months. This rapid complete reversal of autism is consistent with several articles proposing mold in general and Aspergillus specifically as a potential major cause of autism."
  },
  {
    "objectID": "library/life-sciences/health/autism/index.html#reads",
    "href": "library/life-sciences/health/autism/index.html#reads",
    "title": "Autism",
    "section": "",
    "text": "How environmental and genetic factors combine to cause autism: A redox/methylation hypothesis\nMycotoxins in the food chain: human health implications\nPublic Health Impacts of Foodborne Mycotoxins\nMold and Autism\n\n\n\n\nCase Study: Rapid Complete Recovery From An Autism Spectrum Disorder After Treatment of Aspergillus With The Antifungal Drugs Itraconazole And Sporanox\n\nA child with symptoms placing him in the Autism spectruma and with urine biochemical markers consistent with fungal colonization of the gastrointestinal tract was first reated with a antifungal probiotic.\nThe child’s physician (Baker) wished to try a more potent antifungal therapy, itraconazole, in an attempt to reverse the child’s autism since itraconazole is an especially effective agent against Aspergillus species.\nEscalation of the dose of itraconazole resulted in a complete loss of all symptoms of autism over the course of three months. This rapid complete reversal of autism is consistent with several articles proposing mold in general and Aspergillus specifically as a potential major cause of autism."
  },
  {
    "objectID": "library/natural-sciences/crypto/cex/coinbase/index.html",
    "href": "library/natural-sciences/crypto/cex/coinbase/index.html",
    "title": "Coinbase",
    "section": "",
    "text": "Coinbase receives regulatory approval to enable retail perpetual futures trading"
  },
  {
    "objectID": "library/natural-sciences/crypto/cex/coinbase/index.html#news",
    "href": "library/natural-sciences/crypto/cex/coinbase/index.html#news",
    "title": "Coinbase",
    "section": "",
    "text": "Coinbase receives regulatory approval to enable retail perpetual futures trading"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/avax/index.html",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/avax/index.html",
    "title": "Avalanche",
    "section": "",
    "text": "Avalanche Platform\nAvalanche blockchain protocol for distributed computing security\nTokenomics: Avalanche Native Token Dynamics\nA Classification Framework for Stablecoin Designs\n\n\n\n\nConsensus Mechanism: Scalable and Probabilistic Leaderless BFT Consensus through Metastability\nSnowflake to Avalanche: A Novel Metastable Consensus Protocol Family for Cryptocurrencies\n\n\n\n\n\nFirewood Repository\nFirewood MIT, Full EVM Compatible\nIntroducing Firewood: A Next-Generation Database Built for High-Throughput Blockchains\nDevelopment Roadmap"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/avax/index.html#resources",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/avax/index.html#resources",
    "title": "Avalanche",
    "section": "",
    "text": "Avalanche Platform\nAvalanche blockchain protocol for distributed computing security\nTokenomics: Avalanche Native Token Dynamics\nA Classification Framework for Stablecoin Designs\n\n\n\n\nConsensus Mechanism: Scalable and Probabilistic Leaderless BFT Consensus through Metastability\nSnowflake to Avalanche: A Novel Metastable Consensus Protocol Family for Cryptocurrencies\n\n\n\n\n\nFirewood Repository\nFirewood MIT, Full EVM Compatible\nIntroducing Firewood: A Next-Generation Database Built for High-Throughput Blockchains\nDevelopment Roadmap"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/zephyr/index.html",
    "href": "library/natural-sciences/crypto/blockchain/projects/zephyr/index.html",
    "title": "Zephyr",
    "section": "",
    "text": "Blog Announcement\nTwitter Account\nWebsite\nParent Co, Notebook Twitter Account\n\nExcerpt\nZephyr has built infrastructure, starting with Venmo email confirmations, to generate Zero-Knowledge proofs of the payment receipts and verify them on-chain. These provide mathematical proof of payments. Therefore, our smart-contract escrow can verify the payment and release the escrowed funds. Because Zephyr relies on Zero-Knowledge proofs, rather than a central entity, it is significantly more secure than traditional escrow service."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/zephyr/index.html#resources",
    "href": "library/natural-sciences/crypto/blockchain/projects/zephyr/index.html#resources",
    "title": "Zephyr",
    "section": "",
    "text": "Blog Announcement\nTwitter Account\nWebsite\nParent Co, Notebook Twitter Account\n\nExcerpt\nZephyr has built infrastructure, starting with Venmo email confirmations, to generate Zero-Knowledge proofs of the payment receipts and verify them on-chain. These provide mathematical proof of payments. Therefore, our smart-contract escrow can verify the payment and release the escrowed funds. Because Zephyr relies on Zero-Knowledge proofs, rather than a central entity, it is significantly more secure than traditional escrow service."
  },
  {
    "objectID": "library/natural-sciences/crypto/cryptography/fhe.html",
    "href": "library/natural-sciences/crypto/cryptography/fhe.html",
    "title": "FHE",
    "section": "",
    "text": "Reads\n\nFirst Ever Fully Homomorphic Encryption Scheme\nVitalik on FHE\n\nOriginal FHE innovation with bootstrapping (inefficient)\n\n2009, Fully homomorphic encryption using ideal lattices\n2010, Computing arbitrary functions of encrypted data\n\nEfficiency Improvements\n\n2019, TFHE: Fast Fully Homomorphic Encryption Over the Torus\n2021, Programmable Bootstrapping Enables Efficient Homomorphic Inference of Deep Neural Networks\n2023, TFHE Public-Key Encryption Revisited\n\nbased on a variant of Learning With Errors (LEW) problem, first introduced by Regev On lattices, learning with errors, random linear codes, and cryptography\n\n\n\n\nProjects\nZama\n\nwebsite\ndocumentation\ngithub\nZama Concrete: documentation\n\n\n\nfhEVM\n\nfhEVM\nTFHE.sol\nFhenix Blockchain\n\nRelated\n\nPractical and Efficient FHE-based MPC\nNoah’s Ark: Efficient Threshold-FHE Using Noise Flooding\n\n\nNotes\nThere is a global FHE key under which all inputs and private state are encrypted. This allows easy mixing of encrypted data across users and smart contracts. Private decryption key is a secret shared across the validators.\nProviding an encrypted input\nTo provide an encrypted input to a transaction or view function, users must submit two values. 1) encrypted input using the global public FHE key. 2) The associated valid zero-knolwedge proof of plaintext knowledge. These components form a ceritifed cyphertext.\nSolidity Library: TFHE\nOffers four types: euint8, euint16, euint32, ebool."
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/ton/index.html",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/ton/index.html",
    "title": "TON",
    "section": "",
    "text": "TON Whitepaper\nwebsite\nTON Virtual Machine Whitepaper\nTON Blockchain Whitepaper\nCatchain Consensus Whitepaper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/ton/index.html#resources",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/ton/index.html#resources",
    "title": "TON",
    "section": "",
    "text": "TON Whitepaper\nwebsite\nTON Virtual Machine Whitepaper\nTON Blockchain Whitepaper\nCatchain Consensus Whitepaper"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/alt-l1/ton/index.html#brief-history",
    "href": "library/natural-sciences/crypto/blockchain/alt-l1/ton/index.html#brief-history",
    "title": "TON",
    "section": "Brief History",
    "text": "Brief History\nFounder: Dr. Nikolai Durov"
  },
  {
    "objectID": "library/natural-sciences/crypto/cex/ftx/index.html",
    "href": "library/natural-sciences/crypto/cex/ftx/index.html",
    "title": "FTX",
    "section": "",
    "text": "United States District Court Southern District of New York: United States of America v. Samuel Bankman-Fried - Court Listener Docket Entries - Sealed Indictment\nAdderall Bet - polymarket - August 14, 2023 letter to request order to Metrpolitan Detention Center for provide client with prescribed medication - NYT says it’s unlikely SBF will get Adderall due to prior guidance against stimulants due to potential for misuse. - “clinical guidance” document on ADHD treament issued by the feds in december 2021\n\nStories from an Alameda Engineer\nAditya Baradwaj was an engineer at Alameda Research after graduating from Berkeley and working at Google. He tells stories about his time at FTX.\n\n\nStart from the Beginning\nAs an engineer at Alameda Research, I had my entire life savings stolen from me by my former boss: Sam Bankman-Fried. Now, after months of recuperation from the craziness of the FTX collapse, I’m ready to tell my story.\nLet’s start at the beginning:\nI still remember my first time meeting Sam - it was my first day of work at the office. I had just left my job at Google, and was excited to be working at this small, mysterious crypto trading firm. At the time, there had only been minor press coverage of Sam. Alameda/FTX were far from well-known even within tech circles. Heck, I only knew about the company because a bunch of early employees had also been students at Berkeley, and the news had spread to me through the grapevine.\nThe office itself was nondescript. Situated on the 4th floor of an ordinary-looking office building in downtown Berkeley, it was a place that I had walked by many times during college. The 4th floor tenant’s name on the directory was conspicuously empty, revealing only that they shared the building with names such as “Pacific Lutheran Theological Seminary”. Hardly the neighbors one would expect for a multi-billion-dollar crypto trading firm. When I entered the office SBF was sitting at his desk in the middle of the trading floor, taking a call while playing League, in characteristic fashion. And yes, that was Alameda’s trading floor…\nDespite the fact that on paper, Sam had already transitioned to running FTX full-time, in practice both companies were highly intertwined. Joint offices, social events, and housing arrangements between both companies was the norm. But more on that later. I’m not sure who he was talking to, but I caught fragments of their conversation from Sam’s end:\n\n“Decentralization is the future. The single most valuable thing you can do for yourself is to drop whatever you’re doing and get into crypto”\n\nThis was the first of many contradictions that I would see with Sam. On one hand, he would extoll the virtues of decentralized, permissionless finance to anyone who would listen. But a custodial, KYC’d derivatives exchange isn’t exactly a paragon of decentralization. Inside you there are two wolves, I guess… or something.\nLater that night we ordered Sliver Pizza and chatted over a game of bughouse - another favorite of Sam’s - and he revealed his plan to move the entire company to a tiny island in the Caribbean. I knew nothing about the Bahamas at the time. But as Sam spoke, it became clear that he had done his research.\n\n“Did you know that FTX’s revenue is greater than 10% of the Bahamas’ GDP?”\n\nI didn’t know, but a quick Google search revealed that he probably wasn’t far off. Sam’s vision for FTX, as he went on to explain, extended far beyond just a crypto exchange.\nHe talked about building a vaccine factory in the Bahamas to fix the invisible graveyard caused by slow FDA approvals. He discussed the strategizing that had gone into the political donations made by the FTX execs. He talked about hypothetical future technologies like iterated embryo selection, and the importance of not letting China get the lead in fundamental biotech research. And of course, he talked about malarial bednets and veganism too.\nHearing Sam unveil his vision for the future, it became clear that every action he had taken - Alameda, FTX, the Bahamas, policy proposals - was all part of a grand plan. He didn’t just want to build a company. He wanted to build a machine - a growing sphere of influence that could break past the walls of that little office in Berkeley and wash over the world as a force for good. Not just a company, but a monument to effective altruism.\nAs a starry-eyed new hire, it was hard not to get drawn in by the boldness of Sam’s vision. Many of us had joined the company precisely because we wanted to do good in the world. And here was a billionaire, not yet 30 years old, who was using his fortune to bankroll a radical new vision for the future. Not to mention, with his self-effacing and awkward demeanor, I suppose many of us saw a little bit of ourselves in him as well. Over the next year and a half, my life was transformed in ways I could never have imagined:\nI experienced opulence the likes of which I’d only seen before in movies. Got flown around the world on a regular basis between Berkeley, Hong Kong, and the Bahamas. Brushed elbows with celebrities, sports icons, and political figures.\nYet at the same time, I saw irresponsibility: Careless risk management for a company handling billions of dollars in capital. Technical debt that would make any software engineer shed a tear. Millions lost in wasteful spending, and the hubris that it wouldn’t matter.\nOf course, Sam didn’t end up building a vaccine factory or eradicating malaria. His customers, investors, and employees - the ones who trusted him most - are financially devastated. And the ruins of the half-built FTX headquarters lay strewn across the beaches of Nassau. Sam himself is behind bars at MDC, having violated the terms of his house arrest. Even after all this, it seems he is incapable of following the rules.\nOver the past months, I’ve seen a ton of speculation online about FTX and Alameda. Unfortunately, not all of it has been based in reality.\nWhat were Sam, Caroline, and the others like in person? Was it all just a scam? How was life in the Bahamas? People deserve to know. Unfortunately, the story of my time at FTX/Alameda is too complex to put in a single thread.\n\n\nThe Fat Finger\nThe story of how a misplaced decimal point at Alameda Research caused a market crash that echoed around the world.\nThis incident happened just a few weeks after I joined Alameda. I had just gotten a hang of our engineering workflows and was starting to wrap my head around our trading systems.At a high level, Alameda’s trading operated in two modes:\nThe main one was our semi-systematic strategies, where traders set model parameters that control a complex automated trading system. This way, traders aren’t placing actual trades, but rather fine-tuning an algorithm that decides how to execute those trades at high frequency.\nHowever every once in a while, a trader would need to manually execute a trade. Usually this might happen if our automated trading systems were being buggy due to market volatility, or if there was an arbitrage opportunity on a venue where we hadn’t set up automated trading yet.\nOur automated trading systems handled the vast majority of Alameda’s trading. So naturally, we had sanity checks in place to make sure that the orders being sent were reasonable relative to current market prices. Not so for manual trades, which were by nature discretionary.\nThe tricky thing about risk is that it’s usually invisible, right up until it comes around and bites you in the ass. Well, on October 21 2021, an Alameda trader’s finger slipped.\nThe trader was trying to sell a block of BTC in response to news, and sent out the order via our manual trading system. What they missed was the decimal point was off by a few spaces. Rather than selling BTC at the current market price, they sold it for pennies on the dollar.\nThe result was immediate. The price of BTC shot from a high of $65k to as low as $8k on some venues, only to be quickly restored by arbitrageurs. The sudden price movement lit crypto Twitter on fire as traders scrambled to figure out what was going on:\nNews outlets started picking up too. Binance US - which was the epicenter of the flash crash - released a statement claiming that it had been caused by one of their “institutional traders” who had a “bug in their trading algorithm”.\nI guess Caroline had made some phone calls.\nAlameda’s losses on the fat-finger trade were staggering - on the order of tens of millions. But because it had been an honest mistake, there wasn’t much to do except to implement additional sanity checks for manual trades. And that’s what we did.\nThat’s usually how things worked at Alameda - we would wait until something broke, and then rush to fix it. Which is why it took us so long to implement sanity checks that any “traditional” trading firm would have never started trading without.\nAfter that, it was back to business as usual. According to SBF, the utility we gained by moving fast outweighed the occasional costs we paid due to poor risk checks, hacks, and the like. This was SBF’s work philosophy, and it drove the culture he created at Alameda and FTX\nFor almost two years, the BTC flash crash incident has remained a mystery in the minds of the public. Now you know who was responsible, and what was happening behind the scenes."
  },
  {
    "objectID": "library/natural-sciences/crypto/cex/binance/index.html",
    "href": "library/natural-sciences/crypto/cex/binance/index.html",
    "title": "Binance",
    "section": "",
    "text": "Slow Train Wreck: Binance timeline since December 2022\nDecember\n\nBinance Experiences &gt;$10bn of Net Withdrawals; Temporarily Suspends Spot BNB Borrow; Temporarily Halts Withdrawals of ERC USDC; Is Said to Be on the Verge of Being Charged by DoJ\nBinance Proof of Reserves Auditor Mazar’s Pauses All Crypto Work, Removes Binance Attestation\nBinanceUS Temporarily Halts Withdrawals of USDT and USDC\n\nJanuary\n\nBinance Admits Stablecoin Pegged-BUSD Had &gt;$1bn Collateral Hole, Claims It Is Now Fixed\n\nFebruary\n\nNVDFS Investigating Paxos Over BUSD Stablecoin\nSEC Plans to Sue Paxos Over BUSD Stablecoin, Ordered to Stop Issuing BUSD\nCZ Announes an Orderly Wind Down of BUSD Trading Over Time\nCoinbase to Suspend BUSD Trading March 13th\nBinance Australia Closes Derivatives Trading on Some Accounts\nBinanceUS Found with Unexplained $400mm Transfer to CZ-controlled Entity\nBinance Loses Banking Partner, Suspends USD Bank Transfers\n\nMarch\n\nBinance and Changpeng Sued by CFTC Under Scathing Allegations\n\nApril\n\nBinanceUS Allowed by US Government to Continue with Acquisition of Voyager Digital, Then Backs Out of Acquisition\n\nMay\n\nBinance Withdraws from Canada Entirely\nReuters Claims Binance Comingled Customer Funds and Company Revenues in 2020 and 2021\nDoJ Investigating Whether Binance Violated US Sanctions Against Russia\nBinance Temporarily Halts BTC Withdrawals, Falsely Blaming Mempool Congestion\nBinanceUS Withdraws All Assets from Staking Pools, Prices Heavily Deviate from Other Exchanges as Exchange Liquidity Falters\nBinance Has Started Layoffs, Rumored to Be 20%\n\nJune\n\nSEC Sues Binance and Changpeng on 13 Charges with Incredibly Danning Evidence\nBloomberg Claims Changpeng May Step Down and Be Replaced by Richard Teng\nSEC Seeks Restraining Order to Freeze BinanceUS Assets; Judge Denies Restraining Order and Forces SEC and BinanceUS to Compromise on Securing Customer Assets\nBinance Under Investigation in France for Aggravated Money Laundering\nBinance Forced to Cease Operating in Netherlands\nBinance Forced to Cease Operating in Belgium\nBinance Moves 130,000 Bitcoin, Claims It’s a Cold Wallet Shuffle\nBinance and Changpeng Hire George Canellos, Former Chief of SEC Major Crimes Unit, As Criminal Defense Attorney\n\nJuly\n\nBinance doesn’t have Enough BCH to Process Withdrawals\nBinance General Counsel, Chief Strategy Officer and SVP of Compliance All Quit in Response to Changpeng Zhao’s Interactions with US Regulators\nBinance Moves $7.5bn of BNB, Claims to Be “Spreading Coins to More Addresses”\nBinance Withdraws License Application in Germany After It Was Set to Be Rejected Due to Changpeng Zhao\nBinance Lays Off &gt;1,000 Employees\nBinance Cuts Employee Benefits, Citing a Decline in Profits\n\nAugust\n\nBinance Shuts Down Crypto Payments Business\nMastercard Ends Card Partnership with Binance\nBinance’s Credit Card Processor Checkout.com Ends Services with Binance Due to AML Compliance Concerns\nWSJ Claims Binance Is Committing Massive US Sanctions Violations with Russian Banks\nBinance Head of APAC Quits\nBinanceUS Is Unable to Produce Financial Records for SEC\n\nSeptember\n\nBinance’s Head of Product Quits\nthe World’s Biggest Crypto Firm is Melting Down"
  },
  {
    "objectID": "library/natural-sciences/physics/entropy/index.html",
    "href": "library/natural-sciences/physics/entropy/index.html",
    "title": "Entropy",
    "section": "",
    "text": "Entropy measures disorder or uncertainty in a system. In thermodynamics, it quantifies the dispersion of energy among particles. In information theory, it gauges the amount of information contained in a message. In both cases, higher entropy means more randomness or unpredictability.\n\nClassical Thermodynamic Entropy (19th Century)\nThe most basic version of entropy is classical thermodynamic entropy, defined in the context of a macroscopic system. It’s given by the formula:\n\\[\n\\begin{aligned}\nS = k \\ln W\n\\end{aligned}\n\\]\nHere, \\((S)\\) is the entropy, \\((k)\\) is Boltzmann’s constant, and \\((W)\\) is the number of microscopic configurations that correspond to the macroscopic state. This concept originated in the 19th century to describe energy dispersion in thermodynamic systems.\n\nContext: Developed in the context of classical thermodynamics by Rudolf Clausius and Ludwig Boltzmann.\nPurpose: Quantify the dispersal of energy in macroscopic systems to understand heat engines and phase transitions.\nTimeline: 1850s-1870s\n\n\n\nStatistical Mechanics Entropy (Late 19th-Early 20th Century)\nStatistical Mechanics Entropy links the macroscopic behavior of a system to its microscopic states by using probabilities. It’s described by the Boltzmann-Gibbs entropy:\n\\[\n\\begin{aligned}\nS = -k \\sum_i p_i \\ln p_i\n\\end{aligned}\n\\]\n\nContext: Extended by Boltzmann, Josiah Willard Gibbs, and others.\nPurpose: Connect macroscopic thermodynamics to microscopic behavior.\nTimeline: 1870s-1900s\n\n\n\nShannon Entropy (20th Century)\nShannon entropy quantifies the amount of uncertainty or randomness in a random variable. Given a discrete probability distribution \\((p(x))\\), the Shannon entropy \\((H)\\) is defined as:\n\\[\n\\begin{aligned}\nH(X) = - \\sum_{i} p(x_i) \\log_2(p(x_i))\n\\end{aligned}\n\\]\nIt’s a foundational concept in information theory, often interpreted as the average number of bits needed to encode outcomes of \\((X)\\) optimally.\n\nContext: Developed by Claude Shannon in 1948 for information theory.\nPurpose: Measure information content, applicable to coding theory, data compression, and communication.\nTimeline: 1948\n\n\n\nVon Neumann Entropy (20th Century)\nVon Neumann entropy measures the degree of uncertainty or randomness in a quantum state. Given a density matrix \\((\\rho)\\), the von Neumann entropy \\((S)\\)is defined as:\n\\[\n\\begin{aligned}\nS(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)\n\\end{aligned}\n\\]\nIt generalizes classical Shannon entropy to quantum systems and is instrumental in quantum information theory.\n\nContext: Developed by John von Neumann in the early 1930s for quantum systems.\nPurpose: Generalize Shannon entropy to quantum mechanics.\nTimeline: 1932\n\n\n\nAlgebraic Entropy, Topological Entropy (20th Century)\n\nContext: Developed in pure mathematics to study dynamical systems.\nPurpose: Measure the complexity or chaos in mappings and flows.\nTimeline: Mid-20th century\n\n\n\nBekenstein-Hawking Entropy (20th Century)\nConcerns the thermodynamics of black holes. Defined as:\n\\[\n\\begin{aligned}\n\\begin{aligned}\nS_{\\text{BH}} = \\frac{A}{4\\hbar G}\n\\end{aligned}\n\\]\n\nContext: Developed by Jacob Bekenstein and Stephen Hawking in early 1970s.\nPurpose: Describe thermodynamics of black holes.\nTimeline: 1971-1974\n\n\n\nGeneralized Black Hole Entropy (Late 20th-21st Century)\nIncorporates quantum corrections to Bekenstein-Hawking entropy. Form:\n\\[\n\\begin{aligned}\n\\begin{aligned}\nS_{\\text{gen}} = \\frac{A}{4\\hbar G} + \\alpha \\ln \\left( \\frac{A}{4\\hbar G} \\right) + \\beta\n\\end{aligned}\n\\]\n\nContext: Developments in string theory, loop quantum gravity.\nPurpose: Quantum corrections to black hole thermodynamics.\nTimeline: 1990s-present\n\nEach form of entropy extends or adapts earlier concepts to new domains, reflecting evolving understanding of natural phenomena across scales."
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins/index.html",
    "href": "library/life-sciences/health/nutrition/vitamins/index.html",
    "title": "Vitamins",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins/index.html#my-opinionated-stack",
    "href": "library/life-sciences/health/nutrition/vitamins/index.html#my-opinionated-stack",
    "title": "Vitamins",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins/index.html#index",
    "href": "library/life-sciences/health/nutrition/vitamins/index.html#index",
    "title": "Vitamins",
    "section": "Index",
    "text": "Index\n\nVitamin D\nVitamin D is a fat-soluble vitamin essential for calcium absorption and bone health. It exists in two main forms: D2 (ergocalciferol) and D3 (cholecalciferol). D2 is primarily sourced from plants and fortified foods, while D3 is synthesized in the skin upon sun exposure and also obtained from animal-based foods. D3 is generally more effective at raising blood levels of vitamin D. Both forms are converted in the liver and kidneys to their active form, calcitriol.\n\nBenefits\nVitamin D facilitates calcium absorption in the gut, essential for maintaining bone health. It also plays roles in immune function, cell growth, and inflammation regulation.\nD2 and D3 are similar in function but differ in potency and duration. D3 is generally more effective in raising and maintaining serum 25(OH)D levels.\nVitamin D benefits: 1. Bone Health: Enhances calcium and phosphate absorption, reducing osteoporosis risk. 2. Immune System: Modulates innate and adaptive immune responses, possibly reducing susceptibility to infections. 3. Cellular Growth: Involved in cell differentiation, potentially reducing the risk of certain cancers. 4. Mood Regulation: Impacts serotonin levels, possibly affecting mood disorders like depression.\nInadequate vitamin D can lead to poor bone health, increased susceptibility to infections, and a range of chronic conditions. Proper intake or synthesis helps maintain physiological equilibrium across multiple systems.\n\n\nSunlight v. Oral\nSunlight exposure can produce variable amounts of vitamin D3, influenced by factors like skin type, sunscreen use, and clothing. In strong sunlight (UV index ~9), 15–30 minutes for fair-skinned individuals can produce around 10,000 to 20,000 IU of vitamin D3.\n\n\n\nMulti\nFor standard amounts of A, K, E, Iron, Zinc, etc\n\n\nD-3\n\n\nB-12\n\n\nMagnesium\n\n\nGlycine\n\n\nLion’s Mane\n\n\nBeet Root"
  },
  {
    "objectID": "library/life-sciences/health/nutrition/vitamins/index.html#vitamin-a",
    "href": "library/life-sciences/health/nutrition/vitamins/index.html#vitamin-a",
    "title": "Vitamins",
    "section": "Vitamin A",
    "text": "Vitamin A"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#notes",
    "href": "library/natural-sciences/crypto/blockchain/projects/hyperbolic/index.html#notes",
    "title": "Hyperbolic",
    "section": "Notes",
    "text": "Notes\nHyperbolic is a microservices platform, that attempts to acheieve a practical optimum between decentralization (censorhip-resistance) and performance (throughput, bandwidth).\nGoal: combine the best of blockchain and cloud computing\n\nContext and Motivation\n\nweb3 attempts to host the computation of all services on a decentralized platform backed by a ledger (blockchain)\nencoding each step of computation as a transaction is impractical\ncloud compute suffers from isolation, trust assumptions, and lack of interoperability\ncloud compute services vary in performance demand and fault tolerance, so naively applying blockchains is inefficient\nL2s and current blockchain innovations again introduce isolation between services\n\n\n\nOverview\n\nHyperbolic facilitates development and deployment of composable Decentralized Services (D-Services) that follow a new Invoke-Return-Combine (IRC) paradigm.\nD-services are hosted by a dynamic subset of nodes, which make tradeoffs between performance and fault tolerance, and follow a classic client-server model with server side fault tolerance.\nTo help developers build their D-Services, Hyperbolic will provide useful, basic D-services such as\n\nContent delivery network (CDN)\nVideo streaming (D-streaming)\nPublish-subscribe patterns (D-PubSub)\nBlockchain ledger (D-Ledger)\n\nAll services follow IRC model, and will allow an ecosystem of reusable modules.\n\nHyllo\nHyperbolic’s first-party messaging app: non-custodial, bound to cryptographic identities. Hyllo will serve as a portal to Hyperbolic, allowing end-users to seamlessly interact with D-Services.\n\n\nBolic: Self-Healing Network Fabric\nBolic is an internet scale subsystem that delivers arbitrary binary data from one crypto entity to another, designed with modularity from the ground up and with careful thoughts of abstraction. There is a necessary dissagregation of the following three aspects:\n\nNoiton of data transmission from one party to another should be as simple as an airdrop. Tag (encrypt) the message with recipient’s id and “drop” is to Bolic.\nThe actual transport, which could be backed by TCP/UDP/Websocket/SMS/emails, does not need to know the content of the data because it’s E2E encrypted.\nThe routing mechanism to balance resource cost, reliability, and performance, offering different tradeoffs and plans.\n\nBolic represents the web in web3, building on top of the existing internet - but there could also be other data carriers such as Tor-style privacy channels.\n\n\nP2P v. Cient-Server\nClient-server is seen in more centralized systems where servers have more authority oevr user’s data dn computation. However, it still has advantages over pure P2P (lower cost bandwidth).\nImagine a lareg, 100k-person, groupchat.\n\nClient-Server: Everyone talks to server, which sends only one message to each user.\nP2P: gossip protocol where each user sends to every other, massive duplication.\nMiddle-Ground: Group chat has 100 chat servers, where each of the 100k users talks to 60 servers at a time. 100 peers in network, high resistance to failure. Every user guaranteed to share &gt;= 20 servers with another user.\n\nThis resembled quorum intersections in consensus protocols that power PoS blockchains, but sending messages is easier than consensus. Overall effect: cost shrunk 1000x from 100k nodes to 100.\n\n\nD-Services\nAll connected participants in Hyperbolic are nodes. Most nodes will have their relay ability enabled, running Bolic which forwards encrypted data. In addition to relay, nodes can opt into one or more server roles of D-Services.\nServices are rendered by RPC-style invocations of methods offered by the service, whose responses get aggregated and deduplicated locally at each client.\nnotation\n\n\\(S\\): D-service\n\\(N_S\\): Nodes of service\n\\(i\\): Arbitrary client\n\\(Q_{Si} \\Subset N_S\\): Service-prescribed subset of servers\n\nThe Invoke-Return-Combine trip is as follows:\nInvoke: Each client \\(i \\in N_c\\) initiates an RPC call by signing a message \\(S.Invoke(i, method, nonce, input)\\) and sends it to all nodes in \\(Q_{Si}\\), where \\(nonce\\) is a per-invocation identifier to distinguish calls.\nReturn: Each server \\(u\\), upon receiving RPC call message, validates the message and returns its response by signing and sending \\(S.Return(i, method, nonce, input-hash, u, output_u)\\) back to client \\(i\\).\nCombine: Each client \\(i\\), upon receiving at least a threshold (constant \\(T_{Si} \\leq \\|Q_{Si}\\) predefined by the service for each client) of responses from servers:\n\\[\n\\begin{aligned}\nR_i = \\{ output_u : S.Return(i,method,none,input-hash,u,output_u), u \\in Q_{Si}\\}\n\\end{aligned}\n\\] where \\(\\|R_i\\| \\geq T_{Si}\\).\nIt computes the final output locally by a service-prescribed client part of D-Service logic: \\(output_i = S.Combine(R_i)\\). The D-service designer must ensure that as long as the number of collected responses \\(\\|R_i\\|\\) is not les than the threshold, the combined output is deterministic and consistent regardless of the number of responses.\nThe groupchat example can use \\(T_{Si} = 51, \\forall i \\in N_c\\) threshold and run \\(\\|N_S\\| = 100\\) servers.\nThis guarantees if at least 51×2−100 = 2 out of 20 servers to which any two clients connect render the service, the message could be passed over directly. Even if there is no non-faulty server in common between any two clients, the clients can still rely on each one of the 60 servers to transmit the message through the Bolic P2P network.\nD-Service paradigm offers the flexibility to engage “quorum-style” fault tolerance as in Proof-of-Stake consensus protocols, and also naturally fits the idea of “aggregation-style” of cryptography like threshold signatures.\n\n\nIncentivization Algorithms\nTo encourage active participation, they design a Proof-of-Relay scheme for Bolic network, and a Proof-of-Storage scheme for the D-CDN service.\nIn Proof-of-Relay, it’s impractical to require nodes to generate a proof and redeem a reward for each message. Instead, randomly select nodes as a verifiable starting point to conduct a “verifiable random walk” for connectivity in each epoch. Running the challenge epochs indefinitely provides network-wide coverage and incentivizes the network to stay healthy without stuttering the transmission.\nProof-of-Relay is built on the following components:\n\nblockchain: customized ledger to track epoch-related events and keep a record of rewards\nVRF: protocol allowing multiple parties to collaboratively generate verifiable random output\nrandomness beacon: service that regularly produces pseudo-random seeds for the VRF\nElliptic-Curve Diffie-Hellman: a key exchange protocol that allows two parties, each having an elliptic-curve public-private key pair to establish a shared secret over an insecure channel. It’s a variant of Diffie-Hellman using EC cryptography."
  },
  {
    "objectID": "library/natural-sciences/hard-tech/index.html",
    "href": "library/natural-sciences/hard-tech/index.html",
    "title": "Tech",
    "section": "",
    "text": "Rewind Pendant: A wearable device that captures everything you say and hear and then transcribes, encrypts, and stores is entirely locally on your phone. - website\nSilentio: A device that blocks all device recordings, using ultrasound to detect and block any microphone that tries to capture your voice. - NEC: Speaker Selective Cancellation via Neural Enhanced Ultrasound Shadowing"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#forums-and-such",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#forums-and-such",
    "title": "Ethereum",
    "section": "",
    "text": "Ethereum Research Forum\nEth R&D Discord\nFlashbots Collective Forum\nEthereum Youtube: Community calls and such"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#forums",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#forums",
    "title": "Ethereum",
    "section": "",
    "text": "Ethereum Research Forum\nEth R&D Discord\nFlashbots Collective Forum\nEthereum Youtube: Community calls and such"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/ethereum/index.html#research",
    "href": "library/natural-sciences/crypto/blockchain/ethereum/index.html#research",
    "title": "Ethereum",
    "section": "Research",
    "text": "Research\n\nBasics\n\nEth2Book: A lot of Good Info on Ethereum\nThe Hitchhiker’s Guide to Ethereum\nUpdated Ethereum Roadmap by Vitalik Buterin (EF)\nEthereum Data Structures\nSolidity Lang Docs\n\n\n\nGeneral\n\nIntent Based Architectures and Their Risks\nClient Bootnode Concerns\nCollecting Signatures for Faster Finality\nProof of Solvency\nState of Testnets\nVitalik: the roads not taken\nEndgame by Vitalik Buterin (EF)\nTime to Bribe: Measuring Block Construction Markets\nRetroactive Proposer Rewards by Caspar Schwarz-Schilling (RIG/EF)\nSingle Secret Leader Election Boneh et al. (2020)\nCurrent CrList Proposal by Francesco D’Amato\n\n\n\nConsensus\nConsensus Design\n\nEthereum Consensus Spec\nCasper the Friendly Finality Gadget\nCombining GHOST and Casper\n\nelopio’s annotations\n\nBeacon Chain Casper Mini-Spec\nzkCasper: SNARK based scheme for verifying the Ethereum’s Casper FFG consensus proofs\nEthereum Inactivity Leak\n\nConsensus Attacks\n\nTwo Attacks on Proof-of-Stake GHOST/Ethereum\nThree Attacks on Proof-of-Stake Ethereum\nBalancing Attack on Gasper\nMitigating Balancing Attacks on LMD GHOST\nDiscouragement Attacks\nVitalik Paper\nDiscouragement Attacks\n\n\n\nProof of Stake\n\n100 Days After the Merge\nWithdrawals after Shanghai\nOfficial Merge Announcement\nExploring Inequality in Proof of Stake by Barnabe Monnot (RIG/EF)\nWhat Happens After Finality in eth2 by Raul Jordan (Prysmatic)\nRocketpool Post-Merge research\n(Un-)Timeliness in PoS Ethereum by Caspar Schwarz-Schilling (RIG/EF)\n\n\n\nProposer Builder Separation\n\nMEV-Boost Plan\nProposer Boost Considerations by Caspar Schwarz-Schilling (RIG/EF)\nMEV-Boost in a Nutshell\nEthereum Builder API Specs\nMEV-Boost Relay API Specification V1\nPBS Censorship Resistance\nState of research: increasing censorship resistance of transactions under PBS\nPBS Censorship-Resistance Alternatives\nCurrent crList Proposal\nProposer/block builder separation-friendly fee market designs by Vitalik Buterin (EF)\nTwo-slot proposer/builder separation by Vitalik Buterin (EF)\nState of research: increasing censorship resistance of transactions under proposer/builder separation (PBS) by Vitalik Buterin (EF)\nPBS Censorship-Resistance Alternatives by Francesco D’Amato (EF)"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/tools.html",
    "href": "library/natural-sciences/crypto/blockchain/dev/tools.html",
    "title": "Dev Tools",
    "section": "",
    "text": "Useful Things\n\nSolidity Decompiler (interface)\nHeimdall-rs: An advanced EVM smart contract toolkit specializing in bytecode analysis\nWhatsABI\ngo-selfcompile\nscope-eth: Remix-like foundry VSCode plugin\narbiter: Simulation driven development via an EVM emulator\nEchidna: Fast smart contract fuzzer\nMedusa: Parrellizable fuzz testing through CLI or Go API\n\nCool Things\n\nMergeMock\nSimple Serialize: A serialization and merkleization standard created specifically for Ethereum consensus"
  },
  {
    "objectID": "library/natural-sciences/crypto/blockchain/dev/tools.html#evm",
    "href": "library/natural-sciences/crypto/blockchain/dev/tools.html#evm",
    "title": "Dev Tools",
    "section": "",
    "text": "Useful Things\n\nSolidity Decompiler (interface)\nHeimdall-rs: An advanced EVM smart contract toolkit specializing in bytecode analysis\nWhatsABI\ngo-selfcompile\nscope-eth: Remix-like foundry VSCode plugin\narbiter: Simulation driven development via an EVM emulator\nEchidna: Fast smart contract fuzzer\nMedusa: Parrellizable fuzz testing through CLI or Go API\n\nCool Things\n\nMergeMock\nSimple Serialize: A serialization and merkleization standard created specifically for Ethereum consensus"
  }
]